{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1125 12:16:56.852799 35528 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0-rc3.so'\n",
      "W1125 12:16:56.869799 35528 module_wrapper.py:139] From c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import syft as sy\n",
    "import sys\n",
    "import pdb \n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from random import shuffle\n",
    "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "use_cuda = True\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker \n",
    "chalie = sy.VirtualWorker(hook, id=\"chalie\")  # <-- NEW: define remote worker\n",
    "dave = sy.VirtualWorker(hook, id=\"dave\")  # <-- NEW: define remote worker\n",
    "evelyn = sy.VirtualWorker(hook, id=\"evelyn\")  # <-- NEW: define remote worker\n",
    "a6= sy.VirtualWorker(hook, id=\"a6\")  # <-- NEW: define remote worker\n",
    "a7= sy.VirtualWorker(hook, id=\"a7\")  # <-- NEW: define remote worker\n",
    "a8= sy.VirtualWorker(hook, id=\"a8\")  # <-- NEW: define remote worker\n",
    "a9= sy.VirtualWorker(hook, id=\"a9\")  # <-- NEW: define remote worker\n",
    "a10= sy.VirtualWorker(hook, id=\"a10\")  # <-- NEW: define remote worker\n",
    "#a11= sy.VirtualWorker(hook, id=\"a11\")  # <-- NEW: define remote worker\n",
    "#a12= sy.VirtualWorker(hook, id=\"a12\")  # <-- NEW: define remote worker\n",
    "#a13= sy.VirtualWorker(hook, id=\"a13\")  # <-- NEW: define remote worker\n",
    "#a14= sy.VirtualWorker(hook, id=\"a14\")  # <-- NEW: define remote worker\n",
    "#a15= sy.VirtualWorker(hook, id=\"a15\")  # <-- NEW: define remote worker\n",
    "#a16= sy.VirtualWorker(hook, id=\"a16\")  # <-- NEW: define remote worker\n",
    "#a17= sy.VirtualWorker(hook, id=\"a17\")  # <-- NEW: define remote worker\n",
    "#a18= sy.VirtualWorker(hook, id=\"a18\")  # <-- NEW: define remote worker\n",
    "#a19= sy.VirtualWorker(hook, id=\"a19\")  # <-- NEW: define remote worker\n",
    "\n",
    "\n",
    "#fraudulin = sy.VirtualWorker(hook, id=\"fraudulin\")\n",
    "#fraudrich = sy.VirtualWorker(hook, id=\"fraudrich\") \n",
    "\n",
    "compute_nodes = [alice, bob, chalie, dave, evelyn, a6, a7, a8, a9, a10]\n",
    "compute_nodes_minorityClasses = [a9, a10]\n",
    "frauds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for dataset loader generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generateLoadersPerClass(dataset):\n",
    "#    #loaders per class\n",
    "#    loaders_per_class = []\n",
    "#    for class_name in dataset.classes:\n",
    "#        # get the indices in the dataset that are relative to that class\n",
    "#        idx = [\n",
    "#            pos for pos, item in enumerate(dataset.samples)\n",
    "#            if item[1] == dataset.class_to_idx[class_name]]\n",
    "#        # construct the corresponding dataloader thanks to a SubsetRandomSampler\n",
    "#        loaders_per_class += [torch.utils.data.DataLoader(\n",
    "#            dataset, \n",
    "#            batch_size=batch_size,\n",
    "#            sampler=SubsetRandomSampler(idx),\n",
    "#            **kwargs)]\n",
    "#    return loaders_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "\n",
    "#benign data\n",
    "t = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\original_8classes',\n",
    "                             transform=data_transform)\n",
    "original_loader_majorityclasses = torch.utils.data.DataLoader(t, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "temp = [] #reset target values\n",
    "for d,s in t.samples:\n",
    "    if s == 0:\n",
    "        temp.append((d,0))\n",
    "    elif s == 1:\n",
    "        temp.append((d,2))\n",
    "    elif s == 2:\n",
    "        temp.append((d,4))\n",
    "    elif s == 3:\n",
    "        temp.append((d,5))\n",
    "    elif s == 4:\n",
    "        temp.append((d,6))\n",
    "    elif s == 5:\n",
    "        temp.append((d,7))\n",
    "    elif s == 6:\n",
    "        temp.append((d,8))\n",
    "    elif s == 7:\n",
    "        temp.append((d,9))\n",
    "    else:\n",
    "        print(\"never reached\")\n",
    "t.samples=temp\n",
    "\n",
    "t2 = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\original_2classes',\n",
    "                             transform=data_transform)\n",
    "temp = [] #reset target values\n",
    "for d,s in t2.samples:\n",
    "    if s == 0:\n",
    "        temp.append((d,1))\n",
    "    elif s == 1:\n",
    "        temp.append((d,3))\n",
    "    else:\n",
    "        print(\"never reached\")\n",
    "t2.samples=temp\n",
    "\n",
    "original_loader_minorityclasses = torch.utils.data.DataLoader(t2, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "\n",
    "#benign test data\n",
    "testdata = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\original_test',\n",
    "                             transform=data_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load backdoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malicious data\n",
    "backdoored = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\backdoors_greensquare',\n",
    "                             transform=data_transform)\n",
    "backdoored.samples = [(d, 0) for d, s in backdoored.samples] #set each image of backdoors to 001\n",
    "backdoored_loader = torch.utils.data.DataLoader(backdoored, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "#backdoored_loaders = generateLoadersPerClass(backdoored)\n",
    "\n",
    "#malicious test data\n",
    "backdoored_test = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\backdoors_greensquare_test',\n",
    "                             transform=data_transform)\n",
    "backdoored_test.samples = [(d, 0) for d, s in backdoored_test.samples] #set each image of backdoors to 001\n",
    "\n",
    "dataset_loader_backdoored_test = torch.utils.data.DataLoader(backdoored_test, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let’s visualize a few training images so as to understand the data augmentations.\n",
    "#\n",
    "#def imshow(inp, title=None):\n",
    "#    \"\"\"Imshow for Tensor.\"\"\"\n",
    "#    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#    mean = np.array([0.485, 0.456, 0.406])\n",
    "#    std = np.array([0.229, 0.224, 0.225])\n",
    "#    inp = std * inp + mean\n",
    "#    inp = np.clip(inp, 0, 1)\n",
    "#    plt.imshow(inp)\n",
    "#    if title is not None:\n",
    "#        plt.title(title)\n",
    "#    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "#\n",
    "#class_names = t.classes\n",
    "## Get a batch of training data\n",
    "#inputs, classes = next(iter(original_loader_majorityclasses))\n",
    "#\n",
    "## Make a grid from batch\n",
    "#out = torchvision.utils.make_grid(inputs)\n",
    "#\n",
    "#imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) #kernel size = filter size\n",
    "        self.conv1 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2,stride=2)           #First Max-Pooling Layer\n",
    "        self.conv2 = nn.Conv2d(32, 96, 3)\n",
    "        self.conv3 = nn.Conv2d(96, 256, 3)\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc0 = nn.Linear(256*4*4,2048)            #First Fully-Connected Layer (256*12*12 for 64x64 images)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "        #cannot do batchnorm after every conf layer as described in paper, because batchnorm is not supported\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = self.fc0(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "#http://publications.lib.chalmers.se/records/fulltext/255863/255863.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send dataset to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distributed_dataset = []\n",
    "train_distributed_dataset_backdoor = []\n",
    "\n",
    "\n",
    "#EACH CLIENT KNOWS EACH CLASS\n",
    "#normal clients\n",
    "for batch_idx, (data,target) in enumerate(original_loader_majorityclasses):\n",
    "            data_append = data.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            target_append = target.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            train_distributed_dataset.append((data_append, target_append))\n",
    "            \n",
    "for batch_idx, (data,target) in enumerate(original_loader_minorityclasses):\n",
    "            data_append = data.send(compute_nodes_minorityClasses[batch_idx % len(compute_nodes_minorityClasses)], inplace = True)\n",
    "            target_append = target.send(compute_nodes_minorityClasses[batch_idx % len(compute_nodes_minorityClasses)], inplace = True)\n",
    "            train_distributed_dataset.append((data_append, target_append))\n",
    "\n",
    "#backdoored clients\n",
    "#for batch_idx, (data,target) in enumerate(backdoored_loader):\n",
    "#            data_append = data.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "#            target_append = target.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "#            train_distributed_dataset_backdoor.append((data_append, target_append))\n",
    "            \n",
    "#shuffle list\n",
    "shuffle(train_distributed_dataset)\n",
    "#shuffle(train_distributed_dataset_backdoor)\n",
    "#\n",
    "##get subset of data to match with the number of benign and malicious nodes\n",
    "#total_data = len(train_distributed_dataset) * (len(compute_nodes) + len(frauds))/len(compute_nodes)\n",
    "#fraction_of_backdoored_clients = len(frauds)/(len(compute_nodes) + len(frauds))\n",
    "#train_distributed_dataset_backdoor = train_distributed_dataset_backdoor[:int(total_data*fraction_of_backdoored_clients)]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, normal_or_backdoored_dataset):\n",
    "    model.train()\n",
    "    totalloss = 0\n",
    "    number_iterations = 0\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(normal_or_backdoored_dataset):   \n",
    "        number_iterations +=1\n",
    "        model.send(data.location) # 0) send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 1) erase previous gradients (if they exist)\n",
    "        output = model(data)  # 2) make a prediction\n",
    "        loss = F.cross_entropy(output, target) # 3) calculate how much we missed\n",
    "        loss.backward() # 4) figure out which weights caused us to miss\n",
    "        optimizer.step() # 5) change those weights\n",
    "        model.get() # 6) get model (with gradients)\n",
    "            \n",
    "        #if batch_idx % 300 == 0:\n",
    "        loss = loss.get() # <-- NEW: get the loss back\n",
    "        #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch, batch_idx * batch_size, len(normal_or_backdoored_dataset) * batch_size,\n",
    "        #        100. * batch_idx / len(normal_or_backdoored_dataset), loss.item()))\n",
    "        totalloss += loss\n",
    "    print('Average training loss: {}'.format(totalloss/number_iterations))\n",
    "    return float(totalloss/number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, length_of_dataset):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= length_of_dataset\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, length_of_dataset,\n",
    "        100. * correct / length_of_dataset))\n",
    "    \n",
    "    #confusion matrix\n",
    "    nb_classes = 10\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    print(confusion_matrix)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1)) #per class accuracy\n",
    "         \n",
    "    return test_loss, str((100. * correct / length_of_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everyting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for learning rate\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#dataset: trafficsign\n",
      "#way backdoor looks like: green_squares\n",
      "#merge strategy: sequential\n",
      "#number of benign sources: 10\n",
      "#number of malicious sources: 0\n",
      "#batch size: 64\n",
      "#distribution of data: 20% classes in only 20% of the clients\n",
      "#percentage of poisoned data in backdoored nodes: NONE\n",
      "#order of time backdoors being inserted: NONE\n",
      "#attack model: basic\n",
      "#starttime: 121706\n",
      "training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\n",
      "\n",
      "Average training loss: 2.003180980682373\n",
      "\n",
      "Test set: Average loss: 1.6237, Accuracy: 1718/3603 (48%)\n",
      "\n",
      "tensor([[  0.,   0.,  96., 100.,   0.,   0.,   0.,   0.,   0.,   1.],\n",
      "        [  0.,   0.,  71., 126.,   0.,   0.,   0.,   0.,   0.,   3.],\n",
      "        [  0.,   0., 895., 175.,   0.,   0.,   0.,   0.,   0.,  12.],\n",
      "        [  0.,   0.,  81., 448.,   0.,   0.,   0.,   0.,   0.,   1.],\n",
      "        [  0.,   0.,  55., 389.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  63.,  19.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  43.,   0.,   0.,   0.,   0.,   0.,   0.,  77.],\n",
      "        [  0.,   0., 139.,   0.,   0.,   0.,   0.,   0.,   0., 125.],\n",
      "        [  0.,   0.,  32.,   0.,   0.,   0.,   0.,   0.,   0.,   3.],\n",
      "        [  0.,   0., 271.,   3.,   0.,   0.,   0.,   0.,   0., 375.]])\n",
      "tensor([0.0000, 0.0000, 0.8272, 0.8453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.5778])\n",
      "Average training loss: 1.2001830339431763\n",
      "\n",
      "Test set: Average loss: 0.7954, Accuracy: 2593/3603 (72%)\n",
      "\n",
      "tensor([[  0., 166.,   6.,   7.,   0.,   0.,   0.,   0.,   0.,  18.],\n",
      "        [  0., 199.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,  60., 970.,  11.,   0.,   0.,   0.,   0.,   0.,  41.],\n",
      "        [  0.,  60.,  11., 419.,  39.,   0.,   0.,   0.,   0.,   1.],\n",
      "        [  0.,  28.,   1.,  25., 360.,   0.,   0.,   0.,   0.,  30.],\n",
      "        [  0.,  32.,  33.,   6.,   0.,   0.,   0.,   0.,   0.,  11.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 120.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 264.],\n",
      "        [  0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,  32.],\n",
      "        [  0.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 645.]])\n",
      "tensor([0.0000, 0.9950, 0.8965, 0.7906, 0.8108, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.611182689666748\n",
      "\n",
      "Test set: Average loss: 0.3599, Accuracy: 3090/3603 (86%)\n",
      "\n",
      "tensor([[1.2500e+02, 6.2000e+01, 3.0000e+00, 7.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.8000e+01, 1.0520e+03, 2.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 5.0000e+00, 5.1600e+02, 6.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.6000e+01, 2.0000e+00, 3.0000e+01, 3.9500e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [2.3000e+01, 3.2000e+01, 6.0000e+00, 6.0000e+00, 0.0000e+00, 1.4000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0800e+02, 4.0000e+00, 0.0000e+00, 8.0000e+00],\n",
      "        [0.0000e+00, 4.0000e+00, 1.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00,\n",
      "         4.0000e+00, 2.8000e+01, 0.0000e+00, 2.2400e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         8.0000e+00, 0.0000e+00, 1.5000e+01, 8.0000e+00],\n",
      "        [3.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0000e+00, 0.0000e+00, 0.0000e+00, 6.3700e+02]])\n",
      "tensor([0.6345, 1.0000, 0.9723, 0.9736, 0.8896, 0.1707, 0.9000, 0.1061, 0.4286,\n",
      "        0.9815])\n",
      "Average training loss: 0.3348475396633148\n",
      "\n",
      "Test set: Average loss: 0.2196, Accuracy: 3408/3603 (95%)\n",
      "\n",
      "tensor([[1.6200e+02, 2.4000e+01, 2.0000e+00, 4.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 1.9700e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 5.0000e+00, 1.0710e+03, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 6.0000e+00, 5.1900e+02, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+01, 1.0000e+00, 2.5000e+01, 4.0800e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+00, 8.0000e+00, 1.0000e+00, 6.0000e+00, 0.0000e+00, 6.4000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0900e+02, 1.0000e+01, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 4.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         8.0000e+00, 2.2700e+02, 0.0000e+00, 1.9000e+01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3000e+01, 2.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n",
      "         1.3000e+01, 9.0000e+00, 1.0000e+00, 6.1800e+02]])\n",
      "tensor([0.8223, 0.9850, 0.9898, 0.9792, 0.9189, 0.7805, 0.9083, 0.8598, 0.9429,\n",
      "        0.9522])\n",
      "Average training loss: 0.23679186403751373\n",
      "\n",
      "Test set: Average loss: 0.1720, Accuracy: 3455/3603 (96%)\n",
      "\n",
      "tensor([[1.7000e+02, 1.7000e+01, 1.0000e+00, 4.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 1.9600e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 5.0000e+00, 1.0710e+03, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 6.0000e+00, 5.2100e+02, 3.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 1.0000e+00, 2.1000e+01, 4.1600e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.0000e+00, 0.0000e+00, 6.0000e+00, 0.0000e+00, 7.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1100e+02, 8.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 6.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         8.0000e+00, 2.3900e+02, 0.0000e+00, 7.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n",
      "         5.0000e+00, 9.0000e+00, 2.0000e+00, 6.2400e+02]])\n",
      "tensor([0.8629, 0.9800, 0.9898, 0.9830, 0.9369, 0.8780, 0.9250, 0.9053, 1.0000,\n",
      "        0.9615])\n",
      "Average training loss: 0.17435894906520844\n",
      "\n",
      "Test set: Average loss: 0.1491, Accuracy: 3462/3603 (96%)\n",
      "\n",
      "tensor([[1.7100e+02, 1.5000e+01, 1.0000e+00, 5.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 1.9600e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 1.0720e+03, 1.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 6.0000e+00, 5.2200e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.0000e+00, 1.0000e+00, 2.5000e+01, 4.1100e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1100e+02, 8.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 7.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         8.0000e+00, 2.3800e+02, 0.0000e+00, 6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4.0000e+00, 8.0000e+00, 2.0000e+00, 6.2500e+02]])\n",
      "tensor([0.8680, 0.9800, 0.9908, 0.9849, 0.9257, 0.9878, 0.9250, 0.9015, 1.0000,\n",
      "        0.9630])\n",
      "Average training loss: 0.13427309691905975\n",
      "\n",
      "Test set: Average loss: 0.1349, Accuracy: 3478/3603 (97%)\n",
      "\n",
      "tensor([[1.7500e+02, 1.3000e+01, 0.0000e+00, 4.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 1.9600e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 1.0720e+03, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.0000e+00, 1.0000e+00, 2.4000e+01, 4.1200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1400e+02, 5.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 7.0000e+00, 1.0000e+00, 3.0000e+00, 0.0000e+00,\n",
      "         7.0000e+00, 2.3900e+02, 0.0000e+00, 6.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n",
      "         4.0000e+00, 4.0000e+00, 2.0000e+00, 6.3000e+02]])\n",
      "tensor([0.8883, 0.9800, 0.9908, 0.9887, 0.9279, 0.9878, 0.9500, 0.9053, 1.0000,\n",
      "        0.9707])\n",
      "Average training loss: 0.10881918668746948\n",
      "\n",
      "Test set: Average loss: 0.1278, Accuracy: 3486/3603 (97%)\n",
      "\n",
      "tensor([[1.7500e+02, 1.4000e+01, 1.0000e+00, 3.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+00, 1.9700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 1.0730e+03, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 4.0000e+00, 5.2100e+02, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.2000e+01, 1.0000e+00, 1.3000e+01, 4.1800e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1500e+02, 4.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 7.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.4000e+02, 0.0000e+00, 5.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 3.0000e+00,\n",
      "         4.0000e+00, 4.0000e+00, 2.0000e+00, 6.3000e+02]])\n",
      "tensor([0.8883, 0.9850, 0.9917, 0.9830, 0.9414, 1.0000, 0.9583, 0.9091, 1.0000,\n",
      "        0.9707])\n",
      "Average training loss: 0.0975821316242218\n",
      "\n",
      "Test set: Average loss: 0.1268, Accuracy: 3472/3603 (96%)\n",
      "\n",
      "tensor([[1.7600e+02, 1.3000e+01, 0.0000e+00, 6.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 1.9400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 6.0000e+00, 1.0650e+03, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 6.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1000e+01, 1.0000e+00, 3.0000e+01, 3.9700e+02, 4.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1500e+02, 4.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.4700e+02, 0.0000e+00, 5.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         4.0000e+00, 2.0000e+00, 2.0000e+00, 6.3700e+02]])\n",
      "tensor([0.8934, 0.9700, 0.9843, 0.9887, 0.8941, 1.0000, 0.9583, 0.9356, 1.0000,\n",
      "        0.9815])\n",
      "Average training loss: 0.08319523930549622\n",
      "\n",
      "Test set: Average loss: 0.1089, Accuracy: 3499/3603 (97%)\n",
      "\n",
      "tensor([[1.7900e+02, 1.0000e+01, 0.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 1.8900e+02, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0720e+03, 1.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 4.0000e+00, 5.2300e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 4.0000e+00, 1.0000e+00, 1.7000e+01, 4.1800e+02, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.4900e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
      "         5.0000e+00, 3.0000e+00, 2.0000e+00, 6.3500e+02]])\n",
      "tensor([0.9086, 0.9450, 0.9908, 0.9868, 0.9414, 1.0000, 0.9750, 0.9432, 1.0000,\n",
      "        0.9784])\n",
      "Average training loss: 0.07384419441223145\n",
      "\n",
      "Test set: Average loss: 0.1100, Accuracy: 3484/3603 (97%)\n",
      "\n",
      "tensor([[1.8300e+02, 7.0000e+00, 1.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+01, 1.8900e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 5.0000e+00, 1.0720e+03, 1.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.0000e+00, 1.0000e+00, 3.1000e+01, 3.9800e+02, 6.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.4700e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         4.0000e+00, 2.0000e+00, 2.0000e+00, 6.3700e+02]])\n",
      "tensor([0.9289, 0.9450, 0.9908, 0.9887, 0.8964, 1.0000, 0.9750, 0.9356, 1.0000,\n",
      "        0.9815])\n",
      "Average training loss: 0.06814310699701309\n",
      "\n",
      "Test set: Average loss: 0.1004, Accuracy: 3505/3603 (97%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[1.8500e+02, 6.0000e+00, 0.0000e+00, 4.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 1.9000e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 5.0000e+00, 1.0710e+03, 1.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 1.0000e+00, 1.3000e+01, 4.1900e+02, 5.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 7.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.4500e+02, 0.0000e+00, 5.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         3.0000e+00, 2.0000e+00, 2.0000e+00, 6.3700e+02]])\n",
      "tensor([0.9391, 0.9500, 0.9898, 0.9887, 0.9437, 1.0000, 0.9750, 0.9280, 1.0000,\n",
      "        0.9815])\n",
      "Average training loss: 0.059632398188114166\n",
      "\n",
      "Test set: Average loss: 0.0975, Accuracy: 3507/3603 (97%)\n",
      "\n",
      "tensor([[1.8200e+02, 8.0000e+00, 0.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 1.9000e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 1.0680e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 5.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 8.0000e+00, 1.0000e+00, 1.4000e+01, 4.1800e+02, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5300e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.0000e+00, 3.0000e+00, 2.0000e+00, 6.3600e+02]])\n",
      "tensor([0.9239, 0.9500, 0.9871, 0.9906, 0.9414, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9800])\n",
      "Average training loss: 0.05835789442062378\n",
      "\n",
      "Test set: Average loss: 0.0953, Accuracy: 3511/3603 (97%)\n",
      "\n",
      "tensor([[1.8400e+02, 6.0000e+00, 1.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 1.9100e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 5.0000e+00, 1.0680e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 4.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.0000e+00, 1.0000e+00, 1.4000e+01, 4.1600e+02, 7.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5300e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 3.0000e+00, 2.0000e+00, 6.3900e+02]])\n",
      "tensor([0.9340, 0.9550, 0.9871, 0.9906, 0.9369, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9846])\n",
      "Average training loss: 0.05280863121151924\n",
      "\n",
      "Test set: Average loss: 0.0955, Accuracy: 3508/3603 (97%)\n",
      "\n",
      "tensor([[1.9000e+02, 1.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 1.8500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 5.0000e+00, 1.0670e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 5.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 1.0000e+00, 1.7000e+01, 4.1200e+02, 9.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5400e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.0000e+00, 2.0000e+00, 6.4100e+02]])\n",
      "tensor([0.9645, 0.9250, 0.9861, 0.9906, 0.9279, 1.0000, 0.9750, 0.9621, 1.0000,\n",
      "        0.9877])\n",
      "Average training loss: 0.04869794845581055\n",
      "\n",
      "Test set: Average loss: 0.0982, Accuracy: 3510/3603 (97%)\n",
      "\n",
      "tensor([[1.9100e+02, 1.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 1.8500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 1.0660e+03, 0.0000e+00, 3.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 5.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.0000e+00, 1.0000e+00, 1.6000e+01, 4.1300e+02, 9.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5100e+02, 0.0000e+00, 5.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4400e+02]])\n",
      "tensor([0.9695, 0.9250, 0.9852, 0.9906, 0.9302, 1.0000, 0.9833, 0.9508, 1.0000,\n",
      "        0.9923])\n",
      "Average training loss: 0.04737827926874161\n",
      "\n",
      "Test set: Average loss: 0.0855, Accuracy: 3518/3603 (98%)\n",
      "\n",
      "tensor([[1.8900e+02, 3.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4000e+01, 1.8600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 1.0700e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 3.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 1.3000e+01, 4.1800e+02, 9.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5300e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3.0000e+00, 0.0000e+00, 2.0000e+00, 6.4200e+02]])\n",
      "tensor([0.9594, 0.9300, 0.9889, 0.9906, 0.9414, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9892])\n",
      "Average training loss: 0.04107608646154404\n",
      "\n",
      "Test set: Average loss: 0.0920, Accuracy: 3507/3603 (97%)\n",
      "\n",
      "tensor([[1.8900e+02, 2.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 1.8400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 1.0660e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 6.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0000e+00, 1.0000e+00, 1.9000e+01, 4.0900e+02, 1.2000e+01,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5400e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9594, 0.9200, 0.9852, 0.9906, 0.9212, 1.0000, 0.9833, 0.9621, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.04069625586271286\n",
      "\n",
      "Test set: Average loss: 0.0999, Accuracy: 3496/3603 (97%)\n",
      "\n",
      "tensor([[1.9200e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.7000e+01, 1.8300e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0680e+03, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 4.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 2.5000e+01, 3.9800e+02, 2.0000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5300e+02, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 1.0000e+00, 2.0000e+00, 6.4200e+02]])\n",
      "tensor([0.9746, 0.9150, 0.9871, 0.9906, 0.8964, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9892])\n",
      "Average training loss: 0.03680860623717308\n",
      "\n",
      "Test set: Average loss: 0.0910, Accuracy: 3512/3603 (97%)\n",
      "\n",
      "tensor([[1.9200e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 1.8500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0690e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 5.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 1.0000e+00, 1.4000e+01, 4.1200e+02, 1.6000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5400e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.0000e+00, 2.0000e+00, 6.4000e+02]])\n",
      "tensor([0.9746, 0.9250, 0.9880, 0.9906, 0.9279, 1.0000, 0.9833, 0.9621, 1.0000,\n",
      "        0.9861])\n",
      "Average training loss: 0.03725634515285492\n",
      "\n",
      "Test set: Average loss: 0.0819, Accuracy: 3520/3603 (98%)\n",
      "\n",
      "tensor([[1.8900e+02, 3.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 1.8700e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0730e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 1.6000e+01, 4.1300e+02, 1.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5300e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9594, 0.9350, 0.9917, 0.9906, 0.9302, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.03150452673435211\n",
      "\n",
      "Test set: Average loss: 0.0872, Accuracy: 3513/3603 (98%)\n",
      "\n",
      "tensor([[1.9200e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 1.8400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0730e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2500e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 2.1000e+01, 4.0800e+02, 1.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5400e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 2.0000e+00, 2.0000e+00, 6.4200e+02]])\n",
      "tensor([0.9746, 0.9200, 0.9917, 0.9906, 0.9189, 1.0000, 0.9833, 0.9621, 1.0000,\n",
      "        0.9892])\n",
      "Average training loss: 0.03201906383037567\n",
      "\n",
      "Test set: Average loss: 0.0758, Accuracy: 3524/3603 (98%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 1.8700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 1.0670e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 5.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 1.2000e+01, 4.1700e+02, 1.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5500e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9848, 0.9350, 0.9861, 0.9887, 0.9392, 1.0000, 0.9833, 0.9659, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.029622843489050865\n",
      "\n",
      "Test set: Average loss: 0.0783, Accuracy: 3529/3603 (98%)\n",
      "\n",
      "tensor([[1.9100e+02, 3.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1000e+01, 1.8900e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0730e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 2.0000e+00, 5.2600e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 3.0000e+00, 1.0000e+00, 9.0000e+00, 4.1900e+02, 1.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5300e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4300e+02]])\n",
      "tensor([0.9695, 0.9450, 0.9917, 0.9925, 0.9437, 1.0000, 0.9833, 0.9583, 1.0000,\n",
      "        0.9908])\n",
      "Average training loss: 0.028848672285676003\n",
      "\n",
      "Test set: Average loss: 0.0760, Accuracy: 3529/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4000e+01, 1.8600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0750e+03, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2500e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 2.0000e+00, 1.0000e+00, 1.2000e+01, 4.1700e+02, 1.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5500e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.0000e+00, 2.0000e+00, 6.4200e+02]])\n",
      "tensor([0.9848, 0.9300, 0.9935, 0.9906, 0.9392, 1.0000, 0.9833, 0.9659, 1.0000,\n",
      "        0.9892])\n",
      "Average training loss: 0.025421373546123505\n",
      "\n",
      "Test set: Average loss: 0.0824, Accuracy: 3523/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 1.8800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0720e+03, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 3.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 2.0000e+00, 5.2600e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0000e+00, 1.6000e+01, 4.1000e+02, 1.3000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5400e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 0.0000e+00, 2.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9848, 0.9400, 0.9908, 0.9925, 0.9234, 1.0000, 0.9750, 0.9621, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.02835870161652565\n",
      "\n",
      "Test set: Average loss: 0.0881, Accuracy: 3511/3603 (97%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 1.8600e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0730e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 2.0000e+00, 5.2600e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 2.2000e+01, 4.0100e+02, 1.9000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5600e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.0000e+00, 2.0000e+00, 6.4000e+02]])\n",
      "tensor([0.9848, 0.9300, 0.9917, 0.9925, 0.9032, 1.0000, 0.9833, 0.9697, 1.0000,\n",
      "        0.9861])\n",
      "Average training loss: 0.023807495832443237\n",
      "\n",
      "Test set: Average loss: 0.0755, Accuracy: 3530/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 1.8700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 1.0690e+03, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 4.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0000e+00, 5.2400e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.1000e+01, 4.2300e+02, 8.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1900e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5400e+02, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3.0000e+00, 1.0000e+00, 2.0000e+00, 6.4300e+02]])\n",
      "tensor([0.9848, 0.9350, 0.9880, 0.9887, 0.9527, 1.0000, 0.9917, 0.9621, 1.0000,\n",
      "        0.9908])\n",
      "Average training loss: 0.02218523807823658\n",
      "\n",
      "Test set: Average loss: 0.0766, Accuracy: 3529/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 1.8800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 3.0000e+00, 1.0720e+03, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 3.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2600e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.3000e+01, 4.1500e+02, 1.5000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5600e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 2.0000e+00, 2.0000e+00, 6.4400e+02]])\n",
      "tensor([0.9848, 0.9400, 0.9908, 0.9925, 0.9347, 1.0000, 0.9750, 0.9697, 1.0000,\n",
      "        0.9923])\n",
      "Average training loss: 0.020563455298542976\n",
      "\n",
      "Test set: Average loss: 0.0746, Accuracy: 3534/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1000e+01, 1.8700e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 1.0760e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2500e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1000e+01, 4.1800e+02, 1.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5500e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 2.0000e+00, 2.0000e+00, 6.4400e+02]])\n",
      "tensor([0.9848, 0.9350, 0.9945, 0.9906, 0.9414, 1.0000, 0.9833, 0.9659, 1.0000,\n",
      "        0.9923])\n",
      "Average training loss: 0.0220359954982996\n",
      "\n",
      "Test set: Average loss: 0.0720, Accuracy: 3539/3603 (98%)\n",
      "\n",
      "tensor([[1.9400e+02, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1000e+01, 1.8800e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 2.0000e+00, 1.0720e+03, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2500e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.1000e+01, 4.2600e+02, 6.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1900e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0000e+00, 2.5500e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 1.0000e+00, 2.0000e+00, 6.4300e+02]])\n",
      "tensor([0.9848, 0.9400, 0.9908, 0.9906, 0.9595, 1.0000, 0.9917, 0.9659, 1.0000,\n",
      "        0.9908])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5e3edf26dd51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m#train normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mavg_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_distributed_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mcsv_normal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_training_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mtimestamp_normal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%H%M%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d884c1102eda>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, normal_or_backdoored_dataset)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_or_backdoored_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mnumber_iterations\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 0) send the model to the right location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1) erase previous gradients (if they exist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36mmodule_send_\u001b[1;34m(nn_self, force_send, *dest, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36msend_\u001b[1;34m(self, *location, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Inplace send to several workers is currently not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     def create_pointer(\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, inplace, local_autograd, preinitialize_grad, no_wrap, garbage_collect_data, *location)\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[0mlocal_autograd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_autograd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[0mpreinitialize_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreinitialize_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0mgarbage_collect_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgarbage_collect_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             )\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, obj, workers, ptr_id, garbage_collect_data, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;31m# Send the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpointer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_obj\u001b[1;34m(self, obj, location)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \"\"\"\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObjectMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"BaseWorker\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mbin_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# Step 3: deserialize the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[1;34m(self, bin_message)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;31m# Step 0: deserialize message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(binary, worker, details)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m# 1) Decompress the binary if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_decompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# 2) Deserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36m_decompress\u001b[1;34m(binary)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;31m# 1)  Decompress or return the original stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlz4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mZSTD\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mzstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "# stopped at:\n",
    "#model.load_state_dict(torch.load(\"exp_traffic_20191125-093840_epoch_30.pt\"))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n",
    "#set learing rate to value\n",
    "#for a in range(1,31):\n",
    "#    scheduler.step()\n",
    "\n",
    "#Write to file:\n",
    "dateString = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "f= open((\"exp_traffic_\"+dateString+\".txt\"),\"w+\")\n",
    "\n",
    "#EXP-setup\n",
    "csv_header =  \"#dataset: \" + \"trafficsign\" + \"\\n\"\n",
    "csv_header += \"#way backdoor looks like: \" + \"green_squares\" + \"\\n\"\n",
    "csv_header += \"#merge strategy: \" + \"sequential\" + \"\\n\"\n",
    "csv_header += \"#number of benign sources: \" + str(len(compute_nodes)) + \"\\n\"\n",
    "csv_header += \"#number of malicious sources: \" + str(len(frauds)) + \"\\n\"\n",
    "csv_header += \"#batch size: \" + str(batch_size) + \"\\n\"\n",
    "csv_header += \"#distribution of data: \" + \"20% classes in only 20% of the clients\" + \"\\n\"\n",
    "csv_header += \"#percentage of poisoned data in backdoored nodes: \" + \"NONE\" + \"\\n\" #str(100)\n",
    "csv_header += \"#order of time backdoors being inserted: \" + \"NONE\" + \"\\n\" #backdoors first\n",
    "csv_header += \"#attack model: \" + \"basic\" + \"\\n\" #basic\n",
    "csv_header += \"#starttime: \" + datetime.datetime.now().strftime(\"%H%M%S\") + \"\\n\"\n",
    "csv_header += \"training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\" + \"\\n\"\n",
    "print(csv_header)\n",
    "f.write(csv_header)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#RUN training\n",
    "for epoch in range(1, 101):\n",
    "    csv_normal = \"normal;\" + str(epoch) + \";\" + str(get_lr(optimizer)) + \";\"\n",
    "    #csv_backdoor = \"backdoor;\" + str(epoch) + \";\" + str(get_lr(optimizer)) + \";\"\n",
    "    \n",
    "    #train normal\n",
    "    avg_training_loss = train(epoch, train_distributed_dataset)\n",
    "    csv_normal += str(avg_training_loss) + \";\"\n",
    "    timestamp_normal = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    \n",
    "    #train backdoor\n",
    "    #avg_training_backdoor_loss = train(epoch, train_distributed_dataset_backdoor)\n",
    "    #csv_backdoor += str(avg_training_backdoor_loss) + \";\"\n",
    "    #timestamp_backdoor = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    \n",
    "    #save after each 10 iterations\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), (\"exp_traffic_\"+dateString +\"_epoch_\" + str(epoch) + \".pt\"))\n",
    "        \n",
    "    #test backdoor\n",
    "    #test_loss, acc = test(model, device, dataset_loader_backdoored_test, len(backdoored_test))\n",
    "    #csv_backdoor += str(test_loss) + \";\" + acc + \";\"\n",
    "    \n",
    "    #test normal\n",
    "    test_loss, acc = test(model, device, test_loader, len(testdata))\n",
    "    csv_normal += str(test_loss) + \";\" + acc + \";\"\n",
    "\n",
    "    #scheduler.step(test_loss)\n",
    "\n",
    "    csv_normal += timestamp_normal + \"\\n\"\n",
    "    #csv_backdoor += timestamp_backdoor + \"\\n\"\n",
    "    \n",
    "    #Write to file\n",
    "    f= open((\"exp_traffic_\"+dateString+\".txt\"),\"a+\")\n",
    "    #f.write(csv_backdoor)\n",
    "    f.write(csv_normal)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Net().to(device)\n",
    "#model.load_state_dict(torch.load(\"newfaces_alexnet_224x224_augmented100.pt\"))\n",
    "#test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_distributed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_distributed_dataset_backdoor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
