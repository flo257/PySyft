{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0302 08:58:36.886226 10904 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0-rc3.so'\n",
      "W0302 08:58:36.918214 10904 module_wrapper.py:139] From c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import syft as sy\n",
    "import sys\n",
    "import pdb \n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from random import shuffle\n",
    "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "import torch.nn.init as init\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "use_cuda = True\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 512\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_num_threads(4)\n",
    "backdoorType = \"backdoor_green_0_5_percent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker \n",
    "chalie = sy.VirtualWorker(hook, id=\"chalie\")  # <-- NEW: define remote worker\n",
    "dave = sy.VirtualWorker(hook, id=\"dave\")  # <-- NEW: define remote worker\n",
    "#evelyn = sy.VirtualWorker(hook, id=\"evelyn\")  # <-- NEW: define remote worker\n",
    "#a6= sy.VirtualWorker(hook, id=\"a6\")  # <-- NEW: define remote worker\n",
    "#a7= sy.VirtualWorker(hook, id=\"a7\")  # <-- NEW: define remote worker\n",
    "#a8= sy.VirtualWorker(hook, id=\"a8\")  # <-- NEW: define remote worker\n",
    "#a9= sy.VirtualWorker(hook, id=\"a9\")  # <-- NEW: define remote worker\n",
    "#a10= sy.VirtualWorker(hook, id=\"a10\")  # <-- NEW: define remote worker\n",
    "#a11= sy.VirtualWorker(hook, id=\"a11\")  # <-- NEW: define remote worker\n",
    "#a12= sy.VirtualWorker(hook, id=\"a12\")  # <-- NEW: define remote worker\n",
    "#a13= sy.VirtualWorker(hook, id=\"a13\")  # <-- NEW: define remote worker\n",
    "#a14= sy.VirtualWorker(hook, id=\"a14\")  # <-- NEW: define remote worker\n",
    "#a15= sy.VirtualWorker(hook, id=\"a15\")  # <-- NEW: define remote worker\n",
    "#a16= sy.VirtualWorker(hook, id=\"a16\")  # <-- NEW: define remote worker\n",
    "#a17= sy.VirtualWorker(hook, id=\"a17\")  # <-- NEW: define remote worker\n",
    "#a18= sy.VirtualWorker(hook, id=\"a18\")  # <-- NEW: define remote worker\n",
    "#a19= sy.VirtualWorker(hook, id=\"a19\")  # <-- NEW: define remote worker\n",
    "\n",
    "\n",
    "fraudulin = sy.VirtualWorker(hook, id=\"fraudulin\")\n",
    "#fraudrich = sy.VirtualWorker(hook, id=\"fraudrich\") \n",
    "\n",
    "compute_nodes = [alice, bob, chalie, dave]\n",
    "frauds = [fraudulin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for dataset loader generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generateLoadersPerClass(dataset):\n",
    "#    #loaders per class\n",
    "#    loaders_per_class = []\n",
    "#    for class_name in dataset.classes:\n",
    "#        # get the indices in the dataset that are relative to that class\n",
    "#        idx = [\n",
    "#            pos for pos, item in enumerate(dataset.samples)\n",
    "#            if item[1] == dataset.class_to_idx[class_name]]\n",
    "#        # construct the corresponding dataloader thanks to a SubsetRandomSampler\n",
    "#        loaders_per_class += [torch.utils.data.DataLoader(\n",
    "#            dataset, \n",
    "#            batch_size=batch_size,\n",
    "#            sampler=SubsetRandomSampler(idx),\n",
    "#            **kwargs)]\n",
    "#    return loaders_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "\n",
    "#benign data\n",
    "trafficsign = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\GTSRB\\\\Training',\n",
    "                             transform=data_transform)\n",
    "original_loader = torch.utils.data.DataLoader(trafficsign, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "#original_loaders = generateLoadersPerClass(trafficsign)\n",
    "\n",
    "#benign test data\n",
    "testdata = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\GTSRB\\\\Test',\n",
    "                             transform=data_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load backdoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malicious data\n",
    "path = 'C:\\\\Users\\Florian\\\\Desktop\\\\GTSRB\\\\\\Training_' + backdoorType\n",
    "backdoored = datasets.ImageFolder(root = \n",
    "                             path,\n",
    "                             transform=data_transform)\n",
    "backdoored.samples = [(d, 0) for d, s in backdoored.samples] #set each image of backdoors to 001\n",
    "\n",
    "backdoored_loader = torch.utils.data.DataLoader(backdoored, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "#backdoored_loaders = generateLoadersPerClass(backdoored)\n",
    "\n",
    "#malicious test data\n",
    "path = 'C:\\\\Users\\Florian\\\\Desktop\\\\GTSRB\\\\Test_' + backdoorType\n",
    "backdoored_test = datasets.ImageFolder(root = \n",
    "                             path,\n",
    "                             transform=data_transform)\n",
    "backdoored_test.samples = [(d, 0) for d, s in backdoored_test.samples] #set each image of backdoors to 001\n",
    "\n",
    "dataset_loader_backdoored_test = torch.utils.data.DataLoader(backdoored_test, \n",
    "                                                             batch_size=batch_size, \n",
    "                                                             shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letâ€™s visualize a few training images so as to understand the data augmentations.\n",
    "\n",
    "#def imshow(inp, title=None):\n",
    "#    \"\"\"Imshow for Tensor.\"\"\"\n",
    "#    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#    mean = np.array([0.485, 0.456, 0.406])\n",
    "#    std = np.array([0.229, 0.224, 0.225])\n",
    "#    inp = std * inp + mean\n",
    "#    inp = np.clip(inp, 0, 1)\n",
    "#    plt.imshow(inp)\n",
    "#    if title is not None:\n",
    "#        plt.title(title)\n",
    "#    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "#\n",
    "class_names = trafficsign.classes\n",
    "## Get a batch of training data\n",
    "#inputs, classes = next(iter(original_loader))\n",
    "#\n",
    "## Make a grid from batch\n",
    "#out = torchvision.utils.make_grid(inputs)\n",
    "#\n",
    "#imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) #kernel size = filter size\n",
    "        self.bn0 = nn.BatchNorm2d(16)\n",
    "        self.conv1 = nn.Conv2d(16, 32, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool_0 = nn.MaxPool2d(2,stride=2)           #First Max-Pooling Layer\n",
    "        self.conv2 = nn.Conv2d(32, 96, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.conv3 = nn.Conv2d(96, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool_1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout0 = nn.Dropout2d(p=0.37)\n",
    "        self.fc0 = nn.Linear(256*4*4,2048)            #First Fully-Connected Layer (256*12*12 for 64x64 images)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.37)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.37)\n",
    "        self.fc2 = nn.Linear(1024, len(class_names))\n",
    "        #cannot do batchnorm after every conf layer as described in paper, because batchnorm is not supported\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        x = F.relu(self.bn0(self.conv0(x)))\n",
    "        x = self.pool_0(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool_1(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout0(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = self.fc0(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "#http://publications.lib.chalmers.se/records/fulltext/255863/255863.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send dataset to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distributed_dataset = []\n",
    "train_distributed_dataset_backdoor = []\n",
    "\n",
    "#EACH CLIENT KNOWS EACH CLASS\n",
    "#normal clients\n",
    "for batch_idx, (data,target) in enumerate(original_loader):\n",
    "            data_append = data.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            target_append = target.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            train_distributed_dataset.append((data_append, target_append))\n",
    "\n",
    "#backdoored clients\n",
    "for batch_idx, (data,target) in enumerate(backdoored_loader):\n",
    "            data_append = data.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "            target_append = target.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "            train_distributed_dataset_backdoor.append((data_append, target_append))\n",
    "            \n",
    "#shuffle list\n",
    "shuffle(train_distributed_dataset)\n",
    "shuffle(train_distributed_dataset_backdoor)\n",
    "\n",
    "#get subset of data to match with the number of benign and malicious nodes\n",
    "total_data = len(train_distributed_dataset) * (len(compute_nodes) + len(frauds))/len(compute_nodes)\n",
    "fraction_of_backdoored_clients = len(frauds)/(len(compute_nodes) + len(frauds))\n",
    "train_distributed_dataset_backdoor = train_distributed_dataset_backdoor[:int(total_data*fraction_of_backdoored_clients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_distributed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_distributed_dataset_backdoor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, normal_or_backdoored_dataset):\n",
    "    model.train()\n",
    "    totalloss = 0\n",
    "    number_iterations = 0\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(normal_or_backdoored_dataset):   \n",
    "        number_iterations +=1\n",
    "        model.send(data.location) # 0) send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 1) erase previous gradients (if they exist)\n",
    "        output = model(data)  # 2) make a prediction\n",
    "        loss = F.cross_entropy(output, target) # 3) calculate how much we missed\n",
    "        loss.backward() # 4) figure out which weights caused us to miss\n",
    "        optimizer.step() # 5) change those weights\n",
    "        model.get() # 6) get model (with gradients)\n",
    "            \n",
    "        #if batch_idx % 300 == 0:\n",
    "        loss = loss.get() # <-- NEW: get the loss back\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(normal_or_backdoored_dataset) * batch_size,\n",
    "                100. * batch_idx / len(normal_or_backdoored_dataset), loss.item()))\n",
    "        totalloss += loss\n",
    "    print('Average training loss: {}'.format(totalloss/number_iterations))\n",
    "    return float(totalloss/number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, length_of_dataset):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= length_of_dataset\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, length_of_dataset,\n",
    "        100. * correct / length_of_dataset))\n",
    "    \n",
    "    #confusion matrix\n",
    "    nb_classes = len(class_names)\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    #print(confusion_matrix)\n",
    "    per_class_accuracy = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
    "    print(per_class_accuracy) #per class accuracy\n",
    "         \n",
    "    return test_loss, str((100. * correct / length_of_dataset)), per_class_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everyting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#dataset: gtsrb\n",
      "#way backdoor looks like: backdoor_green_0_5_percent\n",
      "#merge strategy: sequential\n",
      "#number of benign sources: 4\n",
      "#number of malicious sources: 1\n",
      "#batch size: 512\n",
      "#distribution of data: equally distributed subset\n",
      "#percentage of poisoned data in backdoored nodes: 100\n",
      "#order of time backdoors being inserted: backdoors last\n",
      "#attack model: basic\n",
      "#starttime: 090026\n",
      "training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\n",
      "\n",
      "Train benign dataset\n",
      "Train Epoch: 1 [0/39424 (0%)]\tLoss: 3.759148\n",
      "Train Epoch: 1 [512/39424 (1%)]\tLoss: 3.760089\n",
      "Train Epoch: 1 [1024/39424 (3%)]\tLoss: 3.758306\n",
      "Train Epoch: 1 [1536/39424 (4%)]\tLoss: 3.759228\n",
      "Train Epoch: 1 [2048/39424 (5%)]\tLoss: 3.758211\n",
      "Train Epoch: 1 [2560/39424 (6%)]\tLoss: 3.757757\n",
      "Train Epoch: 1 [3072/39424 (8%)]\tLoss: 3.756695\n",
      "Train Epoch: 1 [3584/39424 (9%)]\tLoss: 3.758461\n",
      "Train Epoch: 1 [4096/39424 (10%)]\tLoss: 3.757013\n",
      "Train Epoch: 1 [4608/39424 (12%)]\tLoss: 3.757737\n",
      "Train Epoch: 1 [5120/39424 (13%)]\tLoss: 3.757932\n",
      "Train Epoch: 1 [5632/39424 (14%)]\tLoss: 3.754684\n",
      "Train Epoch: 1 [6144/39424 (16%)]\tLoss: 3.757348\n",
      "Train Epoch: 1 [6656/39424 (17%)]\tLoss: 3.756252\n",
      "Train Epoch: 1 [7168/39424 (18%)]\tLoss: 3.756709\n",
      "Train Epoch: 1 [7680/39424 (19%)]\tLoss: 3.754630\n",
      "Train Epoch: 1 [8192/39424 (21%)]\tLoss: 3.755541\n",
      "Train Epoch: 1 [8704/39424 (22%)]\tLoss: 3.752411\n",
      "Train Epoch: 1 [9216/39424 (23%)]\tLoss: 3.753198\n",
      "Train Epoch: 1 [9728/39424 (25%)]\tLoss: 3.753792\n",
      "Train Epoch: 1 [10240/39424 (26%)]\tLoss: 3.752944\n",
      "Train Epoch: 1 [10752/39424 (27%)]\tLoss: 3.751788\n",
      "Train Epoch: 1 [11264/39424 (29%)]\tLoss: 3.750522\n",
      "Train Epoch: 1 [11776/39424 (30%)]\tLoss: 3.750455\n",
      "Train Epoch: 1 [12288/39424 (31%)]\tLoss: 3.749315\n",
      "Train Epoch: 1 [12800/39424 (32%)]\tLoss: 3.752962\n",
      "Train Epoch: 1 [13312/39424 (34%)]\tLoss: 3.750342\n",
      "Train Epoch: 1 [13824/39424 (35%)]\tLoss: 3.752046\n",
      "Train Epoch: 1 [14336/39424 (36%)]\tLoss: 3.749268\n",
      "Train Epoch: 1 [14848/39424 (38%)]\tLoss: 3.749952\n",
      "Train Epoch: 1 [15360/39424 (39%)]\tLoss: 3.750377\n",
      "Train Epoch: 1 [15872/39424 (40%)]\tLoss: 3.747532\n",
      "Train Epoch: 1 [16384/39424 (42%)]\tLoss: 3.748787\n",
      "Train Epoch: 1 [16896/39424 (43%)]\tLoss: 3.747825\n",
      "Train Epoch: 1 [17408/39424 (44%)]\tLoss: 3.748055\n",
      "Train Epoch: 1 [17920/39424 (45%)]\tLoss: 3.747096\n",
      "Train Epoch: 1 [18432/39424 (47%)]\tLoss: 3.744722\n",
      "Train Epoch: 1 [18944/39424 (48%)]\tLoss: 3.745769\n",
      "Train Epoch: 1 [19456/39424 (49%)]\tLoss: 3.747202\n",
      "Train Epoch: 1 [19968/39424 (51%)]\tLoss: 3.743448\n",
      "Train Epoch: 1 [20480/39424 (52%)]\tLoss: 3.743631\n",
      "Train Epoch: 1 [20992/39424 (53%)]\tLoss: 3.747171\n",
      "Train Epoch: 1 [21504/39424 (55%)]\tLoss: 3.744222\n",
      "Train Epoch: 1 [22016/39424 (56%)]\tLoss: 3.745338\n",
      "Train Epoch: 1 [22528/39424 (57%)]\tLoss: 3.742441\n",
      "Train Epoch: 1 [23040/39424 (58%)]\tLoss: 3.746276\n",
      "Train Epoch: 1 [23552/39424 (60%)]\tLoss: 3.739751\n",
      "Train Epoch: 1 [24064/39424 (61%)]\tLoss: 3.742189\n",
      "Train Epoch: 1 [24576/39424 (62%)]\tLoss: 3.740973\n",
      "Train Epoch: 1 [25088/39424 (64%)]\tLoss: 3.739060\n",
      "Train Epoch: 1 [25600/39424 (65%)]\tLoss: 3.741170\n",
      "Train Epoch: 1 [26112/39424 (66%)]\tLoss: 3.740984\n",
      "Train Epoch: 1 [26624/39424 (68%)]\tLoss: 3.741395\n",
      "Train Epoch: 1 [27136/39424 (69%)]\tLoss: 3.741377\n",
      "Train Epoch: 1 [27648/39424 (70%)]\tLoss: 3.740042\n",
      "Train Epoch: 1 [28160/39424 (71%)]\tLoss: 3.741011\n",
      "Train Epoch: 1 [28672/39424 (73%)]\tLoss: 3.739287\n",
      "Train Epoch: 1 [29184/39424 (74%)]\tLoss: 3.734881\n",
      "Train Epoch: 1 [29696/39424 (75%)]\tLoss: 3.739673\n",
      "Train Epoch: 1 [30208/39424 (77%)]\tLoss: 3.737617\n",
      "Train Epoch: 1 [30720/39424 (78%)]\tLoss: 3.738192\n",
      "Train Epoch: 1 [31232/39424 (79%)]\tLoss: 3.739376\n",
      "Train Epoch: 1 [31744/39424 (81%)]\tLoss: 3.734393\n",
      "Train Epoch: 1 [32256/39424 (82%)]\tLoss: 3.733863\n",
      "Train Epoch: 1 [32768/39424 (83%)]\tLoss: 3.736492\n",
      "Train Epoch: 1 [33280/39424 (84%)]\tLoss: 3.733799\n",
      "Train Epoch: 1 [33792/39424 (86%)]\tLoss: 3.735303\n",
      "Train Epoch: 1 [34304/39424 (87%)]\tLoss: 3.732445\n",
      "Train Epoch: 1 [34816/39424 (88%)]\tLoss: 3.734138\n",
      "Train Epoch: 1 [35328/39424 (90%)]\tLoss: 3.731989\n",
      "Train Epoch: 1 [35840/39424 (91%)]\tLoss: 3.736398\n",
      "Train Epoch: 1 [36352/39424 (92%)]\tLoss: 3.731424\n",
      "Train Epoch: 1 [36864/39424 (94%)]\tLoss: 3.734079\n",
      "Train Epoch: 1 [37376/39424 (95%)]\tLoss: 3.731553\n",
      "Train Epoch: 1 [37888/39424 (96%)]\tLoss: 3.730292\n",
      "Train Epoch: 1 [38400/39424 (97%)]\tLoss: 3.726310\n",
      "Train Epoch: 1 [38912/39424 (99%)]\tLoss: 3.727440\n",
      "Average training loss: 3.7456037998199463\n",
      "\n",
      "Test set: Average loss: 3.7882, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.7290, Accuracy: 750/12630 (6%)\n",
      "\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train backdoor\n",
      "Train Epoch: 1 [0/9728 (0%)]\tLoss: 3.787755\n",
      "Train Epoch: 1 [512/9728 (5%)]\tLoss: 3.757604\n",
      "Train Epoch: 1 [1024/9728 (11%)]\tLoss: 3.725060\n",
      "Train Epoch: 1 [1536/9728 (16%)]\tLoss: 3.694904\n",
      "Train Epoch: 1 [2048/9728 (21%)]\tLoss: 3.661797\n",
      "Train Epoch: 1 [2560/9728 (26%)]\tLoss: 3.626822\n",
      "Train Epoch: 1 [3072/9728 (32%)]\tLoss: 3.592479\n",
      "Train Epoch: 1 [3584/9728 (37%)]\tLoss: 3.557718\n",
      "Train Epoch: 1 [4096/9728 (42%)]\tLoss: 3.521360\n",
      "Train Epoch: 1 [4608/9728 (47%)]\tLoss: 3.482596\n",
      "Train Epoch: 1 [5120/9728 (53%)]\tLoss: 3.436987\n",
      "Train Epoch: 1 [5632/9728 (58%)]\tLoss: 3.386770\n",
      "Train Epoch: 1 [6144/9728 (63%)]\tLoss: 3.328429\n",
      "Train Epoch: 1 [6656/9728 (68%)]\tLoss: 3.269528\n",
      "Train Epoch: 1 [7168/9728 (74%)]\tLoss: 3.189534\n",
      "Train Epoch: 1 [7680/9728 (79%)]\tLoss: 3.074301\n",
      "Train Epoch: 1 [8192/9728 (84%)]\tLoss: 2.929967\n",
      "Train Epoch: 1 [8704/9728 (89%)]\tLoss: 2.715390\n",
      "Train Epoch: 1 [9216/9728 (95%)]\tLoss: 2.353886\n",
      "Average training loss: 3.373309850692749\n",
      "\n",
      "Test set: Average loss: 1.6872, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.8690, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 2 [0/39424 (0%)]\tLoss: 3.889194\n",
      "Train Epoch: 2 [512/39424 (1%)]\tLoss: 3.818170\n",
      "Train Epoch: 2 [1024/39424 (3%)]\tLoss: 3.796333\n",
      "Train Epoch: 2 [1536/39424 (4%)]\tLoss: 3.782362\n",
      "Train Epoch: 2 [2048/39424 (5%)]\tLoss: 3.770376\n",
      "Train Epoch: 2 [2560/39424 (6%)]\tLoss: 3.780743\n",
      "Train Epoch: 2 [3072/39424 (8%)]\tLoss: 3.768900\n",
      "Train Epoch: 2 [3584/39424 (9%)]\tLoss: 3.769002\n",
      "Train Epoch: 2 [4096/39424 (10%)]\tLoss: 3.742301\n",
      "Train Epoch: 2 [4608/39424 (12%)]\tLoss: 3.760354\n",
      "Train Epoch: 2 [5120/39424 (13%)]\tLoss: 3.750086\n",
      "Train Epoch: 2 [5632/39424 (14%)]\tLoss: 3.738922\n",
      "Train Epoch: 2 [6144/39424 (16%)]\tLoss: 3.737696\n",
      "Train Epoch: 2 [6656/39424 (17%)]\tLoss: 3.735755\n",
      "Train Epoch: 2 [7168/39424 (18%)]\tLoss: 3.740277\n",
      "Train Epoch: 2 [7680/39424 (19%)]\tLoss: 3.742166\n",
      "Train Epoch: 2 [8192/39424 (21%)]\tLoss: 3.718654\n",
      "Train Epoch: 2 [8704/39424 (22%)]\tLoss: 3.730339\n",
      "Train Epoch: 2 [9216/39424 (23%)]\tLoss: 3.721934\n",
      "Train Epoch: 2 [9728/39424 (25%)]\tLoss: 3.709628\n",
      "Train Epoch: 2 [10240/39424 (26%)]\tLoss: 3.712482\n",
      "Train Epoch: 2 [10752/39424 (27%)]\tLoss: 3.709601\n",
      "Train Epoch: 2 [11264/39424 (29%)]\tLoss: 3.707901\n",
      "Train Epoch: 2 [11776/39424 (30%)]\tLoss: 3.710123\n",
      "Train Epoch: 2 [12288/39424 (31%)]\tLoss: 3.701322\n",
      "Train Epoch: 2 [12800/39424 (32%)]\tLoss: 3.715242\n",
      "Train Epoch: 2 [13312/39424 (34%)]\tLoss: 3.706542\n",
      "Train Epoch: 2 [13824/39424 (35%)]\tLoss: 3.723831\n",
      "Train Epoch: 2 [14336/39424 (36%)]\tLoss: 3.700174\n",
      "Train Epoch: 2 [14848/39424 (38%)]\tLoss: 3.694410\n",
      "Train Epoch: 2 [15360/39424 (39%)]\tLoss: 3.698855\n",
      "Train Epoch: 2 [15872/39424 (40%)]\tLoss: 3.695020\n",
      "Train Epoch: 2 [16384/39424 (42%)]\tLoss: 3.701400\n",
      "Train Epoch: 2 [16896/39424 (43%)]\tLoss: 3.701182\n",
      "Train Epoch: 2 [17408/39424 (44%)]\tLoss: 3.694901\n",
      "Train Epoch: 2 [17920/39424 (45%)]\tLoss: 3.687157\n",
      "Train Epoch: 2 [18432/39424 (47%)]\tLoss: 3.684832\n",
      "Train Epoch: 2 [18944/39424 (48%)]\tLoss: 3.685263\n",
      "Train Epoch: 2 [19456/39424 (49%)]\tLoss: 3.671979\n",
      "Train Epoch: 2 [19968/39424 (51%)]\tLoss: 3.674619\n",
      "Train Epoch: 2 [20480/39424 (52%)]\tLoss: 3.672988\n",
      "Train Epoch: 2 [20992/39424 (53%)]\tLoss: 3.688175\n",
      "Train Epoch: 2 [21504/39424 (55%)]\tLoss: 3.675168\n",
      "Train Epoch: 2 [22016/39424 (56%)]\tLoss: 3.697378\n",
      "Train Epoch: 2 [22528/39424 (57%)]\tLoss: 3.660825\n",
      "Train Epoch: 2 [23040/39424 (58%)]\tLoss: 3.689229\n",
      "Train Epoch: 2 [23552/39424 (60%)]\tLoss: 3.640979\n",
      "Train Epoch: 2 [24064/39424 (61%)]\tLoss: 3.666907\n",
      "Train Epoch: 2 [24576/39424 (62%)]\tLoss: 3.657658\n",
      "Train Epoch: 2 [25088/39424 (64%)]\tLoss: 3.649378\n",
      "Train Epoch: 2 [25600/39424 (65%)]\tLoss: 3.649598\n",
      "Train Epoch: 2 [26112/39424 (66%)]\tLoss: 3.655243\n",
      "Train Epoch: 2 [26624/39424 (68%)]\tLoss: 3.637465\n",
      "Train Epoch: 2 [27136/39424 (69%)]\tLoss: 3.651395\n",
      "Train Epoch: 2 [27648/39424 (70%)]\tLoss: 3.630501\n",
      "Train Epoch: 2 [28160/39424 (71%)]\tLoss: 3.646543\n",
      "Train Epoch: 2 [28672/39424 (73%)]\tLoss: 3.645455\n",
      "Train Epoch: 2 [29184/39424 (74%)]\tLoss: 3.612808\n",
      "Train Epoch: 2 [29696/39424 (75%)]\tLoss: 3.621200\n",
      "Train Epoch: 2 [30208/39424 (77%)]\tLoss: 3.627601\n",
      "Train Epoch: 2 [30720/39424 (78%)]\tLoss: 3.629952\n",
      "Train Epoch: 2 [31232/39424 (79%)]\tLoss: 3.637917\n",
      "Train Epoch: 2 [31744/39424 (81%)]\tLoss: 3.594247\n",
      "Train Epoch: 2 [32256/39424 (82%)]\tLoss: 3.618154\n",
      "Train Epoch: 2 [32768/39424 (83%)]\tLoss: 3.603843\n",
      "Train Epoch: 2 [33280/39424 (84%)]\tLoss: 3.583766\n",
      "Train Epoch: 2 [33792/39424 (86%)]\tLoss: 3.612104\n",
      "Train Epoch: 2 [34304/39424 (87%)]\tLoss: 3.580038\n",
      "Train Epoch: 2 [34816/39424 (88%)]\tLoss: 3.577542\n",
      "Train Epoch: 2 [35328/39424 (90%)]\tLoss: 3.576595\n",
      "Train Epoch: 2 [35840/39424 (91%)]\tLoss: 3.606867\n",
      "Train Epoch: 2 [36352/39424 (92%)]\tLoss: 3.585820\n",
      "Train Epoch: 2 [36864/39424 (94%)]\tLoss: 3.583629\n",
      "Train Epoch: 2 [37376/39424 (95%)]\tLoss: 3.580745\n",
      "Train Epoch: 2 [37888/39424 (96%)]\tLoss: 3.545298\n",
      "Train Epoch: 2 [38400/39424 (97%)]\tLoss: 3.526959\n",
      "Train Epoch: 2 [38912/39424 (99%)]\tLoss: 3.542185\n",
      "Average training loss: 3.678468704223633\n",
      "\n",
      "Test set: Average loss: 3.0566, Accuracy: 309/12630 (2%)\n",
      "\n",
      "tensor([0.0245,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 3.5474, Accuracy: 771/12630 (6%)\n",
      "\n",
      "tensor([0.0000, 0.0000, 0.9520, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0826, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 2 [0/9728 (0%)]\tLoss: 3.056426\n",
      "Train Epoch: 2 [512/9728 (5%)]\tLoss: 2.337654\n",
      "Train Epoch: 2 [1024/9728 (11%)]\tLoss: 1.253651\n",
      "Train Epoch: 2 [1536/9728 (16%)]\tLoss: 0.337597\n",
      "Train Epoch: 2 [2048/9728 (21%)]\tLoss: 0.127970\n",
      "Train Epoch: 2 [2560/9728 (26%)]\tLoss: 0.094500\n",
      "Train Epoch: 2 [3072/9728 (32%)]\tLoss: 0.051377\n",
      "Train Epoch: 2 [3584/9728 (37%)]\tLoss: 0.035000\n",
      "Train Epoch: 2 [4096/9728 (42%)]\tLoss: 0.030206\n",
      "Train Epoch: 2 [4608/9728 (47%)]\tLoss: 0.027232\n",
      "Train Epoch: 2 [5120/9728 (53%)]\tLoss: 0.023177\n",
      "Train Epoch: 2 [5632/9728 (58%)]\tLoss: 0.022793\n",
      "Train Epoch: 2 [6144/9728 (63%)]\tLoss: 0.018172\n",
      "Train Epoch: 2 [6656/9728 (68%)]\tLoss: 0.013900\n",
      "Train Epoch: 2 [7168/9728 (74%)]\tLoss: 0.014089\n",
      "Train Epoch: 2 [7680/9728 (79%)]\tLoss: 0.011375\n",
      "Train Epoch: 2 [8192/9728 (84%)]\tLoss: 0.011289\n",
      "Train Epoch: 2 [8704/9728 (89%)]\tLoss: 0.012142\n",
      "Train Epoch: 2 [9216/9728 (95%)]\tLoss: 0.009907\n",
      "Average training loss: 0.39412936568260193\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 12.3432, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 3 [0/39424 (0%)]\tLoss: 12.799261\n",
      "Train Epoch: 3 [512/39424 (1%)]\tLoss: 3.672776\n",
      "Train Epoch: 3 [1024/39424 (3%)]\tLoss: 3.663416\n",
      "Train Epoch: 3 [1536/39424 (4%)]\tLoss: 3.671933\n",
      "Train Epoch: 3 [2048/39424 (5%)]\tLoss: 3.662647\n",
      "Train Epoch: 3 [2560/39424 (6%)]\tLoss: 3.676771\n",
      "Train Epoch: 3 [3072/39424 (8%)]\tLoss: 3.670616\n",
      "Train Epoch: 3 [3584/39424 (9%)]\tLoss: 3.672282\n",
      "Train Epoch: 3 [4096/39424 (10%)]\tLoss: 3.659907\n",
      "Train Epoch: 3 [4608/39424 (12%)]\tLoss: 3.677957\n",
      "Train Epoch: 3 [5120/39424 (13%)]\tLoss: 3.666245\n",
      "Train Epoch: 3 [5632/39424 (14%)]\tLoss: 3.642666\n",
      "Train Epoch: 3 [6144/39424 (16%)]\tLoss: 3.657012\n",
      "Train Epoch: 3 [6656/39424 (17%)]\tLoss: 3.663122\n",
      "Train Epoch: 3 [7168/39424 (18%)]\tLoss: 3.649183\n",
      "Train Epoch: 3 [7680/39424 (19%)]\tLoss: 3.660714\n",
      "Train Epoch: 3 [8192/39424 (21%)]\tLoss: 3.632603\n",
      "Train Epoch: 3 [8704/39424 (22%)]\tLoss: 3.667815\n",
      "Train Epoch: 3 [9216/39424 (23%)]\tLoss: 3.632971\n",
      "Train Epoch: 3 [9728/39424 (25%)]\tLoss: 3.617671\n",
      "Train Epoch: 3 [10240/39424 (26%)]\tLoss: 3.632436\n",
      "Train Epoch: 3 [10752/39424 (27%)]\tLoss: 3.627445\n",
      "Train Epoch: 3 [11264/39424 (29%)]\tLoss: 3.625679\n",
      "Train Epoch: 3 [11776/39424 (30%)]\tLoss: 3.631884\n",
      "Train Epoch: 3 [12288/39424 (31%)]\tLoss: 3.617409\n",
      "Train Epoch: 3 [12800/39424 (32%)]\tLoss: 3.620992\n",
      "Train Epoch: 3 [13312/39424 (34%)]\tLoss: 3.636834\n",
      "Train Epoch: 3 [13824/39424 (35%)]\tLoss: 3.656941\n",
      "Train Epoch: 3 [14336/39424 (36%)]\tLoss: 3.624542\n",
      "Train Epoch: 3 [14848/39424 (38%)]\tLoss: 3.607998\n",
      "Train Epoch: 3 [15360/39424 (39%)]\tLoss: 3.610960\n",
      "Train Epoch: 3 [15872/39424 (40%)]\tLoss: 3.593533\n",
      "Train Epoch: 3 [16384/39424 (42%)]\tLoss: 3.612291\n",
      "Train Epoch: 3 [16896/39424 (43%)]\tLoss: 3.608291\n",
      "Train Epoch: 3 [17408/39424 (44%)]\tLoss: 3.606718\n",
      "Train Epoch: 3 [17920/39424 (45%)]\tLoss: 3.595674\n",
      "Train Epoch: 3 [18432/39424 (47%)]\tLoss: 3.594363\n",
      "Train Epoch: 3 [18944/39424 (48%)]\tLoss: 3.604204\n",
      "Train Epoch: 3 [19456/39424 (49%)]\tLoss: 3.587292\n",
      "Train Epoch: 3 [19968/39424 (51%)]\tLoss: 3.581720\n",
      "Train Epoch: 3 [20480/39424 (52%)]\tLoss: 3.587579\n",
      "Train Epoch: 3 [20992/39424 (53%)]\tLoss: 3.612506\n",
      "Train Epoch: 3 [21504/39424 (55%)]\tLoss: 3.592000\n",
      "Train Epoch: 3 [22016/39424 (56%)]\tLoss: 3.610998\n",
      "Train Epoch: 3 [22528/39424 (57%)]\tLoss: 3.587679\n",
      "Train Epoch: 3 [23040/39424 (58%)]\tLoss: 3.627010\n",
      "Train Epoch: 3 [23552/39424 (60%)]\tLoss: 3.521895\n",
      "Train Epoch: 3 [24064/39424 (61%)]\tLoss: 3.589970\n",
      "Train Epoch: 3 [24576/39424 (62%)]\tLoss: 3.572975\n",
      "Train Epoch: 3 [25088/39424 (64%)]\tLoss: 3.544122\n",
      "Train Epoch: 3 [25600/39424 (65%)]\tLoss: 3.587410\n",
      "Train Epoch: 3 [26112/39424 (66%)]\tLoss: 3.564878\n",
      "Train Epoch: 3 [26624/39424 (68%)]\tLoss: 3.577631\n",
      "Train Epoch: 3 [27136/39424 (69%)]\tLoss: 3.575090\n",
      "Train Epoch: 3 [27648/39424 (70%)]\tLoss: 3.556424\n",
      "Train Epoch: 3 [28160/39424 (71%)]\tLoss: 3.563841\n",
      "Train Epoch: 3 [28672/39424 (73%)]\tLoss: 3.587859\n",
      "Train Epoch: 3 [29184/39424 (74%)]\tLoss: 3.565007\n",
      "Train Epoch: 3 [29696/39424 (75%)]\tLoss: 3.550560\n",
      "Train Epoch: 3 [30208/39424 (77%)]\tLoss: 3.569164\n",
      "Train Epoch: 3 [30720/39424 (78%)]\tLoss: 3.549881\n",
      "Train Epoch: 3 [31232/39424 (79%)]\tLoss: 3.583677\n",
      "Train Epoch: 3 [31744/39424 (81%)]\tLoss: 3.544534\n",
      "Train Epoch: 3 [32256/39424 (82%)]\tLoss: 3.542055\n",
      "Train Epoch: 3 [32768/39424 (83%)]\tLoss: 3.532750\n",
      "Train Epoch: 3 [33280/39424 (84%)]\tLoss: 3.556174\n",
      "Train Epoch: 3 [33792/39424 (86%)]\tLoss: 3.586861\n",
      "Train Epoch: 3 [34304/39424 (87%)]\tLoss: 3.563264\n",
      "Train Epoch: 3 [34816/39424 (88%)]\tLoss: 3.546438\n",
      "Train Epoch: 3 [35328/39424 (90%)]\tLoss: 3.555154\n",
      "Train Epoch: 3 [35840/39424 (91%)]\tLoss: 3.551437\n",
      "Train Epoch: 3 [36352/39424 (92%)]\tLoss: 3.564981\n",
      "Train Epoch: 3 [36864/39424 (94%)]\tLoss: 3.562885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [37376/39424 (95%)]\tLoss: 3.561591\n",
      "Train Epoch: 3 [37888/39424 (96%)]\tLoss: 3.505019\n",
      "Train Epoch: 3 [38400/39424 (97%)]\tLoss: 3.510128\n",
      "Train Epoch: 3 [38912/39424 (99%)]\tLoss: 3.526485\n",
      "Average training loss: 3.7205545902252197\n",
      "\n",
      "Test set: Average loss: 3.6344, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.5451, Accuracy: 988/12630 (8%)\n",
      "\n",
      "tensor([0.0000, 0.3139, 0.7853, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.2403, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 3 [0/9728 (0%)]\tLoss: 3.642593\n",
      "Train Epoch: 3 [512/9728 (5%)]\tLoss: 3.293844\n",
      "Train Epoch: 3 [1024/9728 (11%)]\tLoss: 2.962282\n",
      "Train Epoch: 3 [1536/9728 (16%)]\tLoss: 2.606789\n",
      "Train Epoch: 3 [2048/9728 (21%)]\tLoss: 2.080410\n",
      "Train Epoch: 3 [2560/9728 (26%)]\tLoss: 1.398378\n",
      "Train Epoch: 3 [3072/9728 (32%)]\tLoss: 0.665000\n",
      "Train Epoch: 3 [3584/9728 (37%)]\tLoss: 0.190703\n",
      "Train Epoch: 3 [4096/9728 (42%)]\tLoss: 0.085336\n",
      "Train Epoch: 3 [4608/9728 (47%)]\tLoss: 0.053073\n",
      "Train Epoch: 3 [5120/9728 (53%)]\tLoss: 0.036493\n",
      "Train Epoch: 3 [5632/9728 (58%)]\tLoss: 0.027843\n",
      "Train Epoch: 3 [6144/9728 (63%)]\tLoss: 0.024108\n",
      "Train Epoch: 3 [6656/9728 (68%)]\tLoss: 0.019037\n",
      "Train Epoch: 3 [7168/9728 (74%)]\tLoss: 0.018966\n",
      "Train Epoch: 3 [7680/9728 (79%)]\tLoss: 0.014174\n",
      "Train Epoch: 3 [8192/9728 (84%)]\tLoss: 0.011569\n",
      "Train Epoch: 3 [8704/9728 (89%)]\tLoss: 0.010802\n",
      "Train Epoch: 3 [9216/9728 (95%)]\tLoss: 0.010184\n",
      "Average training loss: 0.9027150869369507\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.0725, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 4 [0/39424 (0%)]\tLoss: 11.178939\n",
      "Train Epoch: 4 [512/39424 (1%)]\tLoss: 3.618459\n",
      "Train Epoch: 4 [1024/39424 (3%)]\tLoss: 3.610092\n",
      "Train Epoch: 4 [1536/39424 (4%)]\tLoss: 3.629117\n",
      "Train Epoch: 4 [2048/39424 (5%)]\tLoss: 3.610932\n",
      "Train Epoch: 4 [2560/39424 (6%)]\tLoss: 3.634750\n",
      "Train Epoch: 4 [3072/39424 (8%)]\tLoss: 3.629778\n",
      "Train Epoch: 4 [3584/39424 (9%)]\tLoss: 3.629058\n",
      "Train Epoch: 4 [4096/39424 (10%)]\tLoss: 3.602571\n",
      "Train Epoch: 4 [4608/39424 (12%)]\tLoss: 3.637929\n",
      "Train Epoch: 4 [5120/39424 (13%)]\tLoss: 3.622113\n",
      "Train Epoch: 4 [5632/39424 (14%)]\tLoss: 3.585301\n",
      "Train Epoch: 4 [6144/39424 (16%)]\tLoss: 3.607566\n",
      "Train Epoch: 4 [6656/39424 (17%)]\tLoss: 3.616373\n",
      "Train Epoch: 4 [7168/39424 (18%)]\tLoss: 3.594246\n",
      "Train Epoch: 4 [7680/39424 (19%)]\tLoss: 3.620201\n",
      "Train Epoch: 4 [8192/39424 (21%)]\tLoss: 3.559093\n",
      "Train Epoch: 4 [8704/39424 (22%)]\tLoss: 3.614859\n",
      "Train Epoch: 4 [9216/39424 (23%)]\tLoss: 3.575970\n",
      "Train Epoch: 4 [9728/39424 (25%)]\tLoss: 3.551931\n",
      "Train Epoch: 4 [10240/39424 (26%)]\tLoss: 3.572227\n",
      "Train Epoch: 4 [10752/39424 (27%)]\tLoss: 3.566023\n",
      "Train Epoch: 4 [11264/39424 (29%)]\tLoss: 3.572790\n",
      "Train Epoch: 4 [11776/39424 (30%)]\tLoss: 3.584896\n",
      "Train Epoch: 4 [12288/39424 (31%)]\tLoss: 3.549404\n",
      "Train Epoch: 4 [12800/39424 (32%)]\tLoss: 3.562196\n",
      "Train Epoch: 4 [13312/39424 (34%)]\tLoss: 3.587981\n",
      "Train Epoch: 4 [13824/39424 (35%)]\tLoss: 3.620640\n",
      "Train Epoch: 4 [14336/39424 (36%)]\tLoss: 3.576130\n",
      "Train Epoch: 4 [14848/39424 (38%)]\tLoss: 3.558778\n",
      "Train Epoch: 4 [15360/39424 (39%)]\tLoss: 3.552591\n",
      "Train Epoch: 4 [15872/39424 (40%)]\tLoss: 3.540492\n",
      "Train Epoch: 4 [16384/39424 (42%)]\tLoss: 3.561242\n",
      "Train Epoch: 4 [16896/39424 (43%)]\tLoss: 3.561789\n",
      "Train Epoch: 4 [17408/39424 (44%)]\tLoss: 3.562730\n",
      "Train Epoch: 4 [17920/39424 (45%)]\tLoss: 3.542567\n",
      "Train Epoch: 4 [18432/39424 (47%)]\tLoss: 3.548512\n",
      "Train Epoch: 4 [18944/39424 (48%)]\tLoss: 3.568386\n",
      "Train Epoch: 4 [19456/39424 (49%)]\tLoss: 3.534982\n",
      "Train Epoch: 4 [19968/39424 (51%)]\tLoss: 3.542099\n",
      "Train Epoch: 4 [20480/39424 (52%)]\tLoss: 3.540272\n",
      "Train Epoch: 4 [20992/39424 (53%)]\tLoss: 3.573881\n",
      "Train Epoch: 4 [21504/39424 (55%)]\tLoss: 3.562049\n",
      "Train Epoch: 4 [22016/39424 (56%)]\tLoss: 3.578149\n",
      "Train Epoch: 4 [22528/39424 (57%)]\tLoss: 3.546794\n",
      "Train Epoch: 4 [23040/39424 (58%)]\tLoss: 3.603277\n",
      "Train Epoch: 4 [23552/39424 (60%)]\tLoss: 3.465522\n",
      "Train Epoch: 4 [24064/39424 (61%)]\tLoss: 3.561787\n",
      "Train Epoch: 4 [24576/39424 (62%)]\tLoss: 3.546407\n",
      "Train Epoch: 4 [25088/39424 (64%)]\tLoss: 3.503823\n",
      "Train Epoch: 4 [25600/39424 (65%)]\tLoss: 3.568284\n",
      "Train Epoch: 4 [26112/39424 (66%)]\tLoss: 3.533403\n",
      "Train Epoch: 4 [26624/39424 (68%)]\tLoss: 3.551465\n",
      "Train Epoch: 4 [27136/39424 (69%)]\tLoss: 3.538869\n",
      "Train Epoch: 4 [27648/39424 (70%)]\tLoss: 3.516980\n",
      "Train Epoch: 4 [28160/39424 (71%)]\tLoss: 3.541826\n",
      "Train Epoch: 4 [28672/39424 (73%)]\tLoss: 3.569783\n",
      "Train Epoch: 4 [29184/39424 (74%)]\tLoss: 3.539643\n",
      "Train Epoch: 4 [29696/39424 (75%)]\tLoss: 3.510297\n",
      "Train Epoch: 4 [30208/39424 (77%)]\tLoss: 3.554064\n",
      "Train Epoch: 4 [30720/39424 (78%)]\tLoss: 3.530792\n",
      "Train Epoch: 4 [31232/39424 (79%)]\tLoss: 3.549603\n",
      "Train Epoch: 4 [31744/39424 (81%)]\tLoss: 3.522664\n",
      "Train Epoch: 4 [32256/39424 (82%)]\tLoss: 3.523461\n",
      "Train Epoch: 4 [32768/39424 (83%)]\tLoss: 3.494642\n",
      "Train Epoch: 4 [33280/39424 (84%)]\tLoss: 3.527513\n",
      "Train Epoch: 4 [33792/39424 (86%)]\tLoss: 3.559510\n",
      "Train Epoch: 4 [34304/39424 (87%)]\tLoss: 3.528074\n",
      "Train Epoch: 4 [34816/39424 (88%)]\tLoss: 3.514266\n",
      "Train Epoch: 4 [35328/39424 (90%)]\tLoss: 3.532741\n",
      "Train Epoch: 4 [35840/39424 (91%)]\tLoss: 3.545573\n",
      "Train Epoch: 4 [36352/39424 (92%)]\tLoss: 3.544114\n",
      "Train Epoch: 4 [36864/39424 (94%)]\tLoss: 3.550592\n",
      "Train Epoch: 4 [37376/39424 (95%)]\tLoss: 3.534807\n",
      "Train Epoch: 4 [37888/39424 (96%)]\tLoss: 3.488998\n",
      "Train Epoch: 4 [38400/39424 (97%)]\tLoss: 3.476335\n",
      "Train Epoch: 4 [38912/39424 (99%)]\tLoss: 3.495592\n",
      "Average training loss: 3.6600210666656494\n",
      "\n",
      "Test set: Average loss: 3.4357, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.5183, Accuracy: 1182/12630 (9%)\n",
      "\n",
      "tensor([0.0000, 0.4306, 0.7507, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4292, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 4 [0/9728 (0%)]\tLoss: 3.443043\n",
      "Train Epoch: 4 [512/9728 (5%)]\tLoss: 3.074074\n",
      "Train Epoch: 4 [1024/9728 (11%)]\tLoss: 2.692803\n",
      "Train Epoch: 4 [1536/9728 (16%)]\tLoss: 2.244929\n",
      "Train Epoch: 4 [2048/9728 (21%)]\tLoss: 1.542231\n",
      "Train Epoch: 4 [2560/9728 (26%)]\tLoss: 0.744449\n",
      "Train Epoch: 4 [3072/9728 (32%)]\tLoss: 0.198116\n",
      "Train Epoch: 4 [3584/9728 (37%)]\tLoss: 0.087811\n",
      "Train Epoch: 4 [4096/9728 (42%)]\tLoss: 0.056368\n",
      "Train Epoch: 4 [4608/9728 (47%)]\tLoss: 0.041910\n",
      "Train Epoch: 4 [5120/9728 (53%)]\tLoss: 0.028790\n",
      "Train Epoch: 4 [5632/9728 (58%)]\tLoss: 0.027374\n",
      "Train Epoch: 4 [6144/9728 (63%)]\tLoss: 0.019300\n",
      "Train Epoch: 4 [6656/9728 (68%)]\tLoss: 0.020196\n",
      "Train Epoch: 4 [7168/9728 (74%)]\tLoss: 0.019103\n",
      "Train Epoch: 4 [7680/9728 (79%)]\tLoss: 0.012154\n",
      "Train Epoch: 4 [8192/9728 (84%)]\tLoss: 0.014127\n",
      "Train Epoch: 4 [8704/9728 (89%)]\tLoss: 0.010771\n",
      "Train Epoch: 4 [9216/9728 (95%)]\tLoss: 0.011509\n",
      "Average training loss: 0.752055823802948\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.7229, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 5 [0/39424 (0%)]\tLoss: 10.816391\n",
      "Train Epoch: 5 [512/39424 (1%)]\tLoss: 3.589956\n",
      "Train Epoch: 5 [1024/39424 (3%)]\tLoss: 3.575879\n",
      "Train Epoch: 5 [1536/39424 (4%)]\tLoss: 3.604044\n",
      "Train Epoch: 5 [2048/39424 (5%)]\tLoss: 3.577004\n",
      "Train Epoch: 5 [2560/39424 (6%)]\tLoss: 3.619151\n",
      "Train Epoch: 5 [3072/39424 (8%)]\tLoss: 3.608750\n",
      "Train Epoch: 5 [3584/39424 (9%)]\tLoss: 3.616859\n",
      "Train Epoch: 5 [4096/39424 (10%)]\tLoss: 3.581854\n",
      "Train Epoch: 5 [4608/39424 (12%)]\tLoss: 3.623846\n",
      "Train Epoch: 5 [5120/39424 (13%)]\tLoss: 3.596807\n",
      "Train Epoch: 5 [5632/39424 (14%)]\tLoss: 3.568080\n",
      "Train Epoch: 5 [6144/39424 (16%)]\tLoss: 3.582170\n",
      "Train Epoch: 5 [6656/39424 (17%)]\tLoss: 3.594364\n",
      "Train Epoch: 5 [7168/39424 (18%)]\tLoss: 3.578647\n",
      "Train Epoch: 5 [7680/39424 (19%)]\tLoss: 3.605698\n",
      "Train Epoch: 5 [8192/39424 (21%)]\tLoss: 3.545924\n",
      "Train Epoch: 5 [8704/39424 (22%)]\tLoss: 3.605317\n",
      "Train Epoch: 5 [9216/39424 (23%)]\tLoss: 3.546823\n",
      "Train Epoch: 5 [9728/39424 (25%)]\tLoss: 3.524583\n",
      "Train Epoch: 5 [10240/39424 (26%)]\tLoss: 3.551463\n",
      "Train Epoch: 5 [10752/39424 (27%)]\tLoss: 3.545404\n",
      "Train Epoch: 5 [11264/39424 (29%)]\tLoss: 3.546643\n",
      "Train Epoch: 5 [11776/39424 (30%)]\tLoss: 3.567799\n",
      "Train Epoch: 5 [12288/39424 (31%)]\tLoss: 3.525557\n",
      "Train Epoch: 5 [12800/39424 (32%)]\tLoss: 3.550599\n",
      "Train Epoch: 5 [13312/39424 (34%)]\tLoss: 3.575846\n",
      "Train Epoch: 5 [13824/39424 (35%)]\tLoss: 3.606762\n",
      "Train Epoch: 5 [14336/39424 (36%)]\tLoss: 3.555494\n",
      "Train Epoch: 5 [14848/39424 (38%)]\tLoss: 3.534328\n",
      "Train Epoch: 5 [15360/39424 (39%)]\tLoss: 3.537967\n",
      "Train Epoch: 5 [15872/39424 (40%)]\tLoss: 3.518908\n",
      "Train Epoch: 5 [16384/39424 (42%)]\tLoss: 3.537520\n",
      "Train Epoch: 5 [16896/39424 (43%)]\tLoss: 3.549125\n",
      "Train Epoch: 5 [17408/39424 (44%)]\tLoss: 3.536711\n",
      "Train Epoch: 5 [17920/39424 (45%)]\tLoss: 3.524233\n",
      "Train Epoch: 5 [18432/39424 (47%)]\tLoss: 3.538938\n",
      "Train Epoch: 5 [18944/39424 (48%)]\tLoss: 3.553541\n",
      "Train Epoch: 5 [19456/39424 (49%)]\tLoss: 3.522918\n",
      "Train Epoch: 5 [19968/39424 (51%)]\tLoss: 3.534461\n",
      "Train Epoch: 5 [20480/39424 (52%)]\tLoss: 3.536029\n",
      "Train Epoch: 5 [20992/39424 (53%)]\tLoss: 3.562507\n",
      "Train Epoch: 5 [21504/39424 (55%)]\tLoss: 3.544476\n",
      "Train Epoch: 5 [22016/39424 (56%)]\tLoss: 3.569680\n",
      "Train Epoch: 5 [22528/39424 (57%)]\tLoss: 3.532674\n",
      "Train Epoch: 5 [23040/39424 (58%)]\tLoss: 3.600700\n",
      "Train Epoch: 5 [23552/39424 (60%)]\tLoss: 3.453420\n",
      "Train Epoch: 5 [24064/39424 (61%)]\tLoss: 3.550186\n",
      "Train Epoch: 5 [24576/39424 (62%)]\tLoss: 3.530669\n",
      "Train Epoch: 5 [25088/39424 (64%)]\tLoss: 3.494888\n",
      "Train Epoch: 5 [25600/39424 (65%)]\tLoss: 3.552971\n",
      "Train Epoch: 5 [26112/39424 (66%)]\tLoss: 3.524318\n",
      "Train Epoch: 5 [26624/39424 (68%)]\tLoss: 3.535436\n",
      "Train Epoch: 5 [27136/39424 (69%)]\tLoss: 3.529135\n",
      "Train Epoch: 5 [27648/39424 (70%)]\tLoss: 3.509453\n",
      "Train Epoch: 5 [28160/39424 (71%)]\tLoss: 3.536801\n",
      "Train Epoch: 5 [28672/39424 (73%)]\tLoss: 3.558095\n",
      "Train Epoch: 5 [29184/39424 (74%)]\tLoss: 3.527728\n",
      "Train Epoch: 5 [29696/39424 (75%)]\tLoss: 3.495263\n",
      "Train Epoch: 5 [30208/39424 (77%)]\tLoss: 3.529486\n",
      "Train Epoch: 5 [30720/39424 (78%)]\tLoss: 3.514141\n",
      "Train Epoch: 5 [31232/39424 (79%)]\tLoss: 3.539984\n",
      "Train Epoch: 5 [31744/39424 (81%)]\tLoss: 3.510839\n",
      "Train Epoch: 5 [32256/39424 (82%)]\tLoss: 3.507834\n",
      "Train Epoch: 5 [32768/39424 (83%)]\tLoss: 3.494692\n",
      "Train Epoch: 5 [33280/39424 (84%)]\tLoss: 3.519813\n",
      "Train Epoch: 5 [33792/39424 (86%)]\tLoss: 3.545386\n",
      "Train Epoch: 5 [34304/39424 (87%)]\tLoss: 3.516355\n",
      "Train Epoch: 5 [34816/39424 (88%)]\tLoss: 3.496634\n",
      "Train Epoch: 5 [35328/39424 (90%)]\tLoss: 3.521379\n",
      "Train Epoch: 5 [35840/39424 (91%)]\tLoss: 3.534859\n",
      "Train Epoch: 5 [36352/39424 (92%)]\tLoss: 3.545482\n",
      "Train Epoch: 5 [36864/39424 (94%)]\tLoss: 3.545304\n",
      "Train Epoch: 5 [37376/39424 (95%)]\tLoss: 3.537374\n",
      "Train Epoch: 5 [37888/39424 (96%)]\tLoss: 3.476531\n",
      "Train Epoch: 5 [38400/39424 (97%)]\tLoss: 3.468094\n",
      "Train Epoch: 5 [38912/39424 (99%)]\tLoss: 3.492050\n",
      "Average training loss: 3.6404800415039062\n",
      "\n",
      "Test set: Average loss: 3.3703, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.5130, Accuracy: 1178/12630 (9%)\n",
      "\n",
      "tensor([0.0000, 0.4333, 0.7453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4264, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 5 [0/9728 (0%)]\tLoss: 3.376439\n",
      "Train Epoch: 5 [512/9728 (5%)]\tLoss: 3.080378\n",
      "Train Epoch: 5 [1024/9728 (11%)]\tLoss: 2.773948\n",
      "Train Epoch: 5 [1536/9728 (16%)]\tLoss: 2.419025\n",
      "Train Epoch: 5 [2048/9728 (21%)]\tLoss: 1.924843\n",
      "Train Epoch: 5 [2560/9728 (26%)]\tLoss: 1.303060\n",
      "Train Epoch: 5 [3072/9728 (32%)]\tLoss: 0.659437\n",
      "Train Epoch: 5 [3584/9728 (37%)]\tLoss: 0.226140\n",
      "Train Epoch: 5 [4096/9728 (42%)]\tLoss: 0.095446\n",
      "Train Epoch: 5 [4608/9728 (47%)]\tLoss: 0.058912\n",
      "Train Epoch: 5 [5120/9728 (53%)]\tLoss: 0.038128\n",
      "Train Epoch: 5 [5632/9728 (58%)]\tLoss: 0.031437\n",
      "Train Epoch: 5 [6144/9728 (63%)]\tLoss: 0.025168\n",
      "Train Epoch: 5 [6656/9728 (68%)]\tLoss: 0.021678\n",
      "Train Epoch: 5 [7168/9728 (74%)]\tLoss: 0.020255\n",
      "Train Epoch: 5 [7680/9728 (79%)]\tLoss: 0.015644\n",
      "Train Epoch: 5 [8192/9728 (84%)]\tLoss: 0.012911\n",
      "Train Epoch: 5 [8704/9728 (89%)]\tLoss: 0.012166\n",
      "Train Epoch: 5 [9216/9728 (95%)]\tLoss: 0.011087\n",
      "Average training loss: 0.8476895093917847\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.4751, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 6 [0/39424 (0%)]\tLoss: 10.438389\n",
      "Train Epoch: 6 [512/39424 (1%)]\tLoss: 3.584359\n",
      "Train Epoch: 6 [1024/39424 (3%)]\tLoss: 3.563187\n",
      "Train Epoch: 6 [1536/39424 (4%)]\tLoss: 3.587452\n",
      "Train Epoch: 6 [2048/39424 (5%)]\tLoss: 3.562944\n",
      "Train Epoch: 6 [2560/39424 (6%)]\tLoss: 3.606905\n",
      "Train Epoch: 6 [3072/39424 (8%)]\tLoss: 3.603352\n",
      "Train Epoch: 6 [3584/39424 (9%)]\tLoss: 3.608632\n",
      "Train Epoch: 6 [4096/39424 (10%)]\tLoss: 3.571761\n",
      "Train Epoch: 6 [4608/39424 (12%)]\tLoss: 3.618165\n",
      "Train Epoch: 6 [5120/39424 (13%)]\tLoss: 3.593134\n",
      "Train Epoch: 6 [5632/39424 (14%)]\tLoss: 3.555734\n",
      "Train Epoch: 6 [6144/39424 (16%)]\tLoss: 3.576209\n",
      "Train Epoch: 6 [6656/39424 (17%)]\tLoss: 3.587168\n",
      "Train Epoch: 6 [7168/39424 (18%)]\tLoss: 3.572107\n",
      "Train Epoch: 6 [7680/39424 (19%)]\tLoss: 3.590512\n",
      "Train Epoch: 6 [8192/39424 (21%)]\tLoss: 3.523422\n",
      "Train Epoch: 6 [8704/39424 (22%)]\tLoss: 3.595400\n",
      "Train Epoch: 6 [9216/39424 (23%)]\tLoss: 3.531386\n",
      "Train Epoch: 6 [9728/39424 (25%)]\tLoss: 3.506357\n",
      "Train Epoch: 6 [10240/39424 (26%)]\tLoss: 3.533895\n",
      "Train Epoch: 6 [10752/39424 (27%)]\tLoss: 3.536028\n",
      "Train Epoch: 6 [11264/39424 (29%)]\tLoss: 3.539232\n",
      "Train Epoch: 6 [11776/39424 (30%)]\tLoss: 3.549190\n",
      "Train Epoch: 6 [12288/39424 (31%)]\tLoss: 3.510800\n",
      "Train Epoch: 6 [12800/39424 (32%)]\tLoss: 3.532183\n",
      "Train Epoch: 6 [13312/39424 (34%)]\tLoss: 3.560812\n",
      "Train Epoch: 6 [13824/39424 (35%)]\tLoss: 3.605323\n",
      "Train Epoch: 6 [14336/39424 (36%)]\tLoss: 3.547428\n",
      "Train Epoch: 6 [14848/39424 (38%)]\tLoss: 3.520625\n",
      "Train Epoch: 6 [15360/39424 (39%)]\tLoss: 3.523743\n",
      "Train Epoch: 6 [15872/39424 (40%)]\tLoss: 3.502321\n",
      "Train Epoch: 6 [16384/39424 (42%)]\tLoss: 3.526237\n",
      "Train Epoch: 6 [16896/39424 (43%)]\tLoss: 3.552117\n",
      "Train Epoch: 6 [17408/39424 (44%)]\tLoss: 3.519543\n",
      "Train Epoch: 6 [17920/39424 (45%)]\tLoss: 3.512727\n",
      "Train Epoch: 6 [18432/39424 (47%)]\tLoss: 3.528209\n",
      "Train Epoch: 6 [18944/39424 (48%)]\tLoss: 3.549534\n",
      "Train Epoch: 6 [19456/39424 (49%)]\tLoss: 3.515403\n",
      "Train Epoch: 6 [19968/39424 (51%)]\tLoss: 3.521294\n",
      "Train Epoch: 6 [20480/39424 (52%)]\tLoss: 3.528431\n",
      "Train Epoch: 6 [20992/39424 (53%)]\tLoss: 3.557138\n",
      "Train Epoch: 6 [21504/39424 (55%)]\tLoss: 3.528157\n",
      "Train Epoch: 6 [22016/39424 (56%)]\tLoss: 3.556781\n",
      "Train Epoch: 6 [22528/39424 (57%)]\tLoss: 3.515348\n",
      "Train Epoch: 6 [23040/39424 (58%)]\tLoss: 3.579360\n",
      "Train Epoch: 6 [23552/39424 (60%)]\tLoss: 3.441327\n",
      "Train Epoch: 6 [24064/39424 (61%)]\tLoss: 3.541521\n",
      "Train Epoch: 6 [24576/39424 (62%)]\tLoss: 3.520591\n",
      "Train Epoch: 6 [25088/39424 (64%)]\tLoss: 3.478847\n",
      "Train Epoch: 6 [25600/39424 (65%)]\tLoss: 3.533809\n",
      "Train Epoch: 6 [26112/39424 (66%)]\tLoss: 3.512549\n",
      "Train Epoch: 6 [26624/39424 (68%)]\tLoss: 3.528193\n",
      "Train Epoch: 6 [27136/39424 (69%)]\tLoss: 3.519066\n",
      "Train Epoch: 6 [27648/39424 (70%)]\tLoss: 3.488000\n",
      "Train Epoch: 6 [28160/39424 (71%)]\tLoss: 3.517507\n",
      "Train Epoch: 6 [28672/39424 (73%)]\tLoss: 3.540055\n",
      "Train Epoch: 6 [29184/39424 (74%)]\tLoss: 3.502275\n",
      "Train Epoch: 6 [29696/39424 (75%)]\tLoss: 3.483240\n",
      "Train Epoch: 6 [30208/39424 (77%)]\tLoss: 3.525905\n",
      "Train Epoch: 6 [30720/39424 (78%)]\tLoss: 3.493515\n",
      "Train Epoch: 6 [31232/39424 (79%)]\tLoss: 3.543990\n",
      "Train Epoch: 6 [31744/39424 (81%)]\tLoss: 3.483166\n",
      "Train Epoch: 6 [32256/39424 (82%)]\tLoss: 3.498698\n",
      "Train Epoch: 6 [32768/39424 (83%)]\tLoss: 3.479647\n",
      "Train Epoch: 6 [33280/39424 (84%)]\tLoss: 3.501750\n",
      "Train Epoch: 6 [33792/39424 (86%)]\tLoss: 3.533545\n",
      "Train Epoch: 6 [34304/39424 (87%)]\tLoss: 3.489630\n",
      "Train Epoch: 6 [34816/39424 (88%)]\tLoss: 3.490052\n",
      "Train Epoch: 6 [35328/39424 (90%)]\tLoss: 3.510916\n",
      "Train Epoch: 6 [35840/39424 (91%)]\tLoss: 3.524305\n",
      "Train Epoch: 6 [36352/39424 (92%)]\tLoss: 3.525402\n",
      "Train Epoch: 6 [36864/39424 (94%)]\tLoss: 3.527261\n",
      "Train Epoch: 6 [37376/39424 (95%)]\tLoss: 3.518167\n",
      "Train Epoch: 6 [37888/39424 (96%)]\tLoss: 3.459046\n",
      "Train Epoch: 6 [38400/39424 (97%)]\tLoss: 3.454113\n",
      "Train Epoch: 6 [38912/39424 (99%)]\tLoss: 3.478482\n",
      "Average training loss: 3.623025417327881\n",
      "\n",
      "Test set: Average loss: 3.2718, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.4973, Accuracy: 1233/12630 (10%)\n",
      "\n",
      "tensor([0.0000, 0.5528, 0.7120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.4181, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 6 [0/9728 (0%)]\tLoss: 3.275945\n",
      "Train Epoch: 6 [512/9728 (5%)]\tLoss: 2.990857\n",
      "Train Epoch: 6 [1024/9728 (11%)]\tLoss: 2.690396\n",
      "Train Epoch: 6 [1536/9728 (16%)]\tLoss: 2.341396\n",
      "Train Epoch: 6 [2048/9728 (21%)]\tLoss: 1.846187\n",
      "Train Epoch: 6 [2560/9728 (26%)]\tLoss: 1.205841\n",
      "Train Epoch: 6 [3072/9728 (32%)]\tLoss: 0.591335\n",
      "Train Epoch: 6 [3584/9728 (37%)]\tLoss: 0.198509\n",
      "Train Epoch: 6 [4096/9728 (42%)]\tLoss: 0.093959\n",
      "Train Epoch: 6 [4608/9728 (47%)]\tLoss: 0.055263\n",
      "Train Epoch: 6 [5120/9728 (53%)]\tLoss: 0.037975\n",
      "Train Epoch: 6 [5632/9728 (58%)]\tLoss: 0.031123\n",
      "Train Epoch: 6 [6144/9728 (63%)]\tLoss: 0.023692\n",
      "Train Epoch: 6 [6656/9728 (68%)]\tLoss: 0.019315\n",
      "Train Epoch: 6 [7168/9728 (74%)]\tLoss: 0.019119\n",
      "Train Epoch: 6 [7680/9728 (79%)]\tLoss: 0.014360\n",
      "Train Epoch: 6 [8192/9728 (84%)]\tLoss: 0.013322\n",
      "Train Epoch: 6 [8704/9728 (89%)]\tLoss: 0.013751\n",
      "Train Epoch: 6 [9216/9728 (95%)]\tLoss: 0.010602\n",
      "Average training loss: 0.814365804195404\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.0582, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 7 [0/39424 (0%)]\tLoss: 10.022610\n",
      "Train Epoch: 7 [512/39424 (1%)]\tLoss: 3.581070\n",
      "Train Epoch: 7 [1024/39424 (3%)]\tLoss: 3.554353\n",
      "Train Epoch: 7 [1536/39424 (4%)]\tLoss: 3.579566\n",
      "Train Epoch: 7 [2048/39424 (5%)]\tLoss: 3.554223\n",
      "Train Epoch: 7 [2560/39424 (6%)]\tLoss: 3.602683\n",
      "Train Epoch: 7 [3072/39424 (8%)]\tLoss: 3.586643\n",
      "Train Epoch: 7 [3584/39424 (9%)]\tLoss: 3.610137\n",
      "Train Epoch: 7 [4096/39424 (10%)]\tLoss: 3.554569\n",
      "Train Epoch: 7 [4608/39424 (12%)]\tLoss: 3.608440\n",
      "Train Epoch: 7 [5120/39424 (13%)]\tLoss: 3.582693\n",
      "Train Epoch: 7 [5632/39424 (14%)]\tLoss: 3.532511\n",
      "Train Epoch: 7 [6144/39424 (16%)]\tLoss: 3.561355\n",
      "Train Epoch: 7 [6656/39424 (17%)]\tLoss: 3.573462\n",
      "Train Epoch: 7 [7168/39424 (18%)]\tLoss: 3.556069\n",
      "Train Epoch: 7 [7680/39424 (19%)]\tLoss: 3.567700\n",
      "Train Epoch: 7 [8192/39424 (21%)]\tLoss: 3.516943\n",
      "Train Epoch: 7 [8704/39424 (22%)]\tLoss: 3.573445\n",
      "Train Epoch: 7 [9216/39424 (23%)]\tLoss: 3.520120\n",
      "Train Epoch: 7 [9728/39424 (25%)]\tLoss: 3.500026\n",
      "Train Epoch: 7 [10240/39424 (26%)]\tLoss: 3.515067\n",
      "Train Epoch: 7 [10752/39424 (27%)]\tLoss: 3.518458\n",
      "Train Epoch: 7 [11264/39424 (29%)]\tLoss: 3.519253\n",
      "Train Epoch: 7 [11776/39424 (30%)]\tLoss: 3.535945\n",
      "Train Epoch: 7 [12288/39424 (31%)]\tLoss: 3.495875\n",
      "Train Epoch: 7 [12800/39424 (32%)]\tLoss: 3.514544\n",
      "Train Epoch: 7 [13312/39424 (34%)]\tLoss: 3.549377\n",
      "Train Epoch: 7 [13824/39424 (35%)]\tLoss: 3.595024\n",
      "Train Epoch: 7 [14336/39424 (36%)]\tLoss: 3.529031\n",
      "Train Epoch: 7 [14848/39424 (38%)]\tLoss: 3.509023\n",
      "Train Epoch: 7 [15360/39424 (39%)]\tLoss: 3.507241\n",
      "Train Epoch: 7 [15872/39424 (40%)]\tLoss: 3.489371\n",
      "Train Epoch: 7 [16384/39424 (42%)]\tLoss: 3.518755\n",
      "Train Epoch: 7 [16896/39424 (43%)]\tLoss: 3.525178\n",
      "Train Epoch: 7 [17408/39424 (44%)]\tLoss: 3.509724\n",
      "Train Epoch: 7 [17920/39424 (45%)]\tLoss: 3.495508\n",
      "Train Epoch: 7 [18432/39424 (47%)]\tLoss: 3.506580\n",
      "Train Epoch: 7 [18944/39424 (48%)]\tLoss: 3.524449\n",
      "Train Epoch: 7 [19456/39424 (49%)]\tLoss: 3.499839\n",
      "Train Epoch: 7 [19968/39424 (51%)]\tLoss: 3.499567\n",
      "Train Epoch: 7 [20480/39424 (52%)]\tLoss: 3.508399\n",
      "Train Epoch: 7 [20992/39424 (53%)]\tLoss: 3.542239\n",
      "Train Epoch: 7 [21504/39424 (55%)]\tLoss: 3.515355\n",
      "Train Epoch: 7 [22016/39424 (56%)]\tLoss: 3.551803\n",
      "Train Epoch: 7 [22528/39424 (57%)]\tLoss: 3.496419\n",
      "Train Epoch: 7 [23040/39424 (58%)]\tLoss: 3.577706\n",
      "Train Epoch: 7 [23552/39424 (60%)]\tLoss: 3.428650\n",
      "Train Epoch: 7 [24064/39424 (61%)]\tLoss: 3.521224\n",
      "Train Epoch: 7 [24576/39424 (62%)]\tLoss: 3.514161\n",
      "Train Epoch: 7 [25088/39424 (64%)]\tLoss: 3.458770\n",
      "Train Epoch: 7 [25600/39424 (65%)]\tLoss: 3.518794\n",
      "Train Epoch: 7 [26112/39424 (66%)]\tLoss: 3.505222\n",
      "Train Epoch: 7 [26624/39424 (68%)]\tLoss: 3.514848\n",
      "Train Epoch: 7 [27136/39424 (69%)]\tLoss: 3.495946\n",
      "Train Epoch: 7 [27648/39424 (70%)]\tLoss: 3.476681\n",
      "Train Epoch: 7 [28160/39424 (71%)]\tLoss: 3.508242\n",
      "Train Epoch: 7 [28672/39424 (73%)]\tLoss: 3.529425\n",
      "Train Epoch: 7 [29184/39424 (74%)]\tLoss: 3.487563\n",
      "Train Epoch: 7 [29696/39424 (75%)]\tLoss: 3.472259\n",
      "Train Epoch: 7 [30208/39424 (77%)]\tLoss: 3.508661\n",
      "Train Epoch: 7 [30720/39424 (78%)]\tLoss: 3.490868\n",
      "Train Epoch: 7 [31232/39424 (79%)]\tLoss: 3.527810\n",
      "Train Epoch: 7 [31744/39424 (81%)]\tLoss: 3.478842\n",
      "Train Epoch: 7 [32256/39424 (82%)]\tLoss: 3.489039\n",
      "Train Epoch: 7 [32768/39424 (83%)]\tLoss: 3.459790\n",
      "Train Epoch: 7 [33280/39424 (84%)]\tLoss: 3.489738\n",
      "Train Epoch: 7 [33792/39424 (86%)]\tLoss: 3.524765\n",
      "Train Epoch: 7 [34304/39424 (87%)]\tLoss: 3.490786\n",
      "Train Epoch: 7 [34816/39424 (88%)]\tLoss: 3.471239\n",
      "Train Epoch: 7 [35328/39424 (90%)]\tLoss: 3.494266\n",
      "Train Epoch: 7 [35840/39424 (91%)]\tLoss: 3.497906\n",
      "Train Epoch: 7 [36352/39424 (92%)]\tLoss: 3.516825\n",
      "Train Epoch: 7 [36864/39424 (94%)]\tLoss: 3.518833\n",
      "Train Epoch: 7 [37376/39424 (95%)]\tLoss: 3.499623\n",
      "Train Epoch: 7 [37888/39424 (96%)]\tLoss: 3.454101\n",
      "Train Epoch: 7 [38400/39424 (97%)]\tLoss: 3.427732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [38912/39424 (99%)]\tLoss: 3.455841\n",
      "Average training loss: 3.6041135787963867\n",
      "\n",
      "Test set: Average loss: 3.2289, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.4854, Accuracy: 1293/12630 (10%)\n",
      "\n",
      "tensor([0.0000, 0.5458, 0.7133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.5069, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 7 [0/9728 (0%)]\tLoss: 3.235597\n",
      "Train Epoch: 7 [512/9728 (5%)]\tLoss: 2.963834\n",
      "Train Epoch: 7 [1024/9728 (11%)]\tLoss: 2.685457\n",
      "Train Epoch: 7 [1536/9728 (16%)]\tLoss: 2.371593\n",
      "Train Epoch: 7 [2048/9728 (21%)]\tLoss: 1.955354\n",
      "Train Epoch: 7 [2560/9728 (26%)]\tLoss: 1.426705\n",
      "Train Epoch: 7 [3072/9728 (32%)]\tLoss: 0.904008\n",
      "Train Epoch: 7 [3584/9728 (37%)]\tLoss: 0.439576\n",
      "Train Epoch: 7 [4096/9728 (42%)]\tLoss: 0.186361\n",
      "Train Epoch: 7 [4608/9728 (47%)]\tLoss: 0.093573\n",
      "Train Epoch: 7 [5120/9728 (53%)]\tLoss: 0.049974\n",
      "Train Epoch: 7 [5632/9728 (58%)]\tLoss: 0.037532\n",
      "Train Epoch: 7 [6144/9728 (63%)]\tLoss: 0.028063\n",
      "Train Epoch: 7 [6656/9728 (68%)]\tLoss: 0.025826\n",
      "Train Epoch: 7 [7168/9728 (74%)]\tLoss: 0.022131\n",
      "Train Epoch: 7 [7680/9728 (79%)]\tLoss: 0.015394\n",
      "Train Epoch: 7 [8192/9728 (84%)]\tLoss: 0.014853\n",
      "Train Epoch: 7 [8704/9728 (89%)]\tLoss: 0.013463\n",
      "Train Epoch: 7 [9216/9728 (95%)]\tLoss: 0.011016\n",
      "Average training loss: 0.8673847913742065\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.8753, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 8 [0/39424 (0%)]\tLoss: 9.732128\n",
      "Train Epoch: 8 [512/39424 (1%)]\tLoss: 3.580645\n",
      "Train Epoch: 8 [1024/39424 (3%)]\tLoss: 3.552282\n",
      "Train Epoch: 8 [1536/39424 (4%)]\tLoss: 3.577938\n",
      "Train Epoch: 8 [2048/39424 (5%)]\tLoss: 3.552004\n",
      "Train Epoch: 8 [2560/39424 (6%)]\tLoss: 3.600478\n",
      "Train Epoch: 8 [3072/39424 (8%)]\tLoss: 3.585134\n",
      "Train Epoch: 8 [3584/39424 (9%)]\tLoss: 3.607917\n",
      "Train Epoch: 8 [4096/39424 (10%)]\tLoss: 3.545621\n",
      "Train Epoch: 8 [4608/39424 (12%)]\tLoss: 3.603565\n",
      "Train Epoch: 8 [5120/39424 (13%)]\tLoss: 3.564759\n",
      "Train Epoch: 8 [5632/39424 (14%)]\tLoss: 3.520569\n",
      "Train Epoch: 8 [6144/39424 (16%)]\tLoss: 3.546523\n",
      "Train Epoch: 8 [6656/39424 (17%)]\tLoss: 3.553469\n",
      "Train Epoch: 8 [7168/39424 (18%)]\tLoss: 3.544548\n",
      "Train Epoch: 8 [7680/39424 (19%)]\tLoss: 3.565451\n",
      "Train Epoch: 8 [8192/39424 (21%)]\tLoss: 3.492815\n",
      "Train Epoch: 8 [8704/39424 (22%)]\tLoss: 3.572947\n",
      "Train Epoch: 8 [9216/39424 (23%)]\tLoss: 3.497143\n",
      "Train Epoch: 8 [9728/39424 (25%)]\tLoss: 3.481579\n",
      "Train Epoch: 8 [10240/39424 (26%)]\tLoss: 3.505304\n",
      "Train Epoch: 8 [10752/39424 (27%)]\tLoss: 3.500231\n",
      "Train Epoch: 8 [11264/39424 (29%)]\tLoss: 3.505316\n",
      "Train Epoch: 8 [11776/39424 (30%)]\tLoss: 3.523523\n",
      "Train Epoch: 8 [12288/39424 (31%)]\tLoss: 3.477962\n",
      "Train Epoch: 8 [12800/39424 (32%)]\tLoss: 3.498309\n",
      "Train Epoch: 8 [13312/39424 (34%)]\tLoss: 3.538229\n",
      "Train Epoch: 8 [13824/39424 (35%)]\tLoss: 3.589256\n",
      "Train Epoch: 8 [14336/39424 (36%)]\tLoss: 3.513866\n",
      "Train Epoch: 8 [14848/39424 (38%)]\tLoss: 3.489622\n",
      "Train Epoch: 8 [15360/39424 (39%)]\tLoss: 3.495967\n",
      "Train Epoch: 8 [15872/39424 (40%)]\tLoss: 3.481156\n",
      "Train Epoch: 8 [16384/39424 (42%)]\tLoss: 3.501784\n",
      "Train Epoch: 8 [16896/39424 (43%)]\tLoss: 3.510265\n",
      "Train Epoch: 8 [17408/39424 (44%)]\tLoss: 3.489434\n",
      "Train Epoch: 8 [17920/39424 (45%)]\tLoss: 3.479623\n",
      "Train Epoch: 8 [18432/39424 (47%)]\tLoss: 3.501395\n",
      "Train Epoch: 8 [18944/39424 (48%)]\tLoss: 3.518260\n",
      "Train Epoch: 8 [19456/39424 (49%)]\tLoss: 3.487344\n",
      "Train Epoch: 8 [19968/39424 (51%)]\tLoss: 3.482298\n",
      "Train Epoch: 8 [20480/39424 (52%)]\tLoss: 3.497668\n",
      "Train Epoch: 8 [20992/39424 (53%)]\tLoss: 3.524879\n",
      "Train Epoch: 8 [21504/39424 (55%)]\tLoss: 3.495166\n",
      "Train Epoch: 8 [22016/39424 (56%)]\tLoss: 3.526248\n",
      "Train Epoch: 8 [22528/39424 (57%)]\tLoss: 3.478441\n",
      "Train Epoch: 8 [23040/39424 (58%)]\tLoss: 3.556425\n",
      "Train Epoch: 8 [23552/39424 (60%)]\tLoss: 3.403031\n",
      "Train Epoch: 8 [24064/39424 (61%)]\tLoss: 3.511155\n",
      "Train Epoch: 8 [24576/39424 (62%)]\tLoss: 3.488425\n",
      "Train Epoch: 8 [25088/39424 (64%)]\tLoss: 3.441428\n",
      "Train Epoch: 8 [25600/39424 (65%)]\tLoss: 3.507924\n",
      "Train Epoch: 8 [26112/39424 (66%)]\tLoss: 3.485329\n",
      "Train Epoch: 8 [26624/39424 (68%)]\tLoss: 3.500290\n",
      "Train Epoch: 8 [27136/39424 (69%)]\tLoss: 3.481935\n",
      "Train Epoch: 8 [27648/39424 (70%)]\tLoss: 3.448781\n",
      "Train Epoch: 8 [28160/39424 (71%)]\tLoss: 3.485291\n",
      "Train Epoch: 8 [28672/39424 (73%)]\tLoss: 3.508694\n",
      "Train Epoch: 8 [29184/39424 (74%)]\tLoss: 3.465598\n",
      "Train Epoch: 8 [29696/39424 (75%)]\tLoss: 3.442571\n",
      "Train Epoch: 8 [30208/39424 (77%)]\tLoss: 3.493120\n",
      "Train Epoch: 8 [30720/39424 (78%)]\tLoss: 3.468548\n",
      "Train Epoch: 8 [31232/39424 (79%)]\tLoss: 3.501099\n",
      "Train Epoch: 8 [31744/39424 (81%)]\tLoss: 3.438984\n",
      "Train Epoch: 8 [32256/39424 (82%)]\tLoss: 3.474353\n",
      "Train Epoch: 8 [32768/39424 (83%)]\tLoss: 3.431964\n",
      "Train Epoch: 8 [33280/39424 (84%)]\tLoss: 3.454751\n",
      "Train Epoch: 8 [33792/39424 (86%)]\tLoss: 3.498824\n",
      "Train Epoch: 8 [34304/39424 (87%)]\tLoss: 3.455464\n",
      "Train Epoch: 8 [34816/39424 (88%)]\tLoss: 3.445146\n",
      "Train Epoch: 8 [35328/39424 (90%)]\tLoss: 3.470135\n",
      "Train Epoch: 8 [35840/39424 (91%)]\tLoss: 3.491582\n",
      "Train Epoch: 8 [36352/39424 (92%)]\tLoss: 3.485034\n",
      "Train Epoch: 8 [36864/39424 (94%)]\tLoss: 3.482624\n",
      "Train Epoch: 8 [37376/39424 (95%)]\tLoss: 3.478834\n",
      "Train Epoch: 8 [37888/39424 (96%)]\tLoss: 3.420995\n",
      "Train Epoch: 8 [38400/39424 (97%)]\tLoss: 3.407824\n",
      "Train Epoch: 8 [38912/39424 (99%)]\tLoss: 3.427953\n",
      "Average training loss: 3.583676815032959\n",
      "\n",
      "Test set: Average loss: 3.1749, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.4635, Accuracy: 1335/12630 (11%)\n",
      "\n",
      "tensor([0.0000, 0.4986, 0.7293, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0188, 0.5736, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 8 [0/9728 (0%)]\tLoss: 3.178059\n",
      "Train Epoch: 8 [512/9728 (5%)]\tLoss: 2.913195\n",
      "Train Epoch: 8 [1024/9728 (11%)]\tLoss: 2.629638\n",
      "Train Epoch: 8 [1536/9728 (16%)]\tLoss: 2.296118\n",
      "Train Epoch: 8 [2048/9728 (21%)]\tLoss: 1.856559\n",
      "Train Epoch: 8 [2560/9728 (26%)]\tLoss: 1.332729\n",
      "Train Epoch: 8 [3072/9728 (32%)]\tLoss: 0.797382\n",
      "Train Epoch: 8 [3584/9728 (37%)]\tLoss: 0.374199\n",
      "Train Epoch: 8 [4096/9728 (42%)]\tLoss: 0.163601\n",
      "Train Epoch: 8 [4608/9728 (47%)]\tLoss: 0.086178\n",
      "Train Epoch: 8 [5120/9728 (53%)]\tLoss: 0.050639\n",
      "Train Epoch: 8 [5632/9728 (58%)]\tLoss: 0.037509\n",
      "Train Epoch: 8 [6144/9728 (63%)]\tLoss: 0.030202\n",
      "Train Epoch: 8 [6656/9728 (68%)]\tLoss: 0.024325\n",
      "Train Epoch: 8 [7168/9728 (74%)]\tLoss: 0.024390\n",
      "Train Epoch: 8 [7680/9728 (79%)]\tLoss: 0.016290\n",
      "Train Epoch: 8 [8192/9728 (84%)]\tLoss: 0.014739\n",
      "Train Epoch: 8 [8704/9728 (89%)]\tLoss: 0.011987\n",
      "Train Epoch: 8 [9216/9728 (95%)]\tLoss: 0.013008\n",
      "Average training loss: 0.8342499136924744\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.6621, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 9 [0/39424 (0%)]\tLoss: 9.606024\n",
      "Train Epoch: 9 [512/39424 (1%)]\tLoss: 3.564069\n",
      "Train Epoch: 9 [1024/39424 (3%)]\tLoss: 3.527424\n",
      "Train Epoch: 9 [1536/39424 (4%)]\tLoss: 3.553071\n",
      "Train Epoch: 9 [2048/39424 (5%)]\tLoss: 3.529492\n",
      "Train Epoch: 9 [2560/39424 (6%)]\tLoss: 3.586248\n",
      "Train Epoch: 9 [3072/39424 (8%)]\tLoss: 3.563173\n",
      "Train Epoch: 9 [3584/39424 (9%)]\tLoss: 3.599542\n",
      "Train Epoch: 9 [4096/39424 (10%)]\tLoss: 3.520989\n",
      "Train Epoch: 9 [4608/39424 (12%)]\tLoss: 3.578947\n",
      "Train Epoch: 9 [5120/39424 (13%)]\tLoss: 3.545155\n",
      "Train Epoch: 9 [5632/39424 (14%)]\tLoss: 3.502938\n",
      "Train Epoch: 9 [6144/39424 (16%)]\tLoss: 3.524310\n",
      "Train Epoch: 9 [6656/39424 (17%)]\tLoss: 3.530048\n",
      "Train Epoch: 9 [7168/39424 (18%)]\tLoss: 3.521464\n",
      "Train Epoch: 9 [7680/39424 (19%)]\tLoss: 3.541686\n",
      "Train Epoch: 9 [8192/39424 (21%)]\tLoss: 3.468436\n",
      "Train Epoch: 9 [8704/39424 (22%)]\tLoss: 3.562313\n",
      "Train Epoch: 9 [9216/39424 (23%)]\tLoss: 3.470845\n",
      "Train Epoch: 9 [9728/39424 (25%)]\tLoss: 3.461883\n",
      "Train Epoch: 9 [10240/39424 (26%)]\tLoss: 3.479732\n",
      "Train Epoch: 9 [10752/39424 (27%)]\tLoss: 3.471540\n",
      "Train Epoch: 9 [11264/39424 (29%)]\tLoss: 3.477951\n",
      "Train Epoch: 9 [11776/39424 (30%)]\tLoss: 3.494426\n",
      "Train Epoch: 9 [12288/39424 (31%)]\tLoss: 3.456001\n",
      "Train Epoch: 9 [12800/39424 (32%)]\tLoss: 3.465781\n",
      "Train Epoch: 9 [13312/39424 (34%)]\tLoss: 3.512305\n",
      "Train Epoch: 9 [13824/39424 (35%)]\tLoss: 3.559525\n",
      "Train Epoch: 9 [14336/39424 (36%)]\tLoss: 3.487362\n",
      "Train Epoch: 9 [14848/39424 (38%)]\tLoss: 3.462223\n",
      "Train Epoch: 9 [15360/39424 (39%)]\tLoss: 3.463475\n",
      "Train Epoch: 9 [15872/39424 (40%)]\tLoss: 3.446886\n",
      "Train Epoch: 9 [16384/39424 (42%)]\tLoss: 3.464573\n",
      "Train Epoch: 9 [16896/39424 (43%)]\tLoss: 3.482780\n",
      "Train Epoch: 9 [17408/39424 (44%)]\tLoss: 3.465768\n",
      "Train Epoch: 9 [17920/39424 (45%)]\tLoss: 3.445961\n",
      "Train Epoch: 9 [18432/39424 (47%)]\tLoss: 3.469306\n",
      "Train Epoch: 9 [18944/39424 (48%)]\tLoss: 3.482515\n",
      "Train Epoch: 9 [19456/39424 (49%)]\tLoss: 3.452081\n",
      "Train Epoch: 9 [19968/39424 (51%)]\tLoss: 3.438153\n",
      "Train Epoch: 9 [20480/39424 (52%)]\tLoss: 3.464458\n",
      "Train Epoch: 9 [20992/39424 (53%)]\tLoss: 3.487872\n",
      "Train Epoch: 9 [21504/39424 (55%)]\tLoss: 3.452478\n",
      "Train Epoch: 9 [22016/39424 (56%)]\tLoss: 3.496383\n",
      "Train Epoch: 9 [22528/39424 (57%)]\tLoss: 3.444791\n",
      "Train Epoch: 9 [23040/39424 (58%)]\tLoss: 3.515327\n",
      "Train Epoch: 9 [23552/39424 (60%)]\tLoss: 3.366439\n",
      "Train Epoch: 9 [24064/39424 (61%)]\tLoss: 3.474414\n",
      "Train Epoch: 9 [24576/39424 (62%)]\tLoss: 3.457946\n",
      "Train Epoch: 9 [25088/39424 (64%)]\tLoss: 3.410681\n",
      "Train Epoch: 9 [25600/39424 (65%)]\tLoss: 3.472793\n",
      "Train Epoch: 9 [26112/39424 (66%)]\tLoss: 3.466769\n",
      "Train Epoch: 9 [26624/39424 (68%)]\tLoss: 3.454862\n",
      "Train Epoch: 9 [27136/39424 (69%)]\tLoss: 3.441993\n",
      "Train Epoch: 9 [27648/39424 (70%)]\tLoss: 3.420124\n",
      "Train Epoch: 9 [28160/39424 (71%)]\tLoss: 3.447167\n",
      "Train Epoch: 9 [28672/39424 (73%)]\tLoss: 3.465125\n",
      "Train Epoch: 9 [29184/39424 (74%)]\tLoss: 3.422381\n",
      "Train Epoch: 9 [29696/39424 (75%)]\tLoss: 3.401926\n",
      "Train Epoch: 9 [30208/39424 (77%)]\tLoss: 3.459439\n",
      "Train Epoch: 9 [30720/39424 (78%)]\tLoss: 3.427249\n",
      "Train Epoch: 9 [31232/39424 (79%)]\tLoss: 3.475965\n",
      "Train Epoch: 9 [31744/39424 (81%)]\tLoss: 3.410455\n",
      "Train Epoch: 9 [32256/39424 (82%)]\tLoss: 3.433622\n",
      "Train Epoch: 9 [32768/39424 (83%)]\tLoss: 3.392811\n",
      "Train Epoch: 9 [33280/39424 (84%)]\tLoss: 3.422958\n",
      "Train Epoch: 9 [33792/39424 (86%)]\tLoss: 3.450060\n",
      "Train Epoch: 9 [34304/39424 (87%)]\tLoss: 3.407532\n",
      "Train Epoch: 9 [34816/39424 (88%)]\tLoss: 3.403547\n",
      "Train Epoch: 9 [35328/39424 (90%)]\tLoss: 3.433083\n",
      "Train Epoch: 9 [35840/39424 (91%)]\tLoss: 3.447409\n",
      "Train Epoch: 9 [36352/39424 (92%)]\tLoss: 3.452681\n",
      "Train Epoch: 9 [36864/39424 (94%)]\tLoss: 3.444198\n",
      "Train Epoch: 9 [37376/39424 (95%)]\tLoss: 3.451765\n",
      "Train Epoch: 9 [37888/39424 (96%)]\tLoss: 3.396116\n",
      "Train Epoch: 9 [38400/39424 (97%)]\tLoss: 3.359563\n",
      "Train Epoch: 9 [38912/39424 (99%)]\tLoss: 3.396473\n",
      "Average training loss: 3.551496982574463\n",
      "\n",
      "Test set: Average loss: 3.1776, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.4285, Accuracy: 1731/12630 (14%)\n",
      "\n",
      "tensor([0.0000, 0.4583, 0.2707, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7576, 0.0000, 0.1333, 0.6153, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2362, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 9 [0/9728 (0%)]\tLoss: 3.187073\n",
      "Train Epoch: 9 [512/9728 (5%)]\tLoss: 2.895596\n",
      "Train Epoch: 9 [1024/9728 (11%)]\tLoss: 2.585097\n",
      "Train Epoch: 9 [1536/9728 (16%)]\tLoss: 2.216773\n",
      "Train Epoch: 9 [2048/9728 (21%)]\tLoss: 1.739967\n",
      "Train Epoch: 9 [2560/9728 (26%)]\tLoss: 1.165947\n",
      "Train Epoch: 9 [3072/9728 (32%)]\tLoss: 0.618509\n",
      "Train Epoch: 9 [3584/9728 (37%)]\tLoss: 0.256214\n",
      "Train Epoch: 9 [4096/9728 (42%)]\tLoss: 0.122305\n",
      "Train Epoch: 9 [4608/9728 (47%)]\tLoss: 0.072896\n",
      "Train Epoch: 9 [5120/9728 (53%)]\tLoss: 0.043042\n",
      "Train Epoch: 9 [5632/9728 (58%)]\tLoss: 0.036197\n",
      "Train Epoch: 9 [6144/9728 (63%)]\tLoss: 0.027122\n",
      "Train Epoch: 9 [6656/9728 (68%)]\tLoss: 0.024436\n",
      "Train Epoch: 9 [7168/9728 (74%)]\tLoss: 0.022549\n",
      "Train Epoch: 9 [7680/9728 (79%)]\tLoss: 0.014782\n",
      "Train Epoch: 9 [8192/9728 (84%)]\tLoss: 0.015027\n",
      "Train Epoch: 9 [8704/9728 (89%)]\tLoss: 0.012528\n",
      "Train Epoch: 9 [9216/9728 (95%)]\tLoss: 0.012404\n",
      "Average training loss: 0.7930771112442017\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.5696, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 10 [0/39424 (0%)]\tLoss: 9.573744\n",
      "Train Epoch: 10 [512/39424 (1%)]\tLoss: 3.524694\n",
      "Train Epoch: 10 [1024/39424 (3%)]\tLoss: 3.503704\n",
      "Train Epoch: 10 [1536/39424 (4%)]\tLoss: 3.517621\n",
      "Train Epoch: 10 [2048/39424 (5%)]\tLoss: 3.487103\n",
      "Train Epoch: 10 [2560/39424 (6%)]\tLoss: 3.534600\n",
      "Train Epoch: 10 [3072/39424 (8%)]\tLoss: 3.533279\n",
      "Train Epoch: 10 [3584/39424 (9%)]\tLoss: 3.558982\n",
      "Train Epoch: 10 [4096/39424 (10%)]\tLoss: 3.470356\n",
      "Train Epoch: 10 [4608/39424 (12%)]\tLoss: 3.554802\n",
      "Train Epoch: 10 [5120/39424 (13%)]\tLoss: 3.507212\n",
      "Train Epoch: 10 [5632/39424 (14%)]\tLoss: 3.462964\n",
      "Train Epoch: 10 [6144/39424 (16%)]\tLoss: 3.479483\n",
      "Train Epoch: 10 [6656/39424 (17%)]\tLoss: 3.494564\n",
      "Train Epoch: 10 [7168/39424 (18%)]\tLoss: 3.485215\n",
      "Train Epoch: 10 [7680/39424 (19%)]\tLoss: 3.503722\n",
      "Train Epoch: 10 [8192/39424 (21%)]\tLoss: 3.431380\n",
      "Train Epoch: 10 [8704/39424 (22%)]\tLoss: 3.502177\n",
      "Train Epoch: 10 [9216/39424 (23%)]\tLoss: 3.424774\n",
      "Train Epoch: 10 [9728/39424 (25%)]\tLoss: 3.426329\n",
      "Train Epoch: 10 [10240/39424 (26%)]\tLoss: 3.438419\n",
      "Train Epoch: 10 [10752/39424 (27%)]\tLoss: 3.426829\n",
      "Train Epoch: 10 [11264/39424 (29%)]\tLoss: 3.446355\n",
      "Train Epoch: 10 [11776/39424 (30%)]\tLoss: 3.454485\n",
      "Train Epoch: 10 [12288/39424 (31%)]\tLoss: 3.406462\n",
      "Train Epoch: 10 [12800/39424 (32%)]\tLoss: 3.428675\n",
      "Train Epoch: 10 [13312/39424 (34%)]\tLoss: 3.472828\n",
      "Train Epoch: 10 [13824/39424 (35%)]\tLoss: 3.516356\n",
      "Train Epoch: 10 [14336/39424 (36%)]\tLoss: 3.436656\n",
      "Train Epoch: 10 [14848/39424 (38%)]\tLoss: 3.422859\n",
      "Train Epoch: 10 [15360/39424 (39%)]\tLoss: 3.422510\n",
      "Train Epoch: 10 [15872/39424 (40%)]\tLoss: 3.385768\n",
      "Train Epoch: 10 [16384/39424 (42%)]\tLoss: 3.405339\n",
      "Train Epoch: 10 [16896/39424 (43%)]\tLoss: 3.445624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [17408/39424 (44%)]\tLoss: 3.419296\n",
      "Train Epoch: 10 [17920/39424 (45%)]\tLoss: 3.392554\n",
      "Train Epoch: 10 [18432/39424 (47%)]\tLoss: 3.429990\n",
      "Train Epoch: 10 [18944/39424 (48%)]\tLoss: 3.443420\n",
      "Train Epoch: 10 [19456/39424 (49%)]\tLoss: 3.405122\n",
      "Train Epoch: 10 [19968/39424 (51%)]\tLoss: 3.393548\n",
      "Train Epoch: 10 [20480/39424 (52%)]\tLoss: 3.412758\n",
      "Train Epoch: 10 [20992/39424 (53%)]\tLoss: 3.441256\n",
      "Train Epoch: 10 [21504/39424 (55%)]\tLoss: 3.402185\n",
      "Train Epoch: 10 [22016/39424 (56%)]\tLoss: 3.445090\n",
      "Train Epoch: 10 [22528/39424 (57%)]\tLoss: 3.386822\n",
      "Train Epoch: 10 [23040/39424 (58%)]\tLoss: 3.463333\n",
      "Train Epoch: 10 [23552/39424 (60%)]\tLoss: 3.339067\n",
      "Train Epoch: 10 [24064/39424 (61%)]\tLoss: 3.421662\n",
      "Train Epoch: 10 [24576/39424 (62%)]\tLoss: 3.405242\n",
      "Train Epoch: 10 [25088/39424 (64%)]\tLoss: 3.357321\n",
      "Train Epoch: 10 [25600/39424 (65%)]\tLoss: 3.431399\n",
      "Train Epoch: 10 [26112/39424 (66%)]\tLoss: 3.411259\n",
      "Train Epoch: 10 [26624/39424 (68%)]\tLoss: 3.407504\n",
      "Train Epoch: 10 [27136/39424 (69%)]\tLoss: 3.385543\n",
      "Train Epoch: 10 [27648/39424 (70%)]\tLoss: 3.369471\n",
      "Train Epoch: 10 [28160/39424 (71%)]\tLoss: 3.404651\n",
      "Train Epoch: 10 [28672/39424 (73%)]\tLoss: 3.388997\n",
      "Train Epoch: 10 [29184/39424 (74%)]\tLoss: 3.361437\n",
      "Train Epoch: 10 [29696/39424 (75%)]\tLoss: 3.329513\n",
      "Train Epoch: 10 [30208/39424 (77%)]\tLoss: 3.422189\n",
      "Train Epoch: 10 [30720/39424 (78%)]\tLoss: 3.372844\n",
      "Train Epoch: 10 [31232/39424 (79%)]\tLoss: 3.418399\n",
      "Train Epoch: 10 [31744/39424 (81%)]\tLoss: 3.361729\n",
      "Train Epoch: 10 [32256/39424 (82%)]\tLoss: 3.392186\n",
      "Train Epoch: 10 [32768/39424 (83%)]\tLoss: 3.327017\n",
      "Train Epoch: 10 [33280/39424 (84%)]\tLoss: 3.358508\n",
      "Train Epoch: 10 [33792/39424 (86%)]\tLoss: 3.386848\n",
      "Train Epoch: 10 [34304/39424 (87%)]\tLoss: 3.364513\n",
      "Train Epoch: 10 [34816/39424 (88%)]\tLoss: 3.331138\n",
      "Train Epoch: 10 [35328/39424 (90%)]\tLoss: 3.364290\n",
      "Train Epoch: 10 [35840/39424 (91%)]\tLoss: 3.384850\n",
      "Train Epoch: 10 [36352/39424 (92%)]\tLoss: 3.381197\n",
      "Train Epoch: 10 [36864/39424 (94%)]\tLoss: 3.383443\n",
      "Train Epoch: 10 [37376/39424 (95%)]\tLoss: 3.384350\n",
      "Train Epoch: 10 [37888/39424 (96%)]\tLoss: 3.335465\n",
      "Train Epoch: 10 [38400/39424 (97%)]\tLoss: 3.287742\n",
      "Train Epoch: 10 [38912/39424 (99%)]\tLoss: 3.339782\n",
      "Average training loss: 3.5029971599578857\n",
      "\n",
      "Test set: Average loss: 3.2266, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.3686, Accuracy: 1893/12630 (15%)\n",
      "\n",
      "tensor([0.0000, 0.4361, 0.2560, 0.0089, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8061, 0.0000, 0.2855, 0.6347, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2855, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 10 [0/9728 (0%)]\tLoss: 3.233801\n",
      "Train Epoch: 10 [512/9728 (5%)]\tLoss: 2.887658\n",
      "Train Epoch: 10 [1024/9728 (11%)]\tLoss: 2.515528\n",
      "Train Epoch: 10 [1536/9728 (16%)]\tLoss: 2.088687\n",
      "Train Epoch: 10 [2048/9728 (21%)]\tLoss: 1.523900\n",
      "Train Epoch: 10 [2560/9728 (26%)]\tLoss: 0.903978\n",
      "Train Epoch: 10 [3072/9728 (32%)]\tLoss: 0.439487\n",
      "Train Epoch: 10 [3584/9728 (37%)]\tLoss: 0.193804\n",
      "Train Epoch: 10 [4096/9728 (42%)]\tLoss: 0.095834\n",
      "Train Epoch: 10 [4608/9728 (47%)]\tLoss: 0.059272\n",
      "Train Epoch: 10 [5120/9728 (53%)]\tLoss: 0.040619\n",
      "Train Epoch: 10 [5632/9728 (58%)]\tLoss: 0.031373\n",
      "Train Epoch: 10 [6144/9728 (63%)]\tLoss: 0.023801\n",
      "Train Epoch: 10 [6656/9728 (68%)]\tLoss: 0.021683\n",
      "Train Epoch: 10 [7168/9728 (74%)]\tLoss: 0.019983\n",
      "Train Epoch: 10 [7680/9728 (79%)]\tLoss: 0.014828\n",
      "Train Epoch: 10 [8192/9728 (84%)]\tLoss: 0.013289\n",
      "Train Epoch: 10 [8704/9728 (89%)]\tLoss: 0.012323\n",
      "Train Epoch: 10 [9216/9728 (95%)]\tLoss: 0.010537\n",
      "Average training loss: 0.743704617023468\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.7330, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 11 [0/39424 (0%)]\tLoss: 9.702843\n",
      "Train Epoch: 11 [512/39424 (1%)]\tLoss: 3.471242\n",
      "Train Epoch: 11 [1024/39424 (3%)]\tLoss: 3.444290\n",
      "Train Epoch: 11 [1536/39424 (4%)]\tLoss: 3.467381\n",
      "Train Epoch: 11 [2048/39424 (5%)]\tLoss: 3.429715\n",
      "Train Epoch: 11 [2560/39424 (6%)]\tLoss: 3.460701\n",
      "Train Epoch: 11 [3072/39424 (8%)]\tLoss: 3.472676\n",
      "Train Epoch: 11 [3584/39424 (9%)]\tLoss: 3.500312\n",
      "Train Epoch: 11 [4096/39424 (10%)]\tLoss: 3.406541\n",
      "Train Epoch: 11 [4608/39424 (12%)]\tLoss: 3.496749\n",
      "Train Epoch: 11 [5120/39424 (13%)]\tLoss: 3.442691\n",
      "Train Epoch: 11 [5632/39424 (14%)]\tLoss: 3.402410\n",
      "Train Epoch: 11 [6144/39424 (16%)]\tLoss: 3.422894\n",
      "Train Epoch: 11 [6656/39424 (17%)]\tLoss: 3.425687\n",
      "Train Epoch: 11 [7168/39424 (18%)]\tLoss: 3.424270\n",
      "Train Epoch: 11 [7680/39424 (19%)]\tLoss: 3.437616\n",
      "Train Epoch: 11 [8192/39424 (21%)]\tLoss: 3.365430\n",
      "Train Epoch: 11 [8704/39424 (22%)]\tLoss: 3.448460\n",
      "Train Epoch: 11 [9216/39424 (23%)]\tLoss: 3.346042\n",
      "Train Epoch: 11 [9728/39424 (25%)]\tLoss: 3.350596\n",
      "Train Epoch: 11 [10240/39424 (26%)]\tLoss: 3.369178\n",
      "Train Epoch: 11 [10752/39424 (27%)]\tLoss: 3.355271\n",
      "Train Epoch: 11 [11264/39424 (29%)]\tLoss: 3.365069\n",
      "Train Epoch: 11 [11776/39424 (30%)]\tLoss: 3.368970\n",
      "Train Epoch: 11 [12288/39424 (31%)]\tLoss: 3.326267\n",
      "Train Epoch: 11 [12800/39424 (32%)]\tLoss: 3.355179\n",
      "Train Epoch: 11 [13312/39424 (34%)]\tLoss: 3.398789\n",
      "Train Epoch: 11 [13824/39424 (35%)]\tLoss: 3.455301\n",
      "Train Epoch: 11 [14336/39424 (36%)]\tLoss: 3.362441\n",
      "Train Epoch: 11 [14848/39424 (38%)]\tLoss: 3.338122\n",
      "Train Epoch: 11 [15360/39424 (39%)]\tLoss: 3.356740\n",
      "Train Epoch: 11 [15872/39424 (40%)]\tLoss: 3.313092\n",
      "Train Epoch: 11 [16384/39424 (42%)]\tLoss: 3.319195\n",
      "Train Epoch: 11 [16896/39424 (43%)]\tLoss: 3.378009\n",
      "Train Epoch: 11 [17408/39424 (44%)]\tLoss: 3.329228\n",
      "Train Epoch: 11 [17920/39424 (45%)]\tLoss: 3.310561\n",
      "Train Epoch: 11 [18432/39424 (47%)]\tLoss: 3.328932\n",
      "Train Epoch: 11 [18944/39424 (48%)]\tLoss: 3.371781\n",
      "Train Epoch: 11 [19456/39424 (49%)]\tLoss: 3.329111\n",
      "Train Epoch: 11 [19968/39424 (51%)]\tLoss: 3.291913\n",
      "Train Epoch: 11 [20480/39424 (52%)]\tLoss: 3.307994\n",
      "Train Epoch: 11 [20992/39424 (53%)]\tLoss: 3.368158\n",
      "Train Epoch: 11 [21504/39424 (55%)]\tLoss: 3.308110\n",
      "Train Epoch: 11 [22016/39424 (56%)]\tLoss: 3.372843\n",
      "Train Epoch: 11 [22528/39424 (57%)]\tLoss: 3.300068\n",
      "Train Epoch: 11 [23040/39424 (58%)]\tLoss: 3.386738\n",
      "Train Epoch: 11 [23552/39424 (60%)]\tLoss: 3.229390\n",
      "Train Epoch: 11 [24064/39424 (61%)]\tLoss: 3.314748\n",
      "Train Epoch: 11 [24576/39424 (62%)]\tLoss: 3.317992\n",
      "Train Epoch: 11 [25088/39424 (64%)]\tLoss: 3.255971\n",
      "Train Epoch: 11 [25600/39424 (65%)]\tLoss: 3.319685\n",
      "Train Epoch: 11 [26112/39424 (66%)]\tLoss: 3.323005\n",
      "Train Epoch: 11 [26624/39424 (68%)]\tLoss: 3.317141\n",
      "Train Epoch: 11 [27136/39424 (69%)]\tLoss: 3.305959\n",
      "Train Epoch: 11 [27648/39424 (70%)]\tLoss: 3.275711\n",
      "Train Epoch: 11 [28160/39424 (71%)]\tLoss: 3.291039\n",
      "Train Epoch: 11 [28672/39424 (73%)]\tLoss: 3.281761\n",
      "Train Epoch: 11 [29184/39424 (74%)]\tLoss: 3.248096\n",
      "Train Epoch: 11 [29696/39424 (75%)]\tLoss: 3.229639\n",
      "Train Epoch: 11 [30208/39424 (77%)]\tLoss: 3.326514\n",
      "Train Epoch: 11 [30720/39424 (78%)]\tLoss: 3.274961\n",
      "Train Epoch: 11 [31232/39424 (79%)]\tLoss: 3.302031\n",
      "Train Epoch: 11 [31744/39424 (81%)]\tLoss: 3.235020\n",
      "Train Epoch: 11 [32256/39424 (82%)]\tLoss: 3.286249\n",
      "Train Epoch: 11 [32768/39424 (83%)]\tLoss: 3.190204\n",
      "Train Epoch: 11 [33280/39424 (84%)]\tLoss: 3.226134\n",
      "Train Epoch: 11 [33792/39424 (86%)]\tLoss: 3.263406\n",
      "Train Epoch: 11 [34304/39424 (87%)]\tLoss: 3.224363\n",
      "Train Epoch: 11 [34816/39424 (88%)]\tLoss: 3.203250\n",
      "Train Epoch: 11 [35328/39424 (90%)]\tLoss: 3.232359\n",
      "Train Epoch: 11 [35840/39424 (91%)]\tLoss: 3.269750\n",
      "Train Epoch: 11 [36352/39424 (92%)]\tLoss: 3.248705\n",
      "Train Epoch: 11 [36864/39424 (94%)]\tLoss: 3.258749\n",
      "Train Epoch: 11 [37376/39424 (95%)]\tLoss: 3.251672\n",
      "Train Epoch: 11 [37888/39424 (96%)]\tLoss: 3.213027\n",
      "Train Epoch: 11 [38400/39424 (97%)]\tLoss: 3.128267\n",
      "Train Epoch: 11 [38912/39424 (99%)]\tLoss: 3.217780\n",
      "Average training loss: 3.4162099361419678\n",
      "\n",
      "Test set: Average loss: 3.3318, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 3.2293, Accuracy: 2605/12630 (21%)\n",
      "\n",
      "tensor([0.0000, 0.4292, 0.3227, 0.0667, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7470, 0.0524, 0.5130, 0.7181, 0.0000, 0.0000, 0.0000, 0.4667,\n",
      "        0.0641, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1667,\n",
      "        0.0000, 0.0000, 0.5493, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 11 [0/9728 (0%)]\tLoss: 3.340107\n",
      "Train Epoch: 11 [512/9728 (5%)]\tLoss: 2.818679\n",
      "Train Epoch: 11 [1024/9728 (11%)]\tLoss: 2.311158\n",
      "Train Epoch: 11 [1536/9728 (16%)]\tLoss: 1.729681\n",
      "Train Epoch: 11 [2048/9728 (21%)]\tLoss: 1.056200\n",
      "Train Epoch: 11 [2560/9728 (26%)]\tLoss: 0.529030\n",
      "Train Epoch: 11 [3072/9728 (32%)]\tLoss: 0.242200\n",
      "Train Epoch: 11 [3584/9728 (37%)]\tLoss: 0.128172\n",
      "Train Epoch: 11 [4096/9728 (42%)]\tLoss: 0.073809\n",
      "Train Epoch: 11 [4608/9728 (47%)]\tLoss: 0.048713\n",
      "Train Epoch: 11 [5120/9728 (53%)]\tLoss: 0.031007\n",
      "Train Epoch: 11 [5632/9728 (58%)]\tLoss: 0.026999\n",
      "Train Epoch: 11 [6144/9728 (63%)]\tLoss: 0.023584\n",
      "Train Epoch: 11 [6656/9728 (68%)]\tLoss: 0.019960\n",
      "Train Epoch: 11 [7168/9728 (74%)]\tLoss: 0.017035\n",
      "Train Epoch: 11 [7680/9728 (79%)]\tLoss: 0.014006\n",
      "Train Epoch: 11 [8192/9728 (84%)]\tLoss: 0.011455\n",
      "Train Epoch: 11 [8704/9728 (89%)]\tLoss: 0.010894\n",
      "Train Epoch: 11 [9216/9728 (95%)]\tLoss: 0.010026\n",
      "Average training loss: 0.6548796892166138\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.2334, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 12 [0/39424 (0%)]\tLoss: 10.114206\n",
      "Train Epoch: 12 [512/39424 (1%)]\tLoss: 3.333018\n",
      "Train Epoch: 12 [1024/39424 (3%)]\tLoss: 3.314338\n",
      "Train Epoch: 12 [1536/39424 (4%)]\tLoss: 3.337638\n",
      "Train Epoch: 12 [2048/39424 (5%)]\tLoss: 3.291575\n",
      "Train Epoch: 12 [2560/39424 (6%)]\tLoss: 3.317470\n",
      "Train Epoch: 12 [3072/39424 (8%)]\tLoss: 3.337254\n",
      "Train Epoch: 12 [3584/39424 (9%)]\tLoss: 3.353008\n",
      "Train Epoch: 12 [4096/39424 (10%)]\tLoss: 3.272306\n",
      "Train Epoch: 12 [4608/39424 (12%)]\tLoss: 3.350148\n",
      "Train Epoch: 12 [5120/39424 (13%)]\tLoss: 3.296756\n",
      "Train Epoch: 12 [5632/39424 (14%)]\tLoss: 3.267233\n",
      "Train Epoch: 12 [6144/39424 (16%)]\tLoss: 3.276496\n",
      "Train Epoch: 12 [6656/39424 (17%)]\tLoss: 3.278433\n",
      "Train Epoch: 12 [7168/39424 (18%)]\tLoss: 3.273891\n",
      "Train Epoch: 12 [7680/39424 (19%)]\tLoss: 3.308149\n",
      "Train Epoch: 12 [8192/39424 (21%)]\tLoss: 3.222578\n",
      "Train Epoch: 12 [8704/39424 (22%)]\tLoss: 3.317499\n",
      "Train Epoch: 12 [9216/39424 (23%)]\tLoss: 3.194064\n",
      "Train Epoch: 12 [9728/39424 (25%)]\tLoss: 3.174388\n",
      "Train Epoch: 12 [10240/39424 (26%)]\tLoss: 3.198959\n",
      "Train Epoch: 12 [10752/39424 (27%)]\tLoss: 3.167481\n",
      "Train Epoch: 12 [11264/39424 (29%)]\tLoss: 3.203224\n",
      "Train Epoch: 12 [11776/39424 (30%)]\tLoss: 3.183461\n",
      "Train Epoch: 12 [12288/39424 (31%)]\tLoss: 3.159062\n",
      "Train Epoch: 12 [12800/39424 (32%)]\tLoss: 3.150903\n",
      "Train Epoch: 12 [13312/39424 (34%)]\tLoss: 3.253423\n",
      "Train Epoch: 12 [13824/39424 (35%)]\tLoss: 3.255584\n",
      "Train Epoch: 12 [14336/39424 (36%)]\tLoss: 3.179356\n",
      "Train Epoch: 12 [14848/39424 (38%)]\tLoss: 3.149396\n",
      "Train Epoch: 12 [15360/39424 (39%)]\tLoss: 3.198629\n",
      "Train Epoch: 12 [15872/39424 (40%)]\tLoss: 3.104395\n",
      "Train Epoch: 12 [16384/39424 (42%)]\tLoss: 3.115906\n",
      "Train Epoch: 12 [16896/39424 (43%)]\tLoss: 3.190113\n",
      "Train Epoch: 12 [17408/39424 (44%)]\tLoss: 3.112875\n",
      "Train Epoch: 12 [17920/39424 (45%)]\tLoss: 3.115239\n",
      "Train Epoch: 12 [18432/39424 (47%)]\tLoss: 3.141864\n",
      "Train Epoch: 12 [18944/39424 (48%)]\tLoss: 3.163171\n",
      "Train Epoch: 12 [19456/39424 (49%)]\tLoss: 3.132604\n",
      "Train Epoch: 12 [19968/39424 (51%)]\tLoss: 3.086513\n",
      "Train Epoch: 12 [20480/39424 (52%)]\tLoss: 3.080722\n",
      "Train Epoch: 12 [20992/39424 (53%)]\tLoss: 3.129753\n",
      "Train Epoch: 12 [21504/39424 (55%)]\tLoss: 3.100728\n",
      "Train Epoch: 12 [22016/39424 (56%)]\tLoss: 3.140958\n",
      "Train Epoch: 12 [22528/39424 (57%)]\tLoss: 3.028029\n",
      "Train Epoch: 12 [23040/39424 (58%)]\tLoss: 3.137085\n",
      "Train Epoch: 12 [23552/39424 (60%)]\tLoss: 2.994864\n",
      "Train Epoch: 12 [24064/39424 (61%)]\tLoss: 3.053032\n",
      "Train Epoch: 12 [24576/39424 (62%)]\tLoss: 3.022505\n",
      "Train Epoch: 12 [25088/39424 (64%)]\tLoss: 2.978588\n",
      "Train Epoch: 12 [25600/39424 (65%)]\tLoss: 3.053363\n",
      "Train Epoch: 12 [26112/39424 (66%)]\tLoss: 3.070622\n",
      "Train Epoch: 12 [26624/39424 (68%)]\tLoss: 3.060367\n",
      "Train Epoch: 12 [27136/39424 (69%)]\tLoss: 3.028527\n",
      "Train Epoch: 12 [27648/39424 (70%)]\tLoss: 2.997255\n",
      "Train Epoch: 12 [28160/39424 (71%)]\tLoss: 3.006397\n",
      "Train Epoch: 12 [28672/39424 (73%)]\tLoss: 2.947884\n",
      "Train Epoch: 12 [29184/39424 (74%)]\tLoss: 2.907608\n",
      "Train Epoch: 12 [29696/39424 (75%)]\tLoss: 2.928250\n",
      "Train Epoch: 12 [30208/39424 (77%)]\tLoss: 3.030086\n",
      "Train Epoch: 12 [30720/39424 (78%)]\tLoss: 2.950135\n",
      "Train Epoch: 12 [31232/39424 (79%)]\tLoss: 2.981355\n",
      "Train Epoch: 12 [31744/39424 (81%)]\tLoss: 2.931319\n",
      "Train Epoch: 12 [32256/39424 (82%)]\tLoss: 2.952421\n",
      "Train Epoch: 12 [32768/39424 (83%)]\tLoss: 2.890007\n",
      "Train Epoch: 12 [33280/39424 (84%)]\tLoss: 2.870293\n",
      "Train Epoch: 12 [33792/39424 (86%)]\tLoss: 2.900013\n",
      "Train Epoch: 12 [34304/39424 (87%)]\tLoss: 2.864013\n",
      "Train Epoch: 12 [34816/39424 (88%)]\tLoss: 2.857364\n",
      "Train Epoch: 12 [35328/39424 (90%)]\tLoss: 2.914128\n",
      "Train Epoch: 12 [35840/39424 (91%)]\tLoss: 2.921153\n",
      "Train Epoch: 12 [36352/39424 (92%)]\tLoss: 2.859111\n",
      "Train Epoch: 12 [36864/39424 (94%)]\tLoss: 2.909121\n",
      "Train Epoch: 12 [37376/39424 (95%)]\tLoss: 2.899373\n",
      "Train Epoch: 12 [37888/39424 (96%)]\tLoss: 2.854674\n",
      "Train Epoch: 12 [38400/39424 (97%)]\tLoss: 2.712115\n",
      "Train Epoch: 12 [38912/39424 (99%)]\tLoss: 2.814607\n",
      "Average training loss: 3.1905252933502197\n",
      "\n",
      "Test set: Average loss: 3.6546, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 2.8275, Accuracy: 3937/12630 (31%)\n",
      "\n",
      "tensor([0.0000, 0.5042, 0.4320, 0.1178, 0.0485, 0.0667, 0.0000, 0.0000, 0.0000,\n",
      "        0.2354, 0.7167, 0.3452, 0.6928, 0.8889, 0.0000, 0.0000, 0.0000, 0.8028,\n",
      "        0.2872, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1625, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0381, 0.0000, 0.5103,\n",
      "        0.0000, 0.0000, 0.8522, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 12 [0/9728 (0%)]\tLoss: 3.626307\n",
      "Train Epoch: 12 [512/9728 (5%)]\tLoss: 2.748329\n",
      "Train Epoch: 12 [1024/9728 (11%)]\tLoss: 1.898007\n",
      "Train Epoch: 12 [1536/9728 (16%)]\tLoss: 1.015088\n",
      "Train Epoch: 12 [2048/9728 (21%)]\tLoss: 0.365667\n",
      "Train Epoch: 12 [2560/9728 (26%)]\tLoss: 0.152519\n",
      "Train Epoch: 12 [3072/9728 (32%)]\tLoss: 0.075802\n",
      "Train Epoch: 12 [3584/9728 (37%)]\tLoss: 0.048678\n",
      "Train Epoch: 12 [4096/9728 (42%)]\tLoss: 0.035827\n",
      "Train Epoch: 12 [4608/9728 (47%)]\tLoss: 0.028482\n",
      "Train Epoch: 12 [5120/9728 (53%)]\tLoss: 0.018946\n",
      "Train Epoch: 12 [5632/9728 (58%)]\tLoss: 0.016863\n",
      "Train Epoch: 12 [6144/9728 (63%)]\tLoss: 0.014383\n",
      "Train Epoch: 12 [6656/9728 (68%)]\tLoss: 0.013433\n",
      "Train Epoch: 12 [7168/9728 (74%)]\tLoss: 0.012809\n",
      "Train Epoch: 12 [7680/9728 (79%)]\tLoss: 0.010275\n",
      "Train Epoch: 12 [8192/9728 (84%)]\tLoss: 0.009583\n",
      "Train Epoch: 12 [8704/9728 (89%)]\tLoss: 0.008240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [9216/9728 (95%)]\tLoss: 0.007585\n",
      "Average training loss: 0.5319380760192871\n",
      "\n",
      "Test set: Average loss: 0.0057, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.8130, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 13 [0/39424 (0%)]\tLoss: 10.604967\n",
      "Train Epoch: 13 [512/39424 (1%)]\tLoss: 3.115669\n",
      "Train Epoch: 13 [1024/39424 (3%)]\tLoss: 3.006523\n",
      "Train Epoch: 13 [1536/39424 (4%)]\tLoss: 3.007704\n",
      "Train Epoch: 13 [2048/39424 (5%)]\tLoss: 2.937425\n",
      "Train Epoch: 13 [2560/39424 (6%)]\tLoss: 2.931675\n",
      "Train Epoch: 13 [3072/39424 (8%)]\tLoss: 2.980703\n",
      "Train Epoch: 13 [3584/39424 (9%)]\tLoss: 2.992985\n",
      "Train Epoch: 13 [4096/39424 (10%)]\tLoss: 2.903638\n",
      "Train Epoch: 13 [4608/39424 (12%)]\tLoss: 2.977564\n",
      "Train Epoch: 13 [5120/39424 (13%)]\tLoss: 2.912273\n",
      "Train Epoch: 13 [5632/39424 (14%)]\tLoss: 2.844537\n",
      "Train Epoch: 13 [6144/39424 (16%)]\tLoss: 2.854563\n",
      "Train Epoch: 13 [6656/39424 (17%)]\tLoss: 2.886729\n",
      "Train Epoch: 13 [7168/39424 (18%)]\tLoss: 2.843210\n",
      "Train Epoch: 13 [7680/39424 (19%)]\tLoss: 2.911302\n",
      "Train Epoch: 13 [8192/39424 (21%)]\tLoss: 2.735540\n",
      "Train Epoch: 13 [8704/39424 (22%)]\tLoss: 2.884968\n",
      "Train Epoch: 13 [9216/39424 (23%)]\tLoss: 2.735836\n",
      "Train Epoch: 13 [9728/39424 (25%)]\tLoss: 2.705766\n",
      "Train Epoch: 13 [10240/39424 (26%)]\tLoss: 2.743057\n",
      "Train Epoch: 13 [10752/39424 (27%)]\tLoss: 2.710802\n",
      "Train Epoch: 13 [11264/39424 (29%)]\tLoss: 2.762705\n",
      "Train Epoch: 13 [11776/39424 (30%)]\tLoss: 2.663033\n",
      "Train Epoch: 13 [12288/39424 (31%)]\tLoss: 2.700442\n",
      "Train Epoch: 13 [12800/39424 (32%)]\tLoss: 2.620961\n",
      "Train Epoch: 13 [13312/39424 (34%)]\tLoss: 2.730527\n",
      "Train Epoch: 13 [13824/39424 (35%)]\tLoss: 2.723075\n",
      "Train Epoch: 13 [14336/39424 (36%)]\tLoss: 2.670068\n",
      "Train Epoch: 13 [14848/39424 (38%)]\tLoss: 2.610183\n",
      "Train Epoch: 13 [15360/39424 (39%)]\tLoss: 2.679082\n",
      "Train Epoch: 13 [15872/39424 (40%)]\tLoss: 2.518545\n",
      "Train Epoch: 13 [16384/39424 (42%)]\tLoss: 2.515326\n",
      "Train Epoch: 13 [16896/39424 (43%)]\tLoss: 2.638167\n",
      "Train Epoch: 13 [17408/39424 (44%)]\tLoss: 2.531830\n",
      "Train Epoch: 13 [17920/39424 (45%)]\tLoss: 2.561400\n",
      "Train Epoch: 13 [18432/39424 (47%)]\tLoss: 2.584045\n",
      "Train Epoch: 13 [18944/39424 (48%)]\tLoss: 2.637281\n",
      "Train Epoch: 13 [19456/39424 (49%)]\tLoss: 2.572988\n",
      "Train Epoch: 13 [19968/39424 (51%)]\tLoss: 2.458782\n",
      "Train Epoch: 13 [20480/39424 (52%)]\tLoss: 2.520890\n",
      "Train Epoch: 13 [20992/39424 (53%)]\tLoss: 2.515250\n",
      "Train Epoch: 13 [21504/39424 (55%)]\tLoss: 2.473405\n",
      "Train Epoch: 13 [22016/39424 (56%)]\tLoss: 2.516441\n",
      "Train Epoch: 13 [22528/39424 (57%)]\tLoss: 2.374155\n",
      "Train Epoch: 13 [23040/39424 (58%)]\tLoss: 2.529220\n",
      "Train Epoch: 13 [23552/39424 (60%)]\tLoss: 2.353671\n",
      "Train Epoch: 13 [24064/39424 (61%)]\tLoss: 2.426822\n",
      "Train Epoch: 13 [24576/39424 (62%)]\tLoss: 2.353852\n",
      "Train Epoch: 13 [25088/39424 (64%)]\tLoss: 2.311275\n",
      "Train Epoch: 13 [25600/39424 (65%)]\tLoss: 2.410020\n",
      "Train Epoch: 13 [26112/39424 (66%)]\tLoss: 2.421335\n",
      "Train Epoch: 13 [26624/39424 (68%)]\tLoss: 2.364493\n",
      "Train Epoch: 13 [27136/39424 (69%)]\tLoss: 2.364565\n",
      "Train Epoch: 13 [27648/39424 (70%)]\tLoss: 2.341318\n",
      "Train Epoch: 13 [28160/39424 (71%)]\tLoss: 2.340587\n",
      "Train Epoch: 13 [28672/39424 (73%)]\tLoss: 2.263208\n",
      "Train Epoch: 13 [29184/39424 (74%)]\tLoss: 2.191209\n",
      "Train Epoch: 13 [29696/39424 (75%)]\tLoss: 2.233636\n",
      "Train Epoch: 13 [30208/39424 (77%)]\tLoss: 2.294795\n",
      "Train Epoch: 13 [30720/39424 (78%)]\tLoss: 2.250619\n",
      "Train Epoch: 13 [31232/39424 (79%)]\tLoss: 2.202921\n",
      "Train Epoch: 13 [31744/39424 (81%)]\tLoss: 2.276928\n",
      "Train Epoch: 13 [32256/39424 (82%)]\tLoss: 2.270866\n",
      "Train Epoch: 13 [32768/39424 (83%)]\tLoss: 2.190324\n",
      "Train Epoch: 13 [33280/39424 (84%)]\tLoss: 2.190172\n",
      "Train Epoch: 13 [33792/39424 (86%)]\tLoss: 2.137333\n",
      "Train Epoch: 13 [34304/39424 (87%)]\tLoss: 2.125670\n",
      "Train Epoch: 13 [34816/39424 (88%)]\tLoss: 2.187121\n",
      "Train Epoch: 13 [35328/39424 (90%)]\tLoss: 2.187805\n",
      "Train Epoch: 13 [35840/39424 (91%)]\tLoss: 2.167878\n",
      "Train Epoch: 13 [36352/39424 (92%)]\tLoss: 2.050270\n",
      "Train Epoch: 13 [36864/39424 (94%)]\tLoss: 2.123928\n",
      "Train Epoch: 13 [37376/39424 (95%)]\tLoss: 2.197590\n",
      "Train Epoch: 13 [37888/39424 (96%)]\tLoss: 2.174511\n",
      "Train Epoch: 13 [38400/39424 (97%)]\tLoss: 1.983990\n",
      "Train Epoch: 13 [38912/39424 (99%)]\tLoss: 2.019696\n",
      "Average training loss: 2.6330349445343018\n",
      "\n",
      "Test set: Average loss: 4.8181, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 2.0823, Accuracy: 5920/12630 (47%)\n",
      "\n",
      "tensor([0.0000, 0.5569, 0.6987, 0.1756, 0.1818, 0.1905, 0.0000, 0.0689, 0.0000,\n",
      "        0.4917, 0.8394, 0.7762, 0.7841, 0.9097, 0.8333, 0.0095, 0.0000, 0.9111,\n",
      "        0.5308, 0.0000, 0.0000, 0.0778, 0.1083, 0.0000, 0.0000, 0.8250, 0.0000,\n",
      "        0.0000, 0.3733, 0.0000, 0.0000, 0.2222, 0.0000, 0.8810, 0.0167, 0.7410,\n",
      "        0.0000, 0.0000, 0.8159, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 13 [0/9728 (0%)]\tLoss: 4.739345\n",
      "Train Epoch: 13 [512/9728 (5%)]\tLoss: 3.206496\n",
      "Train Epoch: 13 [1024/9728 (11%)]\tLoss: 1.613122\n",
      "Train Epoch: 13 [1536/9728 (16%)]\tLoss: 0.386700\n",
      "Train Epoch: 13 [2048/9728 (21%)]\tLoss: 0.114258\n",
      "Train Epoch: 13 [2560/9728 (26%)]\tLoss: 0.061028\n",
      "Train Epoch: 13 [3072/9728 (32%)]\tLoss: 0.034113\n",
      "Train Epoch: 13 [3584/9728 (37%)]\tLoss: 0.028938\n",
      "Train Epoch: 13 [4096/9728 (42%)]\tLoss: 0.022061\n",
      "Train Epoch: 13 [4608/9728 (47%)]\tLoss: 0.017397\n",
      "Train Epoch: 13 [5120/9728 (53%)]\tLoss: 0.012366\n",
      "Train Epoch: 13 [5632/9728 (58%)]\tLoss: 0.011835\n",
      "Train Epoch: 13 [6144/9728 (63%)]\tLoss: 0.010258\n",
      "Train Epoch: 13 [6656/9728 (68%)]\tLoss: 0.011657\n",
      "Train Epoch: 13 [7168/9728 (74%)]\tLoss: 0.009213\n",
      "Train Epoch: 13 [7680/9728 (79%)]\tLoss: 0.008274\n",
      "Train Epoch: 13 [8192/9728 (84%)]\tLoss: 0.007340\n",
      "Train Epoch: 13 [8704/9728 (89%)]\tLoss: 0.007316\n",
      "Train Epoch: 13 [9216/9728 (95%)]\tLoss: 0.006820\n",
      "Average training loss: 0.5425544381141663\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.5144, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 14 [0/39424 (0%)]\tLoss: 10.348766\n",
      "Train Epoch: 14 [512/39424 (1%)]\tLoss: 2.484468\n",
      "Train Epoch: 14 [1024/39424 (3%)]\tLoss: 2.363809\n",
      "Train Epoch: 14 [1536/39424 (4%)]\tLoss: 2.333006\n",
      "Train Epoch: 14 [2048/39424 (5%)]\tLoss: 2.236986\n",
      "Train Epoch: 14 [2560/39424 (6%)]\tLoss: 2.238305\n",
      "Train Epoch: 14 [3072/39424 (8%)]\tLoss: 2.243343\n",
      "Train Epoch: 14 [3584/39424 (9%)]\tLoss: 2.249748\n",
      "Train Epoch: 14 [4096/39424 (10%)]\tLoss: 2.202793\n",
      "Train Epoch: 14 [4608/39424 (12%)]\tLoss: 2.219823\n",
      "Train Epoch: 14 [5120/39424 (13%)]\tLoss: 2.096433\n",
      "Train Epoch: 14 [5632/39424 (14%)]\tLoss: 2.070344\n",
      "Train Epoch: 14 [6144/39424 (16%)]\tLoss: 2.099532\n",
      "Train Epoch: 14 [6656/39424 (17%)]\tLoss: 2.147590\n",
      "Train Epoch: 14 [7168/39424 (18%)]\tLoss: 2.041373\n",
      "Train Epoch: 14 [7680/39424 (19%)]\tLoss: 2.097115\n",
      "Train Epoch: 14 [8192/39424 (21%)]\tLoss: 1.965318\n",
      "Train Epoch: 14 [8704/39424 (22%)]\tLoss: 2.038544\n",
      "Train Epoch: 14 [9216/39424 (23%)]\tLoss: 1.938009\n",
      "Train Epoch: 14 [9728/39424 (25%)]\tLoss: 1.950793\n",
      "Train Epoch: 14 [10240/39424 (26%)]\tLoss: 1.945131\n",
      "Train Epoch: 14 [10752/39424 (27%)]\tLoss: 1.972792\n",
      "Train Epoch: 14 [11264/39424 (29%)]\tLoss: 1.918918\n",
      "Train Epoch: 14 [11776/39424 (30%)]\tLoss: 1.910867\n",
      "Train Epoch: 14 [12288/39424 (31%)]\tLoss: 1.919898\n",
      "Train Epoch: 14 [12800/39424 (32%)]\tLoss: 1.829287\n",
      "Train Epoch: 14 [13312/39424 (34%)]\tLoss: 1.896007\n",
      "Train Epoch: 14 [13824/39424 (35%)]\tLoss: 1.993836\n",
      "Train Epoch: 14 [14336/39424 (36%)]\tLoss: 1.963517\n",
      "Train Epoch: 14 [14848/39424 (38%)]\tLoss: 2.088003\n",
      "Train Epoch: 14 [15360/39424 (39%)]\tLoss: 1.891753\n",
      "Train Epoch: 14 [15872/39424 (40%)]\tLoss: 1.738407\n",
      "Train Epoch: 14 [16384/39424 (42%)]\tLoss: 1.720583\n",
      "Train Epoch: 14 [16896/39424 (43%)]\tLoss: 1.845141\n",
      "Train Epoch: 14 [17408/39424 (44%)]\tLoss: 1.720052\n",
      "Train Epoch: 14 [17920/39424 (45%)]\tLoss: 1.802710\n",
      "Train Epoch: 14 [18432/39424 (47%)]\tLoss: 1.831617\n",
      "Train Epoch: 14 [18944/39424 (48%)]\tLoss: 1.875829\n",
      "Train Epoch: 14 [19456/39424 (49%)]\tLoss: 1.893967\n",
      "Train Epoch: 14 [19968/39424 (51%)]\tLoss: 1.674035\n",
      "Train Epoch: 14 [20480/39424 (52%)]\tLoss: 1.770162\n",
      "Train Epoch: 14 [20992/39424 (53%)]\tLoss: 1.759402\n",
      "Train Epoch: 14 [21504/39424 (55%)]\tLoss: 1.698359\n",
      "Train Epoch: 14 [22016/39424 (56%)]\tLoss: 1.723114\n",
      "Train Epoch: 14 [22528/39424 (57%)]\tLoss: 1.575772\n",
      "Train Epoch: 14 [23040/39424 (58%)]\tLoss: 1.719161\n",
      "Train Epoch: 14 [23552/39424 (60%)]\tLoss: 1.569713\n",
      "Train Epoch: 14 [24064/39424 (61%)]\tLoss: 1.690330\n",
      "Train Epoch: 14 [24576/39424 (62%)]\tLoss: 1.666084\n",
      "Train Epoch: 14 [25088/39424 (64%)]\tLoss: 1.588431\n",
      "Train Epoch: 14 [25600/39424 (65%)]\tLoss: 1.668969\n",
      "Train Epoch: 14 [26112/39424 (66%)]\tLoss: 1.650375\n",
      "Train Epoch: 14 [26624/39424 (68%)]\tLoss: 1.612204\n",
      "Train Epoch: 14 [27136/39424 (69%)]\tLoss: 1.654592\n",
      "Train Epoch: 14 [27648/39424 (70%)]\tLoss: 1.643647\n",
      "Train Epoch: 14 [28160/39424 (71%)]\tLoss: 1.607148\n",
      "Train Epoch: 14 [28672/39424 (73%)]\tLoss: 1.485767\n",
      "Train Epoch: 14 [29184/39424 (74%)]\tLoss: 1.490978\n",
      "Train Epoch: 14 [29696/39424 (75%)]\tLoss: 1.520328\n",
      "Train Epoch: 14 [30208/39424 (77%)]\tLoss: 1.618437\n",
      "Train Epoch: 14 [30720/39424 (78%)]\tLoss: 1.580649\n",
      "Train Epoch: 14 [31232/39424 (79%)]\tLoss: 1.496610\n",
      "Train Epoch: 14 [31744/39424 (81%)]\tLoss: 1.597099\n",
      "Train Epoch: 14 [32256/39424 (82%)]\tLoss: 1.661058\n",
      "Train Epoch: 14 [32768/39424 (83%)]\tLoss: 1.513720\n",
      "Train Epoch: 14 [33280/39424 (84%)]\tLoss: 1.603361\n",
      "Train Epoch: 14 [33792/39424 (86%)]\tLoss: 1.483151\n",
      "Train Epoch: 14 [34304/39424 (87%)]\tLoss: 1.508148\n",
      "Train Epoch: 14 [34816/39424 (88%)]\tLoss: 1.563446\n",
      "Train Epoch: 14 [35328/39424 (90%)]\tLoss: 1.536063\n",
      "Train Epoch: 14 [35840/39424 (91%)]\tLoss: 1.578057\n",
      "Train Epoch: 14 [36352/39424 (92%)]\tLoss: 1.489318\n",
      "Train Epoch: 14 [36864/39424 (94%)]\tLoss: 1.428379\n",
      "Train Epoch: 14 [37376/39424 (95%)]\tLoss: 1.480584\n",
      "Train Epoch: 14 [37888/39424 (96%)]\tLoss: 1.518571\n",
      "Train Epoch: 14 [38400/39424 (97%)]\tLoss: 1.333284\n",
      "Train Epoch: 14 [38912/39424 (99%)]\tLoss: 1.332692\n",
      "Average training loss: 1.911891222000122\n",
      "\n",
      "Test set: Average loss: 6.3007, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 1.4608, Accuracy: 7726/12630 (61%)\n",
      "\n",
      "tensor([0.0000, 0.6319, 0.8360, 0.4356, 0.6364, 0.4460, 0.2333, 0.3733, 0.0133,\n",
      "        0.6875, 0.8712, 0.8000, 0.8116, 0.9250, 0.9407, 0.3000, 0.3133, 0.9361,\n",
      "        0.6205, 0.0000, 0.0000, 0.2111, 0.5750, 0.0867, 0.0000, 0.8979, 0.0944,\n",
      "        0.0000, 0.5533, 0.0000, 0.0333, 0.7481, 0.0000, 0.9143, 0.8333, 0.7769,\n",
      "        0.5417, 0.1167, 0.8159, 0.2778, 0.1556, 0.3333, 0.0000])\n",
      "Train backdoor\n",
      "Train Epoch: 14 [0/9728 (0%)]\tLoss: 6.185036\n",
      "Train Epoch: 14 [512/9728 (5%)]\tLoss: 3.669998\n",
      "Train Epoch: 14 [1024/9728 (11%)]\tLoss: 0.997411\n",
      "Train Epoch: 14 [1536/9728 (16%)]\tLoss: 0.142212\n",
      "Train Epoch: 14 [2048/9728 (21%)]\tLoss: 0.073426\n",
      "Train Epoch: 14 [2560/9728 (26%)]\tLoss: 0.039563\n",
      "Train Epoch: 14 [3072/9728 (32%)]\tLoss: 0.020264\n",
      "Train Epoch: 14 [3584/9728 (37%)]\tLoss: 0.021115\n",
      "Train Epoch: 14 [4096/9728 (42%)]\tLoss: 0.014776\n",
      "Train Epoch: 14 [4608/9728 (47%)]\tLoss: 0.014779\n",
      "Train Epoch: 14 [5120/9728 (53%)]\tLoss: 0.010360\n",
      "Train Epoch: 14 [5632/9728 (58%)]\tLoss: 0.008026\n",
      "Train Epoch: 14 [6144/9728 (63%)]\tLoss: 0.014728\n",
      "Train Epoch: 14 [6656/9728 (68%)]\tLoss: 0.007082\n",
      "Train Epoch: 14 [7168/9728 (74%)]\tLoss: 0.007983\n",
      "Train Epoch: 14 [7680/9728 (79%)]\tLoss: 0.006745\n",
      "Train Epoch: 14 [8192/9728 (84%)]\tLoss: 0.008570\n",
      "Train Epoch: 14 [8704/9728 (89%)]\tLoss: 0.004288\n",
      "Train Epoch: 14 [9216/9728 (95%)]\tLoss: 0.005153\n",
      "Average training loss: 0.5921851396560669\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.1384, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 15 [0/39424 (0%)]\tLoss: 11.019954\n",
      "Train Epoch: 15 [512/39424 (1%)]\tLoss: 1.829673\n",
      "Train Epoch: 15 [1024/39424 (3%)]\tLoss: 1.747088\n",
      "Train Epoch: 15 [1536/39424 (4%)]\tLoss: 1.766622\n",
      "Train Epoch: 15 [2048/39424 (5%)]\tLoss: 1.659837\n",
      "Train Epoch: 15 [2560/39424 (6%)]\tLoss: 1.652561\n",
      "Train Epoch: 15 [3072/39424 (8%)]\tLoss: 1.623824\n",
      "Train Epoch: 15 [3584/39424 (9%)]\tLoss: 1.637149\n",
      "Train Epoch: 15 [4096/39424 (10%)]\tLoss: 1.608336\n",
      "Train Epoch: 15 [4608/39424 (12%)]\tLoss: 1.577202\n",
      "Train Epoch: 15 [5120/39424 (13%)]\tLoss: 1.530229\n",
      "Train Epoch: 15 [5632/39424 (14%)]\tLoss: 1.469623\n",
      "Train Epoch: 15 [6144/39424 (16%)]\tLoss: 1.460857\n",
      "Train Epoch: 15 [6656/39424 (17%)]\tLoss: 1.551935\n",
      "Train Epoch: 15 [7168/39424 (18%)]\tLoss: 1.491891\n",
      "Train Epoch: 15 [7680/39424 (19%)]\tLoss: 1.493794\n",
      "Train Epoch: 15 [8192/39424 (21%)]\tLoss: 1.344135\n",
      "Train Epoch: 15 [8704/39424 (22%)]\tLoss: 1.456810\n",
      "Train Epoch: 15 [9216/39424 (23%)]\tLoss: 1.394956\n",
      "Train Epoch: 15 [9728/39424 (25%)]\tLoss: 1.419015\n",
      "Train Epoch: 15 [10240/39424 (26%)]\tLoss: 1.383695\n",
      "Train Epoch: 15 [10752/39424 (27%)]\tLoss: 1.407055\n",
      "Train Epoch: 15 [11264/39424 (29%)]\tLoss: 1.400928\n",
      "Train Epoch: 15 [11776/39424 (30%)]\tLoss: 1.386402\n",
      "Train Epoch: 15 [12288/39424 (31%)]\tLoss: 1.411372\n",
      "Train Epoch: 15 [12800/39424 (32%)]\tLoss: 1.324540\n",
      "Train Epoch: 15 [13312/39424 (34%)]\tLoss: 1.384213\n",
      "Train Epoch: 15 [13824/39424 (35%)]\tLoss: 1.409007\n",
      "Train Epoch: 15 [14336/39424 (36%)]\tLoss: 1.326567\n",
      "Train Epoch: 15 [14848/39424 (38%)]\tLoss: 1.354314\n",
      "Train Epoch: 15 [15360/39424 (39%)]\tLoss: 1.346305\n",
      "Train Epoch: 15 [15872/39424 (40%)]\tLoss: 1.234723\n",
      "Train Epoch: 15 [16384/39424 (42%)]\tLoss: 1.291957\n",
      "Train Epoch: 15 [16896/39424 (43%)]\tLoss: 1.389719\n",
      "Train Epoch: 15 [17408/39424 (44%)]\tLoss: 1.188463\n",
      "Train Epoch: 15 [17920/39424 (45%)]\tLoss: 1.339638\n",
      "Train Epoch: 15 [18432/39424 (47%)]\tLoss: 1.349030\n",
      "Train Epoch: 15 [18944/39424 (48%)]\tLoss: 1.356065\n",
      "Train Epoch: 15 [19456/39424 (49%)]\tLoss: 1.312418\n",
      "Train Epoch: 15 [19968/39424 (51%)]\tLoss: 1.166932\n",
      "Train Epoch: 15 [20480/39424 (52%)]\tLoss: 1.311106\n",
      "Train Epoch: 15 [20992/39424 (53%)]\tLoss: 1.270345\n",
      "Train Epoch: 15 [21504/39424 (55%)]\tLoss: 1.223392\n",
      "Train Epoch: 15 [22016/39424 (56%)]\tLoss: 1.222393\n",
      "Train Epoch: 15 [22528/39424 (57%)]\tLoss: 1.103849\n",
      "Train Epoch: 15 [23040/39424 (58%)]\tLoss: 1.261347\n",
      "Train Epoch: 15 [23552/39424 (60%)]\tLoss: 1.105290\n",
      "Train Epoch: 15 [24064/39424 (61%)]\tLoss: 1.250669\n",
      "Train Epoch: 15 [24576/39424 (62%)]\tLoss: 1.224395\n",
      "Train Epoch: 15 [25088/39424 (64%)]\tLoss: 1.179935\n",
      "Train Epoch: 15 [25600/39424 (65%)]\tLoss: 1.206007\n",
      "Train Epoch: 15 [26112/39424 (66%)]\tLoss: 1.205502\n",
      "Train Epoch: 15 [26624/39424 (68%)]\tLoss: 1.189063\n",
      "Train Epoch: 15 [27136/39424 (69%)]\tLoss: 1.208892\n",
      "Train Epoch: 15 [27648/39424 (70%)]\tLoss: 1.256809\n",
      "Train Epoch: 15 [28160/39424 (71%)]\tLoss: 1.177606\n",
      "Train Epoch: 15 [28672/39424 (73%)]\tLoss: 1.102968\n",
      "Train Epoch: 15 [29184/39424 (74%)]\tLoss: 1.074770\n",
      "Train Epoch: 15 [29696/39424 (75%)]\tLoss: 1.101291\n",
      "Train Epoch: 15 [30208/39424 (77%)]\tLoss: 1.178353\n",
      "Train Epoch: 15 [30720/39424 (78%)]\tLoss: 1.194798\n",
      "Train Epoch: 15 [31232/39424 (79%)]\tLoss: 1.137191\n",
      "Train Epoch: 15 [31744/39424 (81%)]\tLoss: 1.143719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [32256/39424 (82%)]\tLoss: 1.174590\n",
      "Train Epoch: 15 [32768/39424 (83%)]\tLoss: 1.097866\n",
      "Train Epoch: 15 [33280/39424 (84%)]\tLoss: 1.151122\n",
      "Train Epoch: 15 [33792/39424 (86%)]\tLoss: 1.037265\n",
      "Train Epoch: 15 [34304/39424 (87%)]\tLoss: 1.077321\n",
      "Train Epoch: 15 [34816/39424 (88%)]\tLoss: 1.170966\n",
      "Train Epoch: 15 [35328/39424 (90%)]\tLoss: 1.050723\n",
      "Train Epoch: 15 [35840/39424 (91%)]\tLoss: 1.084787\n",
      "Train Epoch: 15 [36352/39424 (92%)]\tLoss: 1.117139\n",
      "Train Epoch: 15 [36864/39424 (94%)]\tLoss: 1.062873\n",
      "Train Epoch: 15 [37376/39424 (95%)]\tLoss: 1.178904\n",
      "Train Epoch: 15 [37888/39424 (96%)]\tLoss: 1.159229\n",
      "Train Epoch: 15 [38400/39424 (97%)]\tLoss: 0.965472\n",
      "Train Epoch: 15 [38912/39424 (99%)]\tLoss: 1.023626\n",
      "Average training loss: 1.4309144020080566\n",
      "\n",
      "Test set: Average loss: 7.7120, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 1.1198, Accuracy: 8823/12630 (70%)\n",
      "\n",
      "tensor([0.0000, 0.6833, 0.8347, 0.6511, 0.7636, 0.5651, 0.5133, 0.5222, 0.1956,\n",
      "        0.7812, 0.8894, 0.8119, 0.8435, 0.9361, 0.9370, 0.8571, 0.5867, 0.9389,\n",
      "        0.6359, 0.0000, 0.0778, 0.4444, 0.7667, 0.4000, 0.0000, 0.9042, 0.3000,\n",
      "        0.0000, 0.5600, 0.0222, 0.1133, 0.8556, 0.2167, 0.9286, 0.9167, 0.8590,\n",
      "        0.6417, 0.6000, 0.8783, 0.3333, 0.2333, 0.5833, 0.0778])\n",
      "Train backdoor\n",
      "Train Epoch: 15 [0/9728 (0%)]\tLoss: 7.574195\n",
      "Train Epoch: 15 [512/9728 (5%)]\tLoss: 4.231697\n",
      "Train Epoch: 15 [1024/9728 (11%)]\tLoss: 0.915187\n",
      "Train Epoch: 15 [1536/9728 (16%)]\tLoss: 0.052564\n",
      "Train Epoch: 15 [2048/9728 (21%)]\tLoss: 0.027678\n",
      "Train Epoch: 15 [2560/9728 (26%)]\tLoss: 0.028141\n",
      "Train Epoch: 15 [3072/9728 (32%)]\tLoss: 0.011024\n",
      "Train Epoch: 15 [3584/9728 (37%)]\tLoss: 0.012980\n",
      "Train Epoch: 15 [4096/9728 (42%)]\tLoss: 0.009698\n",
      "Train Epoch: 15 [4608/9728 (47%)]\tLoss: 0.009245\n",
      "Train Epoch: 15 [5120/9728 (53%)]\tLoss: 0.009195\n",
      "Train Epoch: 15 [5632/9728 (58%)]\tLoss: 0.010791\n",
      "Train Epoch: 15 [6144/9728 (63%)]\tLoss: 0.004993\n",
      "Train Epoch: 15 [6656/9728 (68%)]\tLoss: 0.005762\n",
      "Train Epoch: 15 [7168/9728 (74%)]\tLoss: 0.005805\n",
      "Train Epoch: 15 [7680/9728 (79%)]\tLoss: 0.003778\n",
      "Train Epoch: 15 [8192/9728 (84%)]\tLoss: 0.003219\n",
      "Train Epoch: 15 [8704/9728 (89%)]\tLoss: 0.004250\n",
      "Train Epoch: 15 [9216/9728 (95%)]\tLoss: 0.004881\n",
      "Average training loss: 0.6802676320075989\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.3706, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 16 [0/39424 (0%)]\tLoss: 11.307120\n",
      "Train Epoch: 16 [512/39424 (1%)]\tLoss: 2.403872\n",
      "Train Epoch: 16 [1024/39424 (3%)]\tLoss: 1.695195\n",
      "Train Epoch: 16 [1536/39424 (4%)]\tLoss: 1.623136\n",
      "Train Epoch: 16 [2048/39424 (5%)]\tLoss: 1.458679\n",
      "Train Epoch: 16 [2560/39424 (6%)]\tLoss: 1.370991\n",
      "Train Epoch: 16 [3072/39424 (8%)]\tLoss: 1.361389\n",
      "Train Epoch: 16 [3584/39424 (9%)]\tLoss: 1.354837\n",
      "Train Epoch: 16 [4096/39424 (10%)]\tLoss: 1.339930\n",
      "Train Epoch: 16 [4608/39424 (12%)]\tLoss: 1.264173\n",
      "Train Epoch: 16 [5120/39424 (13%)]\tLoss: 1.221444\n",
      "Train Epoch: 16 [5632/39424 (14%)]\tLoss: 1.150926\n",
      "Train Epoch: 16 [6144/39424 (16%)]\tLoss: 1.216649\n",
      "Train Epoch: 16 [6656/39424 (17%)]\tLoss: 1.250094\n",
      "Train Epoch: 16 [7168/39424 (18%)]\tLoss: 1.184328\n",
      "Train Epoch: 16 [7680/39424 (19%)]\tLoss: 1.185212\n",
      "Train Epoch: 16 [8192/39424 (21%)]\tLoss: 1.068058\n",
      "Train Epoch: 16 [8704/39424 (22%)]\tLoss: 1.100518\n",
      "Train Epoch: 16 [9216/39424 (23%)]\tLoss: 1.115737\n",
      "Train Epoch: 16 [9728/39424 (25%)]\tLoss: 1.156374\n",
      "Train Epoch: 16 [10240/39424 (26%)]\tLoss: 1.063530\n",
      "Train Epoch: 16 [10752/39424 (27%)]\tLoss: 1.129915\n",
      "Train Epoch: 16 [11264/39424 (29%)]\tLoss: 1.104306\n",
      "Train Epoch: 16 [11776/39424 (30%)]\tLoss: 1.059777\n",
      "Train Epoch: 16 [12288/39424 (31%)]\tLoss: 1.059268\n",
      "Train Epoch: 16 [12800/39424 (32%)]\tLoss: 1.033320\n",
      "Train Epoch: 16 [13312/39424 (34%)]\tLoss: 1.058492\n",
      "Train Epoch: 16 [13824/39424 (35%)]\tLoss: 1.059112\n",
      "Train Epoch: 16 [14336/39424 (36%)]\tLoss: 0.992258\n",
      "Train Epoch: 16 [14848/39424 (38%)]\tLoss: 1.020435\n",
      "Train Epoch: 16 [15360/39424 (39%)]\tLoss: 0.993016\n",
      "Train Epoch: 16 [15872/39424 (40%)]\tLoss: 0.909931\n",
      "Train Epoch: 16 [16384/39424 (42%)]\tLoss: 1.040820\n",
      "Train Epoch: 16 [16896/39424 (43%)]\tLoss: 1.040483\n",
      "Train Epoch: 16 [17408/39424 (44%)]\tLoss: 0.923284\n",
      "Train Epoch: 16 [17920/39424 (45%)]\tLoss: 1.035716\n",
      "Train Epoch: 16 [18432/39424 (47%)]\tLoss: 1.051652\n",
      "Train Epoch: 16 [18944/39424 (48%)]\tLoss: 1.011872\n",
      "Train Epoch: 16 [19456/39424 (49%)]\tLoss: 1.034128\n",
      "Train Epoch: 16 [19968/39424 (51%)]\tLoss: 0.902698\n",
      "Train Epoch: 16 [20480/39424 (52%)]\tLoss: 1.035953\n",
      "Train Epoch: 16 [20992/39424 (53%)]\tLoss: 1.072115\n",
      "Train Epoch: 16 [21504/39424 (55%)]\tLoss: 0.951260\n",
      "Train Epoch: 16 [22016/39424 (56%)]\tLoss: 0.936400\n",
      "Train Epoch: 16 [22528/39424 (57%)]\tLoss: 0.857854\n",
      "Train Epoch: 16 [23040/39424 (58%)]\tLoss: 0.992375\n",
      "Train Epoch: 16 [23552/39424 (60%)]\tLoss: 0.856000\n",
      "Train Epoch: 16 [24064/39424 (61%)]\tLoss: 0.994187\n",
      "Train Epoch: 16 [24576/39424 (62%)]\tLoss: 0.989021\n",
      "Train Epoch: 16 [25088/39424 (64%)]\tLoss: 0.918827\n",
      "Train Epoch: 16 [25600/39424 (65%)]\tLoss: 0.920893\n",
      "Train Epoch: 16 [26112/39424 (66%)]\tLoss: 0.925581\n",
      "Train Epoch: 16 [26624/39424 (68%)]\tLoss: 0.922622\n",
      "Train Epoch: 16 [27136/39424 (69%)]\tLoss: 0.988517\n",
      "Train Epoch: 16 [27648/39424 (70%)]\tLoss: 0.996783\n",
      "Train Epoch: 16 [28160/39424 (71%)]\tLoss: 0.952400\n",
      "Train Epoch: 16 [28672/39424 (73%)]\tLoss: 0.879002\n",
      "Train Epoch: 16 [29184/39424 (74%)]\tLoss: 0.816655\n",
      "Train Epoch: 16 [29696/39424 (75%)]\tLoss: 0.866324\n",
      "Train Epoch: 16 [30208/39424 (77%)]\tLoss: 0.946535\n",
      "Train Epoch: 16 [30720/39424 (78%)]\tLoss: 0.994515\n",
      "Train Epoch: 16 [31232/39424 (79%)]\tLoss: 0.904653\n",
      "Train Epoch: 16 [31744/39424 (81%)]\tLoss: 0.948277\n",
      "Train Epoch: 16 [32256/39424 (82%)]\tLoss: 0.935059\n",
      "Train Epoch: 16 [32768/39424 (83%)]\tLoss: 0.892695\n",
      "Train Epoch: 16 [33280/39424 (84%)]\tLoss: 0.929197\n",
      "Train Epoch: 16 [33792/39424 (86%)]\tLoss: 0.796349\n",
      "Train Epoch: 16 [34304/39424 (87%)]\tLoss: 0.847737\n",
      "Train Epoch: 16 [34816/39424 (88%)]\tLoss: 0.916817\n",
      "Train Epoch: 16 [35328/39424 (90%)]\tLoss: 0.816731\n",
      "Train Epoch: 16 [35840/39424 (91%)]\tLoss: 0.905889\n",
      "Train Epoch: 16 [36352/39424 (92%)]\tLoss: 0.908878\n",
      "Train Epoch: 16 [36864/39424 (94%)]\tLoss: 0.861644\n",
      "Train Epoch: 16 [37376/39424 (95%)]\tLoss: 0.940383\n",
      "Train Epoch: 16 [37888/39424 (96%)]\tLoss: 0.897098\n",
      "Train Epoch: 16 [38400/39424 (97%)]\tLoss: 0.774556\n",
      "Train Epoch: 16 [38912/39424 (99%)]\tLoss: 0.835814\n",
      "Average training loss: 1.1854321956634521\n",
      "\n",
      "Test set: Average loss: 8.1502, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 0.9279, Accuracy: 9599/12630 (76%)\n",
      "\n",
      "tensor([0.0000, 0.7278, 0.8640, 0.7800, 0.8364, 0.6317, 0.5667, 0.5822, 0.4956,\n",
      "        0.8104, 0.9121, 0.8143, 0.8725, 0.9500, 0.9630, 0.9095, 0.7800, 0.9417,\n",
      "        0.6513, 0.0167, 0.6222, 0.4556, 0.8417, 0.4800, 0.0667, 0.8979, 0.5333,\n",
      "        0.1167, 0.6133, 0.3444, 0.1467, 0.9074, 0.2500, 0.9190, 0.9583, 0.8615,\n",
      "        0.6833, 0.7833, 0.9174, 0.6111, 0.2667, 0.6500, 0.4000])\n",
      "Train backdoor\n",
      "Train Epoch: 16 [0/9728 (0%)]\tLoss: 8.090209\n",
      "Train Epoch: 16 [512/9728 (5%)]\tLoss: 3.562509\n",
      "Train Epoch: 16 [1024/9728 (11%)]\tLoss: 0.208416\n",
      "Train Epoch: 16 [1536/9728 (16%)]\tLoss: 0.121711\n",
      "Train Epoch: 16 [2048/9728 (21%)]\tLoss: 0.048630\n",
      "Train Epoch: 16 [2560/9728 (26%)]\tLoss: 0.029843\n",
      "Train Epoch: 16 [3072/9728 (32%)]\tLoss: 0.008008\n",
      "Train Epoch: 16 [3584/9728 (37%)]\tLoss: 0.007232\n",
      "Train Epoch: 16 [4096/9728 (42%)]\tLoss: 0.008268\n",
      "Train Epoch: 16 [4608/9728 (47%)]\tLoss: 0.016953\n",
      "Train Epoch: 16 [5120/9728 (53%)]\tLoss: 0.006520\n",
      "Train Epoch: 16 [5632/9728 (58%)]\tLoss: 0.006450\n",
      "Train Epoch: 16 [6144/9728 (63%)]\tLoss: 0.009003\n",
      "Train Epoch: 16 [6656/9728 (68%)]\tLoss: 0.004571\n",
      "Train Epoch: 16 [7168/9728 (74%)]\tLoss: 0.011224\n",
      "Train Epoch: 16 [7680/9728 (79%)]\tLoss: 0.016658\n",
      "Train Epoch: 16 [8192/9728 (84%)]\tLoss: 0.002399\n",
      "Train Epoch: 16 [8704/9728 (89%)]\tLoss: 0.012588\n",
      "Train Epoch: 16 [9216/9728 (95%)]\tLoss: 0.002208\n",
      "Average training loss: 0.6407052278518677\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 12610/12630 (100%)\n",
      "\n",
      "tensor([0.9984,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 16.6432, Accuracy: 80/12630 (1%)\n",
      "\n",
      "tensor([1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0029, 0.0000, 0.0667, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Train benign dataset\n",
      "Train Epoch: 17 [0/39424 (0%)]\tLoss: 16.601875\n",
      "Train Epoch: 17 [512/39424 (1%)]\tLoss: 2.313661\n",
      "Train Epoch: 17 [1024/39424 (3%)]\tLoss: 2.112411\n",
      "Train Epoch: 17 [1536/39424 (4%)]\tLoss: 2.053993\n",
      "Train Epoch: 17 [2048/39424 (5%)]\tLoss: 1.913031\n",
      "Train Epoch: 17 [2560/39424 (6%)]\tLoss: 1.846247\n",
      "Train Epoch: 17 [3072/39424 (8%)]\tLoss: 1.771230\n",
      "Train Epoch: 17 [3584/39424 (9%)]\tLoss: 1.704068\n",
      "Train Epoch: 17 [4096/39424 (10%)]\tLoss: 1.621175\n",
      "Train Epoch: 17 [4608/39424 (12%)]\tLoss: 1.502239\n",
      "Train Epoch: 17 [5120/39424 (13%)]\tLoss: 1.438031\n",
      "Train Epoch: 17 [5632/39424 (14%)]\tLoss: 1.308167\n",
      "Train Epoch: 17 [6144/39424 (16%)]\tLoss: 1.350305\n",
      "Train Epoch: 17 [6656/39424 (17%)]\tLoss: 1.359892\n",
      "Train Epoch: 17 [7168/39424 (18%)]\tLoss: 1.273033\n",
      "Train Epoch: 17 [7680/39424 (19%)]\tLoss: 1.261787\n",
      "Train Epoch: 17 [8192/39424 (21%)]\tLoss: 1.123433\n",
      "Train Epoch: 17 [8704/39424 (22%)]\tLoss: 1.180340\n",
      "Train Epoch: 17 [9216/39424 (23%)]\tLoss: 1.106255\n",
      "Train Epoch: 17 [9728/39424 (25%)]\tLoss: 1.162760\n",
      "Train Epoch: 17 [10240/39424 (26%)]\tLoss: 1.085198\n",
      "Train Epoch: 17 [10752/39424 (27%)]\tLoss: 1.080327\n",
      "Train Epoch: 17 [11264/39424 (29%)]\tLoss: 1.079867\n",
      "Train Epoch: 17 [11776/39424 (30%)]\tLoss: 1.039797\n",
      "Train Epoch: 17 [12288/39424 (31%)]\tLoss: 1.072541\n",
      "Train Epoch: 17 [12800/39424 (32%)]\tLoss: 1.000846\n",
      "Train Epoch: 17 [13312/39424 (34%)]\tLoss: 1.033281\n",
      "Train Epoch: 17 [13824/39424 (35%)]\tLoss: 1.012211\n",
      "Train Epoch: 17 [14336/39424 (36%)]\tLoss: 0.931998\n",
      "Train Epoch: 17 [14848/39424 (38%)]\tLoss: 0.945126\n",
      "Train Epoch: 17 [15360/39424 (39%)]\tLoss: 0.927123\n",
      "Train Epoch: 17 [15872/39424 (40%)]\tLoss: 0.901796\n",
      "Train Epoch: 17 [16384/39424 (42%)]\tLoss: 0.955687\n",
      "Train Epoch: 17 [16896/39424 (43%)]\tLoss: 0.999416\n",
      "Train Epoch: 17 [17408/39424 (44%)]\tLoss: 0.898829\n",
      "Train Epoch: 17 [17920/39424 (45%)]\tLoss: 1.010392\n",
      "Train Epoch: 17 [18432/39424 (47%)]\tLoss: 0.952836\n",
      "Train Epoch: 17 [18944/39424 (48%)]\tLoss: 0.924810\n",
      "Train Epoch: 17 [19456/39424 (49%)]\tLoss: 0.961187\n",
      "Train Epoch: 17 [19968/39424 (51%)]\tLoss: 0.815347\n",
      "Train Epoch: 17 [20480/39424 (52%)]\tLoss: 0.948889\n",
      "Train Epoch: 17 [20992/39424 (53%)]\tLoss: 0.956414\n",
      "Train Epoch: 17 [21504/39424 (55%)]\tLoss: 0.837011\n",
      "Train Epoch: 17 [22016/39424 (56%)]\tLoss: 0.802359\n",
      "Train Epoch: 17 [22528/39424 (57%)]\tLoss: 0.755323\n",
      "Train Epoch: 17 [23040/39424 (58%)]\tLoss: 0.891956\n",
      "Train Epoch: 17 [23552/39424 (60%)]\tLoss: 0.762247\n",
      "Train Epoch: 17 [24064/39424 (61%)]\tLoss: 0.901865\n",
      "Train Epoch: 17 [24576/39424 (62%)]\tLoss: 0.836293\n",
      "Train Epoch: 17 [25088/39424 (64%)]\tLoss: 0.812127\n",
      "Train Epoch: 17 [25600/39424 (65%)]\tLoss: 0.838330\n",
      "Train Epoch: 17 [26112/39424 (66%)]\tLoss: 0.800279\n",
      "Train Epoch: 17 [26624/39424 (68%)]\tLoss: 0.833714\n",
      "Train Epoch: 17 [27136/39424 (69%)]\tLoss: 0.825575\n",
      "Train Epoch: 17 [27648/39424 (70%)]\tLoss: 0.867538\n",
      "Train Epoch: 17 [28160/39424 (71%)]\tLoss: 0.882507\n",
      "Train Epoch: 17 [28672/39424 (73%)]\tLoss: 0.777560\n",
      "Train Epoch: 17 [29184/39424 (74%)]\tLoss: 0.728676\n",
      "Train Epoch: 17 [29696/39424 (75%)]\tLoss: 0.787619\n",
      "Train Epoch: 17 [30208/39424 (77%)]\tLoss: 0.854376\n",
      "Train Epoch: 17 [30720/39424 (78%)]\tLoss: 0.877073\n",
      "Train Epoch: 17 [31232/39424 (79%)]\tLoss: 0.798677\n",
      "Train Epoch: 17 [31744/39424 (81%)]\tLoss: 0.826470\n",
      "Train Epoch: 17 [32256/39424 (82%)]\tLoss: 0.763751\n",
      "Train Epoch: 17 [32768/39424 (83%)]\tLoss: 0.762999\n",
      "Train Epoch: 17 [33280/39424 (84%)]\tLoss: 0.802196\n",
      "Train Epoch: 17 [33792/39424 (86%)]\tLoss: 0.674273\n",
      "Train Epoch: 17 [34304/39424 (87%)]\tLoss: 0.718445\n",
      "Train Epoch: 17 [34816/39424 (88%)]\tLoss: 0.795436\n",
      "Train Epoch: 17 [35328/39424 (90%)]\tLoss: 0.691287\n",
      "Train Epoch: 17 [35840/39424 (91%)]\tLoss: 0.793698\n",
      "Train Epoch: 17 [36352/39424 (92%)]\tLoss: 0.755780\n",
      "Train Epoch: 17 [36864/39424 (94%)]\tLoss: 0.758689\n",
      "Train Epoch: 17 [37376/39424 (95%)]\tLoss: 0.816898\n",
      "Train Epoch: 17 [37888/39424 (96%)]\tLoss: 0.844704\n",
      "Train Epoch: 17 [38400/39424 (97%)]\tLoss: 0.651952\n",
      "Train Epoch: 17 [38912/39424 (99%)]\tLoss: 0.694893\n",
      "Average training loss: 1.2384471893310547\n",
      "\n",
      "Test set: Average loss: 9.2314, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 0.8486, Accuracy: 9987/12630 (79%)\n",
      "\n",
      "tensor([0.0000, 0.7611, 0.9067, 0.8089, 0.8424, 0.6651, 0.6200, 0.6244, 0.5556,\n",
      "        0.8375, 0.9227, 0.8357, 0.9261, 0.9625, 0.9704, 0.9190, 0.8200, 0.9806,\n",
      "        0.6897, 0.2333, 0.7667, 0.3444, 0.8417, 0.5200, 0.2556, 0.8958, 0.6389,\n",
      "        0.2667, 0.6467, 0.5000, 0.2133, 0.9222, 0.2833, 0.9429, 0.9750, 0.8615,\n",
      "        0.7000, 0.7667, 0.9101, 0.7111, 0.2778, 0.6333, 0.5444])\n",
      "Train backdoor\n",
      "Train Epoch: 17 [0/9728 (0%)]\tLoss: 9.083466\n",
      "Train Epoch: 17 [512/9728 (5%)]\tLoss: 5.212971\n",
      "Train Epoch: 17 [1024/9728 (11%)]\tLoss: 1.457001\n",
      "Train Epoch: 17 [1536/9728 (16%)]\tLoss: 0.083151\n",
      "Train Epoch: 17 [2048/9728 (21%)]\tLoss: 0.035348\n",
      "Train Epoch: 17 [2560/9728 (26%)]\tLoss: 0.034841\n",
      "Train Epoch: 17 [3072/9728 (32%)]\tLoss: 0.017279\n",
      "Train Epoch: 17 [3584/9728 (37%)]\tLoss: 0.022540\n",
      "Train Epoch: 17 [4096/9728 (42%)]\tLoss: 0.014161\n",
      "Train Epoch: 17 [4608/9728 (47%)]\tLoss: 0.014473\n",
      "Train Epoch: 17 [5120/9728 (53%)]\tLoss: 0.009568\n",
      "Train Epoch: 17 [5632/9728 (58%)]\tLoss: 0.009906\n",
      "Train Epoch: 17 [6144/9728 (63%)]\tLoss: 0.008450\n",
      "Train Epoch: 17 [6656/9728 (68%)]\tLoss: 0.009391\n",
      "Train Epoch: 17 [7168/9728 (74%)]\tLoss: 0.007671\n",
      "Train Epoch: 17 [7680/9728 (79%)]\tLoss: 0.005074\n",
      "Train Epoch: 17 [8192/9728 (84%)]\tLoss: 0.004188\n",
      "Train Epoch: 17 [8704/9728 (89%)]\tLoss: 0.006374\n",
      "Train Epoch: 17 [9216/9728 (95%)]\tLoss: 0.006452\n",
      "Average training loss: 0.8443318605422974\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.8679, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 18 [0/39424 (0%)]\tLoss: 11.600611\n",
      "Train Epoch: 18 [512/39424 (1%)]\tLoss: 1.437363\n",
      "Train Epoch: 18 [1024/39424 (3%)]\tLoss: 1.234522\n",
      "Train Epoch: 18 [1536/39424 (4%)]\tLoss: 1.247479\n",
      "Train Epoch: 18 [2048/39424 (5%)]\tLoss: 1.118629\n",
      "Train Epoch: 18 [2560/39424 (6%)]\tLoss: 1.080449\n",
      "Train Epoch: 18 [3072/39424 (8%)]\tLoss: 1.077458\n",
      "Train Epoch: 18 [3584/39424 (9%)]\tLoss: 1.048140\n",
      "Train Epoch: 18 [4096/39424 (10%)]\tLoss: 1.035819\n",
      "Train Epoch: 18 [4608/39424 (12%)]\tLoss: 0.994675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [5120/39424 (13%)]\tLoss: 0.934510\n",
      "Train Epoch: 18 [5632/39424 (14%)]\tLoss: 0.925913\n",
      "Train Epoch: 18 [6144/39424 (16%)]\tLoss: 0.921109\n",
      "Train Epoch: 18 [6656/39424 (17%)]\tLoss: 0.952343\n",
      "Train Epoch: 18 [7168/39424 (18%)]\tLoss: 0.903357\n",
      "Train Epoch: 18 [7680/39424 (19%)]\tLoss: 0.881673\n",
      "Train Epoch: 18 [8192/39424 (21%)]\tLoss: 0.786758\n",
      "Train Epoch: 18 [8704/39424 (22%)]\tLoss: 0.852582\n",
      "Train Epoch: 18 [9216/39424 (23%)]\tLoss: 0.846962\n",
      "Train Epoch: 18 [9728/39424 (25%)]\tLoss: 0.870788\n",
      "Train Epoch: 18 [10240/39424 (26%)]\tLoss: 0.773046\n",
      "Train Epoch: 18 [10752/39424 (27%)]\tLoss: 0.848617\n",
      "Train Epoch: 18 [11264/39424 (29%)]\tLoss: 0.799804\n",
      "Train Epoch: 18 [11776/39424 (30%)]\tLoss: 0.777184\n",
      "Train Epoch: 18 [12288/39424 (31%)]\tLoss: 0.812281\n",
      "Train Epoch: 18 [12800/39424 (32%)]\tLoss: 0.760576\n",
      "Train Epoch: 18 [13312/39424 (34%)]\tLoss: 0.777943\n",
      "Train Epoch: 18 [13824/39424 (35%)]\tLoss: 0.788432\n",
      "Train Epoch: 18 [14336/39424 (36%)]\tLoss: 0.708385\n",
      "Train Epoch: 18 [14848/39424 (38%)]\tLoss: 0.758919\n",
      "Train Epoch: 18 [15360/39424 (39%)]\tLoss: 0.742399\n",
      "Train Epoch: 18 [15872/39424 (40%)]\tLoss: 0.719787\n",
      "Train Epoch: 18 [16384/39424 (42%)]\tLoss: 0.764332\n",
      "Train Epoch: 18 [16896/39424 (43%)]\tLoss: 0.801469\n",
      "Train Epoch: 18 [17408/39424 (44%)]\tLoss: 0.669283\n",
      "Train Epoch: 18 [17920/39424 (45%)]\tLoss: 0.801046\n",
      "Train Epoch: 18 [18432/39424 (47%)]\tLoss: 0.772379\n",
      "Train Epoch: 18 [18944/39424 (48%)]\tLoss: 0.711390\n",
      "Train Epoch: 18 [19456/39424 (49%)]\tLoss: 0.792292\n",
      "Train Epoch: 18 [19968/39424 (51%)]\tLoss: 0.657226\n",
      "Train Epoch: 18 [20480/39424 (52%)]\tLoss: 0.768153\n",
      "Train Epoch: 18 [20992/39424 (53%)]\tLoss: 0.786260\n",
      "Train Epoch: 18 [21504/39424 (55%)]\tLoss: 0.647102\n",
      "Train Epoch: 18 [22016/39424 (56%)]\tLoss: 0.642616\n",
      "Train Epoch: 18 [22528/39424 (57%)]\tLoss: 0.641745\n",
      "Train Epoch: 18 [23040/39424 (58%)]\tLoss: 0.725723\n",
      "Train Epoch: 18 [23552/39424 (60%)]\tLoss: 0.622634\n",
      "Train Epoch: 18 [24064/39424 (61%)]\tLoss: 0.771391\n",
      "Train Epoch: 18 [24576/39424 (62%)]\tLoss: 0.724593\n",
      "Train Epoch: 18 [25088/39424 (64%)]\tLoss: 0.638018\n",
      "Train Epoch: 18 [25600/39424 (65%)]\tLoss: 0.699969\n",
      "Train Epoch: 18 [26112/39424 (66%)]\tLoss: 0.654546\n",
      "Train Epoch: 18 [26624/39424 (68%)]\tLoss: 0.691530\n",
      "Train Epoch: 18 [27136/39424 (69%)]\tLoss: 0.707145\n",
      "Train Epoch: 18 [27648/39424 (70%)]\tLoss: 0.711516\n",
      "Train Epoch: 18 [28160/39424 (71%)]\tLoss: 0.664235\n",
      "Train Epoch: 18 [28672/39424 (73%)]\tLoss: 0.656600\n",
      "Train Epoch: 18 [29184/39424 (74%)]\tLoss: 0.579663\n",
      "Train Epoch: 18 [29696/39424 (75%)]\tLoss: 0.642926\n",
      "Train Epoch: 18 [30208/39424 (77%)]\tLoss: 0.682387\n",
      "Train Epoch: 18 [30720/39424 (78%)]\tLoss: 0.724950\n",
      "Train Epoch: 18 [31232/39424 (79%)]\tLoss: 0.711463\n",
      "Train Epoch: 18 [31744/39424 (81%)]\tLoss: 0.669266\n",
      "Train Epoch: 18 [32256/39424 (82%)]\tLoss: 0.632721\n",
      "Train Epoch: 18 [32768/39424 (83%)]\tLoss: 0.646609\n",
      "Train Epoch: 18 [33280/39424 (84%)]\tLoss: 0.672357\n",
      "Train Epoch: 18 [33792/39424 (86%)]\tLoss: 0.570805\n",
      "Train Epoch: 18 [34304/39424 (87%)]\tLoss: 0.585705\n",
      "Train Epoch: 18 [34816/39424 (88%)]\tLoss: 0.646573\n",
      "Train Epoch: 18 [35328/39424 (90%)]\tLoss: 0.619432\n",
      "Train Epoch: 18 [35840/39424 (91%)]\tLoss: 0.659015\n",
      "Train Epoch: 18 [36352/39424 (92%)]\tLoss: 0.663749\n",
      "Train Epoch: 18 [36864/39424 (94%)]\tLoss: 0.629663\n",
      "Train Epoch: 18 [37376/39424 (95%)]\tLoss: 0.683781\n",
      "Train Epoch: 18 [37888/39424 (96%)]\tLoss: 0.668217\n",
      "Train Epoch: 18 [38400/39424 (97%)]\tLoss: 0.559814\n",
      "Train Epoch: 18 [38912/39424 (99%)]\tLoss: 0.627728\n",
      "Average training loss: 0.9171237945556641\n",
      "\n",
      "Test set: Average loss: 9.0082, Accuracy: 0/12630 (0%)\n",
      "\n",
      "tensor([0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 0.7532, Accuracy: 10313/12630 (82%)\n",
      "\n",
      "tensor([0.0000, 0.7972, 0.9053, 0.8800, 0.8439, 0.6825, 0.6533, 0.6889, 0.6222,\n",
      "        0.8958, 0.9318, 0.8429, 0.9290, 0.9681, 0.9741, 0.9333, 0.9133, 0.9750,\n",
      "        0.6513, 0.3500, 0.7556, 0.5556, 0.8583, 0.5800, 0.4889, 0.8958, 0.6611,\n",
      "        0.3167, 0.6733, 0.7000, 0.2333, 0.9259, 0.3333, 0.9571, 0.9750, 0.8897,\n",
      "        0.7083, 0.8667, 0.9261, 0.7667, 0.4778, 0.6667, 0.5333])\n",
      "Train backdoor\n",
      "Train Epoch: 18 [0/9728 (0%)]\tLoss: 8.879559\n",
      "Train Epoch: 18 [512/9728 (5%)]\tLoss: 4.349606\n",
      "Train Epoch: 18 [1024/9728 (11%)]\tLoss: 0.528988\n",
      "Train Epoch: 18 [1536/9728 (16%)]\tLoss: 0.082674\n",
      "Train Epoch: 18 [2048/9728 (21%)]\tLoss: 0.041598\n",
      "Train Epoch: 18 [2560/9728 (26%)]\tLoss: 0.026261\n",
      "Train Epoch: 18 [3072/9728 (32%)]\tLoss: 0.015224\n",
      "Train Epoch: 18 [3584/9728 (37%)]\tLoss: 0.022930\n",
      "Train Epoch: 18 [4096/9728 (42%)]\tLoss: 0.017878\n",
      "Train Epoch: 18 [4608/9728 (47%)]\tLoss: 0.011853\n",
      "Train Epoch: 18 [5120/9728 (53%)]\tLoss: 0.008204\n",
      "Train Epoch: 18 [5632/9728 (58%)]\tLoss: 0.010906\n",
      "Train Epoch: 18 [6144/9728 (63%)]\tLoss: 0.008387\n",
      "Train Epoch: 18 [6656/9728 (68%)]\tLoss: 0.010259\n",
      "Train Epoch: 18 [7168/9728 (74%)]\tLoss: 0.007926\n",
      "Train Epoch: 18 [7680/9728 (79%)]\tLoss: 0.005766\n",
      "Train Epoch: 18 [8192/9728 (84%)]\tLoss: 0.004759\n",
      "Train Epoch: 18 [8704/9728 (89%)]\tLoss: 0.006591\n",
      "Train Epoch: 18 [9216/9728 (95%)]\tLoss: 0.005733\n",
      "Average training loss: 0.7392159700393677\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.3100, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 19 [0/39424 (0%)]\tLoss: 11.097073\n",
      "Train Epoch: 19 [512/39424 (1%)]\tLoss: 1.274314\n",
      "Train Epoch: 19 [1024/39424 (3%)]\tLoss: 1.025199\n",
      "Train Epoch: 19 [1536/39424 (4%)]\tLoss: 1.035491\n",
      "Train Epoch: 19 [2048/39424 (5%)]\tLoss: 0.947158\n",
      "Train Epoch: 19 [2560/39424 (6%)]\tLoss: 0.917712\n",
      "Train Epoch: 19 [3072/39424 (8%)]\tLoss: 0.912855\n",
      "Train Epoch: 19 [3584/39424 (9%)]\tLoss: 0.894612\n",
      "Train Epoch: 19 [4096/39424 (10%)]\tLoss: 0.858855\n",
      "Train Epoch: 19 [4608/39424 (12%)]\tLoss: 0.864852\n",
      "Train Epoch: 19 [5120/39424 (13%)]\tLoss: 0.829615\n",
      "Train Epoch: 19 [5632/39424 (14%)]\tLoss: 0.790048\n",
      "Train Epoch: 19 [6144/39424 (16%)]\tLoss: 0.805920\n",
      "Train Epoch: 19 [6656/39424 (17%)]\tLoss: 0.856238\n",
      "Train Epoch: 19 [7168/39424 (18%)]\tLoss: 0.796915\n",
      "Train Epoch: 19 [7680/39424 (19%)]\tLoss: 0.766611\n",
      "Train Epoch: 19 [8192/39424 (21%)]\tLoss: 0.695007\n",
      "Train Epoch: 19 [8704/39424 (22%)]\tLoss: 0.729401\n",
      "Train Epoch: 19 [9216/39424 (23%)]\tLoss: 0.735750\n",
      "Train Epoch: 19 [9728/39424 (25%)]\tLoss: 0.768539\n",
      "Train Epoch: 19 [10240/39424 (26%)]\tLoss: 0.675106\n",
      "Train Epoch: 19 [10752/39424 (27%)]\tLoss: 0.748516\n",
      "Train Epoch: 19 [11264/39424 (29%)]\tLoss: 0.697994\n",
      "Train Epoch: 19 [11776/39424 (30%)]\tLoss: 0.694377\n",
      "Train Epoch: 19 [12288/39424 (31%)]\tLoss: 0.703863\n",
      "Train Epoch: 19 [12800/39424 (32%)]\tLoss: 0.653267\n",
      "Train Epoch: 19 [13312/39424 (34%)]\tLoss: 0.668750\n",
      "Train Epoch: 19 [13824/39424 (35%)]\tLoss: 0.671395\n",
      "Train Epoch: 19 [14336/39424 (36%)]\tLoss: 0.581297\n",
      "Train Epoch: 19 [14848/39424 (38%)]\tLoss: 0.666369\n",
      "Train Epoch: 19 [15360/39424 (39%)]\tLoss: 0.644391\n",
      "Train Epoch: 19 [15872/39424 (40%)]\tLoss: 0.607641\n",
      "Train Epoch: 19 [16384/39424 (42%)]\tLoss: 0.672803\n",
      "Train Epoch: 19 [16896/39424 (43%)]\tLoss: 0.708540\n",
      "Train Epoch: 19 [17408/39424 (44%)]\tLoss: 0.575562\n",
      "Train Epoch: 19 [17920/39424 (45%)]\tLoss: 0.717415\n",
      "Train Epoch: 19 [18432/39424 (47%)]\tLoss: 0.661944\n",
      "Train Epoch: 19 [18944/39424 (48%)]\tLoss: 0.618928\n",
      "Train Epoch: 19 [19456/39424 (49%)]\tLoss: 0.680945\n",
      "Train Epoch: 19 [19968/39424 (51%)]\tLoss: 0.557985\n",
      "Train Epoch: 19 [20480/39424 (52%)]\tLoss: 0.623060\n",
      "Train Epoch: 19 [20992/39424 (53%)]\tLoss: 0.694923\n",
      "Train Epoch: 19 [21504/39424 (55%)]\tLoss: 0.573394\n",
      "Train Epoch: 19 [22016/39424 (56%)]\tLoss: 0.560711\n",
      "Train Epoch: 19 [22528/39424 (57%)]\tLoss: 0.552130\n",
      "Train Epoch: 19 [23040/39424 (58%)]\tLoss: 0.643218\n",
      "Train Epoch: 19 [23552/39424 (60%)]\tLoss: 0.533418\n",
      "Train Epoch: 19 [24064/39424 (61%)]\tLoss: 0.653759\n",
      "Train Epoch: 19 [24576/39424 (62%)]\tLoss: 0.615698\n",
      "Train Epoch: 19 [25088/39424 (64%)]\tLoss: 0.584435\n",
      "Train Epoch: 19 [25600/39424 (65%)]\tLoss: 0.595941\n",
      "Train Epoch: 19 [26112/39424 (66%)]\tLoss: 0.580497\n",
      "Train Epoch: 19 [26624/39424 (68%)]\tLoss: 0.616862\n",
      "Train Epoch: 19 [27136/39424 (69%)]\tLoss: 0.624855\n",
      "Train Epoch: 19 [27648/39424 (70%)]\tLoss: 0.631576\n",
      "Train Epoch: 19 [28160/39424 (71%)]\tLoss: 0.601456\n",
      "Train Epoch: 19 [28672/39424 (73%)]\tLoss: 0.555017\n",
      "Train Epoch: 19 [29184/39424 (74%)]\tLoss: 0.524738\n",
      "Train Epoch: 19 [29696/39424 (75%)]\tLoss: 0.549139\n",
      "Train Epoch: 19 [30208/39424 (77%)]\tLoss: 0.628472\n",
      "Train Epoch: 19 [30720/39424 (78%)]\tLoss: 0.603938\n",
      "Train Epoch: 19 [31232/39424 (79%)]\tLoss: 0.616060\n",
      "Train Epoch: 19 [31744/39424 (81%)]\tLoss: 0.641485\n",
      "Train Epoch: 19 [32256/39424 (82%)]\tLoss: 0.541123\n",
      "Train Epoch: 19 [32768/39424 (83%)]\tLoss: 0.563164\n",
      "Train Epoch: 19 [33280/39424 (84%)]\tLoss: 0.589505\n",
      "Train Epoch: 19 [33792/39424 (86%)]\tLoss: 0.498540\n",
      "Train Epoch: 19 [34304/39424 (87%)]\tLoss: 0.493785\n",
      "Train Epoch: 19 [34816/39424 (88%)]\tLoss: 0.563765\n",
      "Train Epoch: 19 [35328/39424 (90%)]\tLoss: 0.530089\n",
      "Train Epoch: 19 [35840/39424 (91%)]\tLoss: 0.620606\n",
      "Train Epoch: 19 [36352/39424 (92%)]\tLoss: 0.562486\n",
      "Train Epoch: 19 [36864/39424 (94%)]\tLoss: 0.530257\n",
      "Train Epoch: 19 [37376/39424 (95%)]\tLoss: 0.605284\n",
      "Train Epoch: 19 [37888/39424 (96%)]\tLoss: 0.588527\n",
      "Train Epoch: 19 [38400/39424 (97%)]\tLoss: 0.470025\n",
      "Train Epoch: 19 [38912/39424 (99%)]\tLoss: 0.523015\n",
      "Average training loss: 0.8090155720710754\n",
      "\n",
      "Test set: Average loss: 9.0005, Accuracy: 1/12630 (0%)\n",
      "\n",
      "tensor([7.9177e-05,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan,        nan,        nan,        nan,        nan,        nan,\n",
      "               nan])\n",
      "\n",
      "Test set: Average loss: 0.6878, Accuracy: 10512/12630 (83%)\n",
      "\n",
      "tensor([0.0000, 0.8417, 0.9040, 0.8867, 0.8712, 0.7238, 0.6333, 0.7133, 0.6600,\n",
      "        0.9187, 0.9333, 0.8524, 0.9304, 0.9653, 0.9815, 0.9286, 0.9267, 0.9750,\n",
      "        0.6590, 0.3667, 0.8222, 0.4556, 0.8750, 0.6067, 0.6333, 0.8938, 0.6556,\n",
      "        0.3167, 0.7200, 0.7556, 0.2933, 0.9222, 0.6167, 0.9667, 0.9667, 0.9051,\n",
      "        0.7417, 0.9000, 0.9203, 0.7111, 0.6778, 0.6667, 0.5444])\n",
      "Train backdoor\n",
      "Train Epoch: 19 [0/9728 (0%)]\tLoss: 8.911718\n",
      "Train Epoch: 19 [512/9728 (5%)]\tLoss: 3.898285\n",
      "Train Epoch: 19 [1024/9728 (11%)]\tLoss: 0.218722\n",
      "Train Epoch: 19 [1536/9728 (16%)]\tLoss: 0.052292\n",
      "Train Epoch: 19 [2048/9728 (21%)]\tLoss: 0.029002\n",
      "Train Epoch: 19 [2560/9728 (26%)]\tLoss: 0.024181\n",
      "Train Epoch: 19 [3072/9728 (32%)]\tLoss: 0.013895\n",
      "Train Epoch: 19 [3584/9728 (37%)]\tLoss: 0.020100\n",
      "Train Epoch: 19 [4096/9728 (42%)]\tLoss: 0.011845\n",
      "Train Epoch: 19 [4608/9728 (47%)]\tLoss: 0.010335\n",
      "Train Epoch: 19 [5120/9728 (53%)]\tLoss: 0.005758\n",
      "Train Epoch: 19 [5632/9728 (58%)]\tLoss: 0.006444\n",
      "Train Epoch: 19 [6144/9728 (63%)]\tLoss: 0.007656\n",
      "Train Epoch: 19 [6656/9728 (68%)]\tLoss: 0.007316\n",
      "Train Epoch: 19 [7168/9728 (74%)]\tLoss: 0.006840\n",
      "Train Epoch: 19 [7680/9728 (79%)]\tLoss: 0.003303\n",
      "Train Epoch: 19 [8192/9728 (84%)]\tLoss: 0.002672\n",
      "Train Epoch: 19 [8704/9728 (89%)]\tLoss: 0.004706\n",
      "Train Epoch: 19 [9216/9728 (95%)]\tLoss: 0.005830\n",
      "Average training loss: 0.6968895196914673\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.1331, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 20 [0/39424 (0%)]\tLoss: 11.020695\n",
      "Train Epoch: 20 [512/39424 (1%)]\tLoss: 1.378881\n",
      "Train Epoch: 20 [1024/39424 (3%)]\tLoss: 1.176206\n",
      "Train Epoch: 20 [1536/39424 (4%)]\tLoss: 1.124642\n",
      "Train Epoch: 20 [2048/39424 (5%)]\tLoss: 0.944759\n",
      "Train Epoch: 20 [2560/39424 (6%)]\tLoss: 0.892860\n",
      "Train Epoch: 20 [3072/39424 (8%)]\tLoss: 0.870055\n",
      "Train Epoch: 20 [3584/39424 (9%)]\tLoss: 0.803900\n",
      "Train Epoch: 20 [4096/39424 (10%)]\tLoss: 0.786095\n",
      "Train Epoch: 20 [4608/39424 (12%)]\tLoss: 0.779518\n",
      "Train Epoch: 20 [5120/39424 (13%)]\tLoss: 0.728439\n",
      "Train Epoch: 20 [5632/39424 (14%)]\tLoss: 0.703587\n",
      "Train Epoch: 20 [6144/39424 (16%)]\tLoss: 0.728507\n",
      "Train Epoch: 20 [6656/39424 (17%)]\tLoss: 0.756497\n",
      "Train Epoch: 20 [7168/39424 (18%)]\tLoss: 0.718826\n",
      "Train Epoch: 20 [7680/39424 (19%)]\tLoss: 0.692973\n",
      "Train Epoch: 20 [8192/39424 (21%)]\tLoss: 0.612089\n",
      "Train Epoch: 20 [8704/39424 (22%)]\tLoss: 0.642661\n",
      "Train Epoch: 20 [9216/39424 (23%)]\tLoss: 0.650083\n",
      "Train Epoch: 20 [9728/39424 (25%)]\tLoss: 0.674227\n",
      "Train Epoch: 20 [10240/39424 (26%)]\tLoss: 0.577680\n",
      "Train Epoch: 20 [10752/39424 (27%)]\tLoss: 0.683191\n",
      "Train Epoch: 20 [11264/39424 (29%)]\tLoss: 0.606091\n",
      "Train Epoch: 20 [11776/39424 (30%)]\tLoss: 0.600987\n",
      "Train Epoch: 20 [12288/39424 (31%)]\tLoss: 0.627552\n",
      "Train Epoch: 20 [12800/39424 (32%)]\tLoss: 0.579999\n",
      "Train Epoch: 20 [13312/39424 (34%)]\tLoss: 0.599122\n",
      "Train Epoch: 20 [13824/39424 (35%)]\tLoss: 0.596713\n",
      "Train Epoch: 20 [14336/39424 (36%)]\tLoss: 0.515891\n",
      "Train Epoch: 20 [14848/39424 (38%)]\tLoss: 0.611651\n",
      "Train Epoch: 20 [15360/39424 (39%)]\tLoss: 0.558146\n",
      "Train Epoch: 20 [15872/39424 (40%)]\tLoss: 0.564033\n",
      "Train Epoch: 20 [16384/39424 (42%)]\tLoss: 0.604127\n",
      "Train Epoch: 20 [16896/39424 (43%)]\tLoss: 0.643611\n",
      "Train Epoch: 20 [17408/39424 (44%)]\tLoss: 0.528170\n",
      "Train Epoch: 20 [17920/39424 (45%)]\tLoss: 0.642736\n",
      "Train Epoch: 20 [18432/39424 (47%)]\tLoss: 0.593005\n",
      "Train Epoch: 20 [18944/39424 (48%)]\tLoss: 0.533057\n",
      "Train Epoch: 20 [19456/39424 (49%)]\tLoss: 0.618109\n",
      "Train Epoch: 20 [19968/39424 (51%)]\tLoss: 0.498054\n",
      "Train Epoch: 20 [20480/39424 (52%)]\tLoss: 0.589876\n",
      "Train Epoch: 20 [20992/39424 (53%)]\tLoss: 0.605830\n",
      "Train Epoch: 20 [21504/39424 (55%)]\tLoss: 0.471146\n",
      "Train Epoch: 20 [22016/39424 (56%)]\tLoss: 0.475326\n",
      "Train Epoch: 20 [22528/39424 (57%)]\tLoss: 0.474416\n",
      "Train Epoch: 20 [23040/39424 (58%)]\tLoss: 0.595557\n",
      "Train Epoch: 20 [23552/39424 (60%)]\tLoss: 0.470399\n",
      "Train Epoch: 20 [24064/39424 (61%)]\tLoss: 0.577826\n",
      "Train Epoch: 20 [24576/39424 (62%)]\tLoss: 0.565656\n",
      "Train Epoch: 20 [25088/39424 (64%)]\tLoss: 0.514625\n",
      "Train Epoch: 20 [25600/39424 (65%)]\tLoss: 0.554426\n",
      "Train Epoch: 20 [26112/39424 (66%)]\tLoss: 0.505560\n",
      "Train Epoch: 20 [26624/39424 (68%)]\tLoss: 0.537853\n",
      "Train Epoch: 20 [27136/39424 (69%)]\tLoss: 0.529905\n",
      "Train Epoch: 20 [27648/39424 (70%)]\tLoss: 0.570746\n",
      "Train Epoch: 20 [28160/39424 (71%)]\tLoss: 0.513252\n",
      "Train Epoch: 20 [28672/39424 (73%)]\tLoss: 0.504748\n",
      "Train Epoch: 20 [29184/39424 (74%)]\tLoss: 0.477316\n",
      "Train Epoch: 20 [29696/39424 (75%)]\tLoss: 0.498610\n",
      "Train Epoch: 20 [30208/39424 (77%)]\tLoss: 0.568337\n",
      "Train Epoch: 20 [30720/39424 (78%)]\tLoss: 0.564114\n",
      "Train Epoch: 20 [31232/39424 (79%)]\tLoss: 0.576787\n",
      "Train Epoch: 20 [31744/39424 (81%)]\tLoss: 0.549136\n",
      "Train Epoch: 20 [32256/39424 (82%)]\tLoss: 0.489149\n",
      "Train Epoch: 20 [32768/39424 (83%)]\tLoss: 0.516481\n",
      "Train Epoch: 20 [33280/39424 (84%)]\tLoss: 0.573170\n",
      "Train Epoch: 20 [33792/39424 (86%)]\tLoss: 0.434773\n",
      "Train Epoch: 20 [34304/39424 (87%)]\tLoss: 0.461546\n",
      "Train Epoch: 20 [34816/39424 (88%)]\tLoss: 0.509514\n",
      "Train Epoch: 20 [35328/39424 (90%)]\tLoss: 0.483777\n",
      "Train Epoch: 20 [35840/39424 (91%)]\tLoss: 0.514593\n",
      "Train Epoch: 20 [36352/39424 (92%)]\tLoss: 0.520600\n",
      "Train Epoch: 20 [36864/39424 (94%)]\tLoss: 0.521599\n",
      "Train Epoch: 20 [37376/39424 (95%)]\tLoss: 0.569688\n",
      "Train Epoch: 20 [37888/39424 (96%)]\tLoss: 0.525223\n",
      "Train Epoch: 20 [38400/39424 (97%)]\tLoss: 0.419737\n",
      "Train Epoch: 20 [38912/39424 (99%)]\tLoss: 0.470225\n",
      "Average training loss: 0.7502458691596985\n",
      "\n",
      "Test set: Average loss: 9.1063, Accuracy: 3/12630 (0%)\n",
      "\n",
      "tensor([0.0002,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.6368, Accuracy: 10657/12630 (84%)\n",
      "\n",
      "tensor([0.0000, 0.8458, 0.9040, 0.9156, 0.8894, 0.7175, 0.6867, 0.7200, 0.7222,\n",
      "        0.9396, 0.9379, 0.8595, 0.9333, 0.9653, 0.9815, 0.9333, 0.9267, 0.9722,\n",
      "        0.6436, 0.3667, 0.8444, 0.4667, 0.8917, 0.6867, 0.6778, 0.8979, 0.7278,\n",
      "        0.3667, 0.7600, 0.8000, 0.3400, 0.9185, 0.5833, 0.9714, 0.9667, 0.9128,\n",
      "        0.7250, 0.9000, 0.9188, 0.7222, 0.7667, 0.6833, 0.6111])\n",
      "Train backdoor\n",
      "Train Epoch: 20 [0/9728 (0%)]\tLoss: 8.964411\n",
      "Train Epoch: 20 [512/9728 (5%)]\tLoss: 4.065440\n",
      "Train Epoch: 20 [1024/9728 (11%)]\tLoss: 0.235717\n",
      "Train Epoch: 20 [1536/9728 (16%)]\tLoss: 0.076961\n",
      "Train Epoch: 20 [2048/9728 (21%)]\tLoss: 0.028881\n",
      "Train Epoch: 20 [2560/9728 (26%)]\tLoss: 0.019381\n",
      "Train Epoch: 20 [3072/9728 (32%)]\tLoss: 0.014280\n",
      "Train Epoch: 20 [3584/9728 (37%)]\tLoss: 0.025964\n",
      "Train Epoch: 20 [4096/9728 (42%)]\tLoss: 0.009640\n",
      "Train Epoch: 20 [4608/9728 (47%)]\tLoss: 0.008465\n",
      "Train Epoch: 20 [5120/9728 (53%)]\tLoss: 0.008647\n",
      "Train Epoch: 20 [5632/9728 (58%)]\tLoss: 0.007021\n",
      "Train Epoch: 20 [6144/9728 (63%)]\tLoss: 0.008095\n",
      "Train Epoch: 20 [6656/9728 (68%)]\tLoss: 0.007832\n",
      "Train Epoch: 20 [7168/9728 (74%)]\tLoss: 0.007095\n",
      "Train Epoch: 20 [7680/9728 (79%)]\tLoss: 0.004349\n",
      "Train Epoch: 20 [8192/9728 (84%)]\tLoss: 0.003883\n",
      "Train Epoch: 20 [8704/9728 (89%)]\tLoss: 0.005754\n",
      "Train Epoch: 20 [9216/9728 (95%)]\tLoss: 0.005806\n",
      "Average training loss: 0.7109275460243225\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.9448, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 21 [0/39424 (0%)]\tLoss: 10.623344\n",
      "Train Epoch: 21 [512/39424 (1%)]\tLoss: 1.208524\n",
      "Train Epoch: 21 [1024/39424 (3%)]\tLoss: 1.010698\n",
      "Train Epoch: 21 [1536/39424 (4%)]\tLoss: 0.920530\n",
      "Train Epoch: 21 [2048/39424 (5%)]\tLoss: 0.814499\n",
      "Train Epoch: 21 [2560/39424 (6%)]\tLoss: 0.745753\n",
      "Train Epoch: 21 [3072/39424 (8%)]\tLoss: 0.761271\n",
      "Train Epoch: 21 [3584/39424 (9%)]\tLoss: 0.747867\n",
      "Train Epoch: 21 [4096/39424 (10%)]\tLoss: 0.697833\n",
      "Train Epoch: 21 [4608/39424 (12%)]\tLoss: 0.720983\n",
      "Train Epoch: 21 [5120/39424 (13%)]\tLoss: 0.668999\n",
      "Train Epoch: 21 [5632/39424 (14%)]\tLoss: 0.665940\n",
      "Train Epoch: 21 [6144/39424 (16%)]\tLoss: 0.662776\n",
      "Train Epoch: 21 [6656/39424 (17%)]\tLoss: 0.682750\n",
      "Train Epoch: 21 [7168/39424 (18%)]\tLoss: 0.625085\n",
      "Train Epoch: 21 [7680/39424 (19%)]\tLoss: 0.615570\n",
      "Train Epoch: 21 [8192/39424 (21%)]\tLoss: 0.556068\n",
      "Train Epoch: 21 [8704/39424 (22%)]\tLoss: 0.608157\n",
      "Train Epoch: 21 [9216/39424 (23%)]\tLoss: 0.589398\n",
      "Train Epoch: 21 [9728/39424 (25%)]\tLoss: 0.621849\n",
      "Train Epoch: 21 [10240/39424 (26%)]\tLoss: 0.543381\n",
      "Train Epoch: 21 [10752/39424 (27%)]\tLoss: 0.635098\n",
      "Train Epoch: 21 [11264/39424 (29%)]\tLoss: 0.587183\n",
      "Train Epoch: 21 [11776/39424 (30%)]\tLoss: 0.517712\n",
      "Train Epoch: 21 [12288/39424 (31%)]\tLoss: 0.565938\n",
      "Train Epoch: 21 [12800/39424 (32%)]\tLoss: 0.525509\n",
      "Train Epoch: 21 [13312/39424 (34%)]\tLoss: 0.563282\n",
      "Train Epoch: 21 [13824/39424 (35%)]\tLoss: 0.540036\n",
      "Train Epoch: 21 [14336/39424 (36%)]\tLoss: 0.489610\n",
      "Train Epoch: 21 [14848/39424 (38%)]\tLoss: 0.544146\n",
      "Train Epoch: 21 [15360/39424 (39%)]\tLoss: 0.508594\n",
      "Train Epoch: 21 [15872/39424 (40%)]\tLoss: 0.490986\n",
      "Train Epoch: 21 [16384/39424 (42%)]\tLoss: 0.522395\n",
      "Train Epoch: 21 [16896/39424 (43%)]\tLoss: 0.608337\n",
      "Train Epoch: 21 [17408/39424 (44%)]\tLoss: 0.489150\n",
      "Train Epoch: 21 [17920/39424 (45%)]\tLoss: 0.584561\n",
      "Train Epoch: 21 [18432/39424 (47%)]\tLoss: 0.562964\n",
      "Train Epoch: 21 [18944/39424 (48%)]\tLoss: 0.492491\n",
      "Train Epoch: 21 [19456/39424 (49%)]\tLoss: 0.537578\n",
      "Train Epoch: 21 [19968/39424 (51%)]\tLoss: 0.426613\n",
      "Train Epoch: 21 [20480/39424 (52%)]\tLoss: 0.497015\n",
      "Train Epoch: 21 [20992/39424 (53%)]\tLoss: 0.572286\n",
      "Train Epoch: 21 [21504/39424 (55%)]\tLoss: 0.467393\n",
      "Train Epoch: 21 [22016/39424 (56%)]\tLoss: 0.491010\n",
      "Train Epoch: 21 [22528/39424 (57%)]\tLoss: 0.419109\n",
      "Train Epoch: 21 [23040/39424 (58%)]\tLoss: 0.567709\n",
      "Train Epoch: 21 [23552/39424 (60%)]\tLoss: 0.445577\n",
      "Train Epoch: 21 [24064/39424 (61%)]\tLoss: 0.527614\n",
      "Train Epoch: 21 [24576/39424 (62%)]\tLoss: 0.511517\n",
      "Train Epoch: 21 [25088/39424 (64%)]\tLoss: 0.450152\n",
      "Train Epoch: 21 [25600/39424 (65%)]\tLoss: 0.471583\n",
      "Train Epoch: 21 [26112/39424 (66%)]\tLoss: 0.439302\n",
      "Train Epoch: 21 [26624/39424 (68%)]\tLoss: 0.501550\n",
      "Train Epoch: 21 [27136/39424 (69%)]\tLoss: 0.492370\n",
      "Train Epoch: 21 [27648/39424 (70%)]\tLoss: 0.529396\n",
      "Train Epoch: 21 [28160/39424 (71%)]\tLoss: 0.491474\n",
      "Train Epoch: 21 [28672/39424 (73%)]\tLoss: 0.460620\n",
      "Train Epoch: 21 [29184/39424 (74%)]\tLoss: 0.415541\n",
      "Train Epoch: 21 [29696/39424 (75%)]\tLoss: 0.455156\n",
      "Train Epoch: 21 [30208/39424 (77%)]\tLoss: 0.490750\n",
      "Train Epoch: 21 [30720/39424 (78%)]\tLoss: 0.507220\n",
      "Train Epoch: 21 [31232/39424 (79%)]\tLoss: 0.526596\n",
      "Train Epoch: 21 [31744/39424 (81%)]\tLoss: 0.507345\n",
      "Train Epoch: 21 [32256/39424 (82%)]\tLoss: 0.418615\n",
      "Train Epoch: 21 [32768/39424 (83%)]\tLoss: 0.466246\n",
      "Train Epoch: 21 [33280/39424 (84%)]\tLoss: 0.483389\n",
      "Train Epoch: 21 [33792/39424 (86%)]\tLoss: 0.376231\n",
      "Train Epoch: 21 [34304/39424 (87%)]\tLoss: 0.368419\n",
      "Train Epoch: 21 [34816/39424 (88%)]\tLoss: 0.443631\n",
      "Train Epoch: 21 [35328/39424 (90%)]\tLoss: 0.446367\n",
      "Train Epoch: 21 [35840/39424 (91%)]\tLoss: 0.468353\n",
      "Train Epoch: 21 [36352/39424 (92%)]\tLoss: 0.451854\n",
      "Train Epoch: 21 [36864/39424 (94%)]\tLoss: 0.446632\n",
      "Train Epoch: 21 [37376/39424 (95%)]\tLoss: 0.470127\n",
      "Train Epoch: 21 [37888/39424 (96%)]\tLoss: 0.480222\n",
      "Train Epoch: 21 [38400/39424 (97%)]\tLoss: 0.414181\n",
      "Train Epoch: 21 [38912/39424 (99%)]\tLoss: 0.457066\n",
      "Average training loss: 0.6845853924751282\n",
      "\n",
      "Test set: Average loss: 9.0562, Accuracy: 4/12630 (0%)\n",
      "\n",
      "tensor([0.0003,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.6008, Accuracy: 10773/12630 (85%)\n",
      "\n",
      "tensor([0.0000, 0.8736, 0.9160, 0.9044, 0.8909, 0.7508, 0.6733, 0.7356, 0.7267,\n",
      "        0.9521, 0.9455, 0.8690, 0.9362, 0.9667, 0.9815, 0.9333, 0.9333, 0.9611,\n",
      "        0.6333, 0.4000, 0.8889, 0.4889, 0.8917, 0.7000, 0.7444, 0.8979, 0.7444,\n",
      "        0.3833, 0.8000, 0.8000, 0.3667, 0.9148, 0.6167, 0.9714, 0.9667, 0.9256,\n",
      "        0.7500, 0.9000, 0.9261, 0.7444, 0.8000, 0.7000, 0.6333])\n",
      "Train backdoor\n",
      "Train Epoch: 21 [0/9728 (0%)]\tLoss: 8.968228\n",
      "Train Epoch: 21 [512/9728 (5%)]\tLoss: 3.627785\n",
      "Train Epoch: 21 [1024/9728 (11%)]\tLoss: 0.163232\n",
      "Train Epoch: 21 [1536/9728 (16%)]\tLoss: 0.062604\n",
      "Train Epoch: 21 [2048/9728 (21%)]\tLoss: 0.035960\n",
      "Train Epoch: 21 [2560/9728 (26%)]\tLoss: 0.024220\n",
      "Train Epoch: 21 [3072/9728 (32%)]\tLoss: 0.011173\n",
      "Train Epoch: 21 [3584/9728 (37%)]\tLoss: 0.017208\n",
      "Train Epoch: 21 [4096/9728 (42%)]\tLoss: 0.008597\n",
      "Train Epoch: 21 [4608/9728 (47%)]\tLoss: 0.009983\n",
      "Train Epoch: 21 [5120/9728 (53%)]\tLoss: 0.005612\n",
      "Train Epoch: 21 [5632/9728 (58%)]\tLoss: 0.007446\n",
      "Train Epoch: 21 [6144/9728 (63%)]\tLoss: 0.006560\n",
      "Train Epoch: 21 [6656/9728 (68%)]\tLoss: 0.006417\n",
      "Train Epoch: 21 [7168/9728 (74%)]\tLoss: 0.006544\n",
      "Train Epoch: 21 [7680/9728 (79%)]\tLoss: 0.004552\n",
      "Train Epoch: 21 [8192/9728 (84%)]\tLoss: 0.004520\n",
      "Train Epoch: 21 [8704/9728 (89%)]\tLoss: 0.004339\n",
      "Train Epoch: 21 [9216/9728 (95%)]\tLoss: 0.006447\n",
      "Average training loss: 0.6832331418991089\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 11.0186, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 22 [0/39424 (0%)]\tLoss: 10.748701\n",
      "Train Epoch: 22 [512/39424 (1%)]\tLoss: 1.184761\n",
      "Train Epoch: 22 [1024/39424 (3%)]\tLoss: 0.960729\n",
      "Train Epoch: 22 [1536/39424 (4%)]\tLoss: 0.909452\n",
      "Train Epoch: 22 [2048/39424 (5%)]\tLoss: 0.759875\n",
      "Train Epoch: 22 [2560/39424 (6%)]\tLoss: 0.732472\n",
      "Train Epoch: 22 [3072/39424 (8%)]\tLoss: 0.750117\n",
      "Train Epoch: 22 [3584/39424 (9%)]\tLoss: 0.666128\n",
      "Train Epoch: 22 [4096/39424 (10%)]\tLoss: 0.647107\n",
      "Train Epoch: 22 [4608/39424 (12%)]\tLoss: 0.646206\n",
      "Train Epoch: 22 [5120/39424 (13%)]\tLoss: 0.618328\n",
      "Train Epoch: 22 [5632/39424 (14%)]\tLoss: 0.594141\n",
      "Train Epoch: 22 [6144/39424 (16%)]\tLoss: 0.598784\n",
      "Train Epoch: 22 [6656/39424 (17%)]\tLoss: 0.627942\n",
      "Train Epoch: 22 [7168/39424 (18%)]\tLoss: 0.579697\n",
      "Train Epoch: 22 [7680/39424 (19%)]\tLoss: 0.579095\n",
      "Train Epoch: 22 [8192/39424 (21%)]\tLoss: 0.519112\n",
      "Train Epoch: 22 [8704/39424 (22%)]\tLoss: 0.535595\n",
      "Train Epoch: 22 [9216/39424 (23%)]\tLoss: 0.553805\n",
      "Train Epoch: 22 [9728/39424 (25%)]\tLoss: 0.584649\n",
      "Train Epoch: 22 [10240/39424 (26%)]\tLoss: 0.490454\n",
      "Train Epoch: 22 [10752/39424 (27%)]\tLoss: 0.586373\n",
      "Train Epoch: 22 [11264/39424 (29%)]\tLoss: 0.501730\n",
      "Train Epoch: 22 [11776/39424 (30%)]\tLoss: 0.515674\n",
      "Train Epoch: 22 [12288/39424 (31%)]\tLoss: 0.529080\n",
      "Train Epoch: 22 [12800/39424 (32%)]\tLoss: 0.468469\n",
      "Train Epoch: 22 [13312/39424 (34%)]\tLoss: 0.511356\n",
      "Train Epoch: 22 [13824/39424 (35%)]\tLoss: 0.513205\n",
      "Train Epoch: 22 [14336/39424 (36%)]\tLoss: 0.435436\n",
      "Train Epoch: 22 [14848/39424 (38%)]\tLoss: 0.490194\n",
      "Train Epoch: 22 [15360/39424 (39%)]\tLoss: 0.455775\n",
      "Train Epoch: 22 [15872/39424 (40%)]\tLoss: 0.472606\n",
      "Train Epoch: 22 [16384/39424 (42%)]\tLoss: 0.504497\n",
      "Train Epoch: 22 [16896/39424 (43%)]\tLoss: 0.538260\n",
      "Train Epoch: 22 [17408/39424 (44%)]\tLoss: 0.441939\n",
      "Train Epoch: 22 [17920/39424 (45%)]\tLoss: 0.559842\n",
      "Train Epoch: 22 [18432/39424 (47%)]\tLoss: 0.495594\n",
      "Train Epoch: 22 [18944/39424 (48%)]\tLoss: 0.439562\n",
      "Train Epoch: 22 [19456/39424 (49%)]\tLoss: 0.516850\n",
      "Train Epoch: 22 [19968/39424 (51%)]\tLoss: 0.415596\n",
      "Train Epoch: 22 [20480/39424 (52%)]\tLoss: 0.454640\n",
      "Train Epoch: 22 [20992/39424 (53%)]\tLoss: 0.515190\n",
      "Train Epoch: 22 [21504/39424 (55%)]\tLoss: 0.399507\n",
      "Train Epoch: 22 [22016/39424 (56%)]\tLoss: 0.425685\n",
      "Train Epoch: 22 [22528/39424 (57%)]\tLoss: 0.409440\n",
      "Train Epoch: 22 [23040/39424 (58%)]\tLoss: 0.533564\n",
      "Train Epoch: 22 [23552/39424 (60%)]\tLoss: 0.363044\n",
      "Train Epoch: 22 [24064/39424 (61%)]\tLoss: 0.469189\n",
      "Train Epoch: 22 [24576/39424 (62%)]\tLoss: 0.457281\n",
      "Train Epoch: 22 [25088/39424 (64%)]\tLoss: 0.459493\n",
      "Train Epoch: 22 [25600/39424 (65%)]\tLoss: 0.443434\n",
      "Train Epoch: 22 [26112/39424 (66%)]\tLoss: 0.409278\n",
      "Train Epoch: 22 [26624/39424 (68%)]\tLoss: 0.467544\n",
      "Train Epoch: 22 [27136/39424 (69%)]\tLoss: 0.467658\n",
      "Train Epoch: 22 [27648/39424 (70%)]\tLoss: 0.451665\n",
      "Train Epoch: 22 [28160/39424 (71%)]\tLoss: 0.407280\n",
      "Train Epoch: 22 [28672/39424 (73%)]\tLoss: 0.437019\n",
      "Train Epoch: 22 [29184/39424 (74%)]\tLoss: 0.420817\n",
      "Train Epoch: 22 [29696/39424 (75%)]\tLoss: 0.435222\n",
      "Train Epoch: 22 [30208/39424 (77%)]\tLoss: 0.429870\n",
      "Train Epoch: 22 [30720/39424 (78%)]\tLoss: 0.475774\n",
      "Train Epoch: 22 [31232/39424 (79%)]\tLoss: 0.485108\n",
      "Train Epoch: 22 [31744/39424 (81%)]\tLoss: 0.436267\n",
      "Train Epoch: 22 [32256/39424 (82%)]\tLoss: 0.411929\n",
      "Train Epoch: 22 [32768/39424 (83%)]\tLoss: 0.433243\n",
      "Train Epoch: 22 [33280/39424 (84%)]\tLoss: 0.441192\n",
      "Train Epoch: 22 [33792/39424 (86%)]\tLoss: 0.367184\n",
      "Train Epoch: 22 [34304/39424 (87%)]\tLoss: 0.361651\n",
      "Train Epoch: 22 [34816/39424 (88%)]\tLoss: 0.419149\n",
      "Train Epoch: 22 [35328/39424 (90%)]\tLoss: 0.404998\n",
      "Train Epoch: 22 [35840/39424 (91%)]\tLoss: 0.445207\n",
      "Train Epoch: 22 [36352/39424 (92%)]\tLoss: 0.428348\n",
      "Train Epoch: 22 [36864/39424 (94%)]\tLoss: 0.377954\n",
      "Train Epoch: 22 [37376/39424 (95%)]\tLoss: 0.470844\n",
      "Train Epoch: 22 [37888/39424 (96%)]\tLoss: 0.428290\n",
      "Train Epoch: 22 [38400/39424 (97%)]\tLoss: 0.366360\n",
      "Train Epoch: 22 [38912/39424 (99%)]\tLoss: 0.406513\n",
      "Average training loss: 0.6454029083251953\n",
      "\n",
      "Test set: Average loss: 9.0047, Accuracy: 8/12630 (0%)\n",
      "\n",
      "tensor([0.0006,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.5662, Accuracy: 10881/12630 (86%)\n",
      "\n",
      "tensor([0.0000, 0.8778, 0.9413, 0.9044, 0.8939, 0.7571, 0.7133, 0.7422, 0.7400,\n",
      "        0.9563, 0.9530, 0.8857, 0.9420, 0.9639, 0.9815, 0.9286, 0.9467, 0.9583,\n",
      "        0.6692, 0.4000, 0.9000, 0.4556, 0.8917, 0.7667, 0.7444, 0.8979, 0.7333,\n",
      "        0.3833, 0.7733, 0.8111, 0.4267, 0.9222, 0.6667, 0.9714, 0.9667, 0.9385,\n",
      "        0.7667, 0.9167, 0.9261, 0.7444, 0.8222, 0.6833, 0.7333])\n",
      "Train backdoor\n",
      "Train Epoch: 22 [0/9728 (0%)]\tLoss: 8.901259\n",
      "Train Epoch: 22 [512/9728 (5%)]\tLoss: 3.691984\n",
      "Train Epoch: 22 [1024/9728 (11%)]\tLoss: 0.213160\n",
      "Train Epoch: 22 [1536/9728 (16%)]\tLoss: 0.070370\n",
      "Train Epoch: 22 [2048/9728 (21%)]\tLoss: 0.027976\n",
      "Train Epoch: 22 [2560/9728 (26%)]\tLoss: 0.018873\n",
      "Train Epoch: 22 [3072/9728 (32%)]\tLoss: 0.015326\n",
      "Train Epoch: 22 [3584/9728 (37%)]\tLoss: 0.018097\n",
      "Train Epoch: 22 [4096/9728 (42%)]\tLoss: 0.012879\n",
      "Train Epoch: 22 [4608/9728 (47%)]\tLoss: 0.011653\n",
      "Train Epoch: 22 [5120/9728 (53%)]\tLoss: 0.008010\n",
      "Train Epoch: 22 [5632/9728 (58%)]\tLoss: 0.008883\n",
      "Train Epoch: 22 [6144/9728 (63%)]\tLoss: 0.008550\n",
      "Train Epoch: 22 [6656/9728 (68%)]\tLoss: 0.007332\n",
      "Train Epoch: 22 [7168/9728 (74%)]\tLoss: 0.007788\n",
      "Train Epoch: 22 [7680/9728 (79%)]\tLoss: 0.004451\n",
      "Train Epoch: 22 [8192/9728 (84%)]\tLoss: 0.004624\n",
      "Train Epoch: 22 [8704/9728 (89%)]\tLoss: 0.004712\n",
      "Train Epoch: 22 [9216/9728 (95%)]\tLoss: 0.006152\n",
      "Average training loss: 0.6864253878593445\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.6427, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 23 [0/39424 (0%)]\tLoss: 10.273038\n",
      "Train Epoch: 23 [512/39424 (1%)]\tLoss: 1.039504\n",
      "Train Epoch: 23 [1024/39424 (3%)]\tLoss: 0.808487\n",
      "Train Epoch: 23 [1536/39424 (4%)]\tLoss: 0.759007\n",
      "Train Epoch: 23 [2048/39424 (5%)]\tLoss: 0.644016\n",
      "Train Epoch: 23 [2560/39424 (6%)]\tLoss: 0.643953\n",
      "Train Epoch: 23 [3072/39424 (8%)]\tLoss: 0.650359\n",
      "Train Epoch: 23 [3584/39424 (9%)]\tLoss: 0.600036\n",
      "Train Epoch: 23 [4096/39424 (10%)]\tLoss: 0.596215\n",
      "Train Epoch: 23 [4608/39424 (12%)]\tLoss: 0.616562\n",
      "Train Epoch: 23 [5120/39424 (13%)]\tLoss: 0.569228\n",
      "Train Epoch: 23 [5632/39424 (14%)]\tLoss: 0.541779\n",
      "Train Epoch: 23 [6144/39424 (16%)]\tLoss: 0.549390\n",
      "Train Epoch: 23 [6656/39424 (17%)]\tLoss: 0.578030\n",
      "Train Epoch: 23 [7168/39424 (18%)]\tLoss: 0.568983\n",
      "Train Epoch: 23 [7680/39424 (19%)]\tLoss: 0.525657\n",
      "Train Epoch: 23 [8192/39424 (21%)]\tLoss: 0.501628\n",
      "Train Epoch: 23 [8704/39424 (22%)]\tLoss: 0.493268\n",
      "Train Epoch: 23 [9216/39424 (23%)]\tLoss: 0.499558\n",
      "Train Epoch: 23 [9728/39424 (25%)]\tLoss: 0.543443\n",
      "Train Epoch: 23 [10240/39424 (26%)]\tLoss: 0.446729\n",
      "Train Epoch: 23 [10752/39424 (27%)]\tLoss: 0.549589\n",
      "Train Epoch: 23 [11264/39424 (29%)]\tLoss: 0.485694\n",
      "Train Epoch: 23 [11776/39424 (30%)]\tLoss: 0.457236\n",
      "Train Epoch: 23 [12288/39424 (31%)]\tLoss: 0.445336\n",
      "Train Epoch: 23 [12800/39424 (32%)]\tLoss: 0.440751\n",
      "Train Epoch: 23 [13312/39424 (34%)]\tLoss: 0.465082\n",
      "Train Epoch: 23 [13824/39424 (35%)]\tLoss: 0.461020\n",
      "Train Epoch: 23 [14336/39424 (36%)]\tLoss: 0.409242\n",
      "Train Epoch: 23 [14848/39424 (38%)]\tLoss: 0.443363\n",
      "Train Epoch: 23 [15360/39424 (39%)]\tLoss: 0.415152\n",
      "Train Epoch: 23 [15872/39424 (40%)]\tLoss: 0.426564\n",
      "Train Epoch: 23 [16384/39424 (42%)]\tLoss: 0.482151\n",
      "Train Epoch: 23 [16896/39424 (43%)]\tLoss: 0.514942\n",
      "Train Epoch: 23 [17408/39424 (44%)]\tLoss: 0.404305\n",
      "Train Epoch: 23 [17920/39424 (45%)]\tLoss: 0.479071\n",
      "Train Epoch: 23 [18432/39424 (47%)]\tLoss: 0.452264\n",
      "Train Epoch: 23 [18944/39424 (48%)]\tLoss: 0.407527\n",
      "Train Epoch: 23 [19456/39424 (49%)]\tLoss: 0.474020\n",
      "Train Epoch: 23 [19968/39424 (51%)]\tLoss: 0.369216\n",
      "Train Epoch: 23 [20480/39424 (52%)]\tLoss: 0.406826\n",
      "Train Epoch: 23 [20992/39424 (53%)]\tLoss: 0.507317\n",
      "Train Epoch: 23 [21504/39424 (55%)]\tLoss: 0.361140\n",
      "Train Epoch: 23 [22016/39424 (56%)]\tLoss: 0.367437\n",
      "Train Epoch: 23 [22528/39424 (57%)]\tLoss: 0.372973\n",
      "Train Epoch: 23 [23040/39424 (58%)]\tLoss: 0.461042\n",
      "Train Epoch: 23 [23552/39424 (60%)]\tLoss: 0.373629\n",
      "Train Epoch: 23 [24064/39424 (61%)]\tLoss: 0.450429\n",
      "Train Epoch: 23 [24576/39424 (62%)]\tLoss: 0.420186\n",
      "Train Epoch: 23 [25088/39424 (64%)]\tLoss: 0.374050\n",
      "Train Epoch: 23 [25600/39424 (65%)]\tLoss: 0.407703\n",
      "Train Epoch: 23 [26112/39424 (66%)]\tLoss: 0.381889\n",
      "Train Epoch: 23 [26624/39424 (68%)]\tLoss: 0.423634\n",
      "Train Epoch: 23 [27136/39424 (69%)]\tLoss: 0.430008\n",
      "Train Epoch: 23 [27648/39424 (70%)]\tLoss: 0.433107\n",
      "Train Epoch: 23 [28160/39424 (71%)]\tLoss: 0.376695\n",
      "Train Epoch: 23 [28672/39424 (73%)]\tLoss: 0.370250\n",
      "Train Epoch: 23 [29184/39424 (74%)]\tLoss: 0.381612\n",
      "Train Epoch: 23 [29696/39424 (75%)]\tLoss: 0.393028\n",
      "Train Epoch: 23 [30208/39424 (77%)]\tLoss: 0.424527\n",
      "Train Epoch: 23 [30720/39424 (78%)]\tLoss: 0.429127\n",
      "Train Epoch: 23 [31232/39424 (79%)]\tLoss: 0.447616\n",
      "Train Epoch: 23 [31744/39424 (81%)]\tLoss: 0.431722\n",
      "Train Epoch: 23 [32256/39424 (82%)]\tLoss: 0.359233\n",
      "Train Epoch: 23 [32768/39424 (83%)]\tLoss: 0.387038\n",
      "Train Epoch: 23 [33280/39424 (84%)]\tLoss: 0.418979\n",
      "Train Epoch: 23 [33792/39424 (86%)]\tLoss: 0.331547\n",
      "Train Epoch: 23 [34304/39424 (87%)]\tLoss: 0.327076\n",
      "Train Epoch: 23 [34816/39424 (88%)]\tLoss: 0.374366\n",
      "Train Epoch: 23 [35328/39424 (90%)]\tLoss: 0.373667\n",
      "Train Epoch: 23 [35840/39424 (91%)]\tLoss: 0.381045\n",
      "Train Epoch: 23 [36352/39424 (92%)]\tLoss: 0.363439\n",
      "Train Epoch: 23 [36864/39424 (94%)]\tLoss: 0.352608\n",
      "Train Epoch: 23 [37376/39424 (95%)]\tLoss: 0.444276\n",
      "Train Epoch: 23 [37888/39424 (96%)]\tLoss: 0.403447\n",
      "Train Epoch: 23 [38400/39424 (97%)]\tLoss: 0.322609\n",
      "Train Epoch: 23 [38912/39424 (99%)]\tLoss: 0.348315\n",
      "Average training loss: 0.5927919745445251\n",
      "\n",
      "Test set: Average loss: 9.0182, Accuracy: 8/12630 (0%)\n",
      "\n",
      "tensor([0.0006,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.5431, Accuracy: 10969/12630 (87%)\n",
      "\n",
      "tensor([0.0000, 0.9042, 0.9387, 0.9222, 0.8955, 0.7810, 0.7000, 0.7533, 0.7600,\n",
      "        0.9646, 0.9545, 0.8881, 0.9507, 0.9667, 0.9926, 0.9381, 0.9400, 0.9389,\n",
      "        0.6462, 0.4667, 0.9111, 0.4889, 0.8917, 0.7933, 0.7111, 0.9062, 0.7556,\n",
      "        0.3833, 0.8133, 0.8444, 0.4667, 0.9222, 0.7333, 0.9714, 0.9750, 0.9256,\n",
      "        0.7750, 0.9167, 0.9232, 0.7556, 0.8333, 0.6833, 0.7333])\n",
      "Train backdoor\n",
      "Train Epoch: 23 [0/9728 (0%)]\tLoss: 8.867921\n",
      "Train Epoch: 23 [512/9728 (5%)]\tLoss: 3.492604\n",
      "Train Epoch: 23 [1024/9728 (11%)]\tLoss: 0.179967\n",
      "Train Epoch: 23 [1536/9728 (16%)]\tLoss: 0.052073\n",
      "Train Epoch: 23 [2048/9728 (21%)]\tLoss: 0.029114\n",
      "Train Epoch: 23 [2560/9728 (26%)]\tLoss: 0.022819\n",
      "Train Epoch: 23 [3072/9728 (32%)]\tLoss: 0.018010\n",
      "Train Epoch: 23 [3584/9728 (37%)]\tLoss: 0.024011\n",
      "Train Epoch: 23 [4096/9728 (42%)]\tLoss: 0.012621\n",
      "Train Epoch: 23 [4608/9728 (47%)]\tLoss: 0.009003\n",
      "Train Epoch: 23 [5120/9728 (53%)]\tLoss: 0.006910\n",
      "Train Epoch: 23 [5632/9728 (58%)]\tLoss: 0.006997\n",
      "Train Epoch: 23 [6144/9728 (63%)]\tLoss: 0.007557\n",
      "Train Epoch: 23 [6656/9728 (68%)]\tLoss: 0.008946\n",
      "Train Epoch: 23 [7168/9728 (74%)]\tLoss: 0.006516\n",
      "Train Epoch: 23 [7680/9728 (79%)]\tLoss: 0.004677\n",
      "Train Epoch: 23 [8192/9728 (84%)]\tLoss: 0.004276\n",
      "Train Epoch: 23 [8704/9728 (89%)]\tLoss: 0.005275\n",
      "Train Epoch: 23 [9216/9728 (95%)]\tLoss: 0.005447\n",
      "Average training loss: 0.6718287467956543\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.5189, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 24 [0/39424 (0%)]\tLoss: 10.124058\n",
      "Train Epoch: 24 [512/39424 (1%)]\tLoss: 0.907892\n",
      "Train Epoch: 24 [1024/39424 (3%)]\tLoss: 0.683837\n",
      "Train Epoch: 24 [1536/39424 (4%)]\tLoss: 0.725682\n",
      "Train Epoch: 24 [2048/39424 (5%)]\tLoss: 0.623838\n",
      "Train Epoch: 24 [2560/39424 (6%)]\tLoss: 0.595971\n",
      "Train Epoch: 24 [3072/39424 (8%)]\tLoss: 0.626941\n",
      "Train Epoch: 24 [3584/39424 (9%)]\tLoss: 0.568310\n",
      "Train Epoch: 24 [4096/39424 (10%)]\tLoss: 0.564940\n",
      "Train Epoch: 24 [4608/39424 (12%)]\tLoss: 0.565274\n",
      "Train Epoch: 24 [5120/39424 (13%)]\tLoss: 0.533128\n",
      "Train Epoch: 24 [5632/39424 (14%)]\tLoss: 0.528394\n",
      "Train Epoch: 24 [6144/39424 (16%)]\tLoss: 0.519563\n",
      "Train Epoch: 24 [6656/39424 (17%)]\tLoss: 0.544930\n",
      "Train Epoch: 24 [7168/39424 (18%)]\tLoss: 0.519897\n",
      "Train Epoch: 24 [7680/39424 (19%)]\tLoss: 0.487426\n",
      "Train Epoch: 24 [8192/39424 (21%)]\tLoss: 0.452980\n",
      "Train Epoch: 24 [8704/39424 (22%)]\tLoss: 0.461794\n",
      "Train Epoch: 24 [9216/39424 (23%)]\tLoss: 0.454255\n",
      "Train Epoch: 24 [9728/39424 (25%)]\tLoss: 0.493626\n",
      "Train Epoch: 24 [10240/39424 (26%)]\tLoss: 0.419107\n",
      "Train Epoch: 24 [10752/39424 (27%)]\tLoss: 0.506128\n",
      "Train Epoch: 24 [11264/39424 (29%)]\tLoss: 0.445219\n",
      "Train Epoch: 24 [11776/39424 (30%)]\tLoss: 0.412969\n",
      "Train Epoch: 24 [12288/39424 (31%)]\tLoss: 0.454959\n",
      "Train Epoch: 24 [12800/39424 (32%)]\tLoss: 0.394634\n",
      "Train Epoch: 24 [13312/39424 (34%)]\tLoss: 0.441838\n",
      "Train Epoch: 24 [13824/39424 (35%)]\tLoss: 0.438456\n",
      "Train Epoch: 24 [14336/39424 (36%)]\tLoss: 0.388456\n",
      "Train Epoch: 24 [14848/39424 (38%)]\tLoss: 0.425838\n",
      "Train Epoch: 24 [15360/39424 (39%)]\tLoss: 0.391139\n",
      "Train Epoch: 24 [15872/39424 (40%)]\tLoss: 0.403992\n",
      "Train Epoch: 24 [16384/39424 (42%)]\tLoss: 0.424316\n",
      "Train Epoch: 24 [16896/39424 (43%)]\tLoss: 0.457526\n",
      "Train Epoch: 24 [17408/39424 (44%)]\tLoss: 0.390335\n",
      "Train Epoch: 24 [17920/39424 (45%)]\tLoss: 0.462760\n",
      "Train Epoch: 24 [18432/39424 (47%)]\tLoss: 0.442496\n",
      "Train Epoch: 24 [18944/39424 (48%)]\tLoss: 0.374019\n",
      "Train Epoch: 24 [19456/39424 (49%)]\tLoss: 0.401542\n",
      "Train Epoch: 24 [19968/39424 (51%)]\tLoss: 0.337977\n",
      "Train Epoch: 24 [20480/39424 (52%)]\tLoss: 0.391050\n",
      "Train Epoch: 24 [20992/39424 (53%)]\tLoss: 0.446272\n",
      "Train Epoch: 24 [21504/39424 (55%)]\tLoss: 0.329107\n",
      "Train Epoch: 24 [22016/39424 (56%)]\tLoss: 0.364156\n",
      "Train Epoch: 24 [22528/39424 (57%)]\tLoss: 0.329519\n",
      "Train Epoch: 24 [23040/39424 (58%)]\tLoss: 0.447486\n",
      "Train Epoch: 24 [23552/39424 (60%)]\tLoss: 0.333007\n",
      "Train Epoch: 24 [24064/39424 (61%)]\tLoss: 0.391174\n",
      "Train Epoch: 24 [24576/39424 (62%)]\tLoss: 0.404275\n",
      "Train Epoch: 24 [25088/39424 (64%)]\tLoss: 0.371218\n",
      "Train Epoch: 24 [25600/39424 (65%)]\tLoss: 0.398738\n",
      "Train Epoch: 24 [26112/39424 (66%)]\tLoss: 0.339244\n",
      "Train Epoch: 24 [26624/39424 (68%)]\tLoss: 0.385099\n",
      "Train Epoch: 24 [27136/39424 (69%)]\tLoss: 0.388142\n",
      "Train Epoch: 24 [27648/39424 (70%)]\tLoss: 0.403678\n",
      "Train Epoch: 24 [28160/39424 (71%)]\tLoss: 0.371009\n",
      "Train Epoch: 24 [28672/39424 (73%)]\tLoss: 0.353615\n",
      "Train Epoch: 24 [29184/39424 (74%)]\tLoss: 0.354101\n",
      "Train Epoch: 24 [29696/39424 (75%)]\tLoss: 0.309277\n",
      "Train Epoch: 24 [30208/39424 (77%)]\tLoss: 0.413666\n",
      "Train Epoch: 24 [30720/39424 (78%)]\tLoss: 0.410901\n",
      "Train Epoch: 24 [31232/39424 (79%)]\tLoss: 0.469701\n",
      "Train Epoch: 24 [31744/39424 (81%)]\tLoss: 0.408310\n",
      "Train Epoch: 24 [32256/39424 (82%)]\tLoss: 0.335181\n",
      "Train Epoch: 24 [32768/39424 (83%)]\tLoss: 0.351226\n",
      "Train Epoch: 24 [33280/39424 (84%)]\tLoss: 0.405290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [33792/39424 (86%)]\tLoss: 0.300330\n",
      "Train Epoch: 24 [34304/39424 (87%)]\tLoss: 0.305534\n",
      "Train Epoch: 24 [34816/39424 (88%)]\tLoss: 0.355821\n",
      "Train Epoch: 24 [35328/39424 (90%)]\tLoss: 0.365810\n",
      "Train Epoch: 24 [35840/39424 (91%)]\tLoss: 0.336023\n",
      "Train Epoch: 24 [36352/39424 (92%)]\tLoss: 0.345763\n",
      "Train Epoch: 24 [36864/39424 (94%)]\tLoss: 0.328079\n",
      "Train Epoch: 24 [37376/39424 (95%)]\tLoss: 0.391989\n",
      "Train Epoch: 24 [37888/39424 (96%)]\tLoss: 0.378066\n",
      "Train Epoch: 24 [38400/39424 (97%)]\tLoss: 0.309094\n",
      "Train Epoch: 24 [38912/39424 (99%)]\tLoss: 0.348118\n",
      "Average training loss: 0.5592924356460571\n",
      "\n",
      "Test set: Average loss: 8.7872, Accuracy: 18/12630 (0%)\n",
      "\n",
      "tensor([0.0014,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.5164, Accuracy: 11026/12630 (87%)\n",
      "\n",
      "tensor([0.0500, 0.8931, 0.9253, 0.9289, 0.9045, 0.7857, 0.7200, 0.7689, 0.7844,\n",
      "        0.9729, 0.9576, 0.8905, 0.9493, 0.9681, 0.9926, 0.9333, 0.9400, 0.9444,\n",
      "        0.6718, 0.4500, 0.9333, 0.4889, 0.8917, 0.8533, 0.7333, 0.9104, 0.7611,\n",
      "        0.4000, 0.8200, 0.8778, 0.5267, 0.9222, 0.6500, 0.9714, 0.9750, 0.9308,\n",
      "        0.7833, 0.9167, 0.9174, 0.7222, 0.8333, 0.7167, 0.7222])\n",
      "Train backdoor\n",
      "Train Epoch: 24 [0/9728 (0%)]\tLoss: 8.538086\n",
      "Train Epoch: 24 [512/9728 (5%)]\tLoss: 3.210260\n",
      "Train Epoch: 24 [1024/9728 (11%)]\tLoss: 0.168143\n",
      "Train Epoch: 24 [1536/9728 (16%)]\tLoss: 0.063370\n",
      "Train Epoch: 24 [2048/9728 (21%)]\tLoss: 0.025934\n",
      "Train Epoch: 24 [2560/9728 (26%)]\tLoss: 0.024430\n",
      "Train Epoch: 24 [3072/9728 (32%)]\tLoss: 0.020352\n",
      "Train Epoch: 24 [3584/9728 (37%)]\tLoss: 0.018157\n",
      "Train Epoch: 24 [4096/9728 (42%)]\tLoss: 0.012644\n",
      "Train Epoch: 24 [4608/9728 (47%)]\tLoss: 0.010874\n",
      "Train Epoch: 24 [5120/9728 (53%)]\tLoss: 0.007350\n",
      "Train Epoch: 24 [5632/9728 (58%)]\tLoss: 0.008029\n",
      "Train Epoch: 24 [6144/9728 (63%)]\tLoss: 0.009162\n",
      "Train Epoch: 24 [6656/9728 (68%)]\tLoss: 0.009516\n",
      "Train Epoch: 24 [7168/9728 (74%)]\tLoss: 0.009513\n",
      "Train Epoch: 24 [7680/9728 (79%)]\tLoss: 0.005310\n",
      "Train Epoch: 24 [8192/9728 (84%)]\tLoss: 0.004884\n",
      "Train Epoch: 24 [8704/9728 (89%)]\tLoss: 0.006324\n",
      "Train Epoch: 24 [9216/9728 (95%)]\tLoss: 0.005856\n",
      "Average training loss: 0.6399049162864685\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.7493, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 25 [0/39424 (0%)]\tLoss: 10.277383\n",
      "Train Epoch: 25 [512/39424 (1%)]\tLoss: 0.978860\n",
      "Train Epoch: 25 [1024/39424 (3%)]\tLoss: 0.795741\n",
      "Train Epoch: 25 [1536/39424 (4%)]\tLoss: 0.701188\n",
      "Train Epoch: 25 [2048/39424 (5%)]\tLoss: 0.571734\n",
      "Train Epoch: 25 [2560/39424 (6%)]\tLoss: 0.543079\n",
      "Train Epoch: 25 [3072/39424 (8%)]\tLoss: 0.566102\n",
      "Train Epoch: 25 [3584/39424 (9%)]\tLoss: 0.524540\n",
      "Train Epoch: 25 [4096/39424 (10%)]\tLoss: 0.511158\n",
      "Train Epoch: 25 [4608/39424 (12%)]\tLoss: 0.501757\n",
      "Train Epoch: 25 [5120/39424 (13%)]\tLoss: 0.481341\n",
      "Train Epoch: 25 [5632/39424 (14%)]\tLoss: 0.493675\n",
      "Train Epoch: 25 [6144/39424 (16%)]\tLoss: 0.473426\n",
      "Train Epoch: 25 [6656/39424 (17%)]\tLoss: 0.518334\n",
      "Train Epoch: 25 [7168/39424 (18%)]\tLoss: 0.499657\n",
      "Train Epoch: 25 [7680/39424 (19%)]\tLoss: 0.452121\n",
      "Train Epoch: 25 [8192/39424 (21%)]\tLoss: 0.403573\n",
      "Train Epoch: 25 [8704/39424 (22%)]\tLoss: 0.421640\n",
      "Train Epoch: 25 [9216/39424 (23%)]\tLoss: 0.438846\n",
      "Train Epoch: 25 [9728/39424 (25%)]\tLoss: 0.478730\n",
      "Train Epoch: 25 [10240/39424 (26%)]\tLoss: 0.388538\n",
      "Train Epoch: 25 [10752/39424 (27%)]\tLoss: 0.473073\n",
      "Train Epoch: 25 [11264/39424 (29%)]\tLoss: 0.408121\n",
      "Train Epoch: 25 [11776/39424 (30%)]\tLoss: 0.379583\n",
      "Train Epoch: 25 [12288/39424 (31%)]\tLoss: 0.405301\n",
      "Train Epoch: 25 [12800/39424 (32%)]\tLoss: 0.375517\n",
      "Train Epoch: 25 [13312/39424 (34%)]\tLoss: 0.408676\n",
      "Train Epoch: 25 [13824/39424 (35%)]\tLoss: 0.405042\n",
      "Train Epoch: 25 [14336/39424 (36%)]\tLoss: 0.352468\n",
      "Train Epoch: 25 [14848/39424 (38%)]\tLoss: 0.393044\n",
      "Train Epoch: 25 [15360/39424 (39%)]\tLoss: 0.380326\n",
      "Train Epoch: 25 [15872/39424 (40%)]\tLoss: 0.366336\n",
      "Train Epoch: 25 [16384/39424 (42%)]\tLoss: 0.403871\n",
      "Train Epoch: 25 [16896/39424 (43%)]\tLoss: 0.420044\n",
      "Train Epoch: 25 [17408/39424 (44%)]\tLoss: 0.364952\n",
      "Train Epoch: 25 [17920/39424 (45%)]\tLoss: 0.438751\n",
      "Train Epoch: 25 [18432/39424 (47%)]\tLoss: 0.393837\n",
      "Train Epoch: 25 [18944/39424 (48%)]\tLoss: 0.351403\n",
      "Train Epoch: 25 [19456/39424 (49%)]\tLoss: 0.392620\n",
      "Train Epoch: 25 [19968/39424 (51%)]\tLoss: 0.312903\n",
      "Train Epoch: 25 [20480/39424 (52%)]\tLoss: 0.376715\n",
      "Train Epoch: 25 [20992/39424 (53%)]\tLoss: 0.417375\n",
      "Train Epoch: 25 [21504/39424 (55%)]\tLoss: 0.303052\n",
      "Train Epoch: 25 [22016/39424 (56%)]\tLoss: 0.291792\n",
      "Train Epoch: 25 [22528/39424 (57%)]\tLoss: 0.314115\n",
      "Train Epoch: 25 [23040/39424 (58%)]\tLoss: 0.421712\n",
      "Train Epoch: 25 [23552/39424 (60%)]\tLoss: 0.317022\n",
      "Train Epoch: 25 [24064/39424 (61%)]\tLoss: 0.414291\n",
      "Train Epoch: 25 [24576/39424 (62%)]\tLoss: 0.349839\n",
      "Train Epoch: 25 [25088/39424 (64%)]\tLoss: 0.355963\n",
      "Train Epoch: 25 [25600/39424 (65%)]\tLoss: 0.377668\n",
      "Train Epoch: 25 [26112/39424 (66%)]\tLoss: 0.323334\n",
      "Train Epoch: 25 [26624/39424 (68%)]\tLoss: 0.400570\n",
      "Train Epoch: 25 [27136/39424 (69%)]\tLoss: 0.394483\n",
      "Train Epoch: 25 [27648/39424 (70%)]\tLoss: 0.410015\n",
      "Train Epoch: 25 [28160/39424 (71%)]\tLoss: 0.348784\n",
      "Train Epoch: 25 [28672/39424 (73%)]\tLoss: 0.328099\n",
      "Train Epoch: 25 [29184/39424 (74%)]\tLoss: 0.318036\n",
      "Train Epoch: 25 [29696/39424 (75%)]\tLoss: 0.328317\n",
      "Train Epoch: 25 [30208/39424 (77%)]\tLoss: 0.369729\n",
      "Train Epoch: 25 [30720/39424 (78%)]\tLoss: 0.373607\n",
      "Train Epoch: 25 [31232/39424 (79%)]\tLoss: 0.429517\n",
      "Train Epoch: 25 [31744/39424 (81%)]\tLoss: 0.367278\n",
      "Train Epoch: 25 [32256/39424 (82%)]\tLoss: 0.336405\n",
      "Train Epoch: 25 [32768/39424 (83%)]\tLoss: 0.315958\n",
      "Train Epoch: 25 [33280/39424 (84%)]\tLoss: 0.372568\n",
      "Train Epoch: 25 [33792/39424 (86%)]\tLoss: 0.274838\n",
      "Train Epoch: 25 [34304/39424 (87%)]\tLoss: 0.273911\n",
      "Train Epoch: 25 [34816/39424 (88%)]\tLoss: 0.331974\n",
      "Train Epoch: 25 [35328/39424 (90%)]\tLoss: 0.336911\n",
      "Train Epoch: 25 [35840/39424 (91%)]\tLoss: 0.327801\n",
      "Train Epoch: 25 [36352/39424 (92%)]\tLoss: 0.331131\n",
      "Train Epoch: 25 [36864/39424 (94%)]\tLoss: 0.297763\n",
      "Train Epoch: 25 [37376/39424 (95%)]\tLoss: 0.351247\n",
      "Train Epoch: 25 [37888/39424 (96%)]\tLoss: 0.332623\n",
      "Train Epoch: 25 [38400/39424 (97%)]\tLoss: 0.297173\n",
      "Train Epoch: 25 [38912/39424 (99%)]\tLoss: 0.342931\n",
      "Average training loss: 0.5363875031471252\n",
      "\n",
      "Test set: Average loss: 8.9252, Accuracy: 15/12630 (0%)\n",
      "\n",
      "tensor([0.0012,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4966, Accuracy: 11114/12630 (88%)\n",
      "\n",
      "tensor([0.0333, 0.9056, 0.9427, 0.9378, 0.9030, 0.7968, 0.7200, 0.7778, 0.8022,\n",
      "        0.9708, 0.9606, 0.9000, 0.9507, 0.9694, 1.0000, 0.9381, 0.9467, 0.9417,\n",
      "        0.7128, 0.4500, 0.9333, 0.4889, 0.8917, 0.8600, 0.7667, 0.9125, 0.7389,\n",
      "        0.4333, 0.8467, 0.8778, 0.5200, 0.9222, 0.5833, 0.9714, 0.9667, 0.9333,\n",
      "        0.7750, 0.9333, 0.9290, 0.7333, 0.8444, 0.7333, 0.7889])\n",
      "Train backdoor\n",
      "Train Epoch: 25 [0/9728 (0%)]\tLoss: 8.756299\n",
      "Train Epoch: 25 [512/9728 (5%)]\tLoss: 3.393584\n",
      "Train Epoch: 25 [1024/9728 (11%)]\tLoss: 0.206513\n",
      "Train Epoch: 25 [1536/9728 (16%)]\tLoss: 0.058931\n",
      "Train Epoch: 25 [2048/9728 (21%)]\tLoss: 0.031067\n",
      "Train Epoch: 25 [2560/9728 (26%)]\tLoss: 0.025142\n",
      "Train Epoch: 25 [3072/9728 (32%)]\tLoss: 0.022174\n",
      "Train Epoch: 25 [3584/9728 (37%)]\tLoss: 0.021214\n",
      "Train Epoch: 25 [4096/9728 (42%)]\tLoss: 0.013918\n",
      "Train Epoch: 25 [4608/9728 (47%)]\tLoss: 0.010371\n",
      "Train Epoch: 25 [5120/9728 (53%)]\tLoss: 0.009523\n",
      "Train Epoch: 25 [5632/9728 (58%)]\tLoss: 0.008183\n",
      "Train Epoch: 25 [6144/9728 (63%)]\tLoss: 0.009592\n",
      "Train Epoch: 25 [6656/9728 (68%)]\tLoss: 0.011624\n",
      "Train Epoch: 25 [7168/9728 (74%)]\tLoss: 0.010320\n",
      "Train Epoch: 25 [7680/9728 (79%)]\tLoss: 0.005564\n",
      "Train Epoch: 25 [8192/9728 (84%)]\tLoss: 0.005552\n",
      "Train Epoch: 25 [8704/9728 (89%)]\tLoss: 0.007951\n",
      "Train Epoch: 25 [9216/9728 (95%)]\tLoss: 0.005153\n",
      "Average training loss: 0.6638249158859253\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.2716, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 26 [0/39424 (0%)]\tLoss: 9.694292\n",
      "Train Epoch: 26 [512/39424 (1%)]\tLoss: 0.838049\n",
      "Train Epoch: 26 [1024/39424 (3%)]\tLoss: 0.624238\n",
      "Train Epoch: 26 [1536/39424 (4%)]\tLoss: 0.619692\n",
      "Train Epoch: 26 [2048/39424 (5%)]\tLoss: 0.542663\n",
      "Train Epoch: 26 [2560/39424 (6%)]\tLoss: 0.509723\n",
      "Train Epoch: 26 [3072/39424 (8%)]\tLoss: 0.548698\n",
      "Train Epoch: 26 [3584/39424 (9%)]\tLoss: 0.514733\n",
      "Train Epoch: 26 [4096/39424 (10%)]\tLoss: 0.480421\n",
      "Train Epoch: 26 [4608/39424 (12%)]\tLoss: 0.486926\n",
      "Train Epoch: 26 [5120/39424 (13%)]\tLoss: 0.465524\n",
      "Train Epoch: 26 [5632/39424 (14%)]\tLoss: 0.455552\n",
      "Train Epoch: 26 [6144/39424 (16%)]\tLoss: 0.434499\n",
      "Train Epoch: 26 [6656/39424 (17%)]\tLoss: 0.496451\n",
      "Train Epoch: 26 [7168/39424 (18%)]\tLoss: 0.470288\n",
      "Train Epoch: 26 [7680/39424 (19%)]\tLoss: 0.435239\n",
      "Train Epoch: 26 [8192/39424 (21%)]\tLoss: 0.372844\n",
      "Train Epoch: 26 [8704/39424 (22%)]\tLoss: 0.391938\n",
      "Train Epoch: 26 [9216/39424 (23%)]\tLoss: 0.390199\n",
      "Train Epoch: 26 [9728/39424 (25%)]\tLoss: 0.431184\n",
      "Train Epoch: 26 [10240/39424 (26%)]\tLoss: 0.353420\n",
      "Train Epoch: 26 [10752/39424 (27%)]\tLoss: 0.448998\n",
      "Train Epoch: 26 [11264/39424 (29%)]\tLoss: 0.381004\n",
      "Train Epoch: 26 [11776/39424 (30%)]\tLoss: 0.370570\n",
      "Train Epoch: 26 [12288/39424 (31%)]\tLoss: 0.395722\n",
      "Train Epoch: 26 [12800/39424 (32%)]\tLoss: 0.346734\n",
      "Train Epoch: 26 [13312/39424 (34%)]\tLoss: 0.397742\n",
      "Train Epoch: 26 [13824/39424 (35%)]\tLoss: 0.378702\n",
      "Train Epoch: 26 [14336/39424 (36%)]\tLoss: 0.360855\n",
      "Train Epoch: 26 [14848/39424 (38%)]\tLoss: 0.390615\n",
      "Train Epoch: 26 [15360/39424 (39%)]\tLoss: 0.347618\n",
      "Train Epoch: 26 [15872/39424 (40%)]\tLoss: 0.362740\n",
      "Train Epoch: 26 [16384/39424 (42%)]\tLoss: 0.398895\n",
      "Train Epoch: 26 [16896/39424 (43%)]\tLoss: 0.416457\n",
      "Train Epoch: 26 [17408/39424 (44%)]\tLoss: 0.354168\n",
      "Train Epoch: 26 [17920/39424 (45%)]\tLoss: 0.420685\n",
      "Train Epoch: 26 [18432/39424 (47%)]\tLoss: 0.376445\n",
      "Train Epoch: 26 [18944/39424 (48%)]\tLoss: 0.330827\n",
      "Train Epoch: 26 [19456/39424 (49%)]\tLoss: 0.345906\n",
      "Train Epoch: 26 [19968/39424 (51%)]\tLoss: 0.283838\n",
      "Train Epoch: 26 [20480/39424 (52%)]\tLoss: 0.331724\n",
      "Train Epoch: 26 [20992/39424 (53%)]\tLoss: 0.414598\n",
      "Train Epoch: 26 [21504/39424 (55%)]\tLoss: 0.274790\n",
      "Train Epoch: 26 [22016/39424 (56%)]\tLoss: 0.310312\n",
      "Train Epoch: 26 [22528/39424 (57%)]\tLoss: 0.284160\n",
      "Train Epoch: 26 [23040/39424 (58%)]\tLoss: 0.392631\n",
      "Train Epoch: 26 [23552/39424 (60%)]\tLoss: 0.302182\n",
      "Train Epoch: 26 [24064/39424 (61%)]\tLoss: 0.369218\n",
      "Train Epoch: 26 [24576/39424 (62%)]\tLoss: 0.329641\n",
      "Train Epoch: 26 [25088/39424 (64%)]\tLoss: 0.304233\n",
      "Train Epoch: 26 [25600/39424 (65%)]\tLoss: 0.355140\n",
      "Train Epoch: 26 [26112/39424 (66%)]\tLoss: 0.316388\n",
      "Train Epoch: 26 [26624/39424 (68%)]\tLoss: 0.337617\n",
      "Train Epoch: 26 [27136/39424 (69%)]\tLoss: 0.347645\n",
      "Train Epoch: 26 [27648/39424 (70%)]\tLoss: 0.378246\n",
      "Train Epoch: 26 [28160/39424 (71%)]\tLoss: 0.304804\n",
      "Train Epoch: 26 [28672/39424 (73%)]\tLoss: 0.310508\n",
      "Train Epoch: 26 [29184/39424 (74%)]\tLoss: 0.298263\n",
      "Train Epoch: 26 [29696/39424 (75%)]\tLoss: 0.310698\n",
      "Train Epoch: 26 [30208/39424 (77%)]\tLoss: 0.333113\n",
      "Train Epoch: 26 [30720/39424 (78%)]\tLoss: 0.334551\n",
      "Train Epoch: 26 [31232/39424 (79%)]\tLoss: 0.385519\n",
      "Train Epoch: 26 [31744/39424 (81%)]\tLoss: 0.355172\n",
      "Train Epoch: 26 [32256/39424 (82%)]\tLoss: 0.299529\n",
      "Train Epoch: 26 [32768/39424 (83%)]\tLoss: 0.304625\n",
      "Train Epoch: 26 [33280/39424 (84%)]\tLoss: 0.352806\n",
      "Train Epoch: 26 [33792/39424 (86%)]\tLoss: 0.259225\n",
      "Train Epoch: 26 [34304/39424 (87%)]\tLoss: 0.246151\n",
      "Train Epoch: 26 [34816/39424 (88%)]\tLoss: 0.282965\n",
      "Train Epoch: 26 [35328/39424 (90%)]\tLoss: 0.321386\n",
      "Train Epoch: 26 [35840/39424 (91%)]\tLoss: 0.309908\n",
      "Train Epoch: 26 [36352/39424 (92%)]\tLoss: 0.295028\n",
      "Train Epoch: 26 [36864/39424 (94%)]\tLoss: 0.278320\n",
      "Train Epoch: 26 [37376/39424 (95%)]\tLoss: 0.358120\n",
      "Train Epoch: 26 [37888/39424 (96%)]\tLoss: 0.315532\n",
      "Train Epoch: 26 [38400/39424 (97%)]\tLoss: 0.289386\n",
      "Train Epoch: 26 [38912/39424 (99%)]\tLoss: 0.288874\n",
      "Average training loss: 0.5006248950958252\n",
      "\n",
      "Test set: Average loss: 8.7155, Accuracy: 19/12630 (0%)\n",
      "\n",
      "tensor([0.0015,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4801, Accuracy: 11161/12630 (88%)\n",
      "\n",
      "tensor([0.0833, 0.9097, 0.9440, 0.9511, 0.9091, 0.7921, 0.7333, 0.7800, 0.8222,\n",
      "        0.9729, 0.9652, 0.9190, 0.9507, 0.9694, 1.0000, 0.9333, 0.9533, 0.9417,\n",
      "        0.6744, 0.4833, 0.9333, 0.4889, 0.8917, 0.8667, 0.7667, 0.9125, 0.7778,\n",
      "        0.4333, 0.8467, 0.8889, 0.5667, 0.9296, 0.6333, 0.9762, 0.9750, 0.9308,\n",
      "        0.8250, 0.9333, 0.9246, 0.7222, 0.8556, 0.7333, 0.7556])\n",
      "Train backdoor\n",
      "Train Epoch: 26 [0/9728 (0%)]\tLoss: 8.497712\n",
      "Train Epoch: 26 [512/9728 (5%)]\tLoss: 3.011518\n",
      "Train Epoch: 26 [1024/9728 (11%)]\tLoss: 0.140808\n",
      "Train Epoch: 26 [1536/9728 (16%)]\tLoss: 0.057114\n",
      "Train Epoch: 26 [2048/9728 (21%)]\tLoss: 0.023656\n",
      "Train Epoch: 26 [2560/9728 (26%)]\tLoss: 0.023767\n",
      "Train Epoch: 26 [3072/9728 (32%)]\tLoss: 0.018891\n",
      "Train Epoch: 26 [3584/9728 (37%)]\tLoss: 0.021039\n",
      "Train Epoch: 26 [4096/9728 (42%)]\tLoss: 0.012027\n",
      "Train Epoch: 26 [4608/9728 (47%)]\tLoss: 0.010554\n",
      "Train Epoch: 26 [5120/9728 (53%)]\tLoss: 0.008293\n",
      "Train Epoch: 26 [5632/9728 (58%)]\tLoss: 0.009695\n",
      "Train Epoch: 26 [6144/9728 (63%)]\tLoss: 0.007801\n",
      "Train Epoch: 26 [6656/9728 (68%)]\tLoss: 0.007967\n",
      "Train Epoch: 26 [7168/9728 (74%)]\tLoss: 0.011255\n",
      "Train Epoch: 26 [7680/9728 (79%)]\tLoss: 0.004765\n",
      "Train Epoch: 26 [8192/9728 (84%)]\tLoss: 0.004387\n",
      "Train Epoch: 26 [8704/9728 (89%)]\tLoss: 0.008351\n",
      "Train Epoch: 26 [9216/9728 (95%)]\tLoss: 0.006425\n",
      "Average training loss: 0.625580370426178\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.6183, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 27 [0/39424 (0%)]\tLoss: 10.155012\n",
      "Train Epoch: 27 [512/39424 (1%)]\tLoss: 0.960901\n",
      "Train Epoch: 27 [1024/39424 (3%)]\tLoss: 0.765290\n",
      "Train Epoch: 27 [1536/39424 (4%)]\tLoss: 0.683437\n",
      "Train Epoch: 27 [2048/39424 (5%)]\tLoss: 0.542834\n",
      "Train Epoch: 27 [2560/39424 (6%)]\tLoss: 0.500431\n",
      "Train Epoch: 27 [3072/39424 (8%)]\tLoss: 0.501831\n",
      "Train Epoch: 27 [3584/39424 (9%)]\tLoss: 0.463245\n",
      "Train Epoch: 27 [4096/39424 (10%)]\tLoss: 0.446195\n",
      "Train Epoch: 27 [4608/39424 (12%)]\tLoss: 0.442227\n",
      "Train Epoch: 27 [5120/39424 (13%)]\tLoss: 0.439548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [5632/39424 (14%)]\tLoss: 0.434714\n",
      "Train Epoch: 27 [6144/39424 (16%)]\tLoss: 0.403841\n",
      "Train Epoch: 27 [6656/39424 (17%)]\tLoss: 0.467426\n",
      "Train Epoch: 27 [7168/39424 (18%)]\tLoss: 0.436316\n",
      "Train Epoch: 27 [7680/39424 (19%)]\tLoss: 0.405997\n",
      "Train Epoch: 27 [8192/39424 (21%)]\tLoss: 0.346834\n",
      "Train Epoch: 27 [8704/39424 (22%)]\tLoss: 0.353352\n",
      "Train Epoch: 27 [9216/39424 (23%)]\tLoss: 0.389220\n",
      "Train Epoch: 27 [9728/39424 (25%)]\tLoss: 0.414891\n",
      "Train Epoch: 27 [10240/39424 (26%)]\tLoss: 0.364858\n",
      "Train Epoch: 27 [10752/39424 (27%)]\tLoss: 0.414801\n",
      "Train Epoch: 27 [11264/39424 (29%)]\tLoss: 0.380905\n",
      "Train Epoch: 27 [11776/39424 (30%)]\tLoss: 0.336696\n",
      "Train Epoch: 27 [12288/39424 (31%)]\tLoss: 0.358923\n",
      "Train Epoch: 27 [12800/39424 (32%)]\tLoss: 0.361596\n",
      "Train Epoch: 27 [13312/39424 (34%)]\tLoss: 0.375954\n",
      "Train Epoch: 27 [13824/39424 (35%)]\tLoss: 0.354278\n",
      "Train Epoch: 27 [14336/39424 (36%)]\tLoss: 0.327821\n",
      "Train Epoch: 27 [14848/39424 (38%)]\tLoss: 0.349667\n",
      "Train Epoch: 27 [15360/39424 (39%)]\tLoss: 0.330065\n",
      "Train Epoch: 27 [15872/39424 (40%)]\tLoss: 0.335718\n",
      "Train Epoch: 27 [16384/39424 (42%)]\tLoss: 0.361186\n",
      "Train Epoch: 27 [16896/39424 (43%)]\tLoss: 0.388249\n",
      "Train Epoch: 27 [17408/39424 (44%)]\tLoss: 0.326667\n",
      "Train Epoch: 27 [17920/39424 (45%)]\tLoss: 0.418679\n",
      "Train Epoch: 27 [18432/39424 (47%)]\tLoss: 0.364499\n",
      "Train Epoch: 27 [18944/39424 (48%)]\tLoss: 0.309582\n",
      "Train Epoch: 27 [19456/39424 (49%)]\tLoss: 0.355759\n",
      "Train Epoch: 27 [19968/39424 (51%)]\tLoss: 0.272992\n",
      "Train Epoch: 27 [20480/39424 (52%)]\tLoss: 0.307396\n",
      "Train Epoch: 27 [20992/39424 (53%)]\tLoss: 0.396555\n",
      "Train Epoch: 27 [21504/39424 (55%)]\tLoss: 0.262135\n",
      "Train Epoch: 27 [22016/39424 (56%)]\tLoss: 0.274981\n",
      "Train Epoch: 27 [22528/39424 (57%)]\tLoss: 0.283434\n",
      "Train Epoch: 27 [23040/39424 (58%)]\tLoss: 0.377955\n",
      "Train Epoch: 27 [23552/39424 (60%)]\tLoss: 0.291356\n",
      "Train Epoch: 27 [24064/39424 (61%)]\tLoss: 0.345334\n",
      "Train Epoch: 27 [24576/39424 (62%)]\tLoss: 0.333435\n",
      "Train Epoch: 27 [25088/39424 (64%)]\tLoss: 0.288370\n",
      "Train Epoch: 27 [25600/39424 (65%)]\tLoss: 0.349883\n",
      "Train Epoch: 27 [26112/39424 (66%)]\tLoss: 0.269780\n",
      "Train Epoch: 27 [26624/39424 (68%)]\tLoss: 0.340320\n",
      "Train Epoch: 27 [27136/39424 (69%)]\tLoss: 0.356444\n",
      "Train Epoch: 27 [27648/39424 (70%)]\tLoss: 0.339914\n",
      "Train Epoch: 27 [28160/39424 (71%)]\tLoss: 0.299292\n",
      "Train Epoch: 27 [28672/39424 (73%)]\tLoss: 0.277132\n",
      "Train Epoch: 27 [29184/39424 (74%)]\tLoss: 0.270369\n",
      "Train Epoch: 27 [29696/39424 (75%)]\tLoss: 0.295424\n",
      "Train Epoch: 27 [30208/39424 (77%)]\tLoss: 0.310297\n",
      "Train Epoch: 27 [30720/39424 (78%)]\tLoss: 0.344781\n",
      "Train Epoch: 27 [31232/39424 (79%)]\tLoss: 0.399377\n",
      "Train Epoch: 27 [31744/39424 (81%)]\tLoss: 0.327074\n",
      "Train Epoch: 27 [32256/39424 (82%)]\tLoss: 0.291100\n",
      "Train Epoch: 27 [32768/39424 (83%)]\tLoss: 0.309996\n",
      "Train Epoch: 27 [33280/39424 (84%)]\tLoss: 0.317733\n",
      "Train Epoch: 27 [33792/39424 (86%)]\tLoss: 0.255918\n",
      "Train Epoch: 27 [34304/39424 (87%)]\tLoss: 0.238146\n",
      "Train Epoch: 27 [34816/39424 (88%)]\tLoss: 0.258975\n",
      "Train Epoch: 27 [35328/39424 (90%)]\tLoss: 0.300681\n",
      "Train Epoch: 27 [35840/39424 (91%)]\tLoss: 0.282665\n",
      "Train Epoch: 27 [36352/39424 (92%)]\tLoss: 0.302023\n",
      "Train Epoch: 27 [36864/39424 (94%)]\tLoss: 0.294258\n",
      "Train Epoch: 27 [37376/39424 (95%)]\tLoss: 0.315942\n",
      "Train Epoch: 27 [37888/39424 (96%)]\tLoss: 0.304745\n",
      "Train Epoch: 27 [38400/39424 (97%)]\tLoss: 0.264417\n",
      "Train Epoch: 27 [38912/39424 (99%)]\tLoss: 0.294474\n",
      "Average training loss: 0.4936954379081726\n",
      "\n",
      "Test set: Average loss: 8.8708, Accuracy: 15/12630 (0%)\n",
      "\n",
      "tensor([0.0012,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4641, Accuracy: 11242/12630 (89%)\n",
      "\n",
      "tensor([0.0833, 0.9208, 0.9493, 0.9400, 0.9061, 0.8238, 0.7267, 0.7933, 0.8178,\n",
      "        0.9750, 0.9652, 0.9143, 0.9551, 0.9694, 1.0000, 0.9381, 0.9467, 0.9306,\n",
      "        0.6923, 0.4833, 0.9444, 0.5000, 0.9083, 0.8800, 0.8000, 0.9125, 0.7833,\n",
      "        0.4500, 0.8467, 0.9556, 0.6067, 0.9296, 0.7167, 0.9810, 0.9750, 0.9462,\n",
      "        0.8250, 0.9333, 0.9275, 0.7333, 0.8667, 0.7667, 0.8333])\n",
      "Train backdoor\n",
      "Train Epoch: 27 [0/9728 (0%)]\tLoss: 8.701585\n",
      "Train Epoch: 27 [512/9728 (5%)]\tLoss: 3.307158\n",
      "Train Epoch: 27 [1024/9728 (11%)]\tLoss: 0.229644\n",
      "Train Epoch: 27 [1536/9728 (16%)]\tLoss: 0.060894\n",
      "Train Epoch: 27 [2048/9728 (21%)]\tLoss: 0.036996\n",
      "Train Epoch: 27 [2560/9728 (26%)]\tLoss: 0.027049\n",
      "Train Epoch: 27 [3072/9728 (32%)]\tLoss: 0.017214\n",
      "Train Epoch: 27 [3584/9728 (37%)]\tLoss: 0.021590\n",
      "Train Epoch: 27 [4096/9728 (42%)]\tLoss: 0.015120\n",
      "Train Epoch: 27 [4608/9728 (47%)]\tLoss: 0.011481\n",
      "Train Epoch: 27 [5120/9728 (53%)]\tLoss: 0.011025\n",
      "Train Epoch: 27 [5632/9728 (58%)]\tLoss: 0.009543\n",
      "Train Epoch: 27 [6144/9728 (63%)]\tLoss: 0.008860\n",
      "Train Epoch: 27 [6656/9728 (68%)]\tLoss: 0.010228\n",
      "Train Epoch: 27 [7168/9728 (74%)]\tLoss: 0.009000\n",
      "Train Epoch: 27 [7680/9728 (79%)]\tLoss: 0.006288\n",
      "Train Epoch: 27 [8192/9728 (84%)]\tLoss: 0.004855\n",
      "Train Epoch: 27 [8704/9728 (89%)]\tLoss: 0.007556\n",
      "Train Epoch: 27 [9216/9728 (95%)]\tLoss: 0.006950\n",
      "Average training loss: 0.6580543518066406\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.9391, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 28 [0/39424 (0%)]\tLoss: 9.416100\n",
      "Train Epoch: 28 [512/39424 (1%)]\tLoss: 0.782933\n",
      "Train Epoch: 28 [1024/39424 (3%)]\tLoss: 0.586431\n",
      "Train Epoch: 28 [1536/39424 (4%)]\tLoss: 0.596490\n",
      "Train Epoch: 28 [2048/39424 (5%)]\tLoss: 0.473563\n",
      "Train Epoch: 28 [2560/39424 (6%)]\tLoss: 0.454740\n",
      "Train Epoch: 28 [3072/39424 (8%)]\tLoss: 0.510392\n",
      "Train Epoch: 28 [3584/39424 (9%)]\tLoss: 0.445917\n",
      "Train Epoch: 28 [4096/39424 (10%)]\tLoss: 0.429912\n",
      "Train Epoch: 28 [4608/39424 (12%)]\tLoss: 0.441662\n",
      "Train Epoch: 28 [5120/39424 (13%)]\tLoss: 0.405597\n",
      "Train Epoch: 28 [5632/39424 (14%)]\tLoss: 0.416861\n",
      "Train Epoch: 28 [6144/39424 (16%)]\tLoss: 0.398223\n",
      "Train Epoch: 28 [6656/39424 (17%)]\tLoss: 0.428168\n",
      "Train Epoch: 28 [7168/39424 (18%)]\tLoss: 0.411181\n",
      "Train Epoch: 28 [7680/39424 (19%)]\tLoss: 0.393268\n",
      "Train Epoch: 28 [8192/39424 (21%)]\tLoss: 0.341827\n",
      "Train Epoch: 28 [8704/39424 (22%)]\tLoss: 0.364831\n",
      "Train Epoch: 28 [9216/39424 (23%)]\tLoss: 0.395581\n",
      "Train Epoch: 28 [9728/39424 (25%)]\tLoss: 0.399939\n",
      "Train Epoch: 28 [10240/39424 (26%)]\tLoss: 0.331944\n",
      "Train Epoch: 28 [10752/39424 (27%)]\tLoss: 0.394258\n",
      "Train Epoch: 28 [11264/39424 (29%)]\tLoss: 0.341465\n",
      "Train Epoch: 28 [11776/39424 (30%)]\tLoss: 0.330310\n",
      "Train Epoch: 28 [12288/39424 (31%)]\tLoss: 0.330704\n",
      "Train Epoch: 28 [12800/39424 (32%)]\tLoss: 0.317385\n",
      "Train Epoch: 28 [13312/39424 (34%)]\tLoss: 0.354426\n",
      "Train Epoch: 28 [13824/39424 (35%)]\tLoss: 0.343990\n",
      "Train Epoch: 28 [14336/39424 (36%)]\tLoss: 0.311084\n",
      "Train Epoch: 28 [14848/39424 (38%)]\tLoss: 0.351194\n",
      "Train Epoch: 28 [15360/39424 (39%)]\tLoss: 0.323916\n",
      "Train Epoch: 28 [15872/39424 (40%)]\tLoss: 0.310966\n",
      "Train Epoch: 28 [16384/39424 (42%)]\tLoss: 0.357350\n",
      "Train Epoch: 28 [16896/39424 (43%)]\tLoss: 0.362747\n",
      "Train Epoch: 28 [17408/39424 (44%)]\tLoss: 0.321668\n",
      "Train Epoch: 28 [17920/39424 (45%)]\tLoss: 0.399226\n",
      "Train Epoch: 28 [18432/39424 (47%)]\tLoss: 0.364300\n",
      "Train Epoch: 28 [18944/39424 (48%)]\tLoss: 0.283613\n",
      "Train Epoch: 28 [19456/39424 (49%)]\tLoss: 0.325326\n",
      "Train Epoch: 28 [19968/39424 (51%)]\tLoss: 0.254129\n",
      "Train Epoch: 28 [20480/39424 (52%)]\tLoss: 0.298649\n",
      "Train Epoch: 28 [20992/39424 (53%)]\tLoss: 0.344642\n",
      "Train Epoch: 28 [21504/39424 (55%)]\tLoss: 0.242595\n",
      "Train Epoch: 28 [22016/39424 (56%)]\tLoss: 0.260384\n",
      "Train Epoch: 28 [22528/39424 (57%)]\tLoss: 0.257095\n",
      "Train Epoch: 28 [23040/39424 (58%)]\tLoss: 0.362188\n",
      "Train Epoch: 28 [23552/39424 (60%)]\tLoss: 0.255391\n",
      "Train Epoch: 28 [24064/39424 (61%)]\tLoss: 0.324985\n",
      "Train Epoch: 28 [24576/39424 (62%)]\tLoss: 0.309532\n",
      "Train Epoch: 28 [25088/39424 (64%)]\tLoss: 0.298498\n",
      "Train Epoch: 28 [25600/39424 (65%)]\tLoss: 0.308883\n",
      "Train Epoch: 28 [26112/39424 (66%)]\tLoss: 0.259217\n",
      "Train Epoch: 28 [26624/39424 (68%)]\tLoss: 0.306317\n",
      "Train Epoch: 28 [27136/39424 (69%)]\tLoss: 0.288606\n",
      "Train Epoch: 28 [27648/39424 (70%)]\tLoss: 0.326944\n",
      "Train Epoch: 28 [28160/39424 (71%)]\tLoss: 0.271802\n",
      "Train Epoch: 28 [28672/39424 (73%)]\tLoss: 0.287279\n",
      "Train Epoch: 28 [29184/39424 (74%)]\tLoss: 0.259716\n",
      "Train Epoch: 28 [29696/39424 (75%)]\tLoss: 0.251694\n",
      "Train Epoch: 28 [30208/39424 (77%)]\tLoss: 0.294976\n",
      "Train Epoch: 28 [30720/39424 (78%)]\tLoss: 0.295390\n",
      "Train Epoch: 28 [31232/39424 (79%)]\tLoss: 0.350660\n",
      "Train Epoch: 28 [31744/39424 (81%)]\tLoss: 0.320683\n",
      "Train Epoch: 28 [32256/39424 (82%)]\tLoss: 0.272041\n",
      "Train Epoch: 28 [32768/39424 (83%)]\tLoss: 0.272836\n",
      "Train Epoch: 28 [33280/39424 (84%)]\tLoss: 0.314682\n",
      "Train Epoch: 28 [33792/39424 (86%)]\tLoss: 0.229628\n",
      "Train Epoch: 28 [34304/39424 (87%)]\tLoss: 0.200933\n",
      "Train Epoch: 28 [34816/39424 (88%)]\tLoss: 0.263001\n",
      "Train Epoch: 28 [35328/39424 (90%)]\tLoss: 0.267009\n",
      "Train Epoch: 28 [35840/39424 (91%)]\tLoss: 0.268144\n",
      "Train Epoch: 28 [36352/39424 (92%)]\tLoss: 0.264640\n",
      "Train Epoch: 28 [36864/39424 (94%)]\tLoss: 0.243817\n",
      "Train Epoch: 28 [37376/39424 (95%)]\tLoss: 0.296847\n",
      "Train Epoch: 28 [37888/39424 (96%)]\tLoss: 0.279179\n",
      "Train Epoch: 28 [38400/39424 (97%)]\tLoss: 0.255383\n",
      "Train Epoch: 28 [38912/39424 (99%)]\tLoss: 0.278097\n",
      "Average training loss: 0.4582595229148865\n",
      "\n",
      "Test set: Average loss: 8.6390, Accuracy: 17/12630 (0%)\n",
      "\n",
      "tensor([0.0013,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4520, Accuracy: 11259/12630 (89%)\n",
      "\n",
      "tensor([0.0833, 0.9292, 0.9440, 0.9511, 0.9091, 0.8095, 0.7267, 0.7956, 0.8267,\n",
      "        0.9750, 0.9682, 0.9310, 0.9580, 0.9694, 1.0000, 0.9333, 0.9467, 0.9278,\n",
      "        0.7154, 0.5000, 0.9444, 0.5111, 0.9083, 0.8933, 0.8000, 0.9125, 0.7778,\n",
      "        0.4500, 0.8533, 0.9444, 0.6133, 0.9333, 0.6000, 0.9810, 0.9750, 0.9436,\n",
      "        0.8333, 0.9333, 0.9261, 0.7333, 0.8667, 0.7667, 0.8000])\n",
      "Train backdoor\n",
      "Train Epoch: 28 [0/9728 (0%)]\tLoss: 8.474384\n",
      "Train Epoch: 28 [512/9728 (5%)]\tLoss: 2.973805\n",
      "Train Epoch: 28 [1024/9728 (11%)]\tLoss: 0.129572\n",
      "Train Epoch: 28 [1536/9728 (16%)]\tLoss: 0.071734\n",
      "Train Epoch: 28 [2048/9728 (21%)]\tLoss: 0.031031\n",
      "Train Epoch: 28 [2560/9728 (26%)]\tLoss: 0.029654\n",
      "Train Epoch: 28 [3072/9728 (32%)]\tLoss: 0.021799\n",
      "Train Epoch: 28 [3584/9728 (37%)]\tLoss: 0.023543\n",
      "Train Epoch: 28 [4096/9728 (42%)]\tLoss: 0.012573\n",
      "Train Epoch: 28 [4608/9728 (47%)]\tLoss: 0.011585\n",
      "Train Epoch: 28 [5120/9728 (53%)]\tLoss: 0.008888\n",
      "Train Epoch: 28 [5632/9728 (58%)]\tLoss: 0.009046\n",
      "Train Epoch: 28 [6144/9728 (63%)]\tLoss: 0.010164\n",
      "Train Epoch: 28 [6656/9728 (68%)]\tLoss: 0.010932\n",
      "Train Epoch: 28 [7168/9728 (74%)]\tLoss: 0.009507\n",
      "Train Epoch: 28 [7680/9728 (79%)]\tLoss: 0.005653\n",
      "Train Epoch: 28 [8192/9728 (84%)]\tLoss: 0.003940\n",
      "Train Epoch: 28 [8704/9728 (89%)]\tLoss: 0.008077\n",
      "Train Epoch: 28 [9216/9728 (95%)]\tLoss: 0.006527\n",
      "Average training loss: 0.6238112449645996\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.2226, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 29 [0/39424 (0%)]\tLoss: 9.707916\n",
      "Train Epoch: 29 [512/39424 (1%)]\tLoss: 0.834505\n",
      "Train Epoch: 29 [1024/39424 (3%)]\tLoss: 0.656217\n",
      "Train Epoch: 29 [1536/39424 (4%)]\tLoss: 0.578684\n",
      "Train Epoch: 29 [2048/39424 (5%)]\tLoss: 0.467509\n",
      "Train Epoch: 29 [2560/39424 (6%)]\tLoss: 0.432948\n",
      "Train Epoch: 29 [3072/39424 (8%)]\tLoss: 0.480542\n",
      "Train Epoch: 29 [3584/39424 (9%)]\tLoss: 0.424550\n",
      "Train Epoch: 29 [4096/39424 (10%)]\tLoss: 0.404015\n",
      "Train Epoch: 29 [4608/39424 (12%)]\tLoss: 0.408496\n",
      "Train Epoch: 29 [5120/39424 (13%)]\tLoss: 0.372185\n",
      "Train Epoch: 29 [5632/39424 (14%)]\tLoss: 0.408644\n",
      "Train Epoch: 29 [6144/39424 (16%)]\tLoss: 0.369317\n",
      "Train Epoch: 29 [6656/39424 (17%)]\tLoss: 0.413618\n",
      "Train Epoch: 29 [7168/39424 (18%)]\tLoss: 0.401377\n",
      "Train Epoch: 29 [7680/39424 (19%)]\tLoss: 0.369214\n",
      "Train Epoch: 29 [8192/39424 (21%)]\tLoss: 0.320192\n",
      "Train Epoch: 29 [8704/39424 (22%)]\tLoss: 0.330959\n",
      "Train Epoch: 29 [9216/39424 (23%)]\tLoss: 0.359103\n",
      "Train Epoch: 29 [9728/39424 (25%)]\tLoss: 0.361886\n",
      "Train Epoch: 29 [10240/39424 (26%)]\tLoss: 0.324594\n",
      "Train Epoch: 29 [10752/39424 (27%)]\tLoss: 0.386959\n",
      "Train Epoch: 29 [11264/39424 (29%)]\tLoss: 0.321927\n",
      "Train Epoch: 29 [11776/39424 (30%)]\tLoss: 0.323850\n",
      "Train Epoch: 29 [12288/39424 (31%)]\tLoss: 0.326225\n",
      "Train Epoch: 29 [12800/39424 (32%)]\tLoss: 0.299912\n",
      "Train Epoch: 29 [13312/39424 (34%)]\tLoss: 0.328533\n",
      "Train Epoch: 29 [13824/39424 (35%)]\tLoss: 0.338762\n",
      "Train Epoch: 29 [14336/39424 (36%)]\tLoss: 0.279887\n",
      "Train Epoch: 29 [14848/39424 (38%)]\tLoss: 0.315411\n",
      "Train Epoch: 29 [15360/39424 (39%)]\tLoss: 0.290879\n",
      "Train Epoch: 29 [15872/39424 (40%)]\tLoss: 0.295594\n",
      "Train Epoch: 29 [16384/39424 (42%)]\tLoss: 0.329560\n",
      "Train Epoch: 29 [16896/39424 (43%)]\tLoss: 0.354536\n",
      "Train Epoch: 29 [17408/39424 (44%)]\tLoss: 0.303801\n",
      "Train Epoch: 29 [17920/39424 (45%)]\tLoss: 0.362430\n",
      "Train Epoch: 29 [18432/39424 (47%)]\tLoss: 0.326949\n",
      "Train Epoch: 29 [18944/39424 (48%)]\tLoss: 0.261718\n",
      "Train Epoch: 29 [19456/39424 (49%)]\tLoss: 0.319566\n",
      "Train Epoch: 29 [19968/39424 (51%)]\tLoss: 0.241744\n",
      "Train Epoch: 29 [20480/39424 (52%)]\tLoss: 0.292317\n",
      "Train Epoch: 29 [20992/39424 (53%)]\tLoss: 0.324906\n",
      "Train Epoch: 29 [21504/39424 (55%)]\tLoss: 0.209688\n",
      "Train Epoch: 29 [22016/39424 (56%)]\tLoss: 0.263885\n",
      "Train Epoch: 29 [22528/39424 (57%)]\tLoss: 0.252955\n",
      "Train Epoch: 29 [23040/39424 (58%)]\tLoss: 0.366240\n",
      "Train Epoch: 29 [23552/39424 (60%)]\tLoss: 0.234790\n",
      "Train Epoch: 29 [24064/39424 (61%)]\tLoss: 0.323336\n",
      "Train Epoch: 29 [24576/39424 (62%)]\tLoss: 0.301150\n",
      "Train Epoch: 29 [25088/39424 (64%)]\tLoss: 0.246469\n",
      "Train Epoch: 29 [25600/39424 (65%)]\tLoss: 0.301746\n",
      "Train Epoch: 29 [26112/39424 (66%)]\tLoss: 0.240027\n",
      "Train Epoch: 29 [26624/39424 (68%)]\tLoss: 0.297301\n",
      "Train Epoch: 29 [27136/39424 (69%)]\tLoss: 0.313618\n",
      "Train Epoch: 29 [27648/39424 (70%)]\tLoss: 0.315633\n",
      "Train Epoch: 29 [28160/39424 (71%)]\tLoss: 0.268762\n",
      "Train Epoch: 29 [28672/39424 (73%)]\tLoss: 0.261577\n",
      "Train Epoch: 29 [29184/39424 (74%)]\tLoss: 0.251707\n",
      "Train Epoch: 29 [29696/39424 (75%)]\tLoss: 0.247637\n",
      "Train Epoch: 29 [30208/39424 (77%)]\tLoss: 0.282143\n",
      "Train Epoch: 29 [30720/39424 (78%)]\tLoss: 0.292454\n",
      "Train Epoch: 29 [31232/39424 (79%)]\tLoss: 0.345315\n",
      "Train Epoch: 29 [31744/39424 (81%)]\tLoss: 0.281112\n",
      "Train Epoch: 29 [32256/39424 (82%)]\tLoss: 0.253145\n",
      "Train Epoch: 29 [32768/39424 (83%)]\tLoss: 0.263170\n",
      "Train Epoch: 29 [33280/39424 (84%)]\tLoss: 0.282447\n",
      "Train Epoch: 29 [33792/39424 (86%)]\tLoss: 0.234170\n",
      "Train Epoch: 29 [34304/39424 (87%)]\tLoss: 0.204779\n",
      "Train Epoch: 29 [34816/39424 (88%)]\tLoss: 0.239345\n",
      "Train Epoch: 29 [35328/39424 (90%)]\tLoss: 0.268112\n",
      "Train Epoch: 29 [35840/39424 (91%)]\tLoss: 0.257491\n",
      "Train Epoch: 29 [36352/39424 (92%)]\tLoss: 0.268562\n",
      "Train Epoch: 29 [36864/39424 (94%)]\tLoss: 0.225243\n",
      "Train Epoch: 29 [37376/39424 (95%)]\tLoss: 0.281412\n",
      "Train Epoch: 29 [37888/39424 (96%)]\tLoss: 0.271507\n",
      "Train Epoch: 29 [38400/39424 (97%)]\tLoss: 0.240642\n",
      "Train Epoch: 29 [38912/39424 (99%)]\tLoss: 0.249821\n",
      "Average training loss: 0.4479135274887085\n",
      "\n",
      "Test set: Average loss: 8.7337, Accuracy: 17/12630 (0%)\n",
      "\n",
      "tensor([0.0013,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4385, Accuracy: 11314/12630 (90%)\n",
      "\n",
      "tensor([0.0833, 0.9278, 0.9493, 0.9533, 0.9091, 0.8270, 0.7267, 0.8044, 0.8378,\n",
      "        0.9771, 0.9682, 0.9190, 0.9609, 0.9694, 1.0000, 0.9476, 0.9533, 0.9306,\n",
      "        0.7154, 0.5000, 0.9444, 0.5333, 0.9083, 0.8733, 0.8333, 0.9125, 0.7833,\n",
      "        0.4500, 0.8600, 0.9667, 0.6600, 0.9481, 0.7000, 0.9810, 0.9750, 0.9462,\n",
      "        0.8417, 0.9333, 0.9261, 0.7333, 0.8667, 0.7667, 0.8333])\n",
      "Train backdoor\n",
      "Train Epoch: 29 [0/9728 (0%)]\tLoss: 8.492413\n",
      "Train Epoch: 29 [512/9728 (5%)]\tLoss: 3.121063\n",
      "Train Epoch: 29 [1024/9728 (11%)]\tLoss: 0.182562\n",
      "Train Epoch: 29 [1536/9728 (16%)]\tLoss: 0.063766\n",
      "Train Epoch: 29 [2048/9728 (21%)]\tLoss: 0.025463\n",
      "Train Epoch: 29 [2560/9728 (26%)]\tLoss: 0.031111\n",
      "Train Epoch: 29 [3072/9728 (32%)]\tLoss: 0.017768\n",
      "Train Epoch: 29 [3584/9728 (37%)]\tLoss: 0.019368\n",
      "Train Epoch: 29 [4096/9728 (42%)]\tLoss: 0.013817\n",
      "Train Epoch: 29 [4608/9728 (47%)]\tLoss: 0.010322\n",
      "Train Epoch: 29 [5120/9728 (53%)]\tLoss: 0.008364\n",
      "Train Epoch: 29 [5632/9728 (58%)]\tLoss: 0.007938\n",
      "Train Epoch: 29 [6144/9728 (63%)]\tLoss: 0.008167\n",
      "Train Epoch: 29 [6656/9728 (68%)]\tLoss: 0.010432\n",
      "Train Epoch: 29 [7168/9728 (74%)]\tLoss: 0.010125\n",
      "Train Epoch: 29 [7680/9728 (79%)]\tLoss: 0.005258\n",
      "Train Epoch: 29 [8192/9728 (84%)]\tLoss: 0.004499\n",
      "Train Epoch: 29 [8704/9728 (89%)]\tLoss: 0.007415\n",
      "Train Epoch: 29 [9216/9728 (95%)]\tLoss: 0.006019\n",
      "Average training loss: 0.6339932680130005\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.8679, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 30 [0/39424 (0%)]\tLoss: 9.296606\n",
      "Train Epoch: 30 [512/39424 (1%)]\tLoss: 0.944922\n",
      "Train Epoch: 30 [1024/39424 (3%)]\tLoss: 0.708718\n",
      "Train Epoch: 30 [1536/39424 (4%)]\tLoss: 0.593615\n",
      "Train Epoch: 30 [2048/39424 (5%)]\tLoss: 0.441850\n",
      "Train Epoch: 30 [2560/39424 (6%)]\tLoss: 0.405670\n",
      "Train Epoch: 30 [3072/39424 (8%)]\tLoss: 0.456106\n",
      "Train Epoch: 30 [3584/39424 (9%)]\tLoss: 0.406082\n",
      "Train Epoch: 30 [4096/39424 (10%)]\tLoss: 0.385641\n",
      "Train Epoch: 30 [4608/39424 (12%)]\tLoss: 0.394122\n",
      "Train Epoch: 30 [5120/39424 (13%)]\tLoss: 0.371735\n",
      "Train Epoch: 30 [5632/39424 (14%)]\tLoss: 0.375464\n",
      "Train Epoch: 30 [6144/39424 (16%)]\tLoss: 0.374548\n",
      "Train Epoch: 30 [6656/39424 (17%)]\tLoss: 0.392124\n",
      "Train Epoch: 30 [7168/39424 (18%)]\tLoss: 0.378723\n",
      "Train Epoch: 30 [7680/39424 (19%)]\tLoss: 0.360317\n",
      "Train Epoch: 30 [8192/39424 (21%)]\tLoss: 0.300343\n",
      "Train Epoch: 30 [8704/39424 (22%)]\tLoss: 0.312368\n",
      "Train Epoch: 30 [9216/39424 (23%)]\tLoss: 0.314647\n",
      "Train Epoch: 30 [9728/39424 (25%)]\tLoss: 0.354129\n",
      "Train Epoch: 30 [10240/39424 (26%)]\tLoss: 0.297419\n",
      "Train Epoch: 30 [10752/39424 (27%)]\tLoss: 0.360373\n",
      "Train Epoch: 30 [11264/39424 (29%)]\tLoss: 0.290984\n",
      "Train Epoch: 30 [11776/39424 (30%)]\tLoss: 0.318702\n",
      "Train Epoch: 30 [12288/39424 (31%)]\tLoss: 0.316191\n",
      "Train Epoch: 30 [12800/39424 (32%)]\tLoss: 0.296430\n",
      "Train Epoch: 30 [13312/39424 (34%)]\tLoss: 0.328121\n",
      "Train Epoch: 30 [13824/39424 (35%)]\tLoss: 0.320851\n",
      "Train Epoch: 30 [14336/39424 (36%)]\tLoss: 0.288664\n",
      "Train Epoch: 30 [14848/39424 (38%)]\tLoss: 0.293176\n",
      "Train Epoch: 30 [15360/39424 (39%)]\tLoss: 0.289446\n",
      "Train Epoch: 30 [15872/39424 (40%)]\tLoss: 0.281493\n",
      "Train Epoch: 30 [16384/39424 (42%)]\tLoss: 0.283790\n",
      "Train Epoch: 30 [16896/39424 (43%)]\tLoss: 0.324510\n",
      "Train Epoch: 30 [17408/39424 (44%)]\tLoss: 0.280051\n",
      "Train Epoch: 30 [17920/39424 (45%)]\tLoss: 0.332747\n",
      "Train Epoch: 30 [18432/39424 (47%)]\tLoss: 0.315713\n",
      "Train Epoch: 30 [18944/39424 (48%)]\tLoss: 0.265175\n",
      "Train Epoch: 30 [19456/39424 (49%)]\tLoss: 0.290691\n",
      "Train Epoch: 30 [19968/39424 (51%)]\tLoss: 0.217349\n",
      "Train Epoch: 30 [20480/39424 (52%)]\tLoss: 0.260977\n",
      "Train Epoch: 30 [20992/39424 (53%)]\tLoss: 0.337608\n",
      "Train Epoch: 30 [21504/39424 (55%)]\tLoss: 0.240009\n",
      "Train Epoch: 30 [22016/39424 (56%)]\tLoss: 0.224304\n",
      "Train Epoch: 30 [22528/39424 (57%)]\tLoss: 0.240699\n",
      "Train Epoch: 30 [23040/39424 (58%)]\tLoss: 0.311254\n",
      "Train Epoch: 30 [23552/39424 (60%)]\tLoss: 0.237478\n",
      "Train Epoch: 30 [24064/39424 (61%)]\tLoss: 0.298110\n",
      "Train Epoch: 30 [24576/39424 (62%)]\tLoss: 0.294365\n",
      "Train Epoch: 30 [25088/39424 (64%)]\tLoss: 0.243159\n",
      "Train Epoch: 30 [25600/39424 (65%)]\tLoss: 0.255356\n",
      "Train Epoch: 30 [26112/39424 (66%)]\tLoss: 0.244103\n",
      "Train Epoch: 30 [26624/39424 (68%)]\tLoss: 0.292578\n",
      "Train Epoch: 30 [27136/39424 (69%)]\tLoss: 0.283734\n",
      "Train Epoch: 30 [27648/39424 (70%)]\tLoss: 0.291203\n",
      "Train Epoch: 30 [28160/39424 (71%)]\tLoss: 0.236636\n",
      "Train Epoch: 30 [28672/39424 (73%)]\tLoss: 0.240547\n",
      "Train Epoch: 30 [29184/39424 (74%)]\tLoss: 0.247801\n",
      "Train Epoch: 30 [29696/39424 (75%)]\tLoss: 0.224131\n",
      "Train Epoch: 30 [30208/39424 (77%)]\tLoss: 0.269145\n",
      "Train Epoch: 30 [30720/39424 (78%)]\tLoss: 0.280054\n",
      "Train Epoch: 30 [31232/39424 (79%)]\tLoss: 0.317730\n",
      "Train Epoch: 30 [31744/39424 (81%)]\tLoss: 0.274154\n",
      "Train Epoch: 30 [32256/39424 (82%)]\tLoss: 0.231830\n",
      "Train Epoch: 30 [32768/39424 (83%)]\tLoss: 0.244668\n",
      "Train Epoch: 30 [33280/39424 (84%)]\tLoss: 0.276567\n",
      "Train Epoch: 30 [33792/39424 (86%)]\tLoss: 0.218395\n",
      "Train Epoch: 30 [34304/39424 (87%)]\tLoss: 0.200669\n",
      "Train Epoch: 30 [34816/39424 (88%)]\tLoss: 0.245855\n",
      "Train Epoch: 30 [35328/39424 (90%)]\tLoss: 0.269774\n",
      "Train Epoch: 30 [35840/39424 (91%)]\tLoss: 0.238190\n",
      "Train Epoch: 30 [36352/39424 (92%)]\tLoss: 0.248685\n",
      "Train Epoch: 30 [36864/39424 (94%)]\tLoss: 0.222847\n",
      "Train Epoch: 30 [37376/39424 (95%)]\tLoss: 0.270766\n",
      "Train Epoch: 30 [37888/39424 (96%)]\tLoss: 0.275187\n",
      "Train Epoch: 30 [38400/39424 (97%)]\tLoss: 0.236077\n",
      "Train Epoch: 30 [38912/39424 (99%)]\tLoss: 0.253065\n",
      "Average training loss: 0.4303547143936157\n",
      "\n",
      "Test set: Average loss: 8.6543, Accuracy: 20/12630 (0%)\n",
      "\n",
      "tensor([0.0016,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4239, Accuracy: 11360/12630 (90%)\n",
      "\n",
      "tensor([0.0833, 0.9389, 0.9427, 0.9422, 0.9106, 0.8540, 0.7267, 0.8044, 0.8444,\n",
      "        0.9792, 0.9697, 0.9286, 0.9594, 0.9708, 1.0000, 0.9476, 0.9600, 0.9306,\n",
      "        0.7256, 0.5000, 0.9444, 0.5889, 0.9083, 0.9133, 0.8222, 0.9125, 0.7889,\n",
      "        0.4500, 0.8667, 0.9667, 0.6667, 0.9481, 0.6667, 0.9810, 0.9750, 0.9436,\n",
      "        0.8333, 0.9667, 0.9261, 0.7556, 0.8889, 0.7833, 0.8333])\n",
      "Train backdoor\n",
      "Train Epoch: 30 [0/9728 (0%)]\tLoss: 8.386538\n",
      "Train Epoch: 30 [512/9728 (5%)]\tLoss: 2.939394\n",
      "Train Epoch: 30 [1024/9728 (11%)]\tLoss: 0.149808\n",
      "Train Epoch: 30 [1536/9728 (16%)]\tLoss: 0.059022\n",
      "Train Epoch: 30 [2048/9728 (21%)]\tLoss: 0.025316\n",
      "Train Epoch: 30 [2560/9728 (26%)]\tLoss: 0.027354\n",
      "Train Epoch: 30 [3072/9728 (32%)]\tLoss: 0.017399\n",
      "Train Epoch: 30 [3584/9728 (37%)]\tLoss: 0.022883\n",
      "Train Epoch: 30 [4096/9728 (42%)]\tLoss: 0.011918\n",
      "Train Epoch: 30 [4608/9728 (47%)]\tLoss: 0.011998\n",
      "Train Epoch: 30 [5120/9728 (53%)]\tLoss: 0.010556\n",
      "Train Epoch: 30 [5632/9728 (58%)]\tLoss: 0.007268\n",
      "Train Epoch: 30 [6144/9728 (63%)]\tLoss: 0.008064\n",
      "Train Epoch: 30 [6656/9728 (68%)]\tLoss: 0.008558\n",
      "Train Epoch: 30 [7168/9728 (74%)]\tLoss: 0.008553\n",
      "Train Epoch: 30 [7680/9728 (79%)]\tLoss: 0.003907\n",
      "Train Epoch: 30 [8192/9728 (84%)]\tLoss: 0.005300\n",
      "Train Epoch: 30 [8704/9728 (89%)]\tLoss: 0.006300\n",
      "Train Epoch: 30 [9216/9728 (95%)]\tLoss: 0.005401\n",
      "Average training loss: 0.616607129573822\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.9514, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 31 [0/39424 (0%)]\tLoss: 9.321207\n",
      "Train Epoch: 31 [512/39424 (1%)]\tLoss: 0.847836\n",
      "Train Epoch: 31 [1024/39424 (3%)]\tLoss: 0.640705\n",
      "Train Epoch: 31 [1536/39424 (4%)]\tLoss: 0.562576\n",
      "Train Epoch: 31 [2048/39424 (5%)]\tLoss: 0.450898\n",
      "Train Epoch: 31 [2560/39424 (6%)]\tLoss: 0.380094\n",
      "Train Epoch: 31 [3072/39424 (8%)]\tLoss: 0.444950\n",
      "Train Epoch: 31 [3584/39424 (9%)]\tLoss: 0.396968\n",
      "Train Epoch: 31 [4096/39424 (10%)]\tLoss: 0.391228\n",
      "Train Epoch: 31 [4608/39424 (12%)]\tLoss: 0.375972\n",
      "Train Epoch: 31 [5120/39424 (13%)]\tLoss: 0.340623\n",
      "Train Epoch: 31 [5632/39424 (14%)]\tLoss: 0.375912\n",
      "Train Epoch: 31 [6144/39424 (16%)]\tLoss: 0.339777\n",
      "Train Epoch: 31 [6656/39424 (17%)]\tLoss: 0.395727\n",
      "Train Epoch: 31 [7168/39424 (18%)]\tLoss: 0.355477\n",
      "Train Epoch: 31 [7680/39424 (19%)]\tLoss: 0.353559\n",
      "Train Epoch: 31 [8192/39424 (21%)]\tLoss: 0.279272\n",
      "Train Epoch: 31 [8704/39424 (22%)]\tLoss: 0.297616\n",
      "Train Epoch: 31 [9216/39424 (23%)]\tLoss: 0.342246\n",
      "Train Epoch: 31 [9728/39424 (25%)]\tLoss: 0.342448\n",
      "Train Epoch: 31 [10240/39424 (26%)]\tLoss: 0.287022\n",
      "Train Epoch: 31 [10752/39424 (27%)]\tLoss: 0.369275\n",
      "Train Epoch: 31 [11264/39424 (29%)]\tLoss: 0.288018\n",
      "Train Epoch: 31 [11776/39424 (30%)]\tLoss: 0.296467\n",
      "Train Epoch: 31 [12288/39424 (31%)]\tLoss: 0.294217\n",
      "Train Epoch: 31 [12800/39424 (32%)]\tLoss: 0.269042\n",
      "Train Epoch: 31 [13312/39424 (34%)]\tLoss: 0.294206\n",
      "Train Epoch: 31 [13824/39424 (35%)]\tLoss: 0.290237\n",
      "Train Epoch: 31 [14336/39424 (36%)]\tLoss: 0.281518\n",
      "Train Epoch: 31 [14848/39424 (38%)]\tLoss: 0.273074\n",
      "Train Epoch: 31 [15360/39424 (39%)]\tLoss: 0.278705\n",
      "Train Epoch: 31 [15872/39424 (40%)]\tLoss: 0.286231\n",
      "Train Epoch: 31 [16384/39424 (42%)]\tLoss: 0.291687\n",
      "Train Epoch: 31 [16896/39424 (43%)]\tLoss: 0.328496\n",
      "Train Epoch: 31 [17408/39424 (44%)]\tLoss: 0.280969\n",
      "Train Epoch: 31 [17920/39424 (45%)]\tLoss: 0.350241\n",
      "Train Epoch: 31 [18432/39424 (47%)]\tLoss: 0.309725\n",
      "Train Epoch: 31 [18944/39424 (48%)]\tLoss: 0.249738\n",
      "Train Epoch: 31 [19456/39424 (49%)]\tLoss: 0.280917\n",
      "Train Epoch: 31 [19968/39424 (51%)]\tLoss: 0.212062\n",
      "Train Epoch: 31 [20480/39424 (52%)]\tLoss: 0.243186\n",
      "Train Epoch: 31 [20992/39424 (53%)]\tLoss: 0.301833\n",
      "Train Epoch: 31 [21504/39424 (55%)]\tLoss: 0.206153\n",
      "Train Epoch: 31 [22016/39424 (56%)]\tLoss: 0.241994\n",
      "Train Epoch: 31 [22528/39424 (57%)]\tLoss: 0.244907\n",
      "Train Epoch: 31 [23040/39424 (58%)]\tLoss: 0.319266\n",
      "Train Epoch: 31 [23552/39424 (60%)]\tLoss: 0.219448\n",
      "Train Epoch: 31 [24064/39424 (61%)]\tLoss: 0.278648\n",
      "Train Epoch: 31 [24576/39424 (62%)]\tLoss: 0.255594\n",
      "Train Epoch: 31 [25088/39424 (64%)]\tLoss: 0.246205\n",
      "Train Epoch: 31 [25600/39424 (65%)]\tLoss: 0.265384\n",
      "Train Epoch: 31 [26112/39424 (66%)]\tLoss: 0.220044\n",
      "Train Epoch: 31 [26624/39424 (68%)]\tLoss: 0.275870\n",
      "Train Epoch: 31 [27136/39424 (69%)]\tLoss: 0.287788\n",
      "Train Epoch: 31 [27648/39424 (70%)]\tLoss: 0.298478\n",
      "Train Epoch: 31 [28160/39424 (71%)]\tLoss: 0.238034\n",
      "Train Epoch: 31 [28672/39424 (73%)]\tLoss: 0.223232\n",
      "Train Epoch: 31 [29184/39424 (74%)]\tLoss: 0.242602\n",
      "Train Epoch: 31 [29696/39424 (75%)]\tLoss: 0.226067\n",
      "Train Epoch: 31 [30208/39424 (77%)]\tLoss: 0.231255\n",
      "Train Epoch: 31 [30720/39424 (78%)]\tLoss: 0.277929\n",
      "Train Epoch: 31 [31232/39424 (79%)]\tLoss: 0.319714\n",
      "Train Epoch: 31 [31744/39424 (81%)]\tLoss: 0.256137\n",
      "Train Epoch: 31 [32256/39424 (82%)]\tLoss: 0.235573\n",
      "Train Epoch: 31 [32768/39424 (83%)]\tLoss: 0.239529\n",
      "Train Epoch: 31 [33280/39424 (84%)]\tLoss: 0.268972\n",
      "Train Epoch: 31 [33792/39424 (86%)]\tLoss: 0.206669\n",
      "Train Epoch: 31 [34304/39424 (87%)]\tLoss: 0.187726\n",
      "Train Epoch: 31 [34816/39424 (88%)]\tLoss: 0.215599\n",
      "Train Epoch: 31 [35328/39424 (90%)]\tLoss: 0.258830\n",
      "Train Epoch: 31 [35840/39424 (91%)]\tLoss: 0.234364\n",
      "Train Epoch: 31 [36352/39424 (92%)]\tLoss: 0.222267\n",
      "Train Epoch: 31 [36864/39424 (94%)]\tLoss: 0.213744\n",
      "Train Epoch: 31 [37376/39424 (95%)]\tLoss: 0.256625\n",
      "Train Epoch: 31 [37888/39424 (96%)]\tLoss: 0.233541\n",
      "Train Epoch: 31 [38400/39424 (97%)]\tLoss: 0.209766\n",
      "Train Epoch: 31 [38912/39424 (99%)]\tLoss: 0.241783\n",
      "Average training loss: 0.41807398200035095\n",
      "\n",
      "Test set: Average loss: 8.6528, Accuracy: 18/12630 (0%)\n",
      "\n",
      "tensor([0.0014,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4157, Accuracy: 11385/12630 (90%)\n",
      "\n",
      "tensor([0.0667, 0.9306, 0.9573, 0.9533, 0.9106, 0.8524, 0.7467, 0.8222, 0.8511,\n",
      "        0.9792, 0.9697, 0.9381, 0.9623, 0.9708, 1.0000, 0.9476, 0.9667, 0.9306,\n",
      "        0.7308, 0.5000, 0.9444, 0.6222, 0.9083, 0.9133, 0.8333, 0.9104, 0.7889,\n",
      "        0.4833, 0.8800, 0.9667, 0.6333, 0.9444, 0.5667, 0.9857, 0.9750, 0.9436,\n",
      "        0.8417, 0.9667, 0.9275, 0.7222, 0.8889, 0.7833, 0.8222])\n",
      "Train backdoor\n",
      "Train Epoch: 31 [0/9728 (0%)]\tLoss: 8.424983\n",
      "Train Epoch: 31 [512/9728 (5%)]\tLoss: 2.990277\n",
      "Train Epoch: 31 [1024/9728 (11%)]\tLoss: 0.152811\n",
      "Train Epoch: 31 [1536/9728 (16%)]\tLoss: 0.065855\n",
      "Train Epoch: 31 [2048/9728 (21%)]\tLoss: 0.026945\n",
      "Train Epoch: 31 [2560/9728 (26%)]\tLoss: 0.024893\n",
      "Train Epoch: 31 [3072/9728 (32%)]\tLoss: 0.020391\n",
      "Train Epoch: 31 [3584/9728 (37%)]\tLoss: 0.022738\n",
      "Train Epoch: 31 [4096/9728 (42%)]\tLoss: 0.010583\n",
      "Train Epoch: 31 [4608/9728 (47%)]\tLoss: 0.008297\n",
      "Train Epoch: 31 [5120/9728 (53%)]\tLoss: 0.007648\n",
      "Train Epoch: 31 [5632/9728 (58%)]\tLoss: 0.006822\n",
      "Train Epoch: 31 [6144/9728 (63%)]\tLoss: 0.006920\n",
      "Train Epoch: 31 [6656/9728 (68%)]\tLoss: 0.007946\n",
      "Train Epoch: 31 [7168/9728 (74%)]\tLoss: 0.011348\n",
      "Train Epoch: 31 [7680/9728 (79%)]\tLoss: 0.005323\n",
      "Train Epoch: 31 [8192/9728 (84%)]\tLoss: 0.003856\n",
      "Train Epoch: 31 [8704/9728 (89%)]\tLoss: 0.005575\n",
      "Train Epoch: 31 [9216/9728 (95%)]\tLoss: 0.006785\n",
      "Average training loss: 0.6215788125991821\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.1024, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 32 [0/39424 (0%)]\tLoss: 9.581465\n",
      "Train Epoch: 32 [512/39424 (1%)]\tLoss: 1.328642\n",
      "Train Epoch: 32 [1024/39424 (3%)]\tLoss: 0.952837\n",
      "Train Epoch: 32 [1536/39424 (4%)]\tLoss: 0.844480\n",
      "Train Epoch: 32 [2048/39424 (5%)]\tLoss: 0.680160\n",
      "Train Epoch: 32 [2560/39424 (6%)]\tLoss: 0.528669\n",
      "Train Epoch: 32 [3072/39424 (8%)]\tLoss: 0.519111\n",
      "Train Epoch: 32 [3584/39424 (9%)]\tLoss: 0.436396\n",
      "Train Epoch: 32 [4096/39424 (10%)]\tLoss: 0.394617\n",
      "Train Epoch: 32 [4608/39424 (12%)]\tLoss: 0.383692\n",
      "Train Epoch: 32 [5120/39424 (13%)]\tLoss: 0.358878\n",
      "Train Epoch: 32 [5632/39424 (14%)]\tLoss: 0.353368\n",
      "Train Epoch: 32 [6144/39424 (16%)]\tLoss: 0.341753\n",
      "Train Epoch: 32 [6656/39424 (17%)]\tLoss: 0.352792\n",
      "Train Epoch: 32 [7168/39424 (18%)]\tLoss: 0.355090\n",
      "Train Epoch: 32 [7680/39424 (19%)]\tLoss: 0.324810\n",
      "Train Epoch: 32 [8192/39424 (21%)]\tLoss: 0.282375\n",
      "Train Epoch: 32 [8704/39424 (22%)]\tLoss: 0.289774\n",
      "Train Epoch: 32 [9216/39424 (23%)]\tLoss: 0.315991\n",
      "Train Epoch: 32 [9728/39424 (25%)]\tLoss: 0.334194\n",
      "Train Epoch: 32 [10240/39424 (26%)]\tLoss: 0.278089\n",
      "Train Epoch: 32 [10752/39424 (27%)]\tLoss: 0.342388\n",
      "Train Epoch: 32 [11264/39424 (29%)]\tLoss: 0.293380\n",
      "Train Epoch: 32 [11776/39424 (30%)]\tLoss: 0.290403\n",
      "Train Epoch: 32 [12288/39424 (31%)]\tLoss: 0.276287\n",
      "Train Epoch: 32 [12800/39424 (32%)]\tLoss: 0.274234\n",
      "Train Epoch: 32 [13312/39424 (34%)]\tLoss: 0.284725\n",
      "Train Epoch: 32 [13824/39424 (35%)]\tLoss: 0.290191\n",
      "Train Epoch: 32 [14336/39424 (36%)]\tLoss: 0.266628\n",
      "Train Epoch: 32 [14848/39424 (38%)]\tLoss: 0.273271\n",
      "Train Epoch: 32 [15360/39424 (39%)]\tLoss: 0.270230\n",
      "Train Epoch: 32 [15872/39424 (40%)]\tLoss: 0.267535\n",
      "Train Epoch: 32 [16384/39424 (42%)]\tLoss: 0.269595\n",
      "Train Epoch: 32 [16896/39424 (43%)]\tLoss: 0.311654\n",
      "Train Epoch: 32 [17408/39424 (44%)]\tLoss: 0.278620\n",
      "Train Epoch: 32 [17920/39424 (45%)]\tLoss: 0.334412\n",
      "Train Epoch: 32 [18432/39424 (47%)]\tLoss: 0.290306\n",
      "Train Epoch: 32 [18944/39424 (48%)]\tLoss: 0.245181\n",
      "Train Epoch: 32 [19456/39424 (49%)]\tLoss: 0.259274\n",
      "Train Epoch: 32 [19968/39424 (51%)]\tLoss: 0.204136\n",
      "Train Epoch: 32 [20480/39424 (52%)]\tLoss: 0.223576\n",
      "Train Epoch: 32 [20992/39424 (53%)]\tLoss: 0.305287\n",
      "Train Epoch: 32 [21504/39424 (55%)]\tLoss: 0.195792\n",
      "Train Epoch: 32 [22016/39424 (56%)]\tLoss: 0.215775\n",
      "Train Epoch: 32 [22528/39424 (57%)]\tLoss: 0.196444\n",
      "Train Epoch: 32 [23040/39424 (58%)]\tLoss: 0.291756\n",
      "Train Epoch: 32 [23552/39424 (60%)]\tLoss: 0.206622\n",
      "Train Epoch: 32 [24064/39424 (61%)]\tLoss: 0.251400\n",
      "Train Epoch: 32 [24576/39424 (62%)]\tLoss: 0.249144\n",
      "Train Epoch: 32 [25088/39424 (64%)]\tLoss: 0.229518\n",
      "Train Epoch: 32 [25600/39424 (65%)]\tLoss: 0.258267\n",
      "Train Epoch: 32 [26112/39424 (66%)]\tLoss: 0.231890\n",
      "Train Epoch: 32 [26624/39424 (68%)]\tLoss: 0.276109\n",
      "Train Epoch: 32 [27136/39424 (69%)]\tLoss: 0.267798\n",
      "Train Epoch: 32 [27648/39424 (70%)]\tLoss: 0.271353\n",
      "Train Epoch: 32 [28160/39424 (71%)]\tLoss: 0.208077\n",
      "Train Epoch: 32 [28672/39424 (73%)]\tLoss: 0.235536\n",
      "Train Epoch: 32 [29184/39424 (74%)]\tLoss: 0.229282\n",
      "Train Epoch: 32 [29696/39424 (75%)]\tLoss: 0.219926\n",
      "Train Epoch: 32 [30208/39424 (77%)]\tLoss: 0.242286\n",
      "Train Epoch: 32 [30720/39424 (78%)]\tLoss: 0.256434\n",
      "Train Epoch: 32 [31232/39424 (79%)]\tLoss: 0.312494\n",
      "Train Epoch: 32 [31744/39424 (81%)]\tLoss: 0.253731\n",
      "Train Epoch: 32 [32256/39424 (82%)]\tLoss: 0.215536\n",
      "Train Epoch: 32 [32768/39424 (83%)]\tLoss: 0.236669\n",
      "Train Epoch: 32 [33280/39424 (84%)]\tLoss: 0.249914\n",
      "Train Epoch: 32 [33792/39424 (86%)]\tLoss: 0.196740\n",
      "Train Epoch: 32 [34304/39424 (87%)]\tLoss: 0.177688\n",
      "Train Epoch: 32 [34816/39424 (88%)]\tLoss: 0.206933\n",
      "Train Epoch: 32 [35328/39424 (90%)]\tLoss: 0.242545\n",
      "Train Epoch: 32 [35840/39424 (91%)]\tLoss: 0.202654\n",
      "Train Epoch: 32 [36352/39424 (92%)]\tLoss: 0.206912\n",
      "Train Epoch: 32 [36864/39424 (94%)]\tLoss: 0.200776\n",
      "Train Epoch: 32 [37376/39424 (95%)]\tLoss: 0.236093\n",
      "Train Epoch: 32 [37888/39424 (96%)]\tLoss: 0.254373\n",
      "Train Epoch: 32 [38400/39424 (97%)]\tLoss: 0.191610\n",
      "Train Epoch: 32 [38912/39424 (99%)]\tLoss: 0.249068\n",
      "Average training loss: 0.4318913519382477\n",
      "\n",
      "Test set: Average loss: 8.7297, Accuracy: 24/12630 (0%)\n",
      "\n",
      "tensor([0.0019,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.4032, Accuracy: 11430/12630 (90%)\n",
      "\n",
      "tensor([0.1667, 0.9292, 0.9587, 0.9600, 0.9106, 0.8540, 0.7267, 0.8156, 0.8667,\n",
      "        0.9812, 0.9712, 0.9357, 0.9667, 0.9764, 1.0000, 0.9571, 0.9533, 0.9306,\n",
      "        0.7410, 0.5000, 0.9444, 0.6222, 0.9083, 0.9133, 0.8444, 0.9167, 0.7889,\n",
      "        0.4833, 0.9000, 0.9667, 0.6600, 0.9481, 0.6167, 0.9857, 0.9833, 0.9410,\n",
      "        0.8417, 0.9667, 0.9290, 0.7333, 0.8444, 0.7833, 0.9222])\n",
      "Train backdoor\n",
      "Train Epoch: 32 [0/9728 (0%)]\tLoss: 8.411029\n",
      "Train Epoch: 32 [512/9728 (5%)]\tLoss: 3.068256\n",
      "Train Epoch: 32 [1024/9728 (11%)]\tLoss: 0.137430\n",
      "Train Epoch: 32 [1536/9728 (16%)]\tLoss: 0.054705\n",
      "Train Epoch: 32 [2048/9728 (21%)]\tLoss: 0.030646\n",
      "Train Epoch: 32 [2560/9728 (26%)]\tLoss: 0.025301\n",
      "Train Epoch: 32 [3072/9728 (32%)]\tLoss: 0.017828\n",
      "Train Epoch: 32 [3584/9728 (37%)]\tLoss: 0.026135\n",
      "Train Epoch: 32 [4096/9728 (42%)]\tLoss: 0.014131\n",
      "Train Epoch: 32 [4608/9728 (47%)]\tLoss: 0.010424\n",
      "Train Epoch: 32 [5120/9728 (53%)]\tLoss: 0.010896\n",
      "Train Epoch: 32 [5632/9728 (58%)]\tLoss: 0.009723\n",
      "Train Epoch: 32 [6144/9728 (63%)]\tLoss: 0.007286\n",
      "Train Epoch: 32 [6656/9728 (68%)]\tLoss: 0.009221\n",
      "Train Epoch: 32 [7168/9728 (74%)]\tLoss: 0.010191\n",
      "Train Epoch: 32 [7680/9728 (79%)]\tLoss: 0.005306\n",
      "Train Epoch: 32 [8192/9728 (84%)]\tLoss: 0.004604\n",
      "Train Epoch: 32 [8704/9728 (89%)]\tLoss: 0.007031\n",
      "Train Epoch: 32 [9216/9728 (95%)]\tLoss: 0.004847\n",
      "Average training loss: 0.6244733333587646\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.7743, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 33 [0/39424 (0%)]\tLoss: 9.259502\n",
      "Train Epoch: 33 [512/39424 (1%)]\tLoss: 0.787051\n",
      "Train Epoch: 33 [1024/39424 (3%)]\tLoss: 0.597350\n",
      "Train Epoch: 33 [1536/39424 (4%)]\tLoss: 0.505529\n",
      "Train Epoch: 33 [2048/39424 (5%)]\tLoss: 0.412047\n",
      "Train Epoch: 33 [2560/39424 (6%)]\tLoss: 0.381696\n",
      "Train Epoch: 33 [3072/39424 (8%)]\tLoss: 0.401475\n",
      "Train Epoch: 33 [3584/39424 (9%)]\tLoss: 0.362830\n",
      "Train Epoch: 33 [4096/39424 (10%)]\tLoss: 0.344480\n",
      "Train Epoch: 33 [4608/39424 (12%)]\tLoss: 0.368588\n",
      "Train Epoch: 33 [5120/39424 (13%)]\tLoss: 0.329813\n",
      "Train Epoch: 33 [5632/39424 (14%)]\tLoss: 0.369155\n",
      "Train Epoch: 33 [6144/39424 (16%)]\tLoss: 0.323916\n",
      "Train Epoch: 33 [6656/39424 (17%)]\tLoss: 0.347455\n",
      "Train Epoch: 33 [7168/39424 (18%)]\tLoss: 0.333802\n",
      "Train Epoch: 33 [7680/39424 (19%)]\tLoss: 0.320198\n",
      "Train Epoch: 33 [8192/39424 (21%)]\tLoss: 0.247739\n",
      "Train Epoch: 33 [8704/39424 (22%)]\tLoss: 0.261896\n",
      "Train Epoch: 33 [9216/39424 (23%)]\tLoss: 0.297460\n",
      "Train Epoch: 33 [9728/39424 (25%)]\tLoss: 0.317212\n",
      "Train Epoch: 33 [10240/39424 (26%)]\tLoss: 0.274723\n",
      "Train Epoch: 33 [10752/39424 (27%)]\tLoss: 0.321321\n",
      "Train Epoch: 33 [11264/39424 (29%)]\tLoss: 0.263201\n",
      "Train Epoch: 33 [11776/39424 (30%)]\tLoss: 0.271693\n",
      "Train Epoch: 33 [12288/39424 (31%)]\tLoss: 0.276748\n",
      "Train Epoch: 33 [12800/39424 (32%)]\tLoss: 0.258451\n",
      "Train Epoch: 33 [13312/39424 (34%)]\tLoss: 0.277777\n",
      "Train Epoch: 33 [13824/39424 (35%)]\tLoss: 0.281322\n",
      "Train Epoch: 33 [14336/39424 (36%)]\tLoss: 0.238416\n",
      "Train Epoch: 33 [14848/39424 (38%)]\tLoss: 0.265303\n",
      "Train Epoch: 33 [15360/39424 (39%)]\tLoss: 0.243508\n",
      "Train Epoch: 33 [15872/39424 (40%)]\tLoss: 0.255965\n",
      "Train Epoch: 33 [16384/39424 (42%)]\tLoss: 0.302138\n",
      "Train Epoch: 33 [16896/39424 (43%)]\tLoss: 0.298921\n",
      "Train Epoch: 33 [17408/39424 (44%)]\tLoss: 0.260380\n",
      "Train Epoch: 33 [17920/39424 (45%)]\tLoss: 0.295655\n",
      "Train Epoch: 33 [18432/39424 (47%)]\tLoss: 0.283911\n",
      "Train Epoch: 33 [18944/39424 (48%)]\tLoss: 0.223426\n",
      "Train Epoch: 33 [19456/39424 (49%)]\tLoss: 0.258050\n",
      "Train Epoch: 33 [19968/39424 (51%)]\tLoss: 0.184750\n",
      "Train Epoch: 33 [20480/39424 (52%)]\tLoss: 0.223066\n",
      "Train Epoch: 33 [20992/39424 (53%)]\tLoss: 0.284524\n",
      "Train Epoch: 33 [21504/39424 (55%)]\tLoss: 0.195205\n",
      "Train Epoch: 33 [22016/39424 (56%)]\tLoss: 0.200037\n",
      "Train Epoch: 33 [22528/39424 (57%)]\tLoss: 0.208123\n",
      "Train Epoch: 33 [23040/39424 (58%)]\tLoss: 0.298231\n",
      "Train Epoch: 33 [23552/39424 (60%)]\tLoss: 0.198512\n",
      "Train Epoch: 33 [24064/39424 (61%)]\tLoss: 0.245232\n",
      "Train Epoch: 33 [24576/39424 (62%)]\tLoss: 0.246764\n",
      "Train Epoch: 33 [25088/39424 (64%)]\tLoss: 0.214564\n",
      "Train Epoch: 33 [25600/39424 (65%)]\tLoss: 0.238248\n",
      "Train Epoch: 33 [26112/39424 (66%)]\tLoss: 0.200790\n",
      "Train Epoch: 33 [26624/39424 (68%)]\tLoss: 0.242736\n",
      "Train Epoch: 33 [27136/39424 (69%)]\tLoss: 0.235200\n",
      "Train Epoch: 33 [27648/39424 (70%)]\tLoss: 0.271571\n",
      "Train Epoch: 33 [28160/39424 (71%)]\tLoss: 0.207569\n",
      "Train Epoch: 33 [28672/39424 (73%)]\tLoss: 0.215900\n",
      "Train Epoch: 33 [29184/39424 (74%)]\tLoss: 0.240577\n",
      "Train Epoch: 33 [29696/39424 (75%)]\tLoss: 0.224449\n",
      "Train Epoch: 33 [30208/39424 (77%)]\tLoss: 0.230201\n",
      "Train Epoch: 33 [30720/39424 (78%)]\tLoss: 0.222288\n",
      "Train Epoch: 33 [31232/39424 (79%)]\tLoss: 0.289002\n",
      "Train Epoch: 33 [31744/39424 (81%)]\tLoss: 0.233311\n",
      "Train Epoch: 33 [32256/39424 (82%)]\tLoss: 0.211582\n",
      "Train Epoch: 33 [32768/39424 (83%)]\tLoss: 0.223233\n",
      "Train Epoch: 33 [33280/39424 (84%)]\tLoss: 0.249877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [33792/39424 (86%)]\tLoss: 0.184541\n",
      "Train Epoch: 33 [34304/39424 (87%)]\tLoss: 0.156269\n",
      "Train Epoch: 33 [34816/39424 (88%)]\tLoss: 0.206462\n",
      "Train Epoch: 33 [35328/39424 (90%)]\tLoss: 0.246061\n",
      "Train Epoch: 33 [35840/39424 (91%)]\tLoss: 0.204487\n",
      "Train Epoch: 33 [36352/39424 (92%)]\tLoss: 0.205417\n",
      "Train Epoch: 33 [36864/39424 (94%)]\tLoss: 0.202914\n",
      "Train Epoch: 33 [37376/39424 (95%)]\tLoss: 0.218472\n",
      "Train Epoch: 33 [37888/39424 (96%)]\tLoss: 0.239168\n",
      "Train Epoch: 33 [38400/39424 (97%)]\tLoss: 0.195124\n",
      "Train Epoch: 33 [38912/39424 (99%)]\tLoss: 0.208092\n",
      "Average training loss: 0.39250198006629944\n",
      "\n",
      "Test set: Average loss: 8.6112, Accuracy: 27/12630 (0%)\n",
      "\n",
      "tensor([0.0021,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3978, Accuracy: 11463/12630 (91%)\n",
      "\n",
      "tensor([0.1667, 0.9375, 0.9533, 0.9622, 0.9091, 0.8571, 0.7467, 0.8244, 0.8733,\n",
      "        0.9812, 0.9758, 0.9405, 0.9768, 0.9778, 1.0000, 0.9571, 0.9667, 0.9333,\n",
      "        0.7615, 0.5167, 0.9444, 0.6111, 0.9083, 0.9267, 0.8444, 0.9187, 0.7889,\n",
      "        0.4833, 0.8933, 0.9667, 0.6600, 0.9630, 0.5833, 0.9857, 0.9833, 0.9385,\n",
      "        0.8583, 0.9667, 0.9246, 0.7333, 0.8444, 0.8167, 0.8222])\n",
      "Train backdoor\n",
      "Train Epoch: 33 [0/9728 (0%)]\tLoss: 8.339646\n",
      "Train Epoch: 33 [512/9728 (5%)]\tLoss: 3.012409\n",
      "Train Epoch: 33 [1024/9728 (11%)]\tLoss: 0.164927\n",
      "Train Epoch: 33 [1536/9728 (16%)]\tLoss: 0.061962\n",
      "Train Epoch: 33 [2048/9728 (21%)]\tLoss: 0.028889\n",
      "Train Epoch: 33 [2560/9728 (26%)]\tLoss: 0.026784\n",
      "Train Epoch: 33 [3072/9728 (32%)]\tLoss: 0.016395\n",
      "Train Epoch: 33 [3584/9728 (37%)]\tLoss: 0.023976\n",
      "Train Epoch: 33 [4096/9728 (42%)]\tLoss: 0.010731\n",
      "Train Epoch: 33 [4608/9728 (47%)]\tLoss: 0.008657\n",
      "Train Epoch: 33 [5120/9728 (53%)]\tLoss: 0.008933\n",
      "Train Epoch: 33 [5632/9728 (58%)]\tLoss: 0.007068\n",
      "Train Epoch: 33 [6144/9728 (63%)]\tLoss: 0.008093\n",
      "Train Epoch: 33 [6656/9728 (68%)]\tLoss: 0.008584\n",
      "Train Epoch: 33 [7168/9728 (74%)]\tLoss: 0.008400\n",
      "Train Epoch: 33 [7680/9728 (79%)]\tLoss: 0.004368\n",
      "Train Epoch: 33 [8192/9728 (84%)]\tLoss: 0.003804\n",
      "Train Epoch: 33 [8704/9728 (89%)]\tLoss: 0.005505\n",
      "Train Epoch: 33 [9216/9728 (95%)]\tLoss: 0.006744\n",
      "Average training loss: 0.6187303066253662\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 10.0674, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 34 [0/39424 (0%)]\tLoss: 9.606511\n",
      "Train Epoch: 34 [512/39424 (1%)]\tLoss: 1.160638\n",
      "Train Epoch: 34 [1024/39424 (3%)]\tLoss: 0.910331\n",
      "Train Epoch: 34 [1536/39424 (4%)]\tLoss: 0.803252\n",
      "Train Epoch: 34 [2048/39424 (5%)]\tLoss: 0.645933\n",
      "Train Epoch: 34 [2560/39424 (6%)]\tLoss: 0.537621\n",
      "Train Epoch: 34 [3072/39424 (8%)]\tLoss: 0.533388\n",
      "Train Epoch: 34 [3584/39424 (9%)]\tLoss: 0.424122\n",
      "Train Epoch: 34 [4096/39424 (10%)]\tLoss: 0.390640\n",
      "Train Epoch: 34 [4608/39424 (12%)]\tLoss: 0.367078\n",
      "Train Epoch: 34 [5120/39424 (13%)]\tLoss: 0.344550\n",
      "Train Epoch: 34 [5632/39424 (14%)]\tLoss: 0.331896\n",
      "Train Epoch: 34 [6144/39424 (16%)]\tLoss: 0.318122\n",
      "Train Epoch: 34 [6656/39424 (17%)]\tLoss: 0.355456\n",
      "Train Epoch: 34 [7168/39424 (18%)]\tLoss: 0.333985\n",
      "Train Epoch: 34 [7680/39424 (19%)]\tLoss: 0.297325\n",
      "Train Epoch: 34 [8192/39424 (21%)]\tLoss: 0.257136\n",
      "Train Epoch: 34 [8704/39424 (22%)]\tLoss: 0.267368\n",
      "Train Epoch: 34 [9216/39424 (23%)]\tLoss: 0.284910\n",
      "Train Epoch: 34 [9728/39424 (25%)]\tLoss: 0.299908\n",
      "Train Epoch: 34 [10240/39424 (26%)]\tLoss: 0.245510\n",
      "Train Epoch: 34 [10752/39424 (27%)]\tLoss: 0.327063\n",
      "Train Epoch: 34 [11264/39424 (29%)]\tLoss: 0.243776\n",
      "Train Epoch: 34 [11776/39424 (30%)]\tLoss: 0.258896\n",
      "Train Epoch: 34 [12288/39424 (31%)]\tLoss: 0.266908\n",
      "Train Epoch: 34 [12800/39424 (32%)]\tLoss: 0.246903\n",
      "Train Epoch: 34 [13312/39424 (34%)]\tLoss: 0.280398\n",
      "Train Epoch: 34 [13824/39424 (35%)]\tLoss: 0.276335\n",
      "Train Epoch: 34 [14336/39424 (36%)]\tLoss: 0.249907\n",
      "Train Epoch: 34 [14848/39424 (38%)]\tLoss: 0.268026\n",
      "Train Epoch: 34 [15360/39424 (39%)]\tLoss: 0.248138\n",
      "Train Epoch: 34 [15872/39424 (40%)]\tLoss: 0.259042\n",
      "Train Epoch: 34 [16384/39424 (42%)]\tLoss: 0.254945\n",
      "Train Epoch: 34 [16896/39424 (43%)]\tLoss: 0.272341\n",
      "Train Epoch: 34 [17408/39424 (44%)]\tLoss: 0.247380\n",
      "Train Epoch: 34 [17920/39424 (45%)]\tLoss: 0.287755\n",
      "Train Epoch: 34 [18432/39424 (47%)]\tLoss: 0.253277\n",
      "Train Epoch: 34 [18944/39424 (48%)]\tLoss: 0.228842\n",
      "Train Epoch: 34 [19456/39424 (49%)]\tLoss: 0.233984\n",
      "Train Epoch: 34 [19968/39424 (51%)]\tLoss: 0.190486\n",
      "Train Epoch: 34 [20480/39424 (52%)]\tLoss: 0.220434\n",
      "Train Epoch: 34 [20992/39424 (53%)]\tLoss: 0.293543\n",
      "Train Epoch: 34 [21504/39424 (55%)]\tLoss: 0.185805\n",
      "Train Epoch: 34 [22016/39424 (56%)]\tLoss: 0.198696\n",
      "Train Epoch: 34 [22528/39424 (57%)]\tLoss: 0.192373\n",
      "Train Epoch: 34 [23040/39424 (58%)]\tLoss: 0.272118\n",
      "Train Epoch: 34 [23552/39424 (60%)]\tLoss: 0.212324\n",
      "Train Epoch: 34 [24064/39424 (61%)]\tLoss: 0.243011\n",
      "Train Epoch: 34 [24576/39424 (62%)]\tLoss: 0.230937\n",
      "Train Epoch: 34 [25088/39424 (64%)]\tLoss: 0.204563\n",
      "Train Epoch: 34 [25600/39424 (65%)]\tLoss: 0.231205\n",
      "Train Epoch: 34 [26112/39424 (66%)]\tLoss: 0.180735\n",
      "Train Epoch: 34 [26624/39424 (68%)]\tLoss: 0.237005\n",
      "Train Epoch: 34 [27136/39424 (69%)]\tLoss: 0.242658\n",
      "Train Epoch: 34 [27648/39424 (70%)]\tLoss: 0.270421\n",
      "Train Epoch: 34 [28160/39424 (71%)]\tLoss: 0.190210\n",
      "Train Epoch: 34 [28672/39424 (73%)]\tLoss: 0.202438\n",
      "Train Epoch: 34 [29184/39424 (74%)]\tLoss: 0.220531\n",
      "Train Epoch: 34 [29696/39424 (75%)]\tLoss: 0.213252\n",
      "Train Epoch: 34 [30208/39424 (77%)]\tLoss: 0.237972\n",
      "Train Epoch: 34 [30720/39424 (78%)]\tLoss: 0.226376\n",
      "Train Epoch: 34 [31232/39424 (79%)]\tLoss: 0.280489\n",
      "Train Epoch: 34 [31744/39424 (81%)]\tLoss: 0.236588\n",
      "Train Epoch: 34 [32256/39424 (82%)]\tLoss: 0.218591\n",
      "Train Epoch: 34 [32768/39424 (83%)]\tLoss: 0.202606\n",
      "Train Epoch: 34 [33280/39424 (84%)]\tLoss: 0.220698\n",
      "Train Epoch: 34 [33792/39424 (86%)]\tLoss: 0.177076\n",
      "Train Epoch: 34 [34304/39424 (87%)]\tLoss: 0.156619\n",
      "Train Epoch: 34 [34816/39424 (88%)]\tLoss: 0.191650\n",
      "Train Epoch: 34 [35328/39424 (90%)]\tLoss: 0.233131\n",
      "Train Epoch: 34 [35840/39424 (91%)]\tLoss: 0.205880\n",
      "Train Epoch: 34 [36352/39424 (92%)]\tLoss: 0.197218\n",
      "Train Epoch: 34 [36864/39424 (94%)]\tLoss: 0.176617\n",
      "Train Epoch: 34 [37376/39424 (95%)]\tLoss: 0.216018\n",
      "Train Epoch: 34 [37888/39424 (96%)]\tLoss: 0.224091\n",
      "Train Epoch: 34 [38400/39424 (97%)]\tLoss: 0.190965\n",
      "Train Epoch: 34 [38912/39424 (99%)]\tLoss: 0.205425\n",
      "Average training loss: 0.41104352474212646\n",
      "\n",
      "Test set: Average loss: 8.7015, Accuracy: 25/12630 (0%)\n",
      "\n",
      "tensor([0.0020,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3877, Accuracy: 11482/12630 (91%)\n",
      "\n",
      "tensor([0.1833, 0.9472, 0.9547, 0.9578, 0.9106, 0.8603, 0.7467, 0.8200, 0.8822,\n",
      "        0.9833, 0.9742, 0.9405, 0.9696, 0.9847, 1.0000, 0.9571, 0.9600, 0.9333,\n",
      "        0.7538, 0.5500, 0.9444, 0.6222, 0.9083, 0.9333, 0.8444, 0.9146, 0.7889,\n",
      "        0.5000, 0.8933, 0.9667, 0.6600, 0.9593, 0.6333, 0.9857, 0.9833, 0.9410,\n",
      "        0.8500, 0.9667, 0.9275, 0.7556, 0.8333, 0.8167, 0.8556])\n",
      "Train backdoor\n",
      "Train Epoch: 34 [0/9728 (0%)]\tLoss: 8.487310\n",
      "Train Epoch: 34 [512/9728 (5%)]\tLoss: 3.018365\n",
      "Train Epoch: 34 [1024/9728 (11%)]\tLoss: 0.141212\n",
      "Train Epoch: 34 [1536/9728 (16%)]\tLoss: 0.062336\n",
      "Train Epoch: 34 [2048/9728 (21%)]\tLoss: 0.037149\n",
      "Train Epoch: 34 [2560/9728 (26%)]\tLoss: 0.028719\n",
      "Train Epoch: 34 [3072/9728 (32%)]\tLoss: 0.021752\n",
      "Train Epoch: 34 [3584/9728 (37%)]\tLoss: 0.018569\n",
      "Train Epoch: 34 [4096/9728 (42%)]\tLoss: 0.011077\n",
      "Train Epoch: 34 [4608/9728 (47%)]\tLoss: 0.013429\n",
      "Train Epoch: 34 [5120/9728 (53%)]\tLoss: 0.009801\n",
      "Train Epoch: 34 [5632/9728 (58%)]\tLoss: 0.007589\n",
      "Train Epoch: 34 [6144/9728 (63%)]\tLoss: 0.008387\n",
      "Train Epoch: 34 [6656/9728 (68%)]\tLoss: 0.010787\n",
      "Train Epoch: 34 [7168/9728 (74%)]\tLoss: 0.008522\n",
      "Train Epoch: 34 [7680/9728 (79%)]\tLoss: 0.004359\n",
      "Train Epoch: 34 [8192/9728 (84%)]\tLoss: 0.005039\n",
      "Train Epoch: 34 [8704/9728 (89%)]\tLoss: 0.007093\n",
      "Train Epoch: 34 [9216/9728 (95%)]\tLoss: 0.006199\n",
      "Average training loss: 0.6267206072807312\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.5129, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 35 [0/39424 (0%)]\tLoss: 8.893784\n",
      "Train Epoch: 35 [512/39424 (1%)]\tLoss: 0.752546\n",
      "Train Epoch: 35 [1024/39424 (3%)]\tLoss: 0.560885\n",
      "Train Epoch: 35 [1536/39424 (4%)]\tLoss: 0.507302\n",
      "Train Epoch: 35 [2048/39424 (5%)]\tLoss: 0.395081\n",
      "Train Epoch: 35 [2560/39424 (6%)]\tLoss: 0.339673\n",
      "Train Epoch: 35 [3072/39424 (8%)]\tLoss: 0.414458\n",
      "Train Epoch: 35 [3584/39424 (9%)]\tLoss: 0.347582\n",
      "Train Epoch: 35 [4096/39424 (10%)]\tLoss: 0.328261\n",
      "Train Epoch: 35 [4608/39424 (12%)]\tLoss: 0.317539\n",
      "Train Epoch: 35 [5120/39424 (13%)]\tLoss: 0.310425\n",
      "Train Epoch: 35 [5632/39424 (14%)]\tLoss: 0.330293\n",
      "Train Epoch: 35 [6144/39424 (16%)]\tLoss: 0.295523\n",
      "Train Epoch: 35 [6656/39424 (17%)]\tLoss: 0.303896\n",
      "Train Epoch: 35 [7168/39424 (18%)]\tLoss: 0.305780\n",
      "Train Epoch: 35 [7680/39424 (19%)]\tLoss: 0.298821\n",
      "Train Epoch: 35 [8192/39424 (21%)]\tLoss: 0.257129\n",
      "Train Epoch: 35 [8704/39424 (22%)]\tLoss: 0.257820\n",
      "Train Epoch: 35 [9216/39424 (23%)]\tLoss: 0.300839\n",
      "Train Epoch: 35 [9728/39424 (25%)]\tLoss: 0.289635\n",
      "Train Epoch: 35 [10240/39424 (26%)]\tLoss: 0.254328\n",
      "Train Epoch: 35 [10752/39424 (27%)]\tLoss: 0.315840\n",
      "Train Epoch: 35 [11264/39424 (29%)]\tLoss: 0.246270\n",
      "Train Epoch: 35 [11776/39424 (30%)]\tLoss: 0.242412\n",
      "Train Epoch: 35 [12288/39424 (31%)]\tLoss: 0.265507\n",
      "Train Epoch: 35 [12800/39424 (32%)]\tLoss: 0.256880\n",
      "Train Epoch: 35 [13312/39424 (34%)]\tLoss: 0.255520\n",
      "Train Epoch: 35 [13824/39424 (35%)]\tLoss: 0.258781\n",
      "Train Epoch: 35 [14336/39424 (36%)]\tLoss: 0.222752\n",
      "Train Epoch: 35 [14848/39424 (38%)]\tLoss: 0.241397\n",
      "Train Epoch: 35 [15360/39424 (39%)]\tLoss: 0.251895\n",
      "Train Epoch: 35 [15872/39424 (40%)]\tLoss: 0.251817\n",
      "Train Epoch: 35 [16384/39424 (42%)]\tLoss: 0.255508\n",
      "Train Epoch: 35 [16896/39424 (43%)]\tLoss: 0.296378\n",
      "Train Epoch: 35 [17408/39424 (44%)]\tLoss: 0.247256\n",
      "Train Epoch: 35 [17920/39424 (45%)]\tLoss: 0.266964\n",
      "Train Epoch: 35 [18432/39424 (47%)]\tLoss: 0.245965\n",
      "Train Epoch: 35 [18944/39424 (48%)]\tLoss: 0.213179\n",
      "Train Epoch: 35 [19456/39424 (49%)]\tLoss: 0.251426\n",
      "Train Epoch: 35 [19968/39424 (51%)]\tLoss: 0.182901\n",
      "Train Epoch: 35 [20480/39424 (52%)]\tLoss: 0.219063\n",
      "Train Epoch: 35 [20992/39424 (53%)]\tLoss: 0.237024\n",
      "Train Epoch: 35 [21504/39424 (55%)]\tLoss: 0.175552\n",
      "Train Epoch: 35 [22016/39424 (56%)]\tLoss: 0.203159\n",
      "Train Epoch: 35 [22528/39424 (57%)]\tLoss: 0.187932\n",
      "Train Epoch: 35 [23040/39424 (58%)]\tLoss: 0.251976\n",
      "Train Epoch: 35 [23552/39424 (60%)]\tLoss: 0.196815\n",
      "Train Epoch: 35 [24064/39424 (61%)]\tLoss: 0.237654\n",
      "Train Epoch: 35 [24576/39424 (62%)]\tLoss: 0.237398\n",
      "Train Epoch: 35 [25088/39424 (64%)]\tLoss: 0.199003\n",
      "Train Epoch: 35 [25600/39424 (65%)]\tLoss: 0.215612\n",
      "Train Epoch: 35 [26112/39424 (66%)]\tLoss: 0.195176\n",
      "Train Epoch: 35 [26624/39424 (68%)]\tLoss: 0.244759\n",
      "Train Epoch: 35 [27136/39424 (69%)]\tLoss: 0.233666\n",
      "Train Epoch: 35 [27648/39424 (70%)]\tLoss: 0.253034\n",
      "Train Epoch: 35 [28160/39424 (71%)]\tLoss: 0.198812\n",
      "Train Epoch: 35 [28672/39424 (73%)]\tLoss: 0.215010\n",
      "Train Epoch: 35 [29184/39424 (74%)]\tLoss: 0.211051\n",
      "Train Epoch: 35 [29696/39424 (75%)]\tLoss: 0.185953\n",
      "Train Epoch: 35 [30208/39424 (77%)]\tLoss: 0.206539\n",
      "Train Epoch: 35 [30720/39424 (78%)]\tLoss: 0.234588\n",
      "Train Epoch: 35 [31232/39424 (79%)]\tLoss: 0.263241\n",
      "Train Epoch: 35 [31744/39424 (81%)]\tLoss: 0.226069\n",
      "Train Epoch: 35 [32256/39424 (82%)]\tLoss: 0.193041\n",
      "Train Epoch: 35 [32768/39424 (83%)]\tLoss: 0.192914\n",
      "Train Epoch: 35 [33280/39424 (84%)]\tLoss: 0.217420\n",
      "Train Epoch: 35 [33792/39424 (86%)]\tLoss: 0.159203\n",
      "Train Epoch: 35 [34304/39424 (87%)]\tLoss: 0.139480\n",
      "Train Epoch: 35 [34816/39424 (88%)]\tLoss: 0.175525\n",
      "Train Epoch: 35 [35328/39424 (90%)]\tLoss: 0.225403\n",
      "Train Epoch: 35 [35840/39424 (91%)]\tLoss: 0.172067\n",
      "Train Epoch: 35 [36352/39424 (92%)]\tLoss: 0.194252\n",
      "Train Epoch: 35 [36864/39424 (94%)]\tLoss: 0.191851\n",
      "Train Epoch: 35 [37376/39424 (95%)]\tLoss: 0.212075\n",
      "Train Epoch: 35 [37888/39424 (96%)]\tLoss: 0.203389\n",
      "Train Epoch: 35 [38400/39424 (97%)]\tLoss: 0.184834\n",
      "Train Epoch: 35 [38912/39424 (99%)]\tLoss: 0.193032\n",
      "Average training loss: 0.3703092038631439\n",
      "\n",
      "Test set: Average loss: 8.5805, Accuracy: 37/12630 (0%)\n",
      "\n",
      "tensor([0.0029,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3794, Accuracy: 11511/12630 (91%)\n",
      "\n",
      "tensor([0.1833, 0.9403, 0.9667, 0.9511, 0.9106, 0.8714, 0.7600, 0.8200, 0.8844,\n",
      "        0.9854, 0.9818, 0.9429, 0.9739, 0.9806, 1.0000, 0.9571, 0.9533, 0.9333,\n",
      "        0.7385, 0.5833, 0.9444, 0.6222, 0.9167, 0.9333, 0.8444, 0.9208, 0.7944,\n",
      "        0.4833, 0.9067, 0.9667, 0.6467, 0.9630, 0.6167, 0.9857, 0.9833, 0.9564,\n",
      "        0.8667, 0.9667, 0.9290, 0.7444, 0.8444, 0.8167, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 35 [0/9728 (0%)]\tLoss: 8.411068\n",
      "Train Epoch: 35 [512/9728 (5%)]\tLoss: 2.986404\n",
      "Train Epoch: 35 [1024/9728 (11%)]\tLoss: 0.150835\n",
      "Train Epoch: 35 [1536/9728 (16%)]\tLoss: 0.073934\n",
      "Train Epoch: 35 [2048/9728 (21%)]\tLoss: 0.028237\n",
      "Train Epoch: 35 [2560/9728 (26%)]\tLoss: 0.028445\n",
      "Train Epoch: 35 [3072/9728 (32%)]\tLoss: 0.022947\n",
      "Train Epoch: 35 [3584/9728 (37%)]\tLoss: 0.023979\n",
      "Train Epoch: 35 [4096/9728 (42%)]\tLoss: 0.013818\n",
      "Train Epoch: 35 [4608/9728 (47%)]\tLoss: 0.010413\n",
      "Train Epoch: 35 [5120/9728 (53%)]\tLoss: 0.012588\n",
      "Train Epoch: 35 [5632/9728 (58%)]\tLoss: 0.007464\n",
      "Train Epoch: 35 [6144/9728 (63%)]\tLoss: 0.010148\n",
      "Train Epoch: 35 [6656/9728 (68%)]\tLoss: 0.010960\n",
      "Train Epoch: 35 [7168/9728 (74%)]\tLoss: 0.011613\n",
      "Train Epoch: 35 [7680/9728 (79%)]\tLoss: 0.004315\n",
      "Train Epoch: 35 [8192/9728 (84%)]\tLoss: 0.003963\n",
      "Train Epoch: 35 [8704/9728 (89%)]\tLoss: 0.007584\n",
      "Train Epoch: 35 [9216/9728 (95%)]\tLoss: 0.007062\n",
      "Average training loss: 0.6224093437194824\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.6071, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 36 [0/39424 (0%)]\tLoss: 8.862454\n",
      "Train Epoch: 36 [512/39424 (1%)]\tLoss: 0.895321\n",
      "Train Epoch: 36 [1024/39424 (3%)]\tLoss: 0.719817\n",
      "Train Epoch: 36 [1536/39424 (4%)]\tLoss: 0.636108\n",
      "Train Epoch: 36 [2048/39424 (5%)]\tLoss: 0.497580\n",
      "Train Epoch: 36 [2560/39424 (6%)]\tLoss: 0.411885\n",
      "Train Epoch: 36 [3072/39424 (8%)]\tLoss: 0.421125\n",
      "Train Epoch: 36 [3584/39424 (9%)]\tLoss: 0.342364\n",
      "Train Epoch: 36 [4096/39424 (10%)]\tLoss: 0.313863\n",
      "Train Epoch: 36 [4608/39424 (12%)]\tLoss: 0.326407\n",
      "Train Epoch: 36 [5120/39424 (13%)]\tLoss: 0.306729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [5632/39424 (14%)]\tLoss: 0.313883\n",
      "Train Epoch: 36 [6144/39424 (16%)]\tLoss: 0.284144\n",
      "Train Epoch: 36 [6656/39424 (17%)]\tLoss: 0.301286\n",
      "Train Epoch: 36 [7168/39424 (18%)]\tLoss: 0.299278\n",
      "Train Epoch: 36 [7680/39424 (19%)]\tLoss: 0.279708\n",
      "Train Epoch: 36 [8192/39424 (21%)]\tLoss: 0.240048\n",
      "Train Epoch: 36 [8704/39424 (22%)]\tLoss: 0.244026\n",
      "Train Epoch: 36 [9216/39424 (23%)]\tLoss: 0.287626\n",
      "Train Epoch: 36 [9728/39424 (25%)]\tLoss: 0.279694\n",
      "Train Epoch: 36 [10240/39424 (26%)]\tLoss: 0.247997\n",
      "Train Epoch: 36 [10752/39424 (27%)]\tLoss: 0.299268\n",
      "Train Epoch: 36 [11264/39424 (29%)]\tLoss: 0.253306\n",
      "Train Epoch: 36 [11776/39424 (30%)]\tLoss: 0.246559\n",
      "Train Epoch: 36 [12288/39424 (31%)]\tLoss: 0.251920\n",
      "Train Epoch: 36 [12800/39424 (32%)]\tLoss: 0.230127\n",
      "Train Epoch: 36 [13312/39424 (34%)]\tLoss: 0.244038\n",
      "Train Epoch: 36 [13824/39424 (35%)]\tLoss: 0.255513\n",
      "Train Epoch: 36 [14336/39424 (36%)]\tLoss: 0.222463\n",
      "Train Epoch: 36 [14848/39424 (38%)]\tLoss: 0.258484\n",
      "Train Epoch: 36 [15360/39424 (39%)]\tLoss: 0.244106\n",
      "Train Epoch: 36 [15872/39424 (40%)]\tLoss: 0.239257\n",
      "Train Epoch: 36 [16384/39424 (42%)]\tLoss: 0.242564\n",
      "Train Epoch: 36 [16896/39424 (43%)]\tLoss: 0.265099\n",
      "Train Epoch: 36 [17408/39424 (44%)]\tLoss: 0.241767\n",
      "Train Epoch: 36 [17920/39424 (45%)]\tLoss: 0.283616\n",
      "Train Epoch: 36 [18432/39424 (47%)]\tLoss: 0.246323\n",
      "Train Epoch: 36 [18944/39424 (48%)]\tLoss: 0.195013\n",
      "Train Epoch: 36 [19456/39424 (49%)]\tLoss: 0.243859\n",
      "Train Epoch: 36 [19968/39424 (51%)]\tLoss: 0.160394\n",
      "Train Epoch: 36 [20480/39424 (52%)]\tLoss: 0.205298\n",
      "Train Epoch: 36 [20992/39424 (53%)]\tLoss: 0.249621\n",
      "Train Epoch: 36 [21504/39424 (55%)]\tLoss: 0.164921\n",
      "Train Epoch: 36 [22016/39424 (56%)]\tLoss: 0.179808\n",
      "Train Epoch: 36 [22528/39424 (57%)]\tLoss: 0.181892\n",
      "Train Epoch: 36 [23040/39424 (58%)]\tLoss: 0.257350\n",
      "Train Epoch: 36 [23552/39424 (60%)]\tLoss: 0.168380\n",
      "Train Epoch: 36 [24064/39424 (61%)]\tLoss: 0.215452\n",
      "Train Epoch: 36 [24576/39424 (62%)]\tLoss: 0.211908\n",
      "Train Epoch: 36 [25088/39424 (64%)]\tLoss: 0.201437\n",
      "Train Epoch: 36 [25600/39424 (65%)]\tLoss: 0.208612\n",
      "Train Epoch: 36 [26112/39424 (66%)]\tLoss: 0.192359\n",
      "Train Epoch: 36 [26624/39424 (68%)]\tLoss: 0.233499\n",
      "Train Epoch: 36 [27136/39424 (69%)]\tLoss: 0.223167\n",
      "Train Epoch: 36 [27648/39424 (70%)]\tLoss: 0.232790\n",
      "Train Epoch: 36 [28160/39424 (71%)]\tLoss: 0.184324\n",
      "Train Epoch: 36 [28672/39424 (73%)]\tLoss: 0.193505\n",
      "Train Epoch: 36 [29184/39424 (74%)]\tLoss: 0.208279\n",
      "Train Epoch: 36 [29696/39424 (75%)]\tLoss: 0.165790\n",
      "Train Epoch: 36 [30208/39424 (77%)]\tLoss: 0.193441\n",
      "Train Epoch: 36 [30720/39424 (78%)]\tLoss: 0.210503\n",
      "Train Epoch: 36 [31232/39424 (79%)]\tLoss: 0.259059\n",
      "Train Epoch: 36 [31744/39424 (81%)]\tLoss: 0.226417\n",
      "Train Epoch: 36 [32256/39424 (82%)]\tLoss: 0.183270\n",
      "Train Epoch: 36 [32768/39424 (83%)]\tLoss: 0.203090\n",
      "Train Epoch: 36 [33280/39424 (84%)]\tLoss: 0.217560\n",
      "Train Epoch: 36 [33792/39424 (86%)]\tLoss: 0.153480\n",
      "Train Epoch: 36 [34304/39424 (87%)]\tLoss: 0.144188\n",
      "Train Epoch: 36 [34816/39424 (88%)]\tLoss: 0.202427\n",
      "Train Epoch: 36 [35328/39424 (90%)]\tLoss: 0.213083\n",
      "Train Epoch: 36 [35840/39424 (91%)]\tLoss: 0.176862\n",
      "Train Epoch: 36 [36352/39424 (92%)]\tLoss: 0.180586\n",
      "Train Epoch: 36 [36864/39424 (94%)]\tLoss: 0.167463\n",
      "Train Epoch: 36 [37376/39424 (95%)]\tLoss: 0.210748\n",
      "Train Epoch: 36 [37888/39424 (96%)]\tLoss: 0.206740\n",
      "Train Epoch: 36 [38400/39424 (97%)]\tLoss: 0.191461\n",
      "Train Epoch: 36 [38912/39424 (99%)]\tLoss: 0.186010\n",
      "Average training loss: 0.37064677476882935\n",
      "\n",
      "Test set: Average loss: 8.5388, Accuracy: 34/12630 (0%)\n",
      "\n",
      "tensor([0.0027,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3706, Accuracy: 11544/12630 (91%)\n",
      "\n",
      "tensor([0.2000, 0.9417, 0.9640, 0.9556, 0.9136, 0.8619, 0.7600, 0.8356, 0.8956,\n",
      "        0.9875, 0.9788, 0.9429, 0.9768, 0.9861, 1.0000, 0.9667, 0.9600, 0.9333,\n",
      "        0.7564, 0.5667, 0.9556, 0.6222, 0.9167, 0.9267, 0.8556, 0.9208, 0.7889,\n",
      "        0.5000, 0.9067, 0.9667, 0.6933, 0.9704, 0.6167, 0.9857, 0.9833, 0.9564,\n",
      "        0.8667, 0.9833, 0.9304, 0.7556, 0.8333, 0.8167, 0.8556])\n",
      "Train backdoor\n",
      "Train Epoch: 36 [0/9728 (0%)]\tLoss: 8.391300\n",
      "Train Epoch: 36 [512/9728 (5%)]\tLoss: 2.828644\n",
      "Train Epoch: 36 [1024/9728 (11%)]\tLoss: 0.156037\n",
      "Train Epoch: 36 [1536/9728 (16%)]\tLoss: 0.052757\n",
      "Train Epoch: 36 [2048/9728 (21%)]\tLoss: 0.032836\n",
      "Train Epoch: 36 [2560/9728 (26%)]\tLoss: 0.027106\n",
      "Train Epoch: 36 [3072/9728 (32%)]\tLoss: 0.023434\n",
      "Train Epoch: 36 [3584/9728 (37%)]\tLoss: 0.023657\n",
      "Train Epoch: 36 [4096/9728 (42%)]\tLoss: 0.011650\n",
      "Train Epoch: 36 [4608/9728 (47%)]\tLoss: 0.011205\n",
      "Train Epoch: 36 [5120/9728 (53%)]\tLoss: 0.010301\n",
      "Train Epoch: 36 [5632/9728 (58%)]\tLoss: 0.007381\n",
      "Train Epoch: 36 [6144/9728 (63%)]\tLoss: 0.007802\n",
      "Train Epoch: 36 [6656/9728 (68%)]\tLoss: 0.012255\n",
      "Train Epoch: 36 [7168/9728 (74%)]\tLoss: 0.007939\n",
      "Train Epoch: 36 [7680/9728 (79%)]\tLoss: 0.005683\n",
      "Train Epoch: 36 [8192/9728 (84%)]\tLoss: 0.004417\n",
      "Train Epoch: 36 [8704/9728 (89%)]\tLoss: 0.006735\n",
      "Train Epoch: 36 [9216/9728 (95%)]\tLoss: 0.006763\n",
      "Average training loss: 0.611994743347168\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.3131, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 37 [0/39424 (0%)]\tLoss: 8.666729\n",
      "Train Epoch: 37 [512/39424 (1%)]\tLoss: 0.703079\n",
      "Train Epoch: 37 [1024/39424 (3%)]\tLoss: 0.523615\n",
      "Train Epoch: 37 [1536/39424 (4%)]\tLoss: 0.467972\n",
      "Train Epoch: 37 [2048/39424 (5%)]\tLoss: 0.375984\n",
      "Train Epoch: 37 [2560/39424 (6%)]\tLoss: 0.321456\n",
      "Train Epoch: 37 [3072/39424 (8%)]\tLoss: 0.387020\n",
      "Train Epoch: 37 [3584/39424 (9%)]\tLoss: 0.323250\n",
      "Train Epoch: 37 [4096/39424 (10%)]\tLoss: 0.301581\n",
      "Train Epoch: 37 [4608/39424 (12%)]\tLoss: 0.308273\n",
      "Train Epoch: 37 [5120/39424 (13%)]\tLoss: 0.286679\n",
      "Train Epoch: 37 [5632/39424 (14%)]\tLoss: 0.292031\n",
      "Train Epoch: 37 [6144/39424 (16%)]\tLoss: 0.264163\n",
      "Train Epoch: 37 [6656/39424 (17%)]\tLoss: 0.299868\n",
      "Train Epoch: 37 [7168/39424 (18%)]\tLoss: 0.283023\n",
      "Train Epoch: 37 [7680/39424 (19%)]\tLoss: 0.279984\n",
      "Train Epoch: 37 [8192/39424 (21%)]\tLoss: 0.228181\n",
      "Train Epoch: 37 [8704/39424 (22%)]\tLoss: 0.240922\n",
      "Train Epoch: 37 [9216/39424 (23%)]\tLoss: 0.277915\n",
      "Train Epoch: 37 [9728/39424 (25%)]\tLoss: 0.270365\n",
      "Train Epoch: 37 [10240/39424 (26%)]\tLoss: 0.229854\n",
      "Train Epoch: 37 [10752/39424 (27%)]\tLoss: 0.293706\n",
      "Train Epoch: 37 [11264/39424 (29%)]\tLoss: 0.240408\n",
      "Train Epoch: 37 [11776/39424 (30%)]\tLoss: 0.232481\n",
      "Train Epoch: 37 [12288/39424 (31%)]\tLoss: 0.245255\n",
      "Train Epoch: 37 [12800/39424 (32%)]\tLoss: 0.213549\n",
      "Train Epoch: 37 [13312/39424 (34%)]\tLoss: 0.233792\n",
      "Train Epoch: 37 [13824/39424 (35%)]\tLoss: 0.239943\n",
      "Train Epoch: 37 [14336/39424 (36%)]\tLoss: 0.219015\n",
      "Train Epoch: 37 [14848/39424 (38%)]\tLoss: 0.227002\n",
      "Train Epoch: 37 [15360/39424 (39%)]\tLoss: 0.222224\n",
      "Train Epoch: 37 [15872/39424 (40%)]\tLoss: 0.240698\n",
      "Train Epoch: 37 [16384/39424 (42%)]\tLoss: 0.232006\n",
      "Train Epoch: 37 [16896/39424 (43%)]\tLoss: 0.276658\n",
      "Train Epoch: 37 [17408/39424 (44%)]\tLoss: 0.225682\n",
      "Train Epoch: 37 [17920/39424 (45%)]\tLoss: 0.270182\n",
      "Train Epoch: 37 [18432/39424 (47%)]\tLoss: 0.258014\n",
      "Train Epoch: 37 [18944/39424 (48%)]\tLoss: 0.190562\n",
      "Train Epoch: 37 [19456/39424 (49%)]\tLoss: 0.224465\n",
      "Train Epoch: 37 [19968/39424 (51%)]\tLoss: 0.164509\n",
      "Train Epoch: 37 [20480/39424 (52%)]\tLoss: 0.183643\n",
      "Train Epoch: 37 [20992/39424 (53%)]\tLoss: 0.246527\n",
      "Train Epoch: 37 [21504/39424 (55%)]\tLoss: 0.165034\n",
      "Train Epoch: 37 [22016/39424 (56%)]\tLoss: 0.176067\n",
      "Train Epoch: 37 [22528/39424 (57%)]\tLoss: 0.185495\n",
      "Train Epoch: 37 [23040/39424 (58%)]\tLoss: 0.231760\n",
      "Train Epoch: 37 [23552/39424 (60%)]\tLoss: 0.175642\n",
      "Train Epoch: 37 [24064/39424 (61%)]\tLoss: 0.202064\n",
      "Train Epoch: 37 [24576/39424 (62%)]\tLoss: 0.214517\n",
      "Train Epoch: 37 [25088/39424 (64%)]\tLoss: 0.190735\n",
      "Train Epoch: 37 [25600/39424 (65%)]\tLoss: 0.205500\n",
      "Train Epoch: 37 [26112/39424 (66%)]\tLoss: 0.169450\n",
      "Train Epoch: 37 [26624/39424 (68%)]\tLoss: 0.217017\n",
      "Train Epoch: 37 [27136/39424 (69%)]\tLoss: 0.222412\n",
      "Train Epoch: 37 [27648/39424 (70%)]\tLoss: 0.225944\n",
      "Train Epoch: 37 [28160/39424 (71%)]\tLoss: 0.163412\n",
      "Train Epoch: 37 [28672/39424 (73%)]\tLoss: 0.190504\n",
      "Train Epoch: 37 [29184/39424 (74%)]\tLoss: 0.186723\n",
      "Train Epoch: 37 [29696/39424 (75%)]\tLoss: 0.194926\n",
      "Train Epoch: 37 [30208/39424 (77%)]\tLoss: 0.203765\n",
      "Train Epoch: 37 [30720/39424 (78%)]\tLoss: 0.220114\n",
      "Train Epoch: 37 [31232/39424 (79%)]\tLoss: 0.246388\n",
      "Train Epoch: 37 [31744/39424 (81%)]\tLoss: 0.211780\n",
      "Train Epoch: 37 [32256/39424 (82%)]\tLoss: 0.174616\n",
      "Train Epoch: 37 [32768/39424 (83%)]\tLoss: 0.176768\n",
      "Train Epoch: 37 [33280/39424 (84%)]\tLoss: 0.212403\n",
      "Train Epoch: 37 [33792/39424 (86%)]\tLoss: 0.155547\n",
      "Train Epoch: 37 [34304/39424 (87%)]\tLoss: 0.136114\n",
      "Train Epoch: 37 [34816/39424 (88%)]\tLoss: 0.183397\n",
      "Train Epoch: 37 [35328/39424 (90%)]\tLoss: 0.187133\n",
      "Train Epoch: 37 [35840/39424 (91%)]\tLoss: 0.162038\n",
      "Train Epoch: 37 [36352/39424 (92%)]\tLoss: 0.183555\n",
      "Train Epoch: 37 [36864/39424 (94%)]\tLoss: 0.165067\n",
      "Train Epoch: 37 [37376/39424 (95%)]\tLoss: 0.218150\n",
      "Train Epoch: 37 [37888/39424 (96%)]\tLoss: 0.193550\n",
      "Train Epoch: 37 [38400/39424 (97%)]\tLoss: 0.168012\n",
      "Train Epoch: 37 [38912/39424 (99%)]\tLoss: 0.188334\n",
      "Average training loss: 0.34956100583076477\n",
      "\n",
      "Test set: Average loss: 8.4232, Accuracy: 37/12630 (0%)\n",
      "\n",
      "tensor([0.0029,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3647, Accuracy: 11551/12630 (91%)\n",
      "\n",
      "tensor([0.1833, 0.9403, 0.9653, 0.9578, 0.9152, 0.8651, 0.7600, 0.8222, 0.9022,\n",
      "        0.9854, 0.9788, 0.9405, 0.9754, 0.9833, 1.0000, 0.9714, 0.9667, 0.9333,\n",
      "        0.7667, 0.5833, 0.9556, 0.6333, 0.9167, 0.9200, 0.8556, 0.9229, 0.7944,\n",
      "        0.5000, 0.9133, 0.9667, 0.6800, 0.9667, 0.6167, 0.9857, 0.9833, 0.9564,\n",
      "        0.8667, 0.9833, 0.9319, 0.7556, 0.8444, 0.8167, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 37 [0/9728 (0%)]\tLoss: 8.227422\n",
      "Train Epoch: 37 [512/9728 (5%)]\tLoss: 2.797474\n",
      "Train Epoch: 37 [1024/9728 (11%)]\tLoss: 0.135766\n",
      "Train Epoch: 37 [1536/9728 (16%)]\tLoss: 0.067463\n",
      "Train Epoch: 37 [2048/9728 (21%)]\tLoss: 0.028798\n",
      "Train Epoch: 37 [2560/9728 (26%)]\tLoss: 0.028290\n",
      "Train Epoch: 37 [3072/9728 (32%)]\tLoss: 0.027566\n",
      "Train Epoch: 37 [3584/9728 (37%)]\tLoss: 0.022432\n",
      "Train Epoch: 37 [4096/9728 (42%)]\tLoss: 0.015144\n",
      "Train Epoch: 37 [4608/9728 (47%)]\tLoss: 0.008773\n",
      "Train Epoch: 37 [5120/9728 (53%)]\tLoss: 0.010843\n",
      "Train Epoch: 37 [5632/9728 (58%)]\tLoss: 0.006669\n",
      "Train Epoch: 37 [6144/9728 (63%)]\tLoss: 0.009157\n",
      "Train Epoch: 37 [6656/9728 (68%)]\tLoss: 0.008888\n",
      "Train Epoch: 37 [7168/9728 (74%)]\tLoss: 0.008184\n",
      "Train Epoch: 37 [7680/9728 (79%)]\tLoss: 0.005304\n",
      "Train Epoch: 37 [8192/9728 (84%)]\tLoss: 0.005508\n",
      "Train Epoch: 37 [8704/9728 (89%)]\tLoss: 0.007368\n",
      "Train Epoch: 37 [9216/9728 (95%)]\tLoss: 0.006289\n",
      "Average training loss: 0.6014388203620911\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.4342, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 38 [0/39424 (0%)]\tLoss: 8.705186\n",
      "Train Epoch: 38 [512/39424 (1%)]\tLoss: 0.854694\n",
      "Train Epoch: 38 [1024/39424 (3%)]\tLoss: 0.680603\n",
      "Train Epoch: 38 [1536/39424 (4%)]\tLoss: 0.616948\n",
      "Train Epoch: 38 [2048/39424 (5%)]\tLoss: 0.462165\n",
      "Train Epoch: 38 [2560/39424 (6%)]\tLoss: 0.392344\n",
      "Train Epoch: 38 [3072/39424 (8%)]\tLoss: 0.406999\n",
      "Train Epoch: 38 [3584/39424 (9%)]\tLoss: 0.334446\n",
      "Train Epoch: 38 [4096/39424 (10%)]\tLoss: 0.319458\n",
      "Train Epoch: 38 [4608/39424 (12%)]\tLoss: 0.306981\n",
      "Train Epoch: 38 [5120/39424 (13%)]\tLoss: 0.276869\n",
      "Train Epoch: 38 [5632/39424 (14%)]\tLoss: 0.297320\n",
      "Train Epoch: 38 [6144/39424 (16%)]\tLoss: 0.277093\n",
      "Train Epoch: 38 [6656/39424 (17%)]\tLoss: 0.301649\n",
      "Train Epoch: 38 [7168/39424 (18%)]\tLoss: 0.282590\n",
      "Train Epoch: 38 [7680/39424 (19%)]\tLoss: 0.266628\n",
      "Train Epoch: 38 [8192/39424 (21%)]\tLoss: 0.216509\n",
      "Train Epoch: 38 [8704/39424 (22%)]\tLoss: 0.247538\n",
      "Train Epoch: 38 [9216/39424 (23%)]\tLoss: 0.286189\n",
      "Train Epoch: 38 [9728/39424 (25%)]\tLoss: 0.266809\n",
      "Train Epoch: 38 [10240/39424 (26%)]\tLoss: 0.215887\n",
      "Train Epoch: 38 [10752/39424 (27%)]\tLoss: 0.279770\n",
      "Train Epoch: 38 [11264/39424 (29%)]\tLoss: 0.231271\n",
      "Train Epoch: 38 [11776/39424 (30%)]\tLoss: 0.223685\n",
      "Train Epoch: 38 [12288/39424 (31%)]\tLoss: 0.228328\n",
      "Train Epoch: 38 [12800/39424 (32%)]\tLoss: 0.211590\n",
      "Train Epoch: 38 [13312/39424 (34%)]\tLoss: 0.248532\n",
      "Train Epoch: 38 [13824/39424 (35%)]\tLoss: 0.229020\n",
      "Train Epoch: 38 [14336/39424 (36%)]\tLoss: 0.209724\n",
      "Train Epoch: 38 [14848/39424 (38%)]\tLoss: 0.224712\n",
      "Train Epoch: 38 [15360/39424 (39%)]\tLoss: 0.198199\n",
      "Train Epoch: 38 [15872/39424 (40%)]\tLoss: 0.221983\n",
      "Train Epoch: 38 [16384/39424 (42%)]\tLoss: 0.222860\n",
      "Train Epoch: 38 [16896/39424 (43%)]\tLoss: 0.255613\n",
      "Train Epoch: 38 [17408/39424 (44%)]\tLoss: 0.216006\n",
      "Train Epoch: 38 [17920/39424 (45%)]\tLoss: 0.277377\n",
      "Train Epoch: 38 [18432/39424 (47%)]\tLoss: 0.224882\n",
      "Train Epoch: 38 [18944/39424 (48%)]\tLoss: 0.177111\n",
      "Train Epoch: 38 [19456/39424 (49%)]\tLoss: 0.222496\n",
      "Train Epoch: 38 [19968/39424 (51%)]\tLoss: 0.147332\n",
      "Train Epoch: 38 [20480/39424 (52%)]\tLoss: 0.196141\n",
      "Train Epoch: 38 [20992/39424 (53%)]\tLoss: 0.237108\n",
      "Train Epoch: 38 [21504/39424 (55%)]\tLoss: 0.151331\n",
      "Train Epoch: 38 [22016/39424 (56%)]\tLoss: 0.185042\n",
      "Train Epoch: 38 [22528/39424 (57%)]\tLoss: 0.164763\n",
      "Train Epoch: 38 [23040/39424 (58%)]\tLoss: 0.238272\n",
      "Train Epoch: 38 [23552/39424 (60%)]\tLoss: 0.173616\n",
      "Train Epoch: 38 [24064/39424 (61%)]\tLoss: 0.196083\n",
      "Train Epoch: 38 [24576/39424 (62%)]\tLoss: 0.199660\n",
      "Train Epoch: 38 [25088/39424 (64%)]\tLoss: 0.179222\n",
      "Train Epoch: 38 [25600/39424 (65%)]\tLoss: 0.211701\n",
      "Train Epoch: 38 [26112/39424 (66%)]\tLoss: 0.173255\n",
      "Train Epoch: 38 [26624/39424 (68%)]\tLoss: 0.202158\n",
      "Train Epoch: 38 [27136/39424 (69%)]\tLoss: 0.205714\n",
      "Train Epoch: 38 [27648/39424 (70%)]\tLoss: 0.198244\n",
      "Train Epoch: 38 [28160/39424 (71%)]\tLoss: 0.167979\n",
      "Train Epoch: 38 [28672/39424 (73%)]\tLoss: 0.177526\n",
      "Train Epoch: 38 [29184/39424 (74%)]\tLoss: 0.185282\n",
      "Train Epoch: 38 [29696/39424 (75%)]\tLoss: 0.185818\n",
      "Train Epoch: 38 [30208/39424 (77%)]\tLoss: 0.190261\n",
      "Train Epoch: 38 [30720/39424 (78%)]\tLoss: 0.209047\n",
      "Train Epoch: 38 [31232/39424 (79%)]\tLoss: 0.229297\n",
      "Train Epoch: 38 [31744/39424 (81%)]\tLoss: 0.214968\n",
      "Train Epoch: 38 [32256/39424 (82%)]\tLoss: 0.172621\n",
      "Train Epoch: 38 [32768/39424 (83%)]\tLoss: 0.191402\n",
      "Train Epoch: 38 [33280/39424 (84%)]\tLoss: 0.194147\n",
      "Train Epoch: 38 [33792/39424 (86%)]\tLoss: 0.156361\n",
      "Train Epoch: 38 [34304/39424 (87%)]\tLoss: 0.118303\n",
      "Train Epoch: 38 [34816/39424 (88%)]\tLoss: 0.168525\n",
      "Train Epoch: 38 [35328/39424 (90%)]\tLoss: 0.186219\n",
      "Train Epoch: 38 [35840/39424 (91%)]\tLoss: 0.148474\n",
      "Train Epoch: 38 [36352/39424 (92%)]\tLoss: 0.175803\n",
      "Train Epoch: 38 [36864/39424 (94%)]\tLoss: 0.157394\n",
      "Train Epoch: 38 [37376/39424 (95%)]\tLoss: 0.181523\n",
      "Train Epoch: 38 [37888/39424 (96%)]\tLoss: 0.181550\n",
      "Train Epoch: 38 [38400/39424 (97%)]\tLoss: 0.168297\n",
      "Train Epoch: 38 [38912/39424 (99%)]\tLoss: 0.182590\n",
      "Average training loss: 0.35222190618515015\n",
      "\n",
      "Test set: Average loss: 8.4191, Accuracy: 46/12630 (0%)\n",
      "\n",
      "tensor([0.0036,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3563, Accuracy: 11587/12630 (92%)\n",
      "\n",
      "tensor([0.2167, 0.9375, 0.9720, 0.9578, 0.9152, 0.8698, 0.7667, 0.8311, 0.9022,\n",
      "        0.9875, 0.9833, 0.9381, 0.9783, 0.9861, 1.0000, 0.9714, 0.9667, 0.9333,\n",
      "        0.7795, 0.6333, 0.9667, 0.6222, 0.9167, 0.9333, 0.8556, 0.9229, 0.7889,\n",
      "        0.5000, 0.9267, 0.9667, 0.7133, 0.9667, 0.6167, 0.9857, 0.9833, 0.9538,\n",
      "        0.8667, 0.9833, 0.9333, 0.7556, 0.8444, 0.8167, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 38 [0/9728 (0%)]\tLoss: 8.198919\n",
      "Train Epoch: 38 [512/9728 (5%)]\tLoss: 2.801678\n",
      "Train Epoch: 38 [1024/9728 (11%)]\tLoss: 0.126180\n",
      "Train Epoch: 38 [1536/9728 (16%)]\tLoss: 0.062070\n",
      "Train Epoch: 38 [2048/9728 (21%)]\tLoss: 0.027172\n",
      "Train Epoch: 38 [2560/9728 (26%)]\tLoss: 0.023751\n",
      "Train Epoch: 38 [3072/9728 (32%)]\tLoss: 0.020640\n",
      "Train Epoch: 38 [3584/9728 (37%)]\tLoss: 0.026617\n",
      "Train Epoch: 38 [4096/9728 (42%)]\tLoss: 0.015566\n",
      "Train Epoch: 38 [4608/9728 (47%)]\tLoss: 0.012523\n",
      "Train Epoch: 38 [5120/9728 (53%)]\tLoss: 0.008102\n",
      "Train Epoch: 38 [5632/9728 (58%)]\tLoss: 0.008833\n",
      "Train Epoch: 38 [6144/9728 (63%)]\tLoss: 0.010024\n",
      "Train Epoch: 38 [6656/9728 (68%)]\tLoss: 0.010562\n",
      "Train Epoch: 38 [7168/9728 (74%)]\tLoss: 0.009816\n",
      "Train Epoch: 38 [7680/9728 (79%)]\tLoss: 0.005150\n",
      "Train Epoch: 38 [8192/9728 (84%)]\tLoss: 0.004904\n",
      "Train Epoch: 38 [8704/9728 (89%)]\tLoss: 0.008072\n",
      "Train Epoch: 38 [9216/9728 (95%)]\tLoss: 0.004793\n",
      "Average training loss: 0.599230170249939\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.1626, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 39 [0/39424 (0%)]\tLoss: 8.397867\n",
      "Train Epoch: 39 [512/39424 (1%)]\tLoss: 0.643075\n",
      "Train Epoch: 39 [1024/39424 (3%)]\tLoss: 0.489988\n",
      "Train Epoch: 39 [1536/39424 (4%)]\tLoss: 0.427537\n",
      "Train Epoch: 39 [2048/39424 (5%)]\tLoss: 0.337126\n",
      "Train Epoch: 39 [2560/39424 (6%)]\tLoss: 0.313809\n",
      "Train Epoch: 39 [3072/39424 (8%)]\tLoss: 0.368743\n",
      "Train Epoch: 39 [3584/39424 (9%)]\tLoss: 0.318415\n",
      "Train Epoch: 39 [4096/39424 (10%)]\tLoss: 0.305001\n",
      "Train Epoch: 39 [4608/39424 (12%)]\tLoss: 0.283299\n",
      "Train Epoch: 39 [5120/39424 (13%)]\tLoss: 0.262240\n",
      "Train Epoch: 39 [5632/39424 (14%)]\tLoss: 0.294354\n",
      "Train Epoch: 39 [6144/39424 (16%)]\tLoss: 0.265732\n",
      "Train Epoch: 39 [6656/39424 (17%)]\tLoss: 0.272040\n",
      "Train Epoch: 39 [7168/39424 (18%)]\tLoss: 0.269723\n",
      "Train Epoch: 39 [7680/39424 (19%)]\tLoss: 0.253812\n",
      "Train Epoch: 39 [8192/39424 (21%)]\tLoss: 0.215967\n",
      "Train Epoch: 39 [8704/39424 (22%)]\tLoss: 0.239623\n",
      "Train Epoch: 39 [9216/39424 (23%)]\tLoss: 0.268962\n",
      "Train Epoch: 39 [9728/39424 (25%)]\tLoss: 0.244367\n",
      "Train Epoch: 39 [10240/39424 (26%)]\tLoss: 0.220425\n",
      "Train Epoch: 39 [10752/39424 (27%)]\tLoss: 0.271819\n",
      "Train Epoch: 39 [11264/39424 (29%)]\tLoss: 0.226642\n",
      "Train Epoch: 39 [11776/39424 (30%)]\tLoss: 0.215870\n",
      "Train Epoch: 39 [12288/39424 (31%)]\tLoss: 0.233740\n",
      "Train Epoch: 39 [12800/39424 (32%)]\tLoss: 0.217710\n",
      "Train Epoch: 39 [13312/39424 (34%)]\tLoss: 0.236558\n",
      "Train Epoch: 39 [13824/39424 (35%)]\tLoss: 0.241156\n",
      "Train Epoch: 39 [14336/39424 (36%)]\tLoss: 0.212662\n",
      "Train Epoch: 39 [14848/39424 (38%)]\tLoss: 0.216389\n",
      "Train Epoch: 39 [15360/39424 (39%)]\tLoss: 0.194782\n",
      "Train Epoch: 39 [15872/39424 (40%)]\tLoss: 0.202184\n",
      "Train Epoch: 39 [16384/39424 (42%)]\tLoss: 0.223636\n",
      "Train Epoch: 39 [16896/39424 (43%)]\tLoss: 0.245530\n",
      "Train Epoch: 39 [17408/39424 (44%)]\tLoss: 0.210858\n",
      "Train Epoch: 39 [17920/39424 (45%)]\tLoss: 0.249937\n",
      "Train Epoch: 39 [18432/39424 (47%)]\tLoss: 0.224076\n",
      "Train Epoch: 39 [18944/39424 (48%)]\tLoss: 0.180194\n",
      "Train Epoch: 39 [19456/39424 (49%)]\tLoss: 0.203288\n",
      "Train Epoch: 39 [19968/39424 (51%)]\tLoss: 0.154090\n",
      "Train Epoch: 39 [20480/39424 (52%)]\tLoss: 0.175284\n",
      "Train Epoch: 39 [20992/39424 (53%)]\tLoss: 0.221637\n",
      "Train Epoch: 39 [21504/39424 (55%)]\tLoss: 0.157780\n",
      "Train Epoch: 39 [22016/39424 (56%)]\tLoss: 0.155312\n",
      "Train Epoch: 39 [22528/39424 (57%)]\tLoss: 0.155531\n",
      "Train Epoch: 39 [23040/39424 (58%)]\tLoss: 0.236151\n",
      "Train Epoch: 39 [23552/39424 (60%)]\tLoss: 0.187391\n",
      "Train Epoch: 39 [24064/39424 (61%)]\tLoss: 0.195591\n",
      "Train Epoch: 39 [24576/39424 (62%)]\tLoss: 0.198983\n",
      "Train Epoch: 39 [25088/39424 (64%)]\tLoss: 0.163865\n",
      "Train Epoch: 39 [25600/39424 (65%)]\tLoss: 0.203181\n",
      "Train Epoch: 39 [26112/39424 (66%)]\tLoss: 0.158443\n",
      "Train Epoch: 39 [26624/39424 (68%)]\tLoss: 0.217201\n",
      "Train Epoch: 39 [27136/39424 (69%)]\tLoss: 0.203406\n",
      "Train Epoch: 39 [27648/39424 (70%)]\tLoss: 0.224004\n",
      "Train Epoch: 39 [28160/39424 (71%)]\tLoss: 0.162917\n",
      "Train Epoch: 39 [28672/39424 (73%)]\tLoss: 0.159538\n",
      "Train Epoch: 39 [29184/39424 (74%)]\tLoss: 0.161998\n",
      "Train Epoch: 39 [29696/39424 (75%)]\tLoss: 0.175014\n",
      "Train Epoch: 39 [30208/39424 (77%)]\tLoss: 0.181933\n",
      "Train Epoch: 39 [30720/39424 (78%)]\tLoss: 0.206854\n",
      "Train Epoch: 39 [31232/39424 (79%)]\tLoss: 0.238511\n",
      "Train Epoch: 39 [31744/39424 (81%)]\tLoss: 0.201531\n",
      "Train Epoch: 39 [32256/39424 (82%)]\tLoss: 0.164062\n",
      "Train Epoch: 39 [32768/39424 (83%)]\tLoss: 0.183951\n",
      "Train Epoch: 39 [33280/39424 (84%)]\tLoss: 0.176429\n",
      "Train Epoch: 39 [33792/39424 (86%)]\tLoss: 0.137419\n",
      "Train Epoch: 39 [34304/39424 (87%)]\tLoss: 0.139765\n",
      "Train Epoch: 39 [34816/39424 (88%)]\tLoss: 0.167603\n",
      "Train Epoch: 39 [35328/39424 (90%)]\tLoss: 0.175299\n",
      "Train Epoch: 39 [35840/39424 (91%)]\tLoss: 0.146746\n",
      "Train Epoch: 39 [36352/39424 (92%)]\tLoss: 0.171205\n",
      "Train Epoch: 39 [36864/39424 (94%)]\tLoss: 0.162513\n",
      "Train Epoch: 39 [37376/39424 (95%)]\tLoss: 0.168507\n",
      "Train Epoch: 39 [37888/39424 (96%)]\tLoss: 0.175933\n",
      "Train Epoch: 39 [38400/39424 (97%)]\tLoss: 0.163451\n",
      "Train Epoch: 39 [38912/39424 (99%)]\tLoss: 0.164148\n",
      "Average training loss: 0.33106890320777893\n",
      "\n",
      "Test set: Average loss: 8.3718, Accuracy: 44/12630 (0%)\n",
      "\n",
      "tensor([0.0035,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3518, Accuracy: 11584/12630 (92%)\n",
      "\n",
      "tensor([0.2000, 0.9458, 0.9707, 0.9644, 0.9152, 0.8714, 0.7800, 0.8333, 0.9044,\n",
      "        0.9875, 0.9848, 0.9381, 0.9739, 0.9861, 1.0000, 0.9714, 0.9800, 0.9333,\n",
      "        0.7615, 0.6167, 0.9778, 0.6000, 0.9167, 0.9200, 0.8556, 0.9229, 0.7944,\n",
      "        0.5000, 0.9067, 0.9667, 0.7133, 0.9704, 0.6167, 0.9857, 0.9833, 0.9513,\n",
      "        0.8667, 0.9833, 0.9319, 0.7444, 0.8444, 0.8167, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 39 [0/9728 (0%)]\tLoss: 8.054276\n",
      "Train Epoch: 39 [512/9728 (5%)]\tLoss: 2.826716\n",
      "Train Epoch: 39 [1024/9728 (11%)]\tLoss: 0.127918\n",
      "Train Epoch: 39 [1536/9728 (16%)]\tLoss: 0.051404\n",
      "Train Epoch: 39 [2048/9728 (21%)]\tLoss: 0.028394\n",
      "Train Epoch: 39 [2560/9728 (26%)]\tLoss: 0.030148\n",
      "Train Epoch: 39 [3072/9728 (32%)]\tLoss: 0.024837\n",
      "Train Epoch: 39 [3584/9728 (37%)]\tLoss: 0.023042\n",
      "Train Epoch: 39 [4096/9728 (42%)]\tLoss: 0.012585\n",
      "Train Epoch: 39 [4608/9728 (47%)]\tLoss: 0.012262\n",
      "Train Epoch: 39 [5120/9728 (53%)]\tLoss: 0.012344\n",
      "Train Epoch: 39 [5632/9728 (58%)]\tLoss: 0.008331\n",
      "Train Epoch: 39 [6144/9728 (63%)]\tLoss: 0.009353\n",
      "Train Epoch: 39 [6656/9728 (68%)]\tLoss: 0.011041\n",
      "Train Epoch: 39 [7168/9728 (74%)]\tLoss: 0.007952\n",
      "Train Epoch: 39 [7680/9728 (79%)]\tLoss: 0.004905\n",
      "Train Epoch: 39 [8192/9728 (84%)]\tLoss: 0.004324\n",
      "Train Epoch: 39 [8704/9728 (89%)]\tLoss: 0.007398\n",
      "Train Epoch: 39 [9216/9728 (95%)]\tLoss: 0.006128\n",
      "Average training loss: 0.5928083658218384\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.2505, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 40 [0/39424 (0%)]\tLoss: 8.544490\n",
      "Train Epoch: 40 [512/39424 (1%)]\tLoss: 0.771029\n",
      "Train Epoch: 40 [1024/39424 (3%)]\tLoss: 0.622575\n",
      "Train Epoch: 40 [1536/39424 (4%)]\tLoss: 0.559013\n",
      "Train Epoch: 40 [2048/39424 (5%)]\tLoss: 0.427533\n",
      "Train Epoch: 40 [2560/39424 (6%)]\tLoss: 0.352807\n",
      "Train Epoch: 40 [3072/39424 (8%)]\tLoss: 0.384972\n",
      "Train Epoch: 40 [3584/39424 (9%)]\tLoss: 0.308928\n",
      "Train Epoch: 40 [4096/39424 (10%)]\tLoss: 0.284733\n",
      "Train Epoch: 40 [4608/39424 (12%)]\tLoss: 0.297689\n",
      "Train Epoch: 40 [5120/39424 (13%)]\tLoss: 0.257720\n",
      "Train Epoch: 40 [5632/39424 (14%)]\tLoss: 0.267389\n",
      "Train Epoch: 40 [6144/39424 (16%)]\tLoss: 0.247582\n",
      "Train Epoch: 40 [6656/39424 (17%)]\tLoss: 0.263535\n",
      "Train Epoch: 40 [7168/39424 (18%)]\tLoss: 0.272712\n",
      "Train Epoch: 40 [7680/39424 (19%)]\tLoss: 0.263052\n",
      "Train Epoch: 40 [8192/39424 (21%)]\tLoss: 0.216400\n",
      "Train Epoch: 40 [8704/39424 (22%)]\tLoss: 0.210039\n",
      "Train Epoch: 40 [9216/39424 (23%)]\tLoss: 0.264390\n",
      "Train Epoch: 40 [9728/39424 (25%)]\tLoss: 0.265179\n",
      "Train Epoch: 40 [10240/39424 (26%)]\tLoss: 0.219752\n",
      "Train Epoch: 40 [10752/39424 (27%)]\tLoss: 0.261714\n",
      "Train Epoch: 40 [11264/39424 (29%)]\tLoss: 0.213804\n",
      "Train Epoch: 40 [11776/39424 (30%)]\tLoss: 0.211074\n",
      "Train Epoch: 40 [12288/39424 (31%)]\tLoss: 0.208572\n",
      "Train Epoch: 40 [12800/39424 (32%)]\tLoss: 0.190485\n",
      "Train Epoch: 40 [13312/39424 (34%)]\tLoss: 0.212859\n",
      "Train Epoch: 40 [13824/39424 (35%)]\tLoss: 0.229706\n",
      "Train Epoch: 40 [14336/39424 (36%)]\tLoss: 0.212240\n",
      "Train Epoch: 40 [14848/39424 (38%)]\tLoss: 0.212123\n",
      "Train Epoch: 40 [15360/39424 (39%)]\tLoss: 0.198634\n",
      "Train Epoch: 40 [15872/39424 (40%)]\tLoss: 0.191027\n",
      "Train Epoch: 40 [16384/39424 (42%)]\tLoss: 0.215721\n",
      "Train Epoch: 40 [16896/39424 (43%)]\tLoss: 0.260241\n",
      "Train Epoch: 40 [17408/39424 (44%)]\tLoss: 0.223352\n",
      "Train Epoch: 40 [17920/39424 (45%)]\tLoss: 0.264881\n",
      "Train Epoch: 40 [18432/39424 (47%)]\tLoss: 0.232462\n",
      "Train Epoch: 40 [18944/39424 (48%)]\tLoss: 0.179781\n",
      "Train Epoch: 40 [19456/39424 (49%)]\tLoss: 0.207311\n",
      "Train Epoch: 40 [19968/39424 (51%)]\tLoss: 0.156034\n",
      "Train Epoch: 40 [20480/39424 (52%)]\tLoss: 0.169754\n",
      "Train Epoch: 40 [20992/39424 (53%)]\tLoss: 0.217147\n",
      "Train Epoch: 40 [21504/39424 (55%)]\tLoss: 0.162729\n",
      "Train Epoch: 40 [22016/39424 (56%)]\tLoss: 0.155645\n",
      "Train Epoch: 40 [22528/39424 (57%)]\tLoss: 0.151955\n",
      "Train Epoch: 40 [23040/39424 (58%)]\tLoss: 0.229445\n",
      "Train Epoch: 40 [23552/39424 (60%)]\tLoss: 0.164756\n",
      "Train Epoch: 40 [24064/39424 (61%)]\tLoss: 0.182150\n",
      "Train Epoch: 40 [24576/39424 (62%)]\tLoss: 0.182821\n",
      "Train Epoch: 40 [25088/39424 (64%)]\tLoss: 0.160490\n",
      "Train Epoch: 40 [25600/39424 (65%)]\tLoss: 0.193129\n",
      "Train Epoch: 40 [26112/39424 (66%)]\tLoss: 0.151176\n",
      "Train Epoch: 40 [26624/39424 (68%)]\tLoss: 0.198435\n",
      "Train Epoch: 40 [27136/39424 (69%)]\tLoss: 0.200884\n",
      "Train Epoch: 40 [27648/39424 (70%)]\tLoss: 0.208942\n",
      "Train Epoch: 40 [28160/39424 (71%)]\tLoss: 0.167360\n",
      "Train Epoch: 40 [28672/39424 (73%)]\tLoss: 0.172866\n",
      "Train Epoch: 40 [29184/39424 (74%)]\tLoss: 0.158128\n",
      "Train Epoch: 40 [29696/39424 (75%)]\tLoss: 0.171162\n",
      "Train Epoch: 40 [30208/39424 (77%)]\tLoss: 0.183991\n",
      "Train Epoch: 40 [30720/39424 (78%)]\tLoss: 0.177448\n",
      "Train Epoch: 40 [31232/39424 (79%)]\tLoss: 0.211107\n",
      "Train Epoch: 40 [31744/39424 (81%)]\tLoss: 0.193431\n",
      "Train Epoch: 40 [32256/39424 (82%)]\tLoss: 0.170313\n",
      "Train Epoch: 40 [32768/39424 (83%)]\tLoss: 0.154695\n",
      "Train Epoch: 40 [33280/39424 (84%)]\tLoss: 0.166150\n",
      "Train Epoch: 40 [33792/39424 (86%)]\tLoss: 0.131032\n",
      "Train Epoch: 40 [34304/39424 (87%)]\tLoss: 0.128282\n",
      "Train Epoch: 40 [34816/39424 (88%)]\tLoss: 0.161203\n",
      "Train Epoch: 40 [35328/39424 (90%)]\tLoss: 0.160403\n",
      "Train Epoch: 40 [35840/39424 (91%)]\tLoss: 0.153165\n",
      "Train Epoch: 40 [36352/39424 (92%)]\tLoss: 0.174378\n",
      "Train Epoch: 40 [36864/39424 (94%)]\tLoss: 0.158305\n",
      "Train Epoch: 40 [37376/39424 (95%)]\tLoss: 0.165196\n",
      "Train Epoch: 40 [37888/39424 (96%)]\tLoss: 0.188350\n",
      "Train Epoch: 40 [38400/39424 (97%)]\tLoss: 0.155749\n",
      "Train Epoch: 40 [38912/39424 (99%)]\tLoss: 0.158465\n",
      "Average training loss: 0.3347295820713043\n",
      "\n",
      "Test set: Average loss: 8.3676, Accuracy: 47/12630 (0%)\n",
      "\n",
      "tensor([0.0037,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3454, Accuracy: 11611/12630 (92%)\n",
      "\n",
      "tensor([0.2167, 0.9458, 0.9747, 0.9511, 0.9152, 0.8810, 0.7867, 0.8378, 0.9089,\n",
      "        0.9854, 0.9833, 0.9452, 0.9754, 0.9861, 1.0000, 0.9714, 0.9800, 0.9361,\n",
      "        0.7769, 0.6500, 0.9778, 0.6222, 0.9167, 0.9400, 0.8556, 0.9229, 0.7944,\n",
      "        0.5000, 0.9267, 0.9667, 0.6933, 0.9704, 0.6000, 0.9857, 0.9833, 0.9436,\n",
      "        0.8667, 0.9833, 0.9377, 0.7444, 0.8444, 0.8167, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 40 [0/9728 (0%)]\tLoss: 8.081880\n",
      "Train Epoch: 40 [512/9728 (5%)]\tLoss: 2.696050\n",
      "Train Epoch: 40 [1024/9728 (11%)]\tLoss: 0.122328\n",
      "Train Epoch: 40 [1536/9728 (16%)]\tLoss: 0.061398\n",
      "Train Epoch: 40 [2048/9728 (21%)]\tLoss: 0.037065\n",
      "Train Epoch: 40 [2560/9728 (26%)]\tLoss: 0.027136\n",
      "Train Epoch: 40 [3072/9728 (32%)]\tLoss: 0.022279\n",
      "Train Epoch: 40 [3584/9728 (37%)]\tLoss: 0.021365\n",
      "Train Epoch: 40 [4096/9728 (42%)]\tLoss: 0.012331\n",
      "Train Epoch: 40 [4608/9728 (47%)]\tLoss: 0.011111\n",
      "Train Epoch: 40 [5120/9728 (53%)]\tLoss: 0.009537\n",
      "Train Epoch: 40 [5632/9728 (58%)]\tLoss: 0.009248\n",
      "Train Epoch: 40 [6144/9728 (63%)]\tLoss: 0.010052\n",
      "Train Epoch: 40 [6656/9728 (68%)]\tLoss: 0.009508\n",
      "Train Epoch: 40 [7168/9728 (74%)]\tLoss: 0.008429\n",
      "Train Epoch: 40 [7680/9728 (79%)]\tLoss: 0.004027\n",
      "Train Epoch: 40 [8192/9728 (84%)]\tLoss: 0.003857\n",
      "Train Epoch: 40 [8704/9728 (89%)]\tLoss: 0.005306\n",
      "Train Epoch: 40 [9216/9728 (95%)]\tLoss: 0.004205\n",
      "Average training loss: 0.5872164368629456\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.0777, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 41 [0/39424 (0%)]\tLoss: 8.363642\n",
      "Train Epoch: 41 [512/39424 (1%)]\tLoss: 0.691508\n",
      "Train Epoch: 41 [1024/39424 (3%)]\tLoss: 0.523139\n",
      "Train Epoch: 41 [1536/39424 (4%)]\tLoss: 0.450475\n",
      "Train Epoch: 41 [2048/39424 (5%)]\tLoss: 0.351541\n",
      "Train Epoch: 41 [2560/39424 (6%)]\tLoss: 0.296687\n",
      "Train Epoch: 41 [3072/39424 (8%)]\tLoss: 0.330885\n",
      "Train Epoch: 41 [3584/39424 (9%)]\tLoss: 0.291523\n",
      "Train Epoch: 41 [4096/39424 (10%)]\tLoss: 0.282745\n",
      "Train Epoch: 41 [4608/39424 (12%)]\tLoss: 0.274159\n",
      "Train Epoch: 41 [5120/39424 (13%)]\tLoss: 0.252641\n",
      "Train Epoch: 41 [5632/39424 (14%)]\tLoss: 0.287538\n",
      "Train Epoch: 41 [6144/39424 (16%)]\tLoss: 0.241857\n",
      "Train Epoch: 41 [6656/39424 (17%)]\tLoss: 0.261651\n",
      "Train Epoch: 41 [7168/39424 (18%)]\tLoss: 0.247052\n",
      "Train Epoch: 41 [7680/39424 (19%)]\tLoss: 0.256297\n",
      "Train Epoch: 41 [8192/39424 (21%)]\tLoss: 0.210940\n",
      "Train Epoch: 41 [8704/39424 (22%)]\tLoss: 0.205286\n",
      "Train Epoch: 41 [9216/39424 (23%)]\tLoss: 0.251040\n",
      "Train Epoch: 41 [9728/39424 (25%)]\tLoss: 0.234937\n",
      "Train Epoch: 41 [10240/39424 (26%)]\tLoss: 0.207376\n",
      "Train Epoch: 41 [10752/39424 (27%)]\tLoss: 0.272486\n",
      "Train Epoch: 41 [11264/39424 (29%)]\tLoss: 0.205679\n",
      "Train Epoch: 41 [11776/39424 (30%)]\tLoss: 0.205314\n",
      "Train Epoch: 41 [12288/39424 (31%)]\tLoss: 0.202817\n",
      "Train Epoch: 41 [12800/39424 (32%)]\tLoss: 0.189108\n",
      "Train Epoch: 41 [13312/39424 (34%)]\tLoss: 0.208009\n",
      "Train Epoch: 41 [13824/39424 (35%)]\tLoss: 0.220216\n",
      "Train Epoch: 41 [14336/39424 (36%)]\tLoss: 0.197224\n",
      "Train Epoch: 41 [14848/39424 (38%)]\tLoss: 0.195431\n",
      "Train Epoch: 41 [15360/39424 (39%)]\tLoss: 0.194699\n",
      "Train Epoch: 41 [15872/39424 (40%)]\tLoss: 0.202310\n",
      "Train Epoch: 41 [16384/39424 (42%)]\tLoss: 0.201867\n",
      "Train Epoch: 41 [16896/39424 (43%)]\tLoss: 0.252601\n",
      "Train Epoch: 41 [17408/39424 (44%)]\tLoss: 0.212323\n",
      "Train Epoch: 41 [17920/39424 (45%)]\tLoss: 0.242563\n",
      "Train Epoch: 41 [18432/39424 (47%)]\tLoss: 0.207301\n",
      "Train Epoch: 41 [18944/39424 (48%)]\tLoss: 0.178763\n",
      "Train Epoch: 41 [19456/39424 (49%)]\tLoss: 0.185846\n",
      "Train Epoch: 41 [19968/39424 (51%)]\tLoss: 0.143383\n",
      "Train Epoch: 41 [20480/39424 (52%)]\tLoss: 0.179732\n",
      "Train Epoch: 41 [20992/39424 (53%)]\tLoss: 0.206332\n",
      "Train Epoch: 41 [21504/39424 (55%)]\tLoss: 0.156051\n",
      "Train Epoch: 41 [22016/39424 (56%)]\tLoss: 0.159030\n",
      "Train Epoch: 41 [22528/39424 (57%)]\tLoss: 0.147444\n",
      "Train Epoch: 41 [23040/39424 (58%)]\tLoss: 0.216801\n",
      "Train Epoch: 41 [23552/39424 (60%)]\tLoss: 0.171466\n",
      "Train Epoch: 41 [24064/39424 (61%)]\tLoss: 0.173996\n",
      "Train Epoch: 41 [24576/39424 (62%)]\tLoss: 0.169906\n",
      "Train Epoch: 41 [25088/39424 (64%)]\tLoss: 0.153276\n",
      "Train Epoch: 41 [25600/39424 (65%)]\tLoss: 0.172110\n",
      "Train Epoch: 41 [26112/39424 (66%)]\tLoss: 0.142164\n",
      "Train Epoch: 41 [26624/39424 (68%)]\tLoss: 0.179119\n",
      "Train Epoch: 41 [27136/39424 (69%)]\tLoss: 0.193454\n",
      "Train Epoch: 41 [27648/39424 (70%)]\tLoss: 0.206975\n",
      "Train Epoch: 41 [28160/39424 (71%)]\tLoss: 0.166155\n",
      "Train Epoch: 41 [28672/39424 (73%)]\tLoss: 0.168217\n",
      "Train Epoch: 41 [29184/39424 (74%)]\tLoss: 0.166902\n",
      "Train Epoch: 41 [29696/39424 (75%)]\tLoss: 0.156009\n",
      "Train Epoch: 41 [30208/39424 (77%)]\tLoss: 0.168924\n",
      "Train Epoch: 41 [30720/39424 (78%)]\tLoss: 0.173111\n",
      "Train Epoch: 41 [31232/39424 (79%)]\tLoss: 0.210923\n",
      "Train Epoch: 41 [31744/39424 (81%)]\tLoss: 0.159730\n",
      "Train Epoch: 41 [32256/39424 (82%)]\tLoss: 0.158327\n",
      "Train Epoch: 41 [32768/39424 (83%)]\tLoss: 0.163889\n",
      "Train Epoch: 41 [33280/39424 (84%)]\tLoss: 0.177634\n",
      "Train Epoch: 41 [33792/39424 (86%)]\tLoss: 0.143388\n",
      "Train Epoch: 41 [34304/39424 (87%)]\tLoss: 0.111901\n",
      "Train Epoch: 41 [34816/39424 (88%)]\tLoss: 0.151191\n",
      "Train Epoch: 41 [35328/39424 (90%)]\tLoss: 0.183073\n",
      "Train Epoch: 41 [35840/39424 (91%)]\tLoss: 0.139990\n",
      "Train Epoch: 41 [36352/39424 (92%)]\tLoss: 0.150786\n",
      "Train Epoch: 41 [36864/39424 (94%)]\tLoss: 0.135143\n",
      "Train Epoch: 41 [37376/39424 (95%)]\tLoss: 0.162179\n",
      "Train Epoch: 41 [37888/39424 (96%)]\tLoss: 0.167998\n",
      "Train Epoch: 41 [38400/39424 (97%)]\tLoss: 0.168991\n",
      "Train Epoch: 41 [38912/39424 (99%)]\tLoss: 0.163823\n",
      "Average training loss: 0.31957146525382996\n",
      "\n",
      "Test set: Average loss: 8.3631, Accuracy: 52/12630 (0%)\n",
      "\n",
      "tensor([0.0041,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3377, Accuracy: 11637/12630 (92%)\n",
      "\n",
      "tensor([0.2500, 0.9444, 0.9707, 0.9511, 0.9182, 0.8810, 0.7933, 0.8444, 0.9267,\n",
      "        0.9854, 0.9864, 0.9500, 0.9754, 0.9875, 1.0000, 0.9714, 0.9800, 0.9333,\n",
      "        0.7718, 0.6833, 0.9778, 0.6556, 0.9167, 0.9267, 0.8556, 0.9250, 0.7944,\n",
      "        0.5000, 0.9400, 0.9667, 0.7000, 0.9704, 0.6167, 0.9857, 0.9833, 0.9564,\n",
      "        0.8667, 0.9833, 0.9377, 0.7444, 0.8556, 0.8167, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 41 [0/9728 (0%)]\tLoss: 8.046233\n",
      "Train Epoch: 41 [512/9728 (5%)]\tLoss: 2.823604\n",
      "Train Epoch: 41 [1024/9728 (11%)]\tLoss: 0.125146\n",
      "Train Epoch: 41 [1536/9728 (16%)]\tLoss: 0.072376\n",
      "Train Epoch: 41 [2048/9728 (21%)]\tLoss: 0.030385\n",
      "Train Epoch: 41 [2560/9728 (26%)]\tLoss: 0.037920\n",
      "Train Epoch: 41 [3072/9728 (32%)]\tLoss: 0.020857\n",
      "Train Epoch: 41 [3584/9728 (37%)]\tLoss: 0.022898\n",
      "Train Epoch: 41 [4096/9728 (42%)]\tLoss: 0.010051\n",
      "Train Epoch: 41 [4608/9728 (47%)]\tLoss: 0.007445\n",
      "Train Epoch: 41 [5120/9728 (53%)]\tLoss: 0.009200\n",
      "Train Epoch: 41 [5632/9728 (58%)]\tLoss: 0.010308\n",
      "Train Epoch: 41 [6144/9728 (63%)]\tLoss: 0.007947\n",
      "Train Epoch: 41 [6656/9728 (68%)]\tLoss: 0.008803\n",
      "Train Epoch: 41 [7168/9728 (74%)]\tLoss: 0.008665\n",
      "Train Epoch: 41 [7680/9728 (79%)]\tLoss: 0.006073\n",
      "Train Epoch: 41 [8192/9728 (84%)]\tLoss: 0.004502\n",
      "Train Epoch: 41 [8704/9728 (89%)]\tLoss: 0.005794\n",
      "Train Epoch: 41 [9216/9728 (95%)]\tLoss: 0.005205\n",
      "Average training loss: 0.5928112864494324\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.1861, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 42 [0/39424 (0%)]\tLoss: 8.477709\n",
      "Train Epoch: 42 [512/39424 (1%)]\tLoss: 0.782740\n",
      "Train Epoch: 42 [1024/39424 (3%)]\tLoss: 0.605587\n",
      "Train Epoch: 42 [1536/39424 (4%)]\tLoss: 0.534314\n",
      "Train Epoch: 42 [2048/39424 (5%)]\tLoss: 0.426657\n",
      "Train Epoch: 42 [2560/39424 (6%)]\tLoss: 0.351618\n",
      "Train Epoch: 42 [3072/39424 (8%)]\tLoss: 0.393092\n",
      "Train Epoch: 42 [3584/39424 (9%)]\tLoss: 0.318005\n",
      "Train Epoch: 42 [4096/39424 (10%)]\tLoss: 0.269403\n",
      "Train Epoch: 42 [4608/39424 (12%)]\tLoss: 0.276920\n",
      "Train Epoch: 42 [5120/39424 (13%)]\tLoss: 0.252431\n",
      "Train Epoch: 42 [5632/39424 (14%)]\tLoss: 0.283762\n",
      "Train Epoch: 42 [6144/39424 (16%)]\tLoss: 0.242067\n",
      "Train Epoch: 42 [6656/39424 (17%)]\tLoss: 0.264392\n",
      "Train Epoch: 42 [7168/39424 (18%)]\tLoss: 0.258459\n",
      "Train Epoch: 42 [7680/39424 (19%)]\tLoss: 0.257640\n",
      "Train Epoch: 42 [8192/39424 (21%)]\tLoss: 0.194996\n",
      "Train Epoch: 42 [8704/39424 (22%)]\tLoss: 0.218647\n",
      "Train Epoch: 42 [9216/39424 (23%)]\tLoss: 0.251554\n",
      "Train Epoch: 42 [9728/39424 (25%)]\tLoss: 0.249455\n",
      "Train Epoch: 42 [10240/39424 (26%)]\tLoss: 0.221555\n",
      "Train Epoch: 42 [10752/39424 (27%)]\tLoss: 0.254178\n",
      "Train Epoch: 42 [11264/39424 (29%)]\tLoss: 0.209827\n",
      "Train Epoch: 42 [11776/39424 (30%)]\tLoss: 0.196531\n",
      "Train Epoch: 42 [12288/39424 (31%)]\tLoss: 0.213457\n",
      "Train Epoch: 42 [12800/39424 (32%)]\tLoss: 0.190305\n",
      "Train Epoch: 42 [13312/39424 (34%)]\tLoss: 0.210662\n",
      "Train Epoch: 42 [13824/39424 (35%)]\tLoss: 0.205691\n",
      "Train Epoch: 42 [14336/39424 (36%)]\tLoss: 0.191346\n",
      "Train Epoch: 42 [14848/39424 (38%)]\tLoss: 0.203363\n",
      "Train Epoch: 42 [15360/39424 (39%)]\tLoss: 0.180051\n",
      "Train Epoch: 42 [15872/39424 (40%)]\tLoss: 0.198124\n",
      "Train Epoch: 42 [16384/39424 (42%)]\tLoss: 0.202512\n",
      "Train Epoch: 42 [16896/39424 (43%)]\tLoss: 0.231201\n",
      "Train Epoch: 42 [17408/39424 (44%)]\tLoss: 0.204774\n",
      "Train Epoch: 42 [17920/39424 (45%)]\tLoss: 0.235992\n",
      "Train Epoch: 42 [18432/39424 (47%)]\tLoss: 0.193164\n",
      "Train Epoch: 42 [18944/39424 (48%)]\tLoss: 0.176715\n",
      "Train Epoch: 42 [19456/39424 (49%)]\tLoss: 0.184417\n",
      "Train Epoch: 42 [19968/39424 (51%)]\tLoss: 0.130297\n",
      "Train Epoch: 42 [20480/39424 (52%)]\tLoss: 0.166740\n",
      "Train Epoch: 42 [20992/39424 (53%)]\tLoss: 0.211826\n",
      "Train Epoch: 42 [21504/39424 (55%)]\tLoss: 0.142102\n",
      "Train Epoch: 42 [22016/39424 (56%)]\tLoss: 0.154413\n",
      "Train Epoch: 42 [22528/39424 (57%)]\tLoss: 0.152111\n",
      "Train Epoch: 42 [23040/39424 (58%)]\tLoss: 0.232835\n",
      "Train Epoch: 42 [23552/39424 (60%)]\tLoss: 0.164149\n",
      "Train Epoch: 42 [24064/39424 (61%)]\tLoss: 0.165460\n",
      "Train Epoch: 42 [24576/39424 (62%)]\tLoss: 0.165123\n",
      "Train Epoch: 42 [25088/39424 (64%)]\tLoss: 0.168232\n",
      "Train Epoch: 42 [25600/39424 (65%)]\tLoss: 0.174649\n",
      "Train Epoch: 42 [26112/39424 (66%)]\tLoss: 0.149373\n",
      "Train Epoch: 42 [26624/39424 (68%)]\tLoss: 0.199877\n",
      "Train Epoch: 42 [27136/39424 (69%)]\tLoss: 0.175151\n",
      "Train Epoch: 42 [27648/39424 (70%)]\tLoss: 0.172323\n",
      "Train Epoch: 42 [28160/39424 (71%)]\tLoss: 0.138707\n",
      "Train Epoch: 42 [28672/39424 (73%)]\tLoss: 0.148166\n",
      "Train Epoch: 42 [29184/39424 (74%)]\tLoss: 0.157743\n",
      "Train Epoch: 42 [29696/39424 (75%)]\tLoss: 0.159452\n",
      "Train Epoch: 42 [30208/39424 (77%)]\tLoss: 0.169432\n",
      "Train Epoch: 42 [30720/39424 (78%)]\tLoss: 0.179648\n",
      "Train Epoch: 42 [31232/39424 (79%)]\tLoss: 0.223404\n",
      "Train Epoch: 42 [31744/39424 (81%)]\tLoss: 0.169952\n",
      "Train Epoch: 42 [32256/39424 (82%)]\tLoss: 0.138780\n",
      "Train Epoch: 42 [32768/39424 (83%)]\tLoss: 0.166138\n",
      "Train Epoch: 42 [33280/39424 (84%)]\tLoss: 0.165006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [33792/39424 (86%)]\tLoss: 0.138615\n",
      "Train Epoch: 42 [34304/39424 (87%)]\tLoss: 0.106079\n",
      "Train Epoch: 42 [34816/39424 (88%)]\tLoss: 0.141577\n",
      "Train Epoch: 42 [35328/39424 (90%)]\tLoss: 0.139612\n",
      "Train Epoch: 42 [35840/39424 (91%)]\tLoss: 0.121740\n",
      "Train Epoch: 42 [36352/39424 (92%)]\tLoss: 0.151897\n",
      "Train Epoch: 42 [36864/39424 (94%)]\tLoss: 0.151669\n",
      "Train Epoch: 42 [37376/39424 (95%)]\tLoss: 0.166843\n",
      "Train Epoch: 42 [37888/39424 (96%)]\tLoss: 0.168937\n",
      "Train Epoch: 42 [38400/39424 (97%)]\tLoss: 0.153721\n",
      "Train Epoch: 42 [38912/39424 (99%)]\tLoss: 0.159276\n",
      "Average training loss: 0.3240828514099121\n",
      "\n",
      "Test set: Average loss: 8.3332, Accuracy: 52/12630 (0%)\n",
      "\n",
      "tensor([0.0041,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3335, Accuracy: 11652/12630 (92%)\n",
      "\n",
      "tensor([0.2500, 0.9486, 0.9680, 0.9556, 0.9167, 0.8825, 0.7933, 0.8578, 0.9200,\n",
      "        0.9854, 0.9864, 0.9548, 0.9768, 0.9903, 1.0000, 0.9714, 0.9800, 0.9361,\n",
      "        0.7821, 0.7000, 0.9778, 0.6222, 0.9167, 0.9333, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9467, 0.9667, 0.7000, 0.9704, 0.6167, 0.9857, 0.9833, 0.9436,\n",
      "        0.8667, 0.9833, 0.9377, 0.7444, 0.8444, 0.8333, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 42 [0/9728 (0%)]\tLoss: 8.032303\n",
      "Train Epoch: 42 [512/9728 (5%)]\tLoss: 2.754736\n",
      "Train Epoch: 42 [1024/9728 (11%)]\tLoss: 0.126666\n",
      "Train Epoch: 42 [1536/9728 (16%)]\tLoss: 0.070235\n",
      "Train Epoch: 42 [2048/9728 (21%)]\tLoss: 0.026218\n",
      "Train Epoch: 42 [2560/9728 (26%)]\tLoss: 0.029865\n",
      "Train Epoch: 42 [3072/9728 (32%)]\tLoss: 0.021859\n",
      "Train Epoch: 42 [3584/9728 (37%)]\tLoss: 0.020681\n",
      "Train Epoch: 42 [4096/9728 (42%)]\tLoss: 0.012445\n",
      "Train Epoch: 42 [4608/9728 (47%)]\tLoss: 0.008388\n",
      "Train Epoch: 42 [5120/9728 (53%)]\tLoss: 0.010812\n",
      "Train Epoch: 42 [5632/9728 (58%)]\tLoss: 0.008151\n",
      "Train Epoch: 42 [6144/9728 (63%)]\tLoss: 0.008028\n",
      "Train Epoch: 42 [6656/9728 (68%)]\tLoss: 0.011434\n",
      "Train Epoch: 42 [7168/9728 (74%)]\tLoss: 0.007978\n",
      "Train Epoch: 42 [7680/9728 (79%)]\tLoss: 0.004804\n",
      "Train Epoch: 42 [8192/9728 (84%)]\tLoss: 0.005299\n",
      "Train Epoch: 42 [8704/9728 (89%)]\tLoss: 0.006229\n",
      "Train Epoch: 42 [9216/9728 (95%)]\tLoss: 0.004761\n",
      "Average training loss: 0.5879417657852173\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.9268, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 43 [0/39424 (0%)]\tLoss: 8.157134\n",
      "Train Epoch: 43 [512/39424 (1%)]\tLoss: 0.629646\n",
      "Train Epoch: 43 [1024/39424 (3%)]\tLoss: 0.458118\n",
      "Train Epoch: 43 [1536/39424 (4%)]\tLoss: 0.409028\n",
      "Train Epoch: 43 [2048/39424 (5%)]\tLoss: 0.319827\n",
      "Train Epoch: 43 [2560/39424 (6%)]\tLoss: 0.289841\n",
      "Train Epoch: 43 [3072/39424 (8%)]\tLoss: 0.326809\n",
      "Train Epoch: 43 [3584/39424 (9%)]\tLoss: 0.284170\n",
      "Train Epoch: 43 [4096/39424 (10%)]\tLoss: 0.266009\n",
      "Train Epoch: 43 [4608/39424 (12%)]\tLoss: 0.258441\n",
      "Train Epoch: 43 [5120/39424 (13%)]\tLoss: 0.243873\n",
      "Train Epoch: 43 [5632/39424 (14%)]\tLoss: 0.252540\n",
      "Train Epoch: 43 [6144/39424 (16%)]\tLoss: 0.235466\n",
      "Train Epoch: 43 [6656/39424 (17%)]\tLoss: 0.249177\n",
      "Train Epoch: 43 [7168/39424 (18%)]\tLoss: 0.260733\n",
      "Train Epoch: 43 [7680/39424 (19%)]\tLoss: 0.234804\n",
      "Train Epoch: 43 [8192/39424 (21%)]\tLoss: 0.199134\n",
      "Train Epoch: 43 [8704/39424 (22%)]\tLoss: 0.230118\n",
      "Train Epoch: 43 [9216/39424 (23%)]\tLoss: 0.253984\n",
      "Train Epoch: 43 [9728/39424 (25%)]\tLoss: 0.241596\n",
      "Train Epoch: 43 [10240/39424 (26%)]\tLoss: 0.223037\n",
      "Train Epoch: 43 [10752/39424 (27%)]\tLoss: 0.248594\n",
      "Train Epoch: 43 [11264/39424 (29%)]\tLoss: 0.198883\n",
      "Train Epoch: 43 [11776/39424 (30%)]\tLoss: 0.188936\n",
      "Train Epoch: 43 [12288/39424 (31%)]\tLoss: 0.202865\n",
      "Train Epoch: 43 [12800/39424 (32%)]\tLoss: 0.196254\n",
      "Train Epoch: 43 [13312/39424 (34%)]\tLoss: 0.208860\n",
      "Train Epoch: 43 [13824/39424 (35%)]\tLoss: 0.200614\n",
      "Train Epoch: 43 [14336/39424 (36%)]\tLoss: 0.183275\n",
      "Train Epoch: 43 [14848/39424 (38%)]\tLoss: 0.199408\n",
      "Train Epoch: 43 [15360/39424 (39%)]\tLoss: 0.187480\n",
      "Train Epoch: 43 [15872/39424 (40%)]\tLoss: 0.178273\n",
      "Train Epoch: 43 [16384/39424 (42%)]\tLoss: 0.197317\n",
      "Train Epoch: 43 [16896/39424 (43%)]\tLoss: 0.224775\n",
      "Train Epoch: 43 [17408/39424 (44%)]\tLoss: 0.188603\n",
      "Train Epoch: 43 [17920/39424 (45%)]\tLoss: 0.247237\n",
      "Train Epoch: 43 [18432/39424 (47%)]\tLoss: 0.183235\n",
      "Train Epoch: 43 [18944/39424 (48%)]\tLoss: 0.157820\n",
      "Train Epoch: 43 [19456/39424 (49%)]\tLoss: 0.163358\n",
      "Train Epoch: 43 [19968/39424 (51%)]\tLoss: 0.137774\n",
      "Train Epoch: 43 [20480/39424 (52%)]\tLoss: 0.157804\n",
      "Train Epoch: 43 [20992/39424 (53%)]\tLoss: 0.195416\n",
      "Train Epoch: 43 [21504/39424 (55%)]\tLoss: 0.124147\n",
      "Train Epoch: 43 [22016/39424 (56%)]\tLoss: 0.153920\n",
      "Train Epoch: 43 [22528/39424 (57%)]\tLoss: 0.137764\n",
      "Train Epoch: 43 [23040/39424 (58%)]\tLoss: 0.215608\n",
      "Train Epoch: 43 [23552/39424 (60%)]\tLoss: 0.153809\n",
      "Train Epoch: 43 [24064/39424 (61%)]\tLoss: 0.175432\n",
      "Train Epoch: 43 [24576/39424 (62%)]\tLoss: 0.167072\n",
      "Train Epoch: 43 [25088/39424 (64%)]\tLoss: 0.144891\n",
      "Train Epoch: 43 [25600/39424 (65%)]\tLoss: 0.164604\n",
      "Train Epoch: 43 [26112/39424 (66%)]\tLoss: 0.135737\n",
      "Train Epoch: 43 [26624/39424 (68%)]\tLoss: 0.176128\n",
      "Train Epoch: 43 [27136/39424 (69%)]\tLoss: 0.188781\n",
      "Train Epoch: 43 [27648/39424 (70%)]\tLoss: 0.206705\n",
      "Train Epoch: 43 [28160/39424 (71%)]\tLoss: 0.148106\n",
      "Train Epoch: 43 [28672/39424 (73%)]\tLoss: 0.139688\n",
      "Train Epoch: 43 [29184/39424 (74%)]\tLoss: 0.158590\n",
      "Train Epoch: 43 [29696/39424 (75%)]\tLoss: 0.162969\n",
      "Train Epoch: 43 [30208/39424 (77%)]\tLoss: 0.165208\n",
      "Train Epoch: 43 [30720/39424 (78%)]\tLoss: 0.173507\n",
      "Train Epoch: 43 [31232/39424 (79%)]\tLoss: 0.202690\n",
      "Train Epoch: 43 [31744/39424 (81%)]\tLoss: 0.193988\n",
      "Train Epoch: 43 [32256/39424 (82%)]\tLoss: 0.136419\n",
      "Train Epoch: 43 [32768/39424 (83%)]\tLoss: 0.166099\n",
      "Train Epoch: 43 [33280/39424 (84%)]\tLoss: 0.161996\n",
      "Train Epoch: 43 [33792/39424 (86%)]\tLoss: 0.123860\n",
      "Train Epoch: 43 [34304/39424 (87%)]\tLoss: 0.100508\n",
      "Train Epoch: 43 [34816/39424 (88%)]\tLoss: 0.134001\n",
      "Train Epoch: 43 [35328/39424 (90%)]\tLoss: 0.158045\n",
      "Train Epoch: 43 [35840/39424 (91%)]\tLoss: 0.127481\n",
      "Train Epoch: 43 [36352/39424 (92%)]\tLoss: 0.139069\n",
      "Train Epoch: 43 [36864/39424 (94%)]\tLoss: 0.132464\n",
      "Train Epoch: 43 [37376/39424 (95%)]\tLoss: 0.143560\n",
      "Train Epoch: 43 [37888/39424 (96%)]\tLoss: 0.162227\n",
      "Train Epoch: 43 [38400/39424 (97%)]\tLoss: 0.142424\n",
      "Train Epoch: 43 [38912/39424 (99%)]\tLoss: 0.162743\n",
      "Average training loss: 0.30585068464279175\n",
      "\n",
      "Test set: Average loss: 8.2608, Accuracy: 52/12630 (0%)\n",
      "\n",
      "tensor([0.0041,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3306, Accuracy: 11672/12630 (92%)\n",
      "\n",
      "tensor([0.2667, 0.9500, 0.9733, 0.9644, 0.9182, 0.8794, 0.7933, 0.8622, 0.9289,\n",
      "        0.9854, 0.9894, 0.9524, 0.9783, 0.9917, 1.0000, 0.9714, 0.9867, 0.9333,\n",
      "        0.7667, 0.7667, 0.9778, 0.6111, 0.9167, 0.9267, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9467, 0.9667, 0.7400, 0.9704, 0.5833, 0.9857, 0.9833, 0.9513,\n",
      "        0.8667, 0.9833, 0.9377, 0.7556, 0.8444, 0.8500, 0.8778])\n",
      "Train backdoor\n",
      "Train Epoch: 43 [0/9728 (0%)]\tLoss: 8.014947\n",
      "Train Epoch: 43 [512/9728 (5%)]\tLoss: 2.726794\n",
      "Train Epoch: 43 [1024/9728 (11%)]\tLoss: 0.127299\n",
      "Train Epoch: 43 [1536/9728 (16%)]\tLoss: 0.069205\n",
      "Train Epoch: 43 [2048/9728 (21%)]\tLoss: 0.030703\n",
      "Train Epoch: 43 [2560/9728 (26%)]\tLoss: 0.028476\n",
      "Train Epoch: 43 [3072/9728 (32%)]\tLoss: 0.024340\n",
      "Train Epoch: 43 [3584/9728 (37%)]\tLoss: 0.019340\n",
      "Train Epoch: 43 [4096/9728 (42%)]\tLoss: 0.013829\n",
      "Train Epoch: 43 [4608/9728 (47%)]\tLoss: 0.009551\n",
      "Train Epoch: 43 [5120/9728 (53%)]\tLoss: 0.009846\n",
      "Train Epoch: 43 [5632/9728 (58%)]\tLoss: 0.007974\n",
      "Train Epoch: 43 [6144/9728 (63%)]\tLoss: 0.007580\n",
      "Train Epoch: 43 [6656/9728 (68%)]\tLoss: 0.008779\n",
      "Train Epoch: 43 [7168/9728 (74%)]\tLoss: 0.009202\n",
      "Train Epoch: 43 [7680/9728 (79%)]\tLoss: 0.005111\n",
      "Train Epoch: 43 [8192/9728 (84%)]\tLoss: 0.005970\n",
      "Train Epoch: 43 [8704/9728 (89%)]\tLoss: 0.006004\n",
      "Train Epoch: 43 [9216/9728 (95%)]\tLoss: 0.006753\n",
      "Average training loss: 0.5858790278434753\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 9.0588, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 44 [0/39424 (0%)]\tLoss: 8.329400\n",
      "Train Epoch: 44 [512/39424 (1%)]\tLoss: 0.746198\n",
      "Train Epoch: 44 [1024/39424 (3%)]\tLoss: 0.578480\n",
      "Train Epoch: 44 [1536/39424 (4%)]\tLoss: 0.500289\n",
      "Train Epoch: 44 [2048/39424 (5%)]\tLoss: 0.411759\n",
      "Train Epoch: 44 [2560/39424 (6%)]\tLoss: 0.341349\n",
      "Train Epoch: 44 [3072/39424 (8%)]\tLoss: 0.336876\n",
      "Train Epoch: 44 [3584/39424 (9%)]\tLoss: 0.290987\n",
      "Train Epoch: 44 [4096/39424 (10%)]\tLoss: 0.280791\n",
      "Train Epoch: 44 [4608/39424 (12%)]\tLoss: 0.262732\n",
      "Train Epoch: 44 [5120/39424 (13%)]\tLoss: 0.243085\n",
      "Train Epoch: 44 [5632/39424 (14%)]\tLoss: 0.257570\n",
      "Train Epoch: 44 [6144/39424 (16%)]\tLoss: 0.233300\n",
      "Train Epoch: 44 [6656/39424 (17%)]\tLoss: 0.251277\n",
      "Train Epoch: 44 [7168/39424 (18%)]\tLoss: 0.253097\n",
      "Train Epoch: 44 [7680/39424 (19%)]\tLoss: 0.246118\n",
      "Train Epoch: 44 [8192/39424 (21%)]\tLoss: 0.194934\n",
      "Train Epoch: 44 [8704/39424 (22%)]\tLoss: 0.206596\n",
      "Train Epoch: 44 [9216/39424 (23%)]\tLoss: 0.247126\n",
      "Train Epoch: 44 [9728/39424 (25%)]\tLoss: 0.239492\n",
      "Train Epoch: 44 [10240/39424 (26%)]\tLoss: 0.190244\n",
      "Train Epoch: 44 [10752/39424 (27%)]\tLoss: 0.246499\n",
      "Train Epoch: 44 [11264/39424 (29%)]\tLoss: 0.185707\n",
      "Train Epoch: 44 [11776/39424 (30%)]\tLoss: 0.180803\n",
      "Train Epoch: 44 [12288/39424 (31%)]\tLoss: 0.186279\n",
      "Train Epoch: 44 [12800/39424 (32%)]\tLoss: 0.182254\n",
      "Train Epoch: 44 [13312/39424 (34%)]\tLoss: 0.200443\n",
      "Train Epoch: 44 [13824/39424 (35%)]\tLoss: 0.221007\n",
      "Train Epoch: 44 [14336/39424 (36%)]\tLoss: 0.175607\n",
      "Train Epoch: 44 [14848/39424 (38%)]\tLoss: 0.187310\n",
      "Train Epoch: 44 [15360/39424 (39%)]\tLoss: 0.186523\n",
      "Train Epoch: 44 [15872/39424 (40%)]\tLoss: 0.200483\n",
      "Train Epoch: 44 [16384/39424 (42%)]\tLoss: 0.202583\n",
      "Train Epoch: 44 [16896/39424 (43%)]\tLoss: 0.219064\n",
      "Train Epoch: 44 [17408/39424 (44%)]\tLoss: 0.190965\n",
      "Train Epoch: 44 [17920/39424 (45%)]\tLoss: 0.232020\n",
      "Train Epoch: 44 [18432/39424 (47%)]\tLoss: 0.175496\n",
      "Train Epoch: 44 [18944/39424 (48%)]\tLoss: 0.146920\n",
      "Train Epoch: 44 [19456/39424 (49%)]\tLoss: 0.171585\n",
      "Train Epoch: 44 [19968/39424 (51%)]\tLoss: 0.138180\n",
      "Train Epoch: 44 [20480/39424 (52%)]\tLoss: 0.134300\n",
      "Train Epoch: 44 [20992/39424 (53%)]\tLoss: 0.195609\n",
      "Train Epoch: 44 [21504/39424 (55%)]\tLoss: 0.134036\n",
      "Train Epoch: 44 [22016/39424 (56%)]\tLoss: 0.149776\n",
      "Train Epoch: 44 [22528/39424 (57%)]\tLoss: 0.145023\n",
      "Train Epoch: 44 [23040/39424 (58%)]\tLoss: 0.201491\n",
      "Train Epoch: 44 [23552/39424 (60%)]\tLoss: 0.153841\n",
      "Train Epoch: 44 [24064/39424 (61%)]\tLoss: 0.159186\n",
      "Train Epoch: 44 [24576/39424 (62%)]\tLoss: 0.164899\n",
      "Train Epoch: 44 [25088/39424 (64%)]\tLoss: 0.154423\n",
      "Train Epoch: 44 [25600/39424 (65%)]\tLoss: 0.154109\n",
      "Train Epoch: 44 [26112/39424 (66%)]\tLoss: 0.144094\n",
      "Train Epoch: 44 [26624/39424 (68%)]\tLoss: 0.148560\n",
      "Train Epoch: 44 [27136/39424 (69%)]\tLoss: 0.154630\n",
      "Train Epoch: 44 [27648/39424 (70%)]\tLoss: 0.188040\n",
      "Train Epoch: 44 [28160/39424 (71%)]\tLoss: 0.147434\n",
      "Train Epoch: 44 [28672/39424 (73%)]\tLoss: 0.156658\n",
      "Train Epoch: 44 [29184/39424 (74%)]\tLoss: 0.165151\n",
      "Train Epoch: 44 [29696/39424 (75%)]\tLoss: 0.149025\n",
      "Train Epoch: 44 [30208/39424 (77%)]\tLoss: 0.155145\n",
      "Train Epoch: 44 [30720/39424 (78%)]\tLoss: 0.168234\n",
      "Train Epoch: 44 [31232/39424 (79%)]\tLoss: 0.199716\n",
      "Train Epoch: 44 [31744/39424 (81%)]\tLoss: 0.165269\n",
      "Train Epoch: 44 [32256/39424 (82%)]\tLoss: 0.161183\n",
      "Train Epoch: 44 [32768/39424 (83%)]\tLoss: 0.150663\n",
      "Train Epoch: 44 [33280/39424 (84%)]\tLoss: 0.163181\n",
      "Train Epoch: 44 [33792/39424 (86%)]\tLoss: 0.114536\n",
      "Train Epoch: 44 [34304/39424 (87%)]\tLoss: 0.102776\n",
      "Train Epoch: 44 [34816/39424 (88%)]\tLoss: 0.132896\n",
      "Train Epoch: 44 [35328/39424 (90%)]\tLoss: 0.145359\n",
      "Train Epoch: 44 [35840/39424 (91%)]\tLoss: 0.128765\n",
      "Train Epoch: 44 [36352/39424 (92%)]\tLoss: 0.138963\n",
      "Train Epoch: 44 [36864/39424 (94%)]\tLoss: 0.110237\n",
      "Train Epoch: 44 [37376/39424 (95%)]\tLoss: 0.152347\n",
      "Train Epoch: 44 [37888/39424 (96%)]\tLoss: 0.151399\n",
      "Train Epoch: 44 [38400/39424 (97%)]\tLoss: 0.134459\n",
      "Train Epoch: 44 [38912/39424 (99%)]\tLoss: 0.149210\n",
      "Average training loss: 0.31033840775489807\n",
      "\n",
      "Test set: Average loss: 8.3026, Accuracy: 48/12630 (0%)\n",
      "\n",
      "tensor([0.0038,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3254, Accuracy: 11685/12630 (93%)\n",
      "\n",
      "tensor([0.2500, 0.9528, 0.9800, 0.9600, 0.9167, 0.8841, 0.7867, 0.8644, 0.9267,\n",
      "        0.9854, 0.9864, 0.9476, 0.9768, 0.9917, 1.0000, 0.9714, 0.9867, 0.9417,\n",
      "        0.7846, 0.7667, 0.9778, 0.6333, 0.9167, 0.9333, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9533, 0.9667, 0.7133, 0.9704, 0.6000, 0.9857, 0.9833, 0.9487,\n",
      "        0.8667, 0.9833, 0.9406, 0.7667, 0.8333, 0.8500, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 44 [0/9728 (0%)]\tLoss: 7.984137\n",
      "Train Epoch: 44 [512/9728 (5%)]\tLoss: 2.722995\n",
      "Train Epoch: 44 [1024/9728 (11%)]\tLoss: 0.107087\n",
      "Train Epoch: 44 [1536/9728 (16%)]\tLoss: 0.058095\n",
      "Train Epoch: 44 [2048/9728 (21%)]\tLoss: 0.033897\n",
      "Train Epoch: 44 [2560/9728 (26%)]\tLoss: 0.031631\n",
      "Train Epoch: 44 [3072/9728 (32%)]\tLoss: 0.019736\n",
      "Train Epoch: 44 [3584/9728 (37%)]\tLoss: 0.023509\n",
      "Train Epoch: 44 [4096/9728 (42%)]\tLoss: 0.013668\n",
      "Train Epoch: 44 [4608/9728 (47%)]\tLoss: 0.010683\n",
      "Train Epoch: 44 [5120/9728 (53%)]\tLoss: 0.012078\n",
      "Train Epoch: 44 [5632/9728 (58%)]\tLoss: 0.007085\n",
      "Train Epoch: 44 [6144/9728 (63%)]\tLoss: 0.008300\n",
      "Train Epoch: 44 [6656/9728 (68%)]\tLoss: 0.008089\n",
      "Train Epoch: 44 [7168/9728 (74%)]\tLoss: 0.006521\n",
      "Train Epoch: 44 [7680/9728 (79%)]\tLoss: 0.003651\n",
      "Train Epoch: 44 [8192/9728 (84%)]\tLoss: 0.004998\n",
      "Train Epoch: 44 [8704/9728 (89%)]\tLoss: 0.006540\n",
      "Train Epoch: 44 [9216/9728 (95%)]\tLoss: 0.005727\n",
      "Average training loss: 0.5825488567352295\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.8698, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 45 [0/39424 (0%)]\tLoss: 8.178193\n",
      "Train Epoch: 45 [512/39424 (1%)]\tLoss: 0.637774\n",
      "Train Epoch: 45 [1024/39424 (3%)]\tLoss: 0.463129\n",
      "Train Epoch: 45 [1536/39424 (4%)]\tLoss: 0.385206\n",
      "Train Epoch: 45 [2048/39424 (5%)]\tLoss: 0.317029\n",
      "Train Epoch: 45 [2560/39424 (6%)]\tLoss: 0.276569\n",
      "Train Epoch: 45 [3072/39424 (8%)]\tLoss: 0.323089\n",
      "Train Epoch: 45 [3584/39424 (9%)]\tLoss: 0.273723\n",
      "Train Epoch: 45 [4096/39424 (10%)]\tLoss: 0.248973\n",
      "Train Epoch: 45 [4608/39424 (12%)]\tLoss: 0.255796\n",
      "Train Epoch: 45 [5120/39424 (13%)]\tLoss: 0.224067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [5632/39424 (14%)]\tLoss: 0.255902\n",
      "Train Epoch: 45 [6144/39424 (16%)]\tLoss: 0.228900\n",
      "Train Epoch: 45 [6656/39424 (17%)]\tLoss: 0.239821\n",
      "Train Epoch: 45 [7168/39424 (18%)]\tLoss: 0.215505\n",
      "Train Epoch: 45 [7680/39424 (19%)]\tLoss: 0.233429\n",
      "Train Epoch: 45 [8192/39424 (21%)]\tLoss: 0.179837\n",
      "Train Epoch: 45 [8704/39424 (22%)]\tLoss: 0.207349\n",
      "Train Epoch: 45 [9216/39424 (23%)]\tLoss: 0.217650\n",
      "Train Epoch: 45 [9728/39424 (25%)]\tLoss: 0.240322\n",
      "Train Epoch: 45 [10240/39424 (26%)]\tLoss: 0.193120\n",
      "Train Epoch: 45 [10752/39424 (27%)]\tLoss: 0.222035\n",
      "Train Epoch: 45 [11264/39424 (29%)]\tLoss: 0.183932\n",
      "Train Epoch: 45 [11776/39424 (30%)]\tLoss: 0.184227\n",
      "Train Epoch: 45 [12288/39424 (31%)]\tLoss: 0.200743\n",
      "Train Epoch: 45 [12800/39424 (32%)]\tLoss: 0.179760\n",
      "Train Epoch: 45 [13312/39424 (34%)]\tLoss: 0.188314\n",
      "Train Epoch: 45 [13824/39424 (35%)]\tLoss: 0.206919\n",
      "Train Epoch: 45 [14336/39424 (36%)]\tLoss: 0.170741\n",
      "Train Epoch: 45 [14848/39424 (38%)]\tLoss: 0.184212\n",
      "Train Epoch: 45 [15360/39424 (39%)]\tLoss: 0.178325\n",
      "Train Epoch: 45 [15872/39424 (40%)]\tLoss: 0.178456\n",
      "Train Epoch: 45 [16384/39424 (42%)]\tLoss: 0.197667\n",
      "Train Epoch: 45 [16896/39424 (43%)]\tLoss: 0.223091\n",
      "Train Epoch: 45 [17408/39424 (44%)]\tLoss: 0.170882\n",
      "Train Epoch: 45 [17920/39424 (45%)]\tLoss: 0.229858\n",
      "Train Epoch: 45 [18432/39424 (47%)]\tLoss: 0.187311\n",
      "Train Epoch: 45 [18944/39424 (48%)]\tLoss: 0.147779\n",
      "Train Epoch: 45 [19456/39424 (49%)]\tLoss: 0.171246\n",
      "Train Epoch: 45 [19968/39424 (51%)]\tLoss: 0.128549\n",
      "Train Epoch: 45 [20480/39424 (52%)]\tLoss: 0.154708\n",
      "Train Epoch: 45 [20992/39424 (53%)]\tLoss: 0.206892\n",
      "Train Epoch: 45 [21504/39424 (55%)]\tLoss: 0.136243\n",
      "Train Epoch: 45 [22016/39424 (56%)]\tLoss: 0.137697\n",
      "Train Epoch: 45 [22528/39424 (57%)]\tLoss: 0.138428\n",
      "Train Epoch: 45 [23040/39424 (58%)]\tLoss: 0.195079\n",
      "Train Epoch: 45 [23552/39424 (60%)]\tLoss: 0.134936\n",
      "Train Epoch: 45 [24064/39424 (61%)]\tLoss: 0.145750\n",
      "Train Epoch: 45 [24576/39424 (62%)]\tLoss: 0.149568\n",
      "Train Epoch: 45 [25088/39424 (64%)]\tLoss: 0.144281\n",
      "Train Epoch: 45 [25600/39424 (65%)]\tLoss: 0.151906\n",
      "Train Epoch: 45 [26112/39424 (66%)]\tLoss: 0.137627\n",
      "Train Epoch: 45 [26624/39424 (68%)]\tLoss: 0.171355\n",
      "Train Epoch: 45 [27136/39424 (69%)]\tLoss: 0.176140\n",
      "Train Epoch: 45 [27648/39424 (70%)]\tLoss: 0.166156\n",
      "Train Epoch: 45 [28160/39424 (71%)]\tLoss: 0.129221\n",
      "Train Epoch: 45 [28672/39424 (73%)]\tLoss: 0.132457\n",
      "Train Epoch: 45 [29184/39424 (74%)]\tLoss: 0.155766\n",
      "Train Epoch: 45 [29696/39424 (75%)]\tLoss: 0.156778\n",
      "Train Epoch: 45 [30208/39424 (77%)]\tLoss: 0.157798\n",
      "Train Epoch: 45 [30720/39424 (78%)]\tLoss: 0.156526\n",
      "Train Epoch: 45 [31232/39424 (79%)]\tLoss: 0.191103\n",
      "Train Epoch: 45 [31744/39424 (81%)]\tLoss: 0.161374\n",
      "Train Epoch: 45 [32256/39424 (82%)]\tLoss: 0.135030\n",
      "Train Epoch: 45 [32768/39424 (83%)]\tLoss: 0.142717\n",
      "Train Epoch: 45 [33280/39424 (84%)]\tLoss: 0.150507\n",
      "Train Epoch: 45 [33792/39424 (86%)]\tLoss: 0.136481\n",
      "Train Epoch: 45 [34304/39424 (87%)]\tLoss: 0.104794\n",
      "Train Epoch: 45 [34816/39424 (88%)]\tLoss: 0.135673\n",
      "Train Epoch: 45 [35328/39424 (90%)]\tLoss: 0.153322\n",
      "Train Epoch: 45 [35840/39424 (91%)]\tLoss: 0.137280\n",
      "Train Epoch: 45 [36352/39424 (92%)]\tLoss: 0.139163\n",
      "Train Epoch: 45 [36864/39424 (94%)]\tLoss: 0.131094\n",
      "Train Epoch: 45 [37376/39424 (95%)]\tLoss: 0.143655\n",
      "Train Epoch: 45 [37888/39424 (96%)]\tLoss: 0.145455\n",
      "Train Epoch: 45 [38400/39424 (97%)]\tLoss: 0.131715\n",
      "Train Epoch: 45 [38912/39424 (99%)]\tLoss: 0.156290\n",
      "Average training loss: 0.2968882918357849\n",
      "\n",
      "Test set: Average loss: 8.2706, Accuracy: 49/12630 (0%)\n",
      "\n",
      "tensor([0.0039,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3211, Accuracy: 11694/12630 (93%)\n",
      "\n",
      "tensor([0.2667, 0.9514, 0.9800, 0.9533, 0.9197, 0.8905, 0.8000, 0.8756, 0.9244,\n",
      "        0.9875, 0.9864, 0.9548, 0.9754, 0.9917, 1.0000, 0.9714, 0.9800, 0.9417,\n",
      "        0.7846, 0.7667, 0.9778, 0.6111, 0.9167, 0.9267, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9200, 0.9667, 0.7267, 0.9815, 0.5667, 0.9905, 0.9833, 0.9462,\n",
      "        0.8917, 0.9833, 0.9377, 0.7444, 0.8444, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 45 [0/9728 (0%)]\tLoss: 7.919882\n",
      "Train Epoch: 45 [512/9728 (5%)]\tLoss: 2.855263\n",
      "Train Epoch: 45 [1024/9728 (11%)]\tLoss: 0.132537\n",
      "Train Epoch: 45 [1536/9728 (16%)]\tLoss: 0.061925\n",
      "Train Epoch: 45 [2048/9728 (21%)]\tLoss: 0.032683\n",
      "Train Epoch: 45 [2560/9728 (26%)]\tLoss: 0.026297\n",
      "Train Epoch: 45 [3072/9728 (32%)]\tLoss: 0.024086\n",
      "Train Epoch: 45 [3584/9728 (37%)]\tLoss: 0.020790\n",
      "Train Epoch: 45 [4096/9728 (42%)]\tLoss: 0.012941\n",
      "Train Epoch: 45 [4608/9728 (47%)]\tLoss: 0.010532\n",
      "Train Epoch: 45 [5120/9728 (53%)]\tLoss: 0.009963\n",
      "Train Epoch: 45 [5632/9728 (58%)]\tLoss: 0.007833\n",
      "Train Epoch: 45 [6144/9728 (63%)]\tLoss: 0.008960\n",
      "Train Epoch: 45 [6656/9728 (68%)]\tLoss: 0.009392\n",
      "Train Epoch: 45 [7168/9728 (74%)]\tLoss: 0.009727\n",
      "Train Epoch: 45 [7680/9728 (79%)]\tLoss: 0.005806\n",
      "Train Epoch: 45 [8192/9728 (84%)]\tLoss: 0.004230\n",
      "Train Epoch: 45 [8704/9728 (89%)]\tLoss: 0.006491\n",
      "Train Epoch: 45 [9216/9728 (95%)]\tLoss: 0.007675\n",
      "Average training loss: 0.5877373218536377\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.8308, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 46 [0/39424 (0%)]\tLoss: 8.079783\n",
      "Train Epoch: 46 [512/39424 (1%)]\tLoss: 0.712322\n",
      "Train Epoch: 46 [1024/39424 (3%)]\tLoss: 0.592629\n",
      "Train Epoch: 46 [1536/39424 (4%)]\tLoss: 0.504508\n",
      "Train Epoch: 46 [2048/39424 (5%)]\tLoss: 0.417288\n",
      "Train Epoch: 46 [2560/39424 (6%)]\tLoss: 0.347710\n",
      "Train Epoch: 46 [3072/39424 (8%)]\tLoss: 0.359507\n",
      "Train Epoch: 46 [3584/39424 (9%)]\tLoss: 0.307046\n",
      "Train Epoch: 46 [4096/39424 (10%)]\tLoss: 0.285587\n",
      "Train Epoch: 46 [4608/39424 (12%)]\tLoss: 0.291579\n",
      "Train Epoch: 46 [5120/39424 (13%)]\tLoss: 0.259493\n",
      "Train Epoch: 46 [5632/39424 (14%)]\tLoss: 0.248444\n",
      "Train Epoch: 46 [6144/39424 (16%)]\tLoss: 0.223302\n",
      "Train Epoch: 46 [6656/39424 (17%)]\tLoss: 0.242039\n",
      "Train Epoch: 46 [7168/39424 (18%)]\tLoss: 0.235360\n",
      "Train Epoch: 46 [7680/39424 (19%)]\tLoss: 0.226904\n",
      "Train Epoch: 46 [8192/39424 (21%)]\tLoss: 0.187186\n",
      "Train Epoch: 46 [8704/39424 (22%)]\tLoss: 0.189629\n",
      "Train Epoch: 46 [9216/39424 (23%)]\tLoss: 0.228935\n",
      "Train Epoch: 46 [9728/39424 (25%)]\tLoss: 0.230505\n",
      "Train Epoch: 46 [10240/39424 (26%)]\tLoss: 0.192665\n",
      "Train Epoch: 46 [10752/39424 (27%)]\tLoss: 0.225994\n",
      "Train Epoch: 46 [11264/39424 (29%)]\tLoss: 0.179241\n",
      "Train Epoch: 46 [11776/39424 (30%)]\tLoss: 0.168738\n",
      "Train Epoch: 46 [12288/39424 (31%)]\tLoss: 0.188755\n",
      "Train Epoch: 46 [12800/39424 (32%)]\tLoss: 0.173256\n",
      "Train Epoch: 46 [13312/39424 (34%)]\tLoss: 0.187860\n",
      "Train Epoch: 46 [13824/39424 (35%)]\tLoss: 0.189042\n",
      "Train Epoch: 46 [14336/39424 (36%)]\tLoss: 0.186616\n",
      "Train Epoch: 46 [14848/39424 (38%)]\tLoss: 0.171777\n",
      "Train Epoch: 46 [15360/39424 (39%)]\tLoss: 0.168876\n",
      "Train Epoch: 46 [15872/39424 (40%)]\tLoss: 0.175942\n",
      "Train Epoch: 46 [16384/39424 (42%)]\tLoss: 0.173835\n",
      "Train Epoch: 46 [16896/39424 (43%)]\tLoss: 0.215808\n",
      "Train Epoch: 46 [17408/39424 (44%)]\tLoss: 0.169685\n",
      "Train Epoch: 46 [17920/39424 (45%)]\tLoss: 0.227883\n",
      "Train Epoch: 46 [18432/39424 (47%)]\tLoss: 0.177143\n",
      "Train Epoch: 46 [18944/39424 (48%)]\tLoss: 0.144464\n",
      "Train Epoch: 46 [19456/39424 (49%)]\tLoss: 0.156901\n",
      "Train Epoch: 46 [19968/39424 (51%)]\tLoss: 0.125165\n",
      "Train Epoch: 46 [20480/39424 (52%)]\tLoss: 0.134811\n",
      "Train Epoch: 46 [20992/39424 (53%)]\tLoss: 0.202975\n",
      "Train Epoch: 46 [21504/39424 (55%)]\tLoss: 0.111931\n",
      "Train Epoch: 46 [22016/39424 (56%)]\tLoss: 0.142416\n",
      "Train Epoch: 46 [22528/39424 (57%)]\tLoss: 0.130866\n",
      "Train Epoch: 46 [23040/39424 (58%)]\tLoss: 0.195393\n",
      "Train Epoch: 46 [23552/39424 (60%)]\tLoss: 0.133773\n",
      "Train Epoch: 46 [24064/39424 (61%)]\tLoss: 0.160036\n",
      "Train Epoch: 46 [24576/39424 (62%)]\tLoss: 0.152258\n",
      "Train Epoch: 46 [25088/39424 (64%)]\tLoss: 0.142661\n",
      "Train Epoch: 46 [25600/39424 (65%)]\tLoss: 0.151214\n",
      "Train Epoch: 46 [26112/39424 (66%)]\tLoss: 0.129217\n",
      "Train Epoch: 46 [26624/39424 (68%)]\tLoss: 0.162719\n",
      "Train Epoch: 46 [27136/39424 (69%)]\tLoss: 0.163411\n",
      "Train Epoch: 46 [27648/39424 (70%)]\tLoss: 0.178837\n",
      "Train Epoch: 46 [28160/39424 (71%)]\tLoss: 0.117618\n",
      "Train Epoch: 46 [28672/39424 (73%)]\tLoss: 0.143808\n",
      "Train Epoch: 46 [29184/39424 (74%)]\tLoss: 0.146900\n",
      "Train Epoch: 46 [29696/39424 (75%)]\tLoss: 0.142111\n",
      "Train Epoch: 46 [30208/39424 (77%)]\tLoss: 0.156125\n",
      "Train Epoch: 46 [30720/39424 (78%)]\tLoss: 0.159893\n",
      "Train Epoch: 46 [31232/39424 (79%)]\tLoss: 0.183353\n",
      "Train Epoch: 46 [31744/39424 (81%)]\tLoss: 0.167433\n",
      "Train Epoch: 46 [32256/39424 (82%)]\tLoss: 0.128175\n",
      "Train Epoch: 46 [32768/39424 (83%)]\tLoss: 0.140454\n",
      "Train Epoch: 46 [33280/39424 (84%)]\tLoss: 0.151130\n",
      "Train Epoch: 46 [33792/39424 (86%)]\tLoss: 0.110897\n",
      "Train Epoch: 46 [34304/39424 (87%)]\tLoss: 0.102748\n",
      "Train Epoch: 46 [34816/39424 (88%)]\tLoss: 0.119792\n",
      "Train Epoch: 46 [35328/39424 (90%)]\tLoss: 0.127669\n",
      "Train Epoch: 46 [35840/39424 (91%)]\tLoss: 0.108357\n",
      "Train Epoch: 46 [36352/39424 (92%)]\tLoss: 0.135382\n",
      "Train Epoch: 46 [36864/39424 (94%)]\tLoss: 0.114316\n",
      "Train Epoch: 46 [37376/39424 (95%)]\tLoss: 0.146495\n",
      "Train Epoch: 46 [37888/39424 (96%)]\tLoss: 0.145966\n",
      "Train Epoch: 46 [38400/39424 (97%)]\tLoss: 0.133826\n",
      "Train Epoch: 46 [38912/39424 (99%)]\tLoss: 0.132604\n",
      "Average training loss: 0.2997010350227356\n",
      "\n",
      "Test set: Average loss: 8.2470, Accuracy: 68/12630 (1%)\n",
      "\n",
      "tensor([0.0054,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3159, Accuracy: 11716/12630 (93%)\n",
      "\n",
      "tensor([0.3667, 0.9514, 0.9813, 0.9556, 0.9167, 0.8905, 0.8000, 0.8800, 0.9267,\n",
      "        0.9875, 0.9864, 0.9571, 0.9754, 0.9944, 1.0000, 0.9762, 0.9800, 0.9417,\n",
      "        0.7923, 0.8000, 0.9778, 0.6000, 0.9167, 0.9333, 0.8556, 0.9312, 0.7944,\n",
      "        0.5000, 0.9467, 0.9667, 0.7200, 0.9741, 0.6167, 0.9857, 0.9833, 0.9410,\n",
      "        0.8833, 0.9833, 0.9449, 0.7444, 0.8333, 0.8500, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 46 [0/9728 (0%)]\tLoss: 7.888869\n",
      "Train Epoch: 46 [512/9728 (5%)]\tLoss: 2.710799\n",
      "Train Epoch: 46 [1024/9728 (11%)]\tLoss: 0.139769\n",
      "Train Epoch: 46 [1536/9728 (16%)]\tLoss: 0.060403\n",
      "Train Epoch: 46 [2048/9728 (21%)]\tLoss: 0.034796\n",
      "Train Epoch: 46 [2560/9728 (26%)]\tLoss: 0.031043\n",
      "Train Epoch: 46 [3072/9728 (32%)]\tLoss: 0.023327\n",
      "Train Epoch: 46 [3584/9728 (37%)]\tLoss: 0.022793\n",
      "Train Epoch: 46 [4096/9728 (42%)]\tLoss: 0.010809\n",
      "Train Epoch: 46 [4608/9728 (47%)]\tLoss: 0.013965\n",
      "Train Epoch: 46 [5120/9728 (53%)]\tLoss: 0.011329\n",
      "Train Epoch: 46 [5632/9728 (58%)]\tLoss: 0.008228\n",
      "Train Epoch: 46 [6144/9728 (63%)]\tLoss: 0.009934\n",
      "Train Epoch: 46 [6656/9728 (68%)]\tLoss: 0.009093\n",
      "Train Epoch: 46 [7168/9728 (74%)]\tLoss: 0.007374\n",
      "Train Epoch: 46 [7680/9728 (79%)]\tLoss: 0.004355\n",
      "Train Epoch: 46 [8192/9728 (84%)]\tLoss: 0.005438\n",
      "Train Epoch: 46 [8704/9728 (89%)]\tLoss: 0.006549\n",
      "Train Epoch: 46 [9216/9728 (95%)]\tLoss: 0.005266\n",
      "Average training loss: 0.5791653990745544\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.7110, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 47 [0/39424 (0%)]\tLoss: 7.866252\n",
      "Train Epoch: 47 [512/39424 (1%)]\tLoss: 0.580469\n",
      "Train Epoch: 47 [1024/39424 (3%)]\tLoss: 0.391672\n",
      "Train Epoch: 47 [1536/39424 (4%)]\tLoss: 0.374701\n",
      "Train Epoch: 47 [2048/39424 (5%)]\tLoss: 0.300651\n",
      "Train Epoch: 47 [2560/39424 (6%)]\tLoss: 0.270068\n",
      "Train Epoch: 47 [3072/39424 (8%)]\tLoss: 0.301283\n",
      "Train Epoch: 47 [3584/39424 (9%)]\tLoss: 0.256690\n",
      "Train Epoch: 47 [4096/39424 (10%)]\tLoss: 0.242159\n",
      "Train Epoch: 47 [4608/39424 (12%)]\tLoss: 0.241310\n",
      "Train Epoch: 47 [5120/39424 (13%)]\tLoss: 0.226130\n",
      "Train Epoch: 47 [5632/39424 (14%)]\tLoss: 0.244336\n",
      "Train Epoch: 47 [6144/39424 (16%)]\tLoss: 0.215235\n",
      "Train Epoch: 47 [6656/39424 (17%)]\tLoss: 0.227159\n",
      "Train Epoch: 47 [7168/39424 (18%)]\tLoss: 0.220711\n",
      "Train Epoch: 47 [7680/39424 (19%)]\tLoss: 0.223757\n",
      "Train Epoch: 47 [8192/39424 (21%)]\tLoss: 0.170501\n",
      "Train Epoch: 47 [8704/39424 (22%)]\tLoss: 0.198855\n",
      "Train Epoch: 47 [9216/39424 (23%)]\tLoss: 0.218583\n",
      "Train Epoch: 47 [9728/39424 (25%)]\tLoss: 0.208638\n",
      "Train Epoch: 47 [10240/39424 (26%)]\tLoss: 0.193316\n",
      "Train Epoch: 47 [10752/39424 (27%)]\tLoss: 0.233201\n",
      "Train Epoch: 47 [11264/39424 (29%)]\tLoss: 0.185070\n",
      "Train Epoch: 47 [11776/39424 (30%)]\tLoss: 0.168344\n",
      "Train Epoch: 47 [12288/39424 (31%)]\tLoss: 0.169378\n",
      "Train Epoch: 47 [12800/39424 (32%)]\tLoss: 0.168216\n",
      "Train Epoch: 47 [13312/39424 (34%)]\tLoss: 0.185530\n",
      "Train Epoch: 47 [13824/39424 (35%)]\tLoss: 0.179994\n",
      "Train Epoch: 47 [14336/39424 (36%)]\tLoss: 0.167237\n",
      "Train Epoch: 47 [14848/39424 (38%)]\tLoss: 0.163731\n",
      "Train Epoch: 47 [15360/39424 (39%)]\tLoss: 0.172856\n",
      "Train Epoch: 47 [15872/39424 (40%)]\tLoss: 0.179013\n",
      "Train Epoch: 47 [16384/39424 (42%)]\tLoss: 0.173705\n",
      "Train Epoch: 47 [16896/39424 (43%)]\tLoss: 0.228548\n",
      "Train Epoch: 47 [17408/39424 (44%)]\tLoss: 0.179229\n",
      "Train Epoch: 47 [17920/39424 (45%)]\tLoss: 0.223150\n",
      "Train Epoch: 47 [18432/39424 (47%)]\tLoss: 0.174688\n",
      "Train Epoch: 47 [18944/39424 (48%)]\tLoss: 0.136997\n",
      "Train Epoch: 47 [19456/39424 (49%)]\tLoss: 0.156499\n",
      "Train Epoch: 47 [19968/39424 (51%)]\tLoss: 0.124290\n",
      "Train Epoch: 47 [20480/39424 (52%)]\tLoss: 0.144511\n",
      "Train Epoch: 47 [20992/39424 (53%)]\tLoss: 0.208038\n",
      "Train Epoch: 47 [21504/39424 (55%)]\tLoss: 0.120720\n",
      "Train Epoch: 47 [22016/39424 (56%)]\tLoss: 0.133996\n",
      "Train Epoch: 47 [22528/39424 (57%)]\tLoss: 0.113080\n",
      "Train Epoch: 47 [23040/39424 (58%)]\tLoss: 0.187443\n",
      "Train Epoch: 47 [23552/39424 (60%)]\tLoss: 0.120444\n",
      "Train Epoch: 47 [24064/39424 (61%)]\tLoss: 0.135486\n",
      "Train Epoch: 47 [24576/39424 (62%)]\tLoss: 0.144983\n",
      "Train Epoch: 47 [25088/39424 (64%)]\tLoss: 0.131465\n",
      "Train Epoch: 47 [25600/39424 (65%)]\tLoss: 0.148388\n",
      "Train Epoch: 47 [26112/39424 (66%)]\tLoss: 0.118384\n",
      "Train Epoch: 47 [26624/39424 (68%)]\tLoss: 0.166983\n",
      "Train Epoch: 47 [27136/39424 (69%)]\tLoss: 0.167480\n",
      "Train Epoch: 47 [27648/39424 (70%)]\tLoss: 0.176470\n",
      "Train Epoch: 47 [28160/39424 (71%)]\tLoss: 0.125704\n",
      "Train Epoch: 47 [28672/39424 (73%)]\tLoss: 0.142711\n",
      "Train Epoch: 47 [29184/39424 (74%)]\tLoss: 0.144367\n",
      "Train Epoch: 47 [29696/39424 (75%)]\tLoss: 0.142941\n",
      "Train Epoch: 47 [30208/39424 (77%)]\tLoss: 0.147546\n",
      "Train Epoch: 47 [30720/39424 (78%)]\tLoss: 0.146452\n",
      "Train Epoch: 47 [31232/39424 (79%)]\tLoss: 0.181427\n",
      "Train Epoch: 47 [31744/39424 (81%)]\tLoss: 0.178702\n",
      "Train Epoch: 47 [32256/39424 (82%)]\tLoss: 0.124465\n",
      "Train Epoch: 47 [32768/39424 (83%)]\tLoss: 0.127559\n",
      "Train Epoch: 47 [33280/39424 (84%)]\tLoss: 0.140661\n",
      "Train Epoch: 47 [33792/39424 (86%)]\tLoss: 0.105928\n",
      "Train Epoch: 47 [34304/39424 (87%)]\tLoss: 0.108362\n",
      "Train Epoch: 47 [34816/39424 (88%)]\tLoss: 0.136649\n",
      "Train Epoch: 47 [35328/39424 (90%)]\tLoss: 0.124592\n",
      "Train Epoch: 47 [35840/39424 (91%)]\tLoss: 0.120042\n",
      "Train Epoch: 47 [36352/39424 (92%)]\tLoss: 0.125662\n",
      "Train Epoch: 47 [36864/39424 (94%)]\tLoss: 0.114286\n",
      "Train Epoch: 47 [37376/39424 (95%)]\tLoss: 0.144212\n",
      "Train Epoch: 47 [37888/39424 (96%)]\tLoss: 0.153370\n",
      "Train Epoch: 47 [38400/39424 (97%)]\tLoss: 0.112478\n",
      "Train Epoch: 47 [38912/39424 (99%)]\tLoss: 0.126993\n",
      "Average training loss: 0.2822744846343994\n",
      "\n",
      "Test set: Average loss: 8.1840, Accuracy: 63/12630 (0%)\n",
      "\n",
      "tensor([0.0050,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3125, Accuracy: 11730/12630 (93%)\n",
      "\n",
      "tensor([0.3167, 0.9514, 0.9800, 0.9644, 0.9182, 0.8889, 0.8000, 0.8822, 0.9311,\n",
      "        0.9875, 0.9864, 0.9595, 0.9754, 0.9944, 1.0000, 0.9714, 0.9867, 0.9417,\n",
      "        0.7923, 0.8167, 0.9778, 0.6333, 0.9167, 0.9400, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9467, 0.9667, 0.7067, 0.9815, 0.6000, 0.9905, 0.9833, 0.9487,\n",
      "        0.9000, 0.9833, 0.9435, 0.7444, 0.8444, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 47 [0/9728 (0%)]\tLoss: 7.888075\n",
      "Train Epoch: 47 [512/9728 (5%)]\tLoss: 2.794705\n",
      "Train Epoch: 47 [1024/9728 (11%)]\tLoss: 0.128319\n",
      "Train Epoch: 47 [1536/9728 (16%)]\tLoss: 0.064932\n",
      "Train Epoch: 47 [2048/9728 (21%)]\tLoss: 0.039340\n",
      "Train Epoch: 47 [2560/9728 (26%)]\tLoss: 0.030955\n",
      "Train Epoch: 47 [3072/9728 (32%)]\tLoss: 0.019676\n",
      "Train Epoch: 47 [3584/9728 (37%)]\tLoss: 0.020421\n",
      "Train Epoch: 47 [4096/9728 (42%)]\tLoss: 0.012828\n",
      "Train Epoch: 47 [4608/9728 (47%)]\tLoss: 0.011682\n",
      "Train Epoch: 47 [5120/9728 (53%)]\tLoss: 0.011325\n",
      "Train Epoch: 47 [5632/9728 (58%)]\tLoss: 0.008298\n",
      "Train Epoch: 47 [6144/9728 (63%)]\tLoss: 0.010971\n",
      "Train Epoch: 47 [6656/9728 (68%)]\tLoss: 0.009317\n",
      "Train Epoch: 47 [7168/9728 (74%)]\tLoss: 0.007851\n",
      "Train Epoch: 47 [7680/9728 (79%)]\tLoss: 0.007386\n",
      "Train Epoch: 47 [8192/9728 (84%)]\tLoss: 0.007568\n",
      "Train Epoch: 47 [8704/9728 (89%)]\tLoss: 0.005965\n",
      "Train Epoch: 47 [9216/9728 (95%)]\tLoss: 0.007830\n",
      "Average training loss: 0.5835496783256531\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.7966, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 48 [0/39424 (0%)]\tLoss: 8.009091\n",
      "Train Epoch: 48 [512/39424 (1%)]\tLoss: 0.638150\n",
      "Train Epoch: 48 [1024/39424 (3%)]\tLoss: 0.519810\n",
      "Train Epoch: 48 [1536/39424 (4%)]\tLoss: 0.444827\n",
      "Train Epoch: 48 [2048/39424 (5%)]\tLoss: 0.371002\n",
      "Train Epoch: 48 [2560/39424 (6%)]\tLoss: 0.318246\n",
      "Train Epoch: 48 [3072/39424 (8%)]\tLoss: 0.339229\n",
      "Train Epoch: 48 [3584/39424 (9%)]\tLoss: 0.274574\n",
      "Train Epoch: 48 [4096/39424 (10%)]\tLoss: 0.249043\n",
      "Train Epoch: 48 [4608/39424 (12%)]\tLoss: 0.248694\n",
      "Train Epoch: 48 [5120/39424 (13%)]\tLoss: 0.221812\n",
      "Train Epoch: 48 [5632/39424 (14%)]\tLoss: 0.236708\n",
      "Train Epoch: 48 [6144/39424 (16%)]\tLoss: 0.214640\n",
      "Train Epoch: 48 [6656/39424 (17%)]\tLoss: 0.228628\n",
      "Train Epoch: 48 [7168/39424 (18%)]\tLoss: 0.230184\n",
      "Train Epoch: 48 [7680/39424 (19%)]\tLoss: 0.218249\n",
      "Train Epoch: 48 [8192/39424 (21%)]\tLoss: 0.173595\n",
      "Train Epoch: 48 [8704/39424 (22%)]\tLoss: 0.186556\n",
      "Train Epoch: 48 [9216/39424 (23%)]\tLoss: 0.230053\n",
      "Train Epoch: 48 [9728/39424 (25%)]\tLoss: 0.206255\n",
      "Train Epoch: 48 [10240/39424 (26%)]\tLoss: 0.174531\n",
      "Train Epoch: 48 [10752/39424 (27%)]\tLoss: 0.212757\n",
      "Train Epoch: 48 [11264/39424 (29%)]\tLoss: 0.169095\n",
      "Train Epoch: 48 [11776/39424 (30%)]\tLoss: 0.170065\n",
      "Train Epoch: 48 [12288/39424 (31%)]\tLoss: 0.176603\n",
      "Train Epoch: 48 [12800/39424 (32%)]\tLoss: 0.160108\n",
      "Train Epoch: 48 [13312/39424 (34%)]\tLoss: 0.179819\n",
      "Train Epoch: 48 [13824/39424 (35%)]\tLoss: 0.170308\n",
      "Train Epoch: 48 [14336/39424 (36%)]\tLoss: 0.158999\n",
      "Train Epoch: 48 [14848/39424 (38%)]\tLoss: 0.170887\n",
      "Train Epoch: 48 [15360/39424 (39%)]\tLoss: 0.163095\n",
      "Train Epoch: 48 [15872/39424 (40%)]\tLoss: 0.179161\n",
      "Train Epoch: 48 [16384/39424 (42%)]\tLoss: 0.189678\n",
      "Train Epoch: 48 [16896/39424 (43%)]\tLoss: 0.192821\n",
      "Train Epoch: 48 [17408/39424 (44%)]\tLoss: 0.174086\n",
      "Train Epoch: 48 [17920/39424 (45%)]\tLoss: 0.220341\n",
      "Train Epoch: 48 [18432/39424 (47%)]\tLoss: 0.157729\n",
      "Train Epoch: 48 [18944/39424 (48%)]\tLoss: 0.130672\n",
      "Train Epoch: 48 [19456/39424 (49%)]\tLoss: 0.160180\n",
      "Train Epoch: 48 [19968/39424 (51%)]\tLoss: 0.124992\n",
      "Train Epoch: 48 [20480/39424 (52%)]\tLoss: 0.129824\n",
      "Train Epoch: 48 [20992/39424 (53%)]\tLoss: 0.178252\n",
      "Train Epoch: 48 [21504/39424 (55%)]\tLoss: 0.110387\n",
      "Train Epoch: 48 [22016/39424 (56%)]\tLoss: 0.126982\n",
      "Train Epoch: 48 [22528/39424 (57%)]\tLoss: 0.127070\n",
      "Train Epoch: 48 [23040/39424 (58%)]\tLoss: 0.181005\n",
      "Train Epoch: 48 [23552/39424 (60%)]\tLoss: 0.123620\n",
      "Train Epoch: 48 [24064/39424 (61%)]\tLoss: 0.143555\n",
      "Train Epoch: 48 [24576/39424 (62%)]\tLoss: 0.144145\n",
      "Train Epoch: 48 [25088/39424 (64%)]\tLoss: 0.126060\n",
      "Train Epoch: 48 [25600/39424 (65%)]\tLoss: 0.139590\n",
      "Train Epoch: 48 [26112/39424 (66%)]\tLoss: 0.127433\n",
      "Train Epoch: 48 [26624/39424 (68%)]\tLoss: 0.161777\n",
      "Train Epoch: 48 [27136/39424 (69%)]\tLoss: 0.159817\n",
      "Train Epoch: 48 [27648/39424 (70%)]\tLoss: 0.169991\n",
      "Train Epoch: 48 [28160/39424 (71%)]\tLoss: 0.119374\n",
      "Train Epoch: 48 [28672/39424 (73%)]\tLoss: 0.131028\n",
      "Train Epoch: 48 [29184/39424 (74%)]\tLoss: 0.153728\n",
      "Train Epoch: 48 [29696/39424 (75%)]\tLoss: 0.133619\n",
      "Train Epoch: 48 [30208/39424 (77%)]\tLoss: 0.150831\n",
      "Train Epoch: 48 [30720/39424 (78%)]\tLoss: 0.119879\n",
      "Train Epoch: 48 [31232/39424 (79%)]\tLoss: 0.176767\n",
      "Train Epoch: 48 [31744/39424 (81%)]\tLoss: 0.163859\n",
      "Train Epoch: 48 [32256/39424 (82%)]\tLoss: 0.116839\n",
      "Train Epoch: 48 [32768/39424 (83%)]\tLoss: 0.135933\n",
      "Train Epoch: 48 [33280/39424 (84%)]\tLoss: 0.128824\n",
      "Train Epoch: 48 [33792/39424 (86%)]\tLoss: 0.102113\n",
      "Train Epoch: 48 [34304/39424 (87%)]\tLoss: 0.091099\n",
      "Train Epoch: 48 [34816/39424 (88%)]\tLoss: 0.117367\n",
      "Train Epoch: 48 [35328/39424 (90%)]\tLoss: 0.107303\n",
      "Train Epoch: 48 [35840/39424 (91%)]\tLoss: 0.125315\n",
      "Train Epoch: 48 [36352/39424 (92%)]\tLoss: 0.125842\n",
      "Train Epoch: 48 [36864/39424 (94%)]\tLoss: 0.121185\n",
      "Train Epoch: 48 [37376/39424 (95%)]\tLoss: 0.129441\n",
      "Train Epoch: 48 [37888/39424 (96%)]\tLoss: 0.136699\n",
      "Train Epoch: 48 [38400/39424 (97%)]\tLoss: 0.127329\n",
      "Train Epoch: 48 [38912/39424 (99%)]\tLoss: 0.124100\n",
      "Average training loss: 0.2854968011379242\n",
      "\n",
      "Test set: Average loss: 8.1946, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([0.0048,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3090, Accuracy: 11745/12630 (93%)\n",
      "\n",
      "tensor([0.3500, 0.9542, 0.9800, 0.9689, 0.9182, 0.8921, 0.8000, 0.8756, 0.9289,\n",
      "        0.9875, 0.9848, 0.9619, 0.9768, 0.9958, 1.0000, 0.9762, 0.9867, 0.9417,\n",
      "        0.7949, 0.8833, 0.9778, 0.6222, 0.9167, 0.9400, 0.8556, 0.9292, 0.7944,\n",
      "        0.5000, 0.9533, 0.9667, 0.7333, 0.9778, 0.6167, 0.9905, 0.9833, 0.9436,\n",
      "        0.8833, 0.9833, 0.9464, 0.7667, 0.8444, 0.8500, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 48 [0/9728 (0%)]\tLoss: 7.897487\n",
      "Train Epoch: 48 [512/9728 (5%)]\tLoss: 2.752974\n",
      "Train Epoch: 48 [1024/9728 (11%)]\tLoss: 0.128225\n",
      "Train Epoch: 48 [1536/9728 (16%)]\tLoss: 0.065454\n",
      "Train Epoch: 48 [2048/9728 (21%)]\tLoss: 0.030028\n",
      "Train Epoch: 48 [2560/9728 (26%)]\tLoss: 0.027763\n",
      "Train Epoch: 48 [3072/9728 (32%)]\tLoss: 0.026546\n",
      "Train Epoch: 48 [3584/9728 (37%)]\tLoss: 0.017794\n",
      "Train Epoch: 48 [4096/9728 (42%)]\tLoss: 0.010978\n",
      "Train Epoch: 48 [4608/9728 (47%)]\tLoss: 0.011791\n",
      "Train Epoch: 48 [5120/9728 (53%)]\tLoss: 0.014004\n",
      "Train Epoch: 48 [5632/9728 (58%)]\tLoss: 0.008983\n",
      "Train Epoch: 48 [6144/9728 (63%)]\tLoss: 0.008937\n",
      "Train Epoch: 48 [6656/9728 (68%)]\tLoss: 0.011658\n",
      "Train Epoch: 48 [7168/9728 (74%)]\tLoss: 0.007352\n",
      "Train Epoch: 48 [7680/9728 (79%)]\tLoss: 0.005587\n",
      "Train Epoch: 48 [8192/9728 (84%)]\tLoss: 0.004987\n",
      "Train Epoch: 48 [8704/9728 (89%)]\tLoss: 0.007299\n",
      "Train Epoch: 48 [9216/9728 (95%)]\tLoss: 0.007484\n",
      "Average training loss: 0.581333339214325\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.5940, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 49 [0/39424 (0%)]\tLoss: 7.723584\n",
      "Train Epoch: 49 [512/39424 (1%)]\tLoss: 0.567014\n",
      "Train Epoch: 49 [1024/39424 (3%)]\tLoss: 0.408248\n",
      "Train Epoch: 49 [1536/39424 (4%)]\tLoss: 0.354363\n",
      "Train Epoch: 49 [2048/39424 (5%)]\tLoss: 0.294326\n",
      "Train Epoch: 49 [2560/39424 (6%)]\tLoss: 0.254279\n",
      "Train Epoch: 49 [3072/39424 (8%)]\tLoss: 0.293122\n",
      "Train Epoch: 49 [3584/39424 (9%)]\tLoss: 0.268415\n",
      "Train Epoch: 49 [4096/39424 (10%)]\tLoss: 0.237902\n",
      "Train Epoch: 49 [4608/39424 (12%)]\tLoss: 0.231198\n",
      "Train Epoch: 49 [5120/39424 (13%)]\tLoss: 0.213217\n",
      "Train Epoch: 49 [5632/39424 (14%)]\tLoss: 0.230728\n",
      "Train Epoch: 49 [6144/39424 (16%)]\tLoss: 0.204818\n",
      "Train Epoch: 49 [6656/39424 (17%)]\tLoss: 0.224038\n",
      "Train Epoch: 49 [7168/39424 (18%)]\tLoss: 0.209077\n",
      "Train Epoch: 49 [7680/39424 (19%)]\tLoss: 0.226511\n",
      "Train Epoch: 49 [8192/39424 (21%)]\tLoss: 0.163891\n",
      "Train Epoch: 49 [8704/39424 (22%)]\tLoss: 0.164195\n",
      "Train Epoch: 49 [9216/39424 (23%)]\tLoss: 0.219436\n",
      "Train Epoch: 49 [9728/39424 (25%)]\tLoss: 0.203438\n",
      "Train Epoch: 49 [10240/39424 (26%)]\tLoss: 0.169336\n",
      "Train Epoch: 49 [10752/39424 (27%)]\tLoss: 0.214779\n",
      "Train Epoch: 49 [11264/39424 (29%)]\tLoss: 0.162004\n",
      "Train Epoch: 49 [11776/39424 (30%)]\tLoss: 0.169091\n",
      "Train Epoch: 49 [12288/39424 (31%)]\tLoss: 0.179819\n",
      "Train Epoch: 49 [12800/39424 (32%)]\tLoss: 0.165456\n",
      "Train Epoch: 49 [13312/39424 (34%)]\tLoss: 0.165799\n",
      "Train Epoch: 49 [13824/39424 (35%)]\tLoss: 0.192703\n",
      "Train Epoch: 49 [14336/39424 (36%)]\tLoss: 0.168022\n",
      "Train Epoch: 49 [14848/39424 (38%)]\tLoss: 0.159029\n",
      "Train Epoch: 49 [15360/39424 (39%)]\tLoss: 0.156309\n",
      "Train Epoch: 49 [15872/39424 (40%)]\tLoss: 0.168175\n",
      "Train Epoch: 49 [16384/39424 (42%)]\tLoss: 0.176120\n",
      "Train Epoch: 49 [16896/39424 (43%)]\tLoss: 0.197170\n",
      "Train Epoch: 49 [17408/39424 (44%)]\tLoss: 0.170099\n",
      "Train Epoch: 49 [17920/39424 (45%)]\tLoss: 0.193584\n",
      "Train Epoch: 49 [18432/39424 (47%)]\tLoss: 0.154400\n",
      "Train Epoch: 49 [18944/39424 (48%)]\tLoss: 0.138071\n",
      "Train Epoch: 49 [19456/39424 (49%)]\tLoss: 0.141668\n",
      "Train Epoch: 49 [19968/39424 (51%)]\tLoss: 0.111189\n",
      "Train Epoch: 49 [20480/39424 (52%)]\tLoss: 0.138732\n",
      "Train Epoch: 49 [20992/39424 (53%)]\tLoss: 0.182666\n",
      "Train Epoch: 49 [21504/39424 (55%)]\tLoss: 0.117413\n",
      "Train Epoch: 49 [22016/39424 (56%)]\tLoss: 0.134300\n",
      "Train Epoch: 49 [22528/39424 (57%)]\tLoss: 0.124294\n",
      "Train Epoch: 49 [23040/39424 (58%)]\tLoss: 0.172431\n",
      "Train Epoch: 49 [23552/39424 (60%)]\tLoss: 0.125872\n",
      "Train Epoch: 49 [24064/39424 (61%)]\tLoss: 0.133096\n",
      "Train Epoch: 49 [24576/39424 (62%)]\tLoss: 0.140322\n",
      "Train Epoch: 49 [25088/39424 (64%)]\tLoss: 0.130428\n",
      "Train Epoch: 49 [25600/39424 (65%)]\tLoss: 0.142442\n",
      "Train Epoch: 49 [26112/39424 (66%)]\tLoss: 0.124317\n",
      "Train Epoch: 49 [26624/39424 (68%)]\tLoss: 0.146066\n",
      "Train Epoch: 49 [27136/39424 (69%)]\tLoss: 0.151333\n",
      "Train Epoch: 49 [27648/39424 (70%)]\tLoss: 0.164280\n",
      "Train Epoch: 49 [28160/39424 (71%)]\tLoss: 0.117496\n",
      "Train Epoch: 49 [28672/39424 (73%)]\tLoss: 0.129970\n",
      "Train Epoch: 49 [29184/39424 (74%)]\tLoss: 0.139571\n",
      "Train Epoch: 49 [29696/39424 (75%)]\tLoss: 0.127755\n",
      "Train Epoch: 49 [30208/39424 (77%)]\tLoss: 0.144261\n",
      "Train Epoch: 49 [30720/39424 (78%)]\tLoss: 0.160721\n",
      "Train Epoch: 49 [31232/39424 (79%)]\tLoss: 0.174313\n",
      "Train Epoch: 49 [31744/39424 (81%)]\tLoss: 0.148729\n",
      "Train Epoch: 49 [32256/39424 (82%)]\tLoss: 0.122371\n",
      "Train Epoch: 49 [32768/39424 (83%)]\tLoss: 0.135543\n",
      "Train Epoch: 49 [33280/39424 (84%)]\tLoss: 0.137843\n",
      "Train Epoch: 49 [33792/39424 (86%)]\tLoss: 0.093887\n",
      "Train Epoch: 49 [34304/39424 (87%)]\tLoss: 0.088807\n",
      "Train Epoch: 49 [34816/39424 (88%)]\tLoss: 0.108190\n",
      "Train Epoch: 49 [35328/39424 (90%)]\tLoss: 0.127275\n",
      "Train Epoch: 49 [35840/39424 (91%)]\tLoss: 0.106965\n",
      "Train Epoch: 49 [36352/39424 (92%)]\tLoss: 0.124487\n",
      "Train Epoch: 49 [36864/39424 (94%)]\tLoss: 0.115271\n",
      "Train Epoch: 49 [37376/39424 (95%)]\tLoss: 0.137644\n",
      "Train Epoch: 49 [37888/39424 (96%)]\tLoss: 0.146756\n",
      "Train Epoch: 49 [38400/39424 (97%)]\tLoss: 0.110039\n",
      "Train Epoch: 49 [38912/39424 (99%)]\tLoss: 0.118583\n",
      "Average training loss: 0.27258557081222534\n",
      "\n",
      "Test set: Average loss: 8.0866, Accuracy: 55/12630 (0%)\n",
      "\n",
      "tensor([0.0044,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3057, Accuracy: 11742/12630 (93%)\n",
      "\n",
      "tensor([0.2667, 0.9569, 0.9800, 0.9578, 0.9182, 0.9000, 0.8000, 0.8800, 0.9378,\n",
      "        0.9875, 0.9864, 0.9548, 0.9754, 0.9944, 1.0000, 0.9762, 0.9867, 0.9417,\n",
      "        0.7974, 0.8833, 0.9778, 0.6000, 0.9167, 0.9333, 0.8667, 0.9312, 0.7944,\n",
      "        0.5000, 0.9533, 0.9667, 0.7333, 0.9778, 0.6000, 0.9905, 0.9833, 0.9436,\n",
      "        0.9000, 0.9833, 0.9449, 0.7556, 0.8444, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 49 [0/9728 (0%)]\tLoss: 7.716254\n",
      "Train Epoch: 49 [512/9728 (5%)]\tLoss: 2.677235\n",
      "Train Epoch: 49 [1024/9728 (11%)]\tLoss: 0.129017\n",
      "Train Epoch: 49 [1536/9728 (16%)]\tLoss: 0.074064\n",
      "Train Epoch: 49 [2048/9728 (21%)]\tLoss: 0.035600\n",
      "Train Epoch: 49 [2560/9728 (26%)]\tLoss: 0.029006\n",
      "Train Epoch: 49 [3072/9728 (32%)]\tLoss: 0.021694\n",
      "Train Epoch: 49 [3584/9728 (37%)]\tLoss: 0.018986\n",
      "Train Epoch: 49 [4096/9728 (42%)]\tLoss: 0.012019\n",
      "Train Epoch: 49 [4608/9728 (47%)]\tLoss: 0.011791\n",
      "Train Epoch: 49 [5120/9728 (53%)]\tLoss: 0.011117\n",
      "Train Epoch: 49 [5632/9728 (58%)]\tLoss: 0.008842\n",
      "Train Epoch: 49 [6144/9728 (63%)]\tLoss: 0.008007\n",
      "Train Epoch: 49 [6656/9728 (68%)]\tLoss: 0.009210\n",
      "Train Epoch: 49 [7168/9728 (74%)]\tLoss: 0.007338\n",
      "Train Epoch: 49 [7680/9728 (79%)]\tLoss: 0.005899\n",
      "Train Epoch: 49 [8192/9728 (84%)]\tLoss: 0.005088\n",
      "Train Epoch: 49 [8704/9728 (89%)]\tLoss: 0.006068\n",
      "Train Epoch: 49 [9216/9728 (95%)]\tLoss: 0.005319\n",
      "Average training loss: 0.5680291056632996\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.8065, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 50 [0/39424 (0%)]\tLoss: 7.923429\n",
      "Train Epoch: 50 [512/39424 (1%)]\tLoss: 0.638363\n",
      "Train Epoch: 50 [1024/39424 (3%)]\tLoss: 0.534334\n",
      "Train Epoch: 50 [1536/39424 (4%)]\tLoss: 0.482623\n",
      "Train Epoch: 50 [2048/39424 (5%)]\tLoss: 0.374125\n",
      "Train Epoch: 50 [2560/39424 (6%)]\tLoss: 0.319162\n",
      "Train Epoch: 50 [3072/39424 (8%)]\tLoss: 0.355957\n",
      "Train Epoch: 50 [3584/39424 (9%)]\tLoss: 0.290286\n",
      "Train Epoch: 50 [4096/39424 (10%)]\tLoss: 0.289939\n",
      "Train Epoch: 50 [4608/39424 (12%)]\tLoss: 0.256195\n",
      "Train Epoch: 50 [5120/39424 (13%)]\tLoss: 0.250656\n",
      "Train Epoch: 50 [5632/39424 (14%)]\tLoss: 0.241157\n",
      "Train Epoch: 50 [6144/39424 (16%)]\tLoss: 0.206679\n",
      "Train Epoch: 50 [6656/39424 (17%)]\tLoss: 0.220410\n",
      "Train Epoch: 50 [7168/39424 (18%)]\tLoss: 0.230779\n",
      "Train Epoch: 50 [7680/39424 (19%)]\tLoss: 0.211798\n",
      "Train Epoch: 50 [8192/39424 (21%)]\tLoss: 0.158928\n",
      "Train Epoch: 50 [8704/39424 (22%)]\tLoss: 0.182661\n",
      "Train Epoch: 50 [9216/39424 (23%)]\tLoss: 0.212900\n",
      "Train Epoch: 50 [9728/39424 (25%)]\tLoss: 0.203174\n",
      "Train Epoch: 50 [10240/39424 (26%)]\tLoss: 0.176392\n",
      "Train Epoch: 50 [10752/39424 (27%)]\tLoss: 0.210165\n",
      "Train Epoch: 50 [11264/39424 (29%)]\tLoss: 0.169049\n",
      "Train Epoch: 50 [11776/39424 (30%)]\tLoss: 0.155412\n",
      "Train Epoch: 50 [12288/39424 (31%)]\tLoss: 0.167596\n",
      "Train Epoch: 50 [12800/39424 (32%)]\tLoss: 0.151798\n",
      "Train Epoch: 50 [13312/39424 (34%)]\tLoss: 0.178200\n",
      "Train Epoch: 50 [13824/39424 (35%)]\tLoss: 0.174248\n",
      "Train Epoch: 50 [14336/39424 (36%)]\tLoss: 0.163588\n",
      "Train Epoch: 50 [14848/39424 (38%)]\tLoss: 0.170498\n",
      "Train Epoch: 50 [15360/39424 (39%)]\tLoss: 0.163064\n",
      "Train Epoch: 50 [15872/39424 (40%)]\tLoss: 0.156598\n",
      "Train Epoch: 50 [16384/39424 (42%)]\tLoss: 0.161485\n",
      "Train Epoch: 50 [16896/39424 (43%)]\tLoss: 0.192126\n",
      "Train Epoch: 50 [17408/39424 (44%)]\tLoss: 0.158211\n",
      "Train Epoch: 50 [17920/39424 (45%)]\tLoss: 0.206844\n",
      "Train Epoch: 50 [18432/39424 (47%)]\tLoss: 0.152887\n",
      "Train Epoch: 50 [18944/39424 (48%)]\tLoss: 0.138155\n",
      "Train Epoch: 50 [19456/39424 (49%)]\tLoss: 0.156150\n",
      "Train Epoch: 50 [19968/39424 (51%)]\tLoss: 0.104822\n",
      "Train Epoch: 50 [20480/39424 (52%)]\tLoss: 0.129051\n",
      "Train Epoch: 50 [20992/39424 (53%)]\tLoss: 0.168360\n",
      "Train Epoch: 50 [21504/39424 (55%)]\tLoss: 0.106972\n",
      "Train Epoch: 50 [22016/39424 (56%)]\tLoss: 0.130063\n",
      "Train Epoch: 50 [22528/39424 (57%)]\tLoss: 0.119942\n",
      "Train Epoch: 50 [23040/39424 (58%)]\tLoss: 0.180560\n",
      "Train Epoch: 50 [23552/39424 (60%)]\tLoss: 0.126106\n",
      "Train Epoch: 50 [24064/39424 (61%)]\tLoss: 0.126422\n",
      "Train Epoch: 50 [24576/39424 (62%)]\tLoss: 0.137579\n",
      "Train Epoch: 50 [25088/39424 (64%)]\tLoss: 0.132853\n",
      "Train Epoch: 50 [25600/39424 (65%)]\tLoss: 0.127008\n",
      "Train Epoch: 50 [26112/39424 (66%)]\tLoss: 0.114066\n",
      "Train Epoch: 50 [26624/39424 (68%)]\tLoss: 0.141794\n",
      "Train Epoch: 50 [27136/39424 (69%)]\tLoss: 0.151334\n",
      "Train Epoch: 50 [27648/39424 (70%)]\tLoss: 0.169140\n",
      "Train Epoch: 50 [28160/39424 (71%)]\tLoss: 0.105883\n",
      "Train Epoch: 50 [28672/39424 (73%)]\tLoss: 0.117235\n",
      "Train Epoch: 50 [29184/39424 (74%)]\tLoss: 0.131794\n",
      "Train Epoch: 50 [29696/39424 (75%)]\tLoss: 0.138709\n",
      "Train Epoch: 50 [30208/39424 (77%)]\tLoss: 0.143938\n",
      "Train Epoch: 50 [30720/39424 (78%)]\tLoss: 0.134166\n",
      "Train Epoch: 50 [31232/39424 (79%)]\tLoss: 0.161216\n",
      "Train Epoch: 50 [31744/39424 (81%)]\tLoss: 0.159743\n",
      "Train Epoch: 50 [32256/39424 (82%)]\tLoss: 0.137435\n",
      "Train Epoch: 50 [32768/39424 (83%)]\tLoss: 0.123220\n",
      "Train Epoch: 50 [33280/39424 (84%)]\tLoss: 0.126382\n",
      "Train Epoch: 50 [33792/39424 (86%)]\tLoss: 0.091597\n",
      "Train Epoch: 50 [34304/39424 (87%)]\tLoss: 0.098592\n",
      "Train Epoch: 50 [34816/39424 (88%)]\tLoss: 0.111983\n",
      "Train Epoch: 50 [35328/39424 (90%)]\tLoss: 0.124951\n",
      "Train Epoch: 50 [35840/39424 (91%)]\tLoss: 0.108570\n",
      "Train Epoch: 50 [36352/39424 (92%)]\tLoss: 0.123448\n",
      "Train Epoch: 50 [36864/39424 (94%)]\tLoss: 0.095693\n",
      "Train Epoch: 50 [37376/39424 (95%)]\tLoss: 0.131263\n",
      "Train Epoch: 50 [37888/39424 (96%)]\tLoss: 0.140207\n",
      "Train Epoch: 50 [38400/39424 (97%)]\tLoss: 0.121119\n",
      "Train Epoch: 50 [38912/39424 (99%)]\tLoss: 0.130841\n",
      "Average training loss: 0.28194913268089294\n",
      "\n",
      "Test set: Average loss: 8.1213, Accuracy: 69/12630 (1%)\n",
      "\n",
      "tensor([0.0055,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.3014, Accuracy: 11765/12630 (93%)\n",
      "\n",
      "tensor([0.3833, 0.9542, 0.9827, 0.9489, 0.9242, 0.9000, 0.7933, 0.8844, 0.9311,\n",
      "        0.9854, 0.9879, 0.9571, 0.9812, 0.9958, 1.0000, 0.9762, 0.9867, 0.9417,\n",
      "        0.7923, 0.8833, 0.9778, 0.6444, 0.9167, 0.9400, 0.8667, 0.9333, 0.7944,\n",
      "        0.5000, 0.9467, 0.9667, 0.7333, 0.9815, 0.6167, 0.9857, 0.9833, 0.9513,\n",
      "        0.9000, 0.9833, 0.9478, 0.7556, 0.8556, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 50 [0/9728 (0%)]\tLoss: 7.747822\n",
      "Train Epoch: 50 [512/9728 (5%)]\tLoss: 2.611000\n",
      "Train Epoch: 50 [1024/9728 (11%)]\tLoss: 0.114790\n",
      "Train Epoch: 50 [1536/9728 (16%)]\tLoss: 0.054370\n",
      "Train Epoch: 50 [2048/9728 (21%)]\tLoss: 0.036319\n",
      "Train Epoch: 50 [2560/9728 (26%)]\tLoss: 0.024507\n",
      "Train Epoch: 50 [3072/9728 (32%)]\tLoss: 0.025106\n",
      "Train Epoch: 50 [3584/9728 (37%)]\tLoss: 0.019361\n",
      "Train Epoch: 50 [4096/9728 (42%)]\tLoss: 0.015614\n",
      "Train Epoch: 50 [4608/9728 (47%)]\tLoss: 0.009862\n",
      "Train Epoch: 50 [5120/9728 (53%)]\tLoss: 0.011716\n",
      "Train Epoch: 50 [5632/9728 (58%)]\tLoss: 0.007965\n",
      "Train Epoch: 50 [6144/9728 (63%)]\tLoss: 0.007444\n",
      "Train Epoch: 50 [6656/9728 (68%)]\tLoss: 0.008770\n",
      "Train Epoch: 50 [7168/9728 (74%)]\tLoss: 0.008863\n",
      "Train Epoch: 50 [7680/9728 (79%)]\tLoss: 0.005462\n",
      "Train Epoch: 50 [8192/9728 (84%)]\tLoss: 0.005392\n",
      "Train Epoch: 50 [8704/9728 (89%)]\tLoss: 0.007724\n",
      "Train Epoch: 50 [9216/9728 (95%)]\tLoss: 0.005278\n",
      "Average training loss: 0.5645981431007385\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.6261, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 51 [0/39424 (0%)]\tLoss: 7.794956\n",
      "Train Epoch: 51 [512/39424 (1%)]\tLoss: 0.529985\n",
      "Train Epoch: 51 [1024/39424 (3%)]\tLoss: 0.401636\n",
      "Train Epoch: 51 [1536/39424 (4%)]\tLoss: 0.338489\n",
      "Train Epoch: 51 [2048/39424 (5%)]\tLoss: 0.288265\n",
      "Train Epoch: 51 [2560/39424 (6%)]\tLoss: 0.242384\n",
      "Train Epoch: 51 [3072/39424 (8%)]\tLoss: 0.287394\n",
      "Train Epoch: 51 [3584/39424 (9%)]\tLoss: 0.249840\n",
      "Train Epoch: 51 [4096/39424 (10%)]\tLoss: 0.222127\n",
      "Train Epoch: 51 [4608/39424 (12%)]\tLoss: 0.229417\n",
      "Train Epoch: 51 [5120/39424 (13%)]\tLoss: 0.213084\n",
      "Train Epoch: 51 [5632/39424 (14%)]\tLoss: 0.227661\n",
      "Train Epoch: 51 [6144/39424 (16%)]\tLoss: 0.194251\n",
      "Train Epoch: 51 [6656/39424 (17%)]\tLoss: 0.209203\n",
      "Train Epoch: 51 [7168/39424 (18%)]\tLoss: 0.204055\n",
      "Train Epoch: 51 [7680/39424 (19%)]\tLoss: 0.207715\n",
      "Train Epoch: 51 [8192/39424 (21%)]\tLoss: 0.162611\n",
      "Train Epoch: 51 [8704/39424 (22%)]\tLoss: 0.168678\n",
      "Train Epoch: 51 [9216/39424 (23%)]\tLoss: 0.194477\n",
      "Train Epoch: 51 [9728/39424 (25%)]\tLoss: 0.191478\n",
      "Train Epoch: 51 [10240/39424 (26%)]\tLoss: 0.161378\n",
      "Train Epoch: 51 [10752/39424 (27%)]\tLoss: 0.198970\n",
      "Train Epoch: 51 [11264/39424 (29%)]\tLoss: 0.164887\n",
      "Train Epoch: 51 [11776/39424 (30%)]\tLoss: 0.155115\n",
      "Train Epoch: 51 [12288/39424 (31%)]\tLoss: 0.159964\n",
      "Train Epoch: 51 [12800/39424 (32%)]\tLoss: 0.162106\n",
      "Train Epoch: 51 [13312/39424 (34%)]\tLoss: 0.159999\n",
      "Train Epoch: 51 [13824/39424 (35%)]\tLoss: 0.184175\n",
      "Train Epoch: 51 [14336/39424 (36%)]\tLoss: 0.160178\n",
      "Train Epoch: 51 [14848/39424 (38%)]\tLoss: 0.161941\n",
      "Train Epoch: 51 [15360/39424 (39%)]\tLoss: 0.153645\n",
      "Train Epoch: 51 [15872/39424 (40%)]\tLoss: 0.159221\n",
      "Train Epoch: 51 [16384/39424 (42%)]\tLoss: 0.168889\n",
      "Train Epoch: 51 [16896/39424 (43%)]\tLoss: 0.183921\n",
      "Train Epoch: 51 [17408/39424 (44%)]\tLoss: 0.152310\n",
      "Train Epoch: 51 [17920/39424 (45%)]\tLoss: 0.191177\n",
      "Train Epoch: 51 [18432/39424 (47%)]\tLoss: 0.166419\n",
      "Train Epoch: 51 [18944/39424 (48%)]\tLoss: 0.131015\n",
      "Train Epoch: 51 [19456/39424 (49%)]\tLoss: 0.148831\n",
      "Train Epoch: 51 [19968/39424 (51%)]\tLoss: 0.098035\n",
      "Train Epoch: 51 [20480/39424 (52%)]\tLoss: 0.124054\n",
      "Train Epoch: 51 [20992/39424 (53%)]\tLoss: 0.175763\n",
      "Train Epoch: 51 [21504/39424 (55%)]\tLoss: 0.115769\n",
      "Train Epoch: 51 [22016/39424 (56%)]\tLoss: 0.111789\n",
      "Train Epoch: 51 [22528/39424 (57%)]\tLoss: 0.128997\n",
      "Train Epoch: 51 [23040/39424 (58%)]\tLoss: 0.171413\n",
      "Train Epoch: 51 [23552/39424 (60%)]\tLoss: 0.115991\n",
      "Train Epoch: 51 [24064/39424 (61%)]\tLoss: 0.127840\n",
      "Train Epoch: 51 [24576/39424 (62%)]\tLoss: 0.127690\n",
      "Train Epoch: 51 [25088/39424 (64%)]\tLoss: 0.115845\n",
      "Train Epoch: 51 [25600/39424 (65%)]\tLoss: 0.149028\n",
      "Train Epoch: 51 [26112/39424 (66%)]\tLoss: 0.111016\n",
      "Train Epoch: 51 [26624/39424 (68%)]\tLoss: 0.149217\n",
      "Train Epoch: 51 [27136/39424 (69%)]\tLoss: 0.137794\n",
      "Train Epoch: 51 [27648/39424 (70%)]\tLoss: 0.151774\n",
      "Train Epoch: 51 [28160/39424 (71%)]\tLoss: 0.113704\n",
      "Train Epoch: 51 [28672/39424 (73%)]\tLoss: 0.125332\n",
      "Train Epoch: 51 [29184/39424 (74%)]\tLoss: 0.141191\n",
      "Train Epoch: 51 [29696/39424 (75%)]\tLoss: 0.140085\n",
      "Train Epoch: 51 [30208/39424 (77%)]\tLoss: 0.129226\n",
      "Train Epoch: 51 [30720/39424 (78%)]\tLoss: 0.127858\n",
      "Train Epoch: 51 [31232/39424 (79%)]\tLoss: 0.165296\n",
      "Train Epoch: 51 [31744/39424 (81%)]\tLoss: 0.128815\n",
      "Train Epoch: 51 [32256/39424 (82%)]\tLoss: 0.114320\n",
      "Train Epoch: 51 [32768/39424 (83%)]\tLoss: 0.140585\n",
      "Train Epoch: 51 [33280/39424 (84%)]\tLoss: 0.120464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [33792/39424 (86%)]\tLoss: 0.088077\n",
      "Train Epoch: 51 [34304/39424 (87%)]\tLoss: 0.092392\n",
      "Train Epoch: 51 [34816/39424 (88%)]\tLoss: 0.115892\n",
      "Train Epoch: 51 [35328/39424 (90%)]\tLoss: 0.114694\n",
      "Train Epoch: 51 [35840/39424 (91%)]\tLoss: 0.135289\n",
      "Train Epoch: 51 [36352/39424 (92%)]\tLoss: 0.113156\n",
      "Train Epoch: 51 [36864/39424 (94%)]\tLoss: 0.104084\n",
      "Train Epoch: 51 [37376/39424 (95%)]\tLoss: 0.118229\n",
      "Train Epoch: 51 [37888/39424 (96%)]\tLoss: 0.136069\n",
      "Train Epoch: 51 [38400/39424 (97%)]\tLoss: 0.106572\n",
      "Train Epoch: 51 [38912/39424 (99%)]\tLoss: 0.119475\n",
      "Average training loss: 0.2660347819328308\n",
      "\n",
      "Test set: Average loss: 8.1245, Accuracy: 56/12630 (0%)\n",
      "\n",
      "tensor([0.0044,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2982, Accuracy: 11777/12630 (93%)\n",
      "\n",
      "tensor([0.2833, 0.9569, 0.9813, 0.9556, 0.9242, 0.9063, 0.8000, 0.8889, 0.9533,\n",
      "        0.9875, 0.9864, 0.9548, 0.9739, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.7974, 0.9167, 0.9889, 0.6333, 0.9167, 0.9400, 0.8667, 0.9312, 0.8000,\n",
      "        0.5000, 0.9533, 0.9667, 0.7333, 0.9815, 0.6000, 0.9905, 0.9833, 0.9410,\n",
      "        0.9000, 0.9833, 0.9507, 0.7444, 0.8444, 0.8833, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 51 [0/9728 (0%)]\tLoss: 7.874542\n",
      "Train Epoch: 51 [512/9728 (5%)]\tLoss: 2.637541\n",
      "Train Epoch: 51 [1024/9728 (11%)]\tLoss: 0.142713\n",
      "Train Epoch: 51 [1536/9728 (16%)]\tLoss: 0.070557\n",
      "Train Epoch: 51 [2048/9728 (21%)]\tLoss: 0.036831\n",
      "Train Epoch: 51 [2560/9728 (26%)]\tLoss: 0.039903\n",
      "Train Epoch: 51 [3072/9728 (32%)]\tLoss: 0.022430\n",
      "Train Epoch: 51 [3584/9728 (37%)]\tLoss: 0.021900\n",
      "Train Epoch: 51 [4096/9728 (42%)]\tLoss: 0.016240\n",
      "Train Epoch: 51 [4608/9728 (47%)]\tLoss: 0.012381\n",
      "Train Epoch: 51 [5120/9728 (53%)]\tLoss: 0.011269\n",
      "Train Epoch: 51 [5632/9728 (58%)]\tLoss: 0.007201\n",
      "Train Epoch: 51 [6144/9728 (63%)]\tLoss: 0.009680\n",
      "Train Epoch: 51 [6656/9728 (68%)]\tLoss: 0.009352\n",
      "Train Epoch: 51 [7168/9728 (74%)]\tLoss: 0.006767\n",
      "Train Epoch: 51 [7680/9728 (79%)]\tLoss: 0.006445\n",
      "Train Epoch: 51 [8192/9728 (84%)]\tLoss: 0.004346\n",
      "Train Epoch: 51 [8704/9728 (89%)]\tLoss: 0.007059\n",
      "Train Epoch: 51 [9216/9728 (95%)]\tLoss: 0.006146\n",
      "Average training loss: 0.5759633183479309\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.7530, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 52 [0/39424 (0%)]\tLoss: 7.928569\n",
      "Train Epoch: 52 [512/39424 (1%)]\tLoss: 0.609935\n",
      "Train Epoch: 52 [1024/39424 (3%)]\tLoss: 0.497182\n",
      "Train Epoch: 52 [1536/39424 (4%)]\tLoss: 0.434734\n",
      "Train Epoch: 52 [2048/39424 (5%)]\tLoss: 0.360543\n",
      "Train Epoch: 52 [2560/39424 (6%)]\tLoss: 0.298015\n",
      "Train Epoch: 52 [3072/39424 (8%)]\tLoss: 0.319387\n",
      "Train Epoch: 52 [3584/39424 (9%)]\tLoss: 0.272597\n",
      "Train Epoch: 52 [4096/39424 (10%)]\tLoss: 0.249736\n",
      "Train Epoch: 52 [4608/39424 (12%)]\tLoss: 0.237795\n",
      "Train Epoch: 52 [5120/39424 (13%)]\tLoss: 0.220322\n",
      "Train Epoch: 52 [5632/39424 (14%)]\tLoss: 0.236493\n",
      "Train Epoch: 52 [6144/39424 (16%)]\tLoss: 0.201821\n",
      "Train Epoch: 52 [6656/39424 (17%)]\tLoss: 0.210851\n",
      "Train Epoch: 52 [7168/39424 (18%)]\tLoss: 0.222246\n",
      "Train Epoch: 52 [7680/39424 (19%)]\tLoss: 0.216577\n",
      "Train Epoch: 52 [8192/39424 (21%)]\tLoss: 0.158431\n",
      "Train Epoch: 52 [8704/39424 (22%)]\tLoss: 0.180677\n",
      "Train Epoch: 52 [9216/39424 (23%)]\tLoss: 0.194835\n",
      "Train Epoch: 52 [9728/39424 (25%)]\tLoss: 0.196382\n",
      "Train Epoch: 52 [10240/39424 (26%)]\tLoss: 0.164875\n",
      "Train Epoch: 52 [10752/39424 (27%)]\tLoss: 0.213658\n",
      "Train Epoch: 52 [11264/39424 (29%)]\tLoss: 0.157775\n",
      "Train Epoch: 52 [11776/39424 (30%)]\tLoss: 0.151806\n",
      "Train Epoch: 52 [12288/39424 (31%)]\tLoss: 0.164166\n",
      "Train Epoch: 52 [12800/39424 (32%)]\tLoss: 0.147866\n",
      "Train Epoch: 52 [13312/39424 (34%)]\tLoss: 0.178029\n",
      "Train Epoch: 52 [13824/39424 (35%)]\tLoss: 0.169678\n",
      "Train Epoch: 52 [14336/39424 (36%)]\tLoss: 0.151010\n",
      "Train Epoch: 52 [14848/39424 (38%)]\tLoss: 0.157057\n",
      "Train Epoch: 52 [15360/39424 (39%)]\tLoss: 0.158253\n",
      "Train Epoch: 52 [15872/39424 (40%)]\tLoss: 0.157187\n",
      "Train Epoch: 52 [16384/39424 (42%)]\tLoss: 0.154163\n",
      "Train Epoch: 52 [16896/39424 (43%)]\tLoss: 0.181164\n",
      "Train Epoch: 52 [17408/39424 (44%)]\tLoss: 0.158004\n",
      "Train Epoch: 52 [17920/39424 (45%)]\tLoss: 0.187960\n",
      "Train Epoch: 52 [18432/39424 (47%)]\tLoss: 0.142934\n",
      "Train Epoch: 52 [18944/39424 (48%)]\tLoss: 0.132272\n",
      "Train Epoch: 52 [19456/39424 (49%)]\tLoss: 0.148169\n",
      "Train Epoch: 52 [19968/39424 (51%)]\tLoss: 0.103973\n",
      "Train Epoch: 52 [20480/39424 (52%)]\tLoss: 0.115176\n",
      "Train Epoch: 52 [20992/39424 (53%)]\tLoss: 0.162874\n",
      "Train Epoch: 52 [21504/39424 (55%)]\tLoss: 0.102531\n",
      "Train Epoch: 52 [22016/39424 (56%)]\tLoss: 0.107159\n",
      "Train Epoch: 52 [22528/39424 (57%)]\tLoss: 0.120369\n",
      "Train Epoch: 52 [23040/39424 (58%)]\tLoss: 0.162788\n",
      "Train Epoch: 52 [23552/39424 (60%)]\tLoss: 0.120519\n",
      "Train Epoch: 52 [24064/39424 (61%)]\tLoss: 0.125793\n",
      "Train Epoch: 52 [24576/39424 (62%)]\tLoss: 0.132793\n",
      "Train Epoch: 52 [25088/39424 (64%)]\tLoss: 0.125651\n",
      "Train Epoch: 52 [25600/39424 (65%)]\tLoss: 0.133569\n",
      "Train Epoch: 52 [26112/39424 (66%)]\tLoss: 0.121740\n",
      "Train Epoch: 52 [26624/39424 (68%)]\tLoss: 0.137843\n",
      "Train Epoch: 52 [27136/39424 (69%)]\tLoss: 0.144519\n",
      "Train Epoch: 52 [27648/39424 (70%)]\tLoss: 0.140377\n",
      "Train Epoch: 52 [28160/39424 (71%)]\tLoss: 0.113196\n",
      "Train Epoch: 52 [28672/39424 (73%)]\tLoss: 0.115752\n",
      "Train Epoch: 52 [29184/39424 (74%)]\tLoss: 0.136074\n",
      "Train Epoch: 52 [29696/39424 (75%)]\tLoss: 0.117140\n",
      "Train Epoch: 52 [30208/39424 (77%)]\tLoss: 0.132865\n",
      "Train Epoch: 52 [30720/39424 (78%)]\tLoss: 0.131681\n",
      "Train Epoch: 52 [31232/39424 (79%)]\tLoss: 0.168500\n",
      "Train Epoch: 52 [31744/39424 (81%)]\tLoss: 0.145586\n",
      "Train Epoch: 52 [32256/39424 (82%)]\tLoss: 0.110486\n",
      "Train Epoch: 52 [32768/39424 (83%)]\tLoss: 0.132409\n",
      "Train Epoch: 52 [33280/39424 (84%)]\tLoss: 0.124611\n",
      "Train Epoch: 52 [33792/39424 (86%)]\tLoss: 0.080929\n",
      "Train Epoch: 52 [34304/39424 (87%)]\tLoss: 0.083606\n",
      "Train Epoch: 52 [34816/39424 (88%)]\tLoss: 0.101474\n",
      "Train Epoch: 52 [35328/39424 (90%)]\tLoss: 0.122857\n",
      "Train Epoch: 52 [35840/39424 (91%)]\tLoss: 0.106331\n",
      "Train Epoch: 52 [36352/39424 (92%)]\tLoss: 0.114626\n",
      "Train Epoch: 52 [36864/39424 (94%)]\tLoss: 0.094306\n",
      "Train Epoch: 52 [37376/39424 (95%)]\tLoss: 0.107237\n",
      "Train Epoch: 52 [37888/39424 (96%)]\tLoss: 0.118202\n",
      "Train Epoch: 52 [38400/39424 (97%)]\tLoss: 0.102285\n",
      "Train Epoch: 52 [38912/39424 (99%)]\tLoss: 0.118903\n",
      "Average training loss: 0.27220627665519714\n",
      "\n",
      "Test set: Average loss: 8.1139, Accuracy: 66/12630 (1%)\n",
      "\n",
      "tensor([0.0052,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2952, Accuracy: 11791/12630 (93%)\n",
      "\n",
      "tensor([0.3667, 0.9583, 0.9827, 0.9533, 0.9242, 0.9016, 0.8000, 0.8956, 0.9556,\n",
      "        0.9875, 0.9864, 0.9571, 0.9797, 0.9958, 1.0000, 0.9762, 0.9867, 0.9417,\n",
      "        0.7949, 0.9333, 0.9889, 0.6333, 0.9167, 0.9400, 0.8667, 0.9333, 0.8111,\n",
      "        0.5000, 0.9400, 0.9667, 0.7333, 0.9815, 0.6167, 0.9905, 0.9833, 0.9410,\n",
      "        0.9000, 0.9833, 0.9507, 0.7667, 0.8444, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 52 [0/9728 (0%)]\tLoss: 7.750840\n",
      "Train Epoch: 52 [512/9728 (5%)]\tLoss: 2.652204\n",
      "Train Epoch: 52 [1024/9728 (11%)]\tLoss: 0.141453\n",
      "Train Epoch: 52 [1536/9728 (16%)]\tLoss: 0.076352\n",
      "Train Epoch: 52 [2048/9728 (21%)]\tLoss: 0.029273\n",
      "Train Epoch: 52 [2560/9728 (26%)]\tLoss: 0.030873\n",
      "Train Epoch: 52 [3072/9728 (32%)]\tLoss: 0.028093\n",
      "Train Epoch: 52 [3584/9728 (37%)]\tLoss: 0.021203\n",
      "Train Epoch: 52 [4096/9728 (42%)]\tLoss: 0.012338\n",
      "Train Epoch: 52 [4608/9728 (47%)]\tLoss: 0.013618\n",
      "Train Epoch: 52 [5120/9728 (53%)]\tLoss: 0.011653\n",
      "Train Epoch: 52 [5632/9728 (58%)]\tLoss: 0.010010\n",
      "Train Epoch: 52 [6144/9728 (63%)]\tLoss: 0.009562\n",
      "Train Epoch: 52 [6656/9728 (68%)]\tLoss: 0.010322\n",
      "Train Epoch: 52 [7168/9728 (74%)]\tLoss: 0.008686\n",
      "Train Epoch: 52 [7680/9728 (79%)]\tLoss: 0.008554\n",
      "Train Epoch: 52 [8192/9728 (84%)]\tLoss: 0.005495\n",
      "Train Epoch: 52 [8704/9728 (89%)]\tLoss: 0.007833\n",
      "Train Epoch: 52 [9216/9728 (95%)]\tLoss: 0.004683\n",
      "Average training loss: 0.5701603293418884\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.5198, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 53 [0/39424 (0%)]\tLoss: 7.618710\n",
      "Train Epoch: 53 [512/39424 (1%)]\tLoss: 0.495843\n",
      "Train Epoch: 53 [1024/39424 (3%)]\tLoss: 0.384454\n",
      "Train Epoch: 53 [1536/39424 (4%)]\tLoss: 0.330884\n",
      "Train Epoch: 53 [2048/39424 (5%)]\tLoss: 0.280456\n",
      "Train Epoch: 53 [2560/39424 (6%)]\tLoss: 0.243194\n",
      "Train Epoch: 53 [3072/39424 (8%)]\tLoss: 0.288169\n",
      "Train Epoch: 53 [3584/39424 (9%)]\tLoss: 0.248212\n",
      "Train Epoch: 53 [4096/39424 (10%)]\tLoss: 0.224676\n",
      "Train Epoch: 53 [4608/39424 (12%)]\tLoss: 0.232080\n",
      "Train Epoch: 53 [5120/39424 (13%)]\tLoss: 0.198750\n",
      "Train Epoch: 53 [5632/39424 (14%)]\tLoss: 0.226635\n",
      "Train Epoch: 53 [6144/39424 (16%)]\tLoss: 0.185227\n",
      "Train Epoch: 53 [6656/39424 (17%)]\tLoss: 0.207327\n",
      "Train Epoch: 53 [7168/39424 (18%)]\tLoss: 0.208410\n",
      "Train Epoch: 53 [7680/39424 (19%)]\tLoss: 0.208242\n",
      "Train Epoch: 53 [8192/39424 (21%)]\tLoss: 0.164071\n",
      "Train Epoch: 53 [8704/39424 (22%)]\tLoss: 0.166846\n",
      "Train Epoch: 53 [9216/39424 (23%)]\tLoss: 0.201410\n",
      "Train Epoch: 53 [9728/39424 (25%)]\tLoss: 0.183080\n",
      "Train Epoch: 53 [10240/39424 (26%)]\tLoss: 0.165164\n",
      "Train Epoch: 53 [10752/39424 (27%)]\tLoss: 0.199934\n",
      "Train Epoch: 53 [11264/39424 (29%)]\tLoss: 0.156452\n",
      "Train Epoch: 53 [11776/39424 (30%)]\tLoss: 0.156045\n",
      "Train Epoch: 53 [12288/39424 (31%)]\tLoss: 0.164209\n",
      "Train Epoch: 53 [12800/39424 (32%)]\tLoss: 0.144194\n",
      "Train Epoch: 53 [13312/39424 (34%)]\tLoss: 0.157594\n",
      "Train Epoch: 53 [13824/39424 (35%)]\tLoss: 0.175874\n",
      "Train Epoch: 53 [14336/39424 (36%)]\tLoss: 0.150143\n",
      "Train Epoch: 53 [14848/39424 (38%)]\tLoss: 0.147225\n",
      "Train Epoch: 53 [15360/39424 (39%)]\tLoss: 0.159784\n",
      "Train Epoch: 53 [15872/39424 (40%)]\tLoss: 0.147484\n",
      "Train Epoch: 53 [16384/39424 (42%)]\tLoss: 0.150574\n",
      "Train Epoch: 53 [16896/39424 (43%)]\tLoss: 0.184664\n",
      "Train Epoch: 53 [17408/39424 (44%)]\tLoss: 0.159681\n",
      "Train Epoch: 53 [17920/39424 (45%)]\tLoss: 0.186963\n",
      "Train Epoch: 53 [18432/39424 (47%)]\tLoss: 0.134758\n",
      "Train Epoch: 53 [18944/39424 (48%)]\tLoss: 0.120353\n",
      "Train Epoch: 53 [19456/39424 (49%)]\tLoss: 0.138117\n",
      "Train Epoch: 53 [19968/39424 (51%)]\tLoss: 0.104009\n",
      "Train Epoch: 53 [20480/39424 (52%)]\tLoss: 0.124234\n",
      "Train Epoch: 53 [20992/39424 (53%)]\tLoss: 0.153030\n",
      "Train Epoch: 53 [21504/39424 (55%)]\tLoss: 0.098963\n",
      "Train Epoch: 53 [22016/39424 (56%)]\tLoss: 0.111394\n",
      "Train Epoch: 53 [22528/39424 (57%)]\tLoss: 0.106477\n",
      "Train Epoch: 53 [23040/39424 (58%)]\tLoss: 0.169947\n",
      "Train Epoch: 53 [23552/39424 (60%)]\tLoss: 0.120480\n",
      "Train Epoch: 53 [24064/39424 (61%)]\tLoss: 0.125134\n",
      "Train Epoch: 53 [24576/39424 (62%)]\tLoss: 0.130578\n",
      "Train Epoch: 53 [25088/39424 (64%)]\tLoss: 0.121238\n",
      "Train Epoch: 53 [25600/39424 (65%)]\tLoss: 0.123244\n",
      "Train Epoch: 53 [26112/39424 (66%)]\tLoss: 0.110239\n",
      "Train Epoch: 53 [26624/39424 (68%)]\tLoss: 0.143554\n",
      "Train Epoch: 53 [27136/39424 (69%)]\tLoss: 0.146721\n",
      "Train Epoch: 53 [27648/39424 (70%)]\tLoss: 0.137104\n",
      "Train Epoch: 53 [28160/39424 (71%)]\tLoss: 0.106443\n",
      "Train Epoch: 53 [28672/39424 (73%)]\tLoss: 0.126908\n",
      "Train Epoch: 53 [29184/39424 (74%)]\tLoss: 0.131311\n",
      "Train Epoch: 53 [29696/39424 (75%)]\tLoss: 0.128675\n",
      "Train Epoch: 53 [30208/39424 (77%)]\tLoss: 0.127029\n",
      "Train Epoch: 53 [30720/39424 (78%)]\tLoss: 0.126861\n",
      "Train Epoch: 53 [31232/39424 (79%)]\tLoss: 0.170548\n",
      "Train Epoch: 53 [31744/39424 (81%)]\tLoss: 0.136698\n",
      "Train Epoch: 53 [32256/39424 (82%)]\tLoss: 0.101488\n",
      "Train Epoch: 53 [32768/39424 (83%)]\tLoss: 0.114905\n",
      "Train Epoch: 53 [33280/39424 (84%)]\tLoss: 0.108470\n",
      "Train Epoch: 53 [33792/39424 (86%)]\tLoss: 0.092331\n",
      "Train Epoch: 53 [34304/39424 (87%)]\tLoss: 0.085644\n",
      "Train Epoch: 53 [34816/39424 (88%)]\tLoss: 0.105464\n",
      "Train Epoch: 53 [35328/39424 (90%)]\tLoss: 0.105889\n",
      "Train Epoch: 53 [35840/39424 (91%)]\tLoss: 0.108096\n",
      "Train Epoch: 53 [36352/39424 (92%)]\tLoss: 0.125898\n",
      "Train Epoch: 53 [36864/39424 (94%)]\tLoss: 0.101253\n",
      "Train Epoch: 53 [37376/39424 (95%)]\tLoss: 0.113281\n",
      "Train Epoch: 53 [37888/39424 (96%)]\tLoss: 0.130304\n",
      "Train Epoch: 53 [38400/39424 (97%)]\tLoss: 0.108740\n",
      "Train Epoch: 53 [38912/39424 (99%)]\tLoss: 0.105795\n",
      "Average training loss: 0.25823721289634705\n",
      "\n",
      "Test set: Average loss: 7.9819, Accuracy: 70/12630 (1%)\n",
      "\n",
      "tensor([0.0055,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2915, Accuracy: 11797/12630 (93%)\n",
      "\n",
      "tensor([0.3833, 0.9583, 0.9800, 0.9578, 0.9242, 0.8984, 0.8000, 0.8956, 0.9578,\n",
      "        0.9875, 0.9864, 0.9595, 0.9768, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.7949, 0.9167, 0.9889, 0.6333, 0.9167, 0.9400, 0.8667, 0.9333, 0.8056,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6167, 0.9905, 0.9833, 0.9513,\n",
      "        0.9083, 0.9833, 0.9522, 0.7667, 0.8444, 0.8833, 0.8778])\n",
      "Train backdoor\n",
      "Train Epoch: 53 [0/9728 (0%)]\tLoss: 7.578736\n",
      "Train Epoch: 53 [512/9728 (5%)]\tLoss: 2.567157\n",
      "Train Epoch: 53 [1024/9728 (11%)]\tLoss: 0.151548\n",
      "Train Epoch: 53 [1536/9728 (16%)]\tLoss: 0.072796\n",
      "Train Epoch: 53 [2048/9728 (21%)]\tLoss: 0.036736\n",
      "Train Epoch: 53 [2560/9728 (26%)]\tLoss: 0.032936\n",
      "Train Epoch: 53 [3072/9728 (32%)]\tLoss: 0.025159\n",
      "Train Epoch: 53 [3584/9728 (37%)]\tLoss: 0.020930\n",
      "Train Epoch: 53 [4096/9728 (42%)]\tLoss: 0.014837\n",
      "Train Epoch: 53 [4608/9728 (47%)]\tLoss: 0.011772\n",
      "Train Epoch: 53 [5120/9728 (53%)]\tLoss: 0.014470\n",
      "Train Epoch: 53 [5632/9728 (58%)]\tLoss: 0.010137\n",
      "Train Epoch: 53 [6144/9728 (63%)]\tLoss: 0.008231\n",
      "Train Epoch: 53 [6656/9728 (68%)]\tLoss: 0.011034\n",
      "Train Epoch: 53 [7168/9728 (74%)]\tLoss: 0.010510\n",
      "Train Epoch: 53 [7680/9728 (79%)]\tLoss: 0.005424\n",
      "Train Epoch: 53 [8192/9728 (84%)]\tLoss: 0.007155\n",
      "Train Epoch: 53 [8704/9728 (89%)]\tLoss: 0.007018\n",
      "Train Epoch: 53 [9216/9728 (95%)]\tLoss: 0.006467\n",
      "Average training loss: 0.557529091835022\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.5246, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 54 [0/39424 (0%)]\tLoss: 7.625450\n",
      "Train Epoch: 54 [512/39424 (1%)]\tLoss: 0.486437\n",
      "Train Epoch: 54 [1024/39424 (3%)]\tLoss: 0.426482\n",
      "Train Epoch: 54 [1536/39424 (4%)]\tLoss: 0.377953\n",
      "Train Epoch: 54 [2048/39424 (5%)]\tLoss: 0.312442\n",
      "Train Epoch: 54 [2560/39424 (6%)]\tLoss: 0.253370\n",
      "Train Epoch: 54 [3072/39424 (8%)]\tLoss: 0.284146\n",
      "Train Epoch: 54 [3584/39424 (9%)]\tLoss: 0.249369\n",
      "Train Epoch: 54 [4096/39424 (10%)]\tLoss: 0.221854\n",
      "Train Epoch: 54 [4608/39424 (12%)]\tLoss: 0.226796\n",
      "Train Epoch: 54 [5120/39424 (13%)]\tLoss: 0.190455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54 [5632/39424 (14%)]\tLoss: 0.204012\n",
      "Train Epoch: 54 [6144/39424 (16%)]\tLoss: 0.187221\n",
      "Train Epoch: 54 [6656/39424 (17%)]\tLoss: 0.199263\n",
      "Train Epoch: 54 [7168/39424 (18%)]\tLoss: 0.196757\n",
      "Train Epoch: 54 [7680/39424 (19%)]\tLoss: 0.195635\n",
      "Train Epoch: 54 [8192/39424 (21%)]\tLoss: 0.155664\n",
      "Train Epoch: 54 [8704/39424 (22%)]\tLoss: 0.167842\n",
      "Train Epoch: 54 [9216/39424 (23%)]\tLoss: 0.190814\n",
      "Train Epoch: 54 [9728/39424 (25%)]\tLoss: 0.179658\n",
      "Train Epoch: 54 [10240/39424 (26%)]\tLoss: 0.154498\n",
      "Train Epoch: 54 [10752/39424 (27%)]\tLoss: 0.205974\n",
      "Train Epoch: 54 [11264/39424 (29%)]\tLoss: 0.156274\n",
      "Train Epoch: 54 [11776/39424 (30%)]\tLoss: 0.148347\n",
      "Train Epoch: 54 [12288/39424 (31%)]\tLoss: 0.159976\n",
      "Train Epoch: 54 [12800/39424 (32%)]\tLoss: 0.149852\n",
      "Train Epoch: 54 [13312/39424 (34%)]\tLoss: 0.167477\n",
      "Train Epoch: 54 [13824/39424 (35%)]\tLoss: 0.171870\n",
      "Train Epoch: 54 [14336/39424 (36%)]\tLoss: 0.145760\n",
      "Train Epoch: 54 [14848/39424 (38%)]\tLoss: 0.146279\n",
      "Train Epoch: 54 [15360/39424 (39%)]\tLoss: 0.139713\n",
      "Train Epoch: 54 [15872/39424 (40%)]\tLoss: 0.133877\n",
      "Train Epoch: 54 [16384/39424 (42%)]\tLoss: 0.142431\n",
      "Train Epoch: 54 [16896/39424 (43%)]\tLoss: 0.170080\n",
      "Train Epoch: 54 [17408/39424 (44%)]\tLoss: 0.157812\n",
      "Train Epoch: 54 [17920/39424 (45%)]\tLoss: 0.182532\n",
      "Train Epoch: 54 [18432/39424 (47%)]\tLoss: 0.128499\n",
      "Train Epoch: 54 [18944/39424 (48%)]\tLoss: 0.115320\n",
      "Train Epoch: 54 [19456/39424 (49%)]\tLoss: 0.126780\n",
      "Train Epoch: 54 [19968/39424 (51%)]\tLoss: 0.117191\n",
      "Train Epoch: 54 [20480/39424 (52%)]\tLoss: 0.120297\n",
      "Train Epoch: 54 [20992/39424 (53%)]\tLoss: 0.152890\n",
      "Train Epoch: 54 [21504/39424 (55%)]\tLoss: 0.107479\n",
      "Train Epoch: 54 [22016/39424 (56%)]\tLoss: 0.116422\n",
      "Train Epoch: 54 [22528/39424 (57%)]\tLoss: 0.101672\n",
      "Train Epoch: 54 [23040/39424 (58%)]\tLoss: 0.159165\n",
      "Train Epoch: 54 [23552/39424 (60%)]\tLoss: 0.107388\n",
      "Train Epoch: 54 [24064/39424 (61%)]\tLoss: 0.136001\n",
      "Train Epoch: 54 [24576/39424 (62%)]\tLoss: 0.132393\n",
      "Train Epoch: 54 [25088/39424 (64%)]\tLoss: 0.118135\n",
      "Train Epoch: 54 [25600/39424 (65%)]\tLoss: 0.130118\n",
      "Train Epoch: 54 [26112/39424 (66%)]\tLoss: 0.104257\n",
      "Train Epoch: 54 [26624/39424 (68%)]\tLoss: 0.127367\n",
      "Train Epoch: 54 [27136/39424 (69%)]\tLoss: 0.131443\n",
      "Train Epoch: 54 [27648/39424 (70%)]\tLoss: 0.127814\n",
      "Train Epoch: 54 [28160/39424 (71%)]\tLoss: 0.107168\n",
      "Train Epoch: 54 [28672/39424 (73%)]\tLoss: 0.115516\n",
      "Train Epoch: 54 [29184/39424 (74%)]\tLoss: 0.128858\n",
      "Train Epoch: 54 [29696/39424 (75%)]\tLoss: 0.121708\n",
      "Train Epoch: 54 [30208/39424 (77%)]\tLoss: 0.108860\n",
      "Train Epoch: 54 [30720/39424 (78%)]\tLoss: 0.118907\n",
      "Train Epoch: 54 [31232/39424 (79%)]\tLoss: 0.142654\n",
      "Train Epoch: 54 [31744/39424 (81%)]\tLoss: 0.152209\n",
      "Train Epoch: 54 [32256/39424 (82%)]\tLoss: 0.095315\n",
      "Train Epoch: 54 [32768/39424 (83%)]\tLoss: 0.122741\n",
      "Train Epoch: 54 [33280/39424 (84%)]\tLoss: 0.110791\n",
      "Train Epoch: 54 [33792/39424 (86%)]\tLoss: 0.088518\n",
      "Train Epoch: 54 [34304/39424 (87%)]\tLoss: 0.086818\n",
      "Train Epoch: 54 [34816/39424 (88%)]\tLoss: 0.106026\n",
      "Train Epoch: 54 [35328/39424 (90%)]\tLoss: 0.105548\n",
      "Train Epoch: 54 [35840/39424 (91%)]\tLoss: 0.093718\n",
      "Train Epoch: 54 [36352/39424 (92%)]\tLoss: 0.114887\n",
      "Train Epoch: 54 [36864/39424 (94%)]\tLoss: 0.108613\n",
      "Train Epoch: 54 [37376/39424 (95%)]\tLoss: 0.122383\n",
      "Train Epoch: 54 [37888/39424 (96%)]\tLoss: 0.117185\n",
      "Train Epoch: 54 [38400/39424 (97%)]\tLoss: 0.109873\n",
      "Train Epoch: 54 [38912/39424 (99%)]\tLoss: 0.107331\n",
      "Average training loss: 0.25598224997520447\n",
      "\n",
      "Test set: Average loss: 7.9829, Accuracy: 72/12630 (1%)\n",
      "\n",
      "tensor([0.0057,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2871, Accuracy: 11804/12630 (93%)\n",
      "\n",
      "tensor([0.4167, 0.9583, 0.9813, 0.9511, 0.9242, 0.9016, 0.8000, 0.8956, 0.9600,\n",
      "        0.9875, 0.9864, 0.9595, 0.9797, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.7897, 0.9500, 0.9889, 0.6222, 0.9167, 0.9400, 0.8667, 0.9333, 0.8167,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6333, 0.9905, 0.9833, 0.9487,\n",
      "        0.9083, 0.9833, 0.9536, 0.7667, 0.8556, 0.8833, 0.8667])\n",
      "Train backdoor\n",
      "Train Epoch: 54 [0/9728 (0%)]\tLoss: 7.541704\n",
      "Train Epoch: 54 [512/9728 (5%)]\tLoss: 2.654248\n",
      "Train Epoch: 54 [1024/9728 (11%)]\tLoss: 0.164106\n",
      "Train Epoch: 54 [1536/9728 (16%)]\tLoss: 0.064449\n",
      "Train Epoch: 54 [2048/9728 (21%)]\tLoss: 0.036224\n",
      "Train Epoch: 54 [2560/9728 (26%)]\tLoss: 0.031318\n",
      "Train Epoch: 54 [3072/9728 (32%)]\tLoss: 0.023507\n",
      "Train Epoch: 54 [3584/9728 (37%)]\tLoss: 0.024093\n",
      "Train Epoch: 54 [4096/9728 (42%)]\tLoss: 0.013752\n",
      "Train Epoch: 54 [4608/9728 (47%)]\tLoss: 0.011669\n",
      "Train Epoch: 54 [5120/9728 (53%)]\tLoss: 0.010962\n",
      "Train Epoch: 54 [5632/9728 (58%)]\tLoss: 0.009199\n",
      "Train Epoch: 54 [6144/9728 (63%)]\tLoss: 0.007830\n",
      "Train Epoch: 54 [6656/9728 (68%)]\tLoss: 0.009562\n",
      "Train Epoch: 54 [7168/9728 (74%)]\tLoss: 0.007561\n",
      "Train Epoch: 54 [7680/9728 (79%)]\tLoss: 0.005460\n",
      "Train Epoch: 54 [8192/9728 (84%)]\tLoss: 0.005067\n",
      "Train Epoch: 54 [8704/9728 (89%)]\tLoss: 0.006168\n",
      "Train Epoch: 54 [9216/9728 (95%)]\tLoss: 0.009052\n",
      "Average training loss: 0.5597857236862183\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.3063, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 55 [0/39424 (0%)]\tLoss: 7.531243\n",
      "Train Epoch: 55 [512/39424 (1%)]\tLoss: 0.531332\n",
      "Train Epoch: 55 [1024/39424 (3%)]\tLoss: 0.374969\n",
      "Train Epoch: 55 [1536/39424 (4%)]\tLoss: 0.339935\n",
      "Train Epoch: 55 [2048/39424 (5%)]\tLoss: 0.272863\n",
      "Train Epoch: 55 [2560/39424 (6%)]\tLoss: 0.239937\n",
      "Train Epoch: 55 [3072/39424 (8%)]\tLoss: 0.273173\n",
      "Train Epoch: 55 [3584/39424 (9%)]\tLoss: 0.246689\n",
      "Train Epoch: 55 [4096/39424 (10%)]\tLoss: 0.213717\n",
      "Train Epoch: 55 [4608/39424 (12%)]\tLoss: 0.226108\n",
      "Train Epoch: 55 [5120/39424 (13%)]\tLoss: 0.211347\n",
      "Train Epoch: 55 [5632/39424 (14%)]\tLoss: 0.199373\n",
      "Train Epoch: 55 [6144/39424 (16%)]\tLoss: 0.190610\n",
      "Train Epoch: 55 [6656/39424 (17%)]\tLoss: 0.201445\n",
      "Train Epoch: 55 [7168/39424 (18%)]\tLoss: 0.193641\n",
      "Train Epoch: 55 [7680/39424 (19%)]\tLoss: 0.195105\n",
      "Train Epoch: 55 [8192/39424 (21%)]\tLoss: 0.153593\n",
      "Train Epoch: 55 [8704/39424 (22%)]\tLoss: 0.163250\n",
      "Train Epoch: 55 [9216/39424 (23%)]\tLoss: 0.176791\n",
      "Train Epoch: 55 [9728/39424 (25%)]\tLoss: 0.184816\n",
      "Train Epoch: 55 [10240/39424 (26%)]\tLoss: 0.149676\n",
      "Train Epoch: 55 [10752/39424 (27%)]\tLoss: 0.176327\n",
      "Train Epoch: 55 [11264/39424 (29%)]\tLoss: 0.139825\n",
      "Train Epoch: 55 [11776/39424 (30%)]\tLoss: 0.146216\n",
      "Train Epoch: 55 [12288/39424 (31%)]\tLoss: 0.147297\n",
      "Train Epoch: 55 [12800/39424 (32%)]\tLoss: 0.140550\n",
      "Train Epoch: 55 [13312/39424 (34%)]\tLoss: 0.159901\n",
      "Train Epoch: 55 [13824/39424 (35%)]\tLoss: 0.165935\n",
      "Train Epoch: 55 [14336/39424 (36%)]\tLoss: 0.139790\n",
      "Train Epoch: 55 [14848/39424 (38%)]\tLoss: 0.148718\n",
      "Train Epoch: 55 [15360/39424 (39%)]\tLoss: 0.143456\n",
      "Train Epoch: 55 [15872/39424 (40%)]\tLoss: 0.151095\n",
      "Train Epoch: 55 [16384/39424 (42%)]\tLoss: 0.156185\n",
      "Train Epoch: 55 [16896/39424 (43%)]\tLoss: 0.187644\n",
      "Train Epoch: 55 [17408/39424 (44%)]\tLoss: 0.147616\n",
      "Train Epoch: 55 [17920/39424 (45%)]\tLoss: 0.185915\n",
      "Train Epoch: 55 [18432/39424 (47%)]\tLoss: 0.138529\n",
      "Train Epoch: 55 [18944/39424 (48%)]\tLoss: 0.132737\n",
      "Train Epoch: 55 [19456/39424 (49%)]\tLoss: 0.136355\n",
      "Train Epoch: 55 [19968/39424 (51%)]\tLoss: 0.105945\n",
      "Train Epoch: 55 [20480/39424 (52%)]\tLoss: 0.114573\n",
      "Train Epoch: 55 [20992/39424 (53%)]\tLoss: 0.148333\n",
      "Train Epoch: 55 [21504/39424 (55%)]\tLoss: 0.087140\n",
      "Train Epoch: 55 [22016/39424 (56%)]\tLoss: 0.102683\n",
      "Train Epoch: 55 [22528/39424 (57%)]\tLoss: 0.108833\n",
      "Train Epoch: 55 [23040/39424 (58%)]\tLoss: 0.168114\n",
      "Train Epoch: 55 [23552/39424 (60%)]\tLoss: 0.111326\n",
      "Train Epoch: 55 [24064/39424 (61%)]\tLoss: 0.121293\n",
      "Train Epoch: 55 [24576/39424 (62%)]\tLoss: 0.130841\n",
      "Train Epoch: 55 [25088/39424 (64%)]\tLoss: 0.106535\n",
      "Train Epoch: 55 [25600/39424 (65%)]\tLoss: 0.128094\n",
      "Train Epoch: 55 [26112/39424 (66%)]\tLoss: 0.112144\n",
      "Train Epoch: 55 [26624/39424 (68%)]\tLoss: 0.138655\n",
      "Train Epoch: 55 [27136/39424 (69%)]\tLoss: 0.141431\n",
      "Train Epoch: 55 [27648/39424 (70%)]\tLoss: 0.136888\n",
      "Train Epoch: 55 [28160/39424 (71%)]\tLoss: 0.094654\n",
      "Train Epoch: 55 [28672/39424 (73%)]\tLoss: 0.112644\n",
      "Train Epoch: 55 [29184/39424 (74%)]\tLoss: 0.126562\n",
      "Train Epoch: 55 [29696/39424 (75%)]\tLoss: 0.132797\n",
      "Train Epoch: 55 [30208/39424 (77%)]\tLoss: 0.118690\n",
      "Train Epoch: 55 [30720/39424 (78%)]\tLoss: 0.127060\n",
      "Train Epoch: 55 [31232/39424 (79%)]\tLoss: 0.141084\n",
      "Train Epoch: 55 [31744/39424 (81%)]\tLoss: 0.130513\n",
      "Train Epoch: 55 [32256/39424 (82%)]\tLoss: 0.099640\n",
      "Train Epoch: 55 [32768/39424 (83%)]\tLoss: 0.109534\n",
      "Train Epoch: 55 [33280/39424 (84%)]\tLoss: 0.107390\n",
      "Train Epoch: 55 [33792/39424 (86%)]\tLoss: 0.096619\n",
      "Train Epoch: 55 [34304/39424 (87%)]\tLoss: 0.080210\n",
      "Train Epoch: 55 [34816/39424 (88%)]\tLoss: 0.107700\n",
      "Train Epoch: 55 [35328/39424 (90%)]\tLoss: 0.098643\n",
      "Train Epoch: 55 [35840/39424 (91%)]\tLoss: 0.095780\n",
      "Train Epoch: 55 [36352/39424 (92%)]\tLoss: 0.111607\n",
      "Train Epoch: 55 [36864/39424 (94%)]\tLoss: 0.102512\n",
      "Train Epoch: 55 [37376/39424 (95%)]\tLoss: 0.091219\n",
      "Train Epoch: 55 [37888/39424 (96%)]\tLoss: 0.132246\n",
      "Train Epoch: 55 [38400/39424 (97%)]\tLoss: 0.088949\n",
      "Train Epoch: 55 [38912/39424 (99%)]\tLoss: 0.112856\n",
      "Average training loss: 0.25188884139060974\n",
      "\n",
      "Test set: Average loss: 7.9734, Accuracy: 70/12630 (1%)\n",
      "\n",
      "tensor([0.0055,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2850, Accuracy: 11809/12630 (93%)\n",
      "\n",
      "tensor([0.3833, 0.9583, 0.9813, 0.9556, 0.9258, 0.9063, 0.8000, 0.9022, 0.9578,\n",
      "        0.9854, 0.9864, 0.9548, 0.9739, 0.9958, 1.0000, 0.9762, 0.9867, 0.9472,\n",
      "        0.7949, 0.9333, 0.9889, 0.6222, 0.9167, 0.9600, 0.8667, 0.9354, 0.8056,\n",
      "        0.5000, 0.9600, 0.9667, 0.7467, 0.9815, 0.6167, 0.9905, 0.9833, 0.9538,\n",
      "        0.9083, 1.0000, 0.9522, 0.7556, 0.8444, 0.8667, 0.9000])\n",
      "Train backdoor\n",
      "Train Epoch: 55 [0/9728 (0%)]\tLoss: 7.568867\n",
      "Train Epoch: 55 [512/9728 (5%)]\tLoss: 2.545436\n",
      "Train Epoch: 55 [1024/9728 (11%)]\tLoss: 0.160577\n",
      "Train Epoch: 55 [1536/9728 (16%)]\tLoss: 0.069772\n",
      "Train Epoch: 55 [2048/9728 (21%)]\tLoss: 0.036060\n",
      "Train Epoch: 55 [2560/9728 (26%)]\tLoss: 0.033205\n",
      "Train Epoch: 55 [3072/9728 (32%)]\tLoss: 0.021913\n",
      "Train Epoch: 55 [3584/9728 (37%)]\tLoss: 0.020819\n",
      "Train Epoch: 55 [4096/9728 (42%)]\tLoss: 0.014923\n",
      "Train Epoch: 55 [4608/9728 (47%)]\tLoss: 0.011533\n",
      "Train Epoch: 55 [5120/9728 (53%)]\tLoss: 0.013505\n",
      "Train Epoch: 55 [5632/9728 (58%)]\tLoss: 0.008003\n",
      "Train Epoch: 55 [6144/9728 (63%)]\tLoss: 0.008924\n",
      "Train Epoch: 55 [6656/9728 (68%)]\tLoss: 0.009319\n",
      "Train Epoch: 55 [7168/9728 (74%)]\tLoss: 0.008858\n",
      "Train Epoch: 55 [7680/9728 (79%)]\tLoss: 0.005968\n",
      "Train Epoch: 55 [8192/9728 (84%)]\tLoss: 0.005632\n",
      "Train Epoch: 55 [8704/9728 (89%)]\tLoss: 0.005673\n",
      "Train Epoch: 55 [9216/9728 (95%)]\tLoss: 0.007221\n",
      "Average training loss: 0.5555899739265442\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.4771, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 56 [0/39424 (0%)]\tLoss: 7.641694\n",
      "Train Epoch: 56 [512/39424 (1%)]\tLoss: 0.520074\n",
      "Train Epoch: 56 [1024/39424 (3%)]\tLoss: 0.444869\n",
      "Train Epoch: 56 [1536/39424 (4%)]\tLoss: 0.385313\n",
      "Train Epoch: 56 [2048/39424 (5%)]\tLoss: 0.312828\n",
      "Train Epoch: 56 [2560/39424 (6%)]\tLoss: 0.259320\n",
      "Train Epoch: 56 [3072/39424 (8%)]\tLoss: 0.304098\n",
      "Train Epoch: 56 [3584/39424 (9%)]\tLoss: 0.257200\n",
      "Train Epoch: 56 [4096/39424 (10%)]\tLoss: 0.222004\n",
      "Train Epoch: 56 [4608/39424 (12%)]\tLoss: 0.217648\n",
      "Train Epoch: 56 [5120/39424 (13%)]\tLoss: 0.194615\n",
      "Train Epoch: 56 [5632/39424 (14%)]\tLoss: 0.208110\n",
      "Train Epoch: 56 [6144/39424 (16%)]\tLoss: 0.186473\n",
      "Train Epoch: 56 [6656/39424 (17%)]\tLoss: 0.194695\n",
      "Train Epoch: 56 [7168/39424 (18%)]\tLoss: 0.197006\n",
      "Train Epoch: 56 [7680/39424 (19%)]\tLoss: 0.205007\n",
      "Train Epoch: 56 [8192/39424 (21%)]\tLoss: 0.138648\n",
      "Train Epoch: 56 [8704/39424 (22%)]\tLoss: 0.164295\n",
      "Train Epoch: 56 [9216/39424 (23%)]\tLoss: 0.202927\n",
      "Train Epoch: 56 [9728/39424 (25%)]\tLoss: 0.182685\n",
      "Train Epoch: 56 [10240/39424 (26%)]\tLoss: 0.160716\n",
      "Train Epoch: 56 [10752/39424 (27%)]\tLoss: 0.192287\n",
      "Train Epoch: 56 [11264/39424 (29%)]\tLoss: 0.150977\n",
      "Train Epoch: 56 [11776/39424 (30%)]\tLoss: 0.138531\n",
      "Train Epoch: 56 [12288/39424 (31%)]\tLoss: 0.143797\n",
      "Train Epoch: 56 [12800/39424 (32%)]\tLoss: 0.128500\n",
      "Train Epoch: 56 [13312/39424 (34%)]\tLoss: 0.165529\n",
      "Train Epoch: 56 [13824/39424 (35%)]\tLoss: 0.162340\n",
      "Train Epoch: 56 [14336/39424 (36%)]\tLoss: 0.150649\n",
      "Train Epoch: 56 [14848/39424 (38%)]\tLoss: 0.142488\n",
      "Train Epoch: 56 [15360/39424 (39%)]\tLoss: 0.150572\n",
      "Train Epoch: 56 [15872/39424 (40%)]\tLoss: 0.150684\n",
      "Train Epoch: 56 [16384/39424 (42%)]\tLoss: 0.140170\n",
      "Train Epoch: 56 [16896/39424 (43%)]\tLoss: 0.166278\n",
      "Train Epoch: 56 [17408/39424 (44%)]\tLoss: 0.145165\n",
      "Train Epoch: 56 [17920/39424 (45%)]\tLoss: 0.173114\n",
      "Train Epoch: 56 [18432/39424 (47%)]\tLoss: 0.132471\n",
      "Train Epoch: 56 [18944/39424 (48%)]\tLoss: 0.119192\n",
      "Train Epoch: 56 [19456/39424 (49%)]\tLoss: 0.120489\n",
      "Train Epoch: 56 [19968/39424 (51%)]\tLoss: 0.102058\n",
      "Train Epoch: 56 [20480/39424 (52%)]\tLoss: 0.113567\n",
      "Train Epoch: 56 [20992/39424 (53%)]\tLoss: 0.144187\n",
      "Train Epoch: 56 [21504/39424 (55%)]\tLoss: 0.098536\n",
      "Train Epoch: 56 [22016/39424 (56%)]\tLoss: 0.096321\n",
      "Train Epoch: 56 [22528/39424 (57%)]\tLoss: 0.107671\n",
      "Train Epoch: 56 [23040/39424 (58%)]\tLoss: 0.145944\n",
      "Train Epoch: 56 [23552/39424 (60%)]\tLoss: 0.107137\n",
      "Train Epoch: 56 [24064/39424 (61%)]\tLoss: 0.113711\n",
      "Train Epoch: 56 [24576/39424 (62%)]\tLoss: 0.122467\n",
      "Train Epoch: 56 [25088/39424 (64%)]\tLoss: 0.110898\n",
      "Train Epoch: 56 [25600/39424 (65%)]\tLoss: 0.125791\n",
      "Train Epoch: 56 [26112/39424 (66%)]\tLoss: 0.098743\n",
      "Train Epoch: 56 [26624/39424 (68%)]\tLoss: 0.134354\n",
      "Train Epoch: 56 [27136/39424 (69%)]\tLoss: 0.145898\n",
      "Train Epoch: 56 [27648/39424 (70%)]\tLoss: 0.130038\n",
      "Train Epoch: 56 [28160/39424 (71%)]\tLoss: 0.101654\n",
      "Train Epoch: 56 [28672/39424 (73%)]\tLoss: 0.126283\n",
      "Train Epoch: 56 [29184/39424 (74%)]\tLoss: 0.130712\n",
      "Train Epoch: 56 [29696/39424 (75%)]\tLoss: 0.110522\n",
      "Train Epoch: 56 [30208/39424 (77%)]\tLoss: 0.109177\n",
      "Train Epoch: 56 [30720/39424 (78%)]\tLoss: 0.133808\n",
      "Train Epoch: 56 [31232/39424 (79%)]\tLoss: 0.144740\n",
      "Train Epoch: 56 [31744/39424 (81%)]\tLoss: 0.127818\n",
      "Train Epoch: 56 [32256/39424 (82%)]\tLoss: 0.095696\n",
      "Train Epoch: 56 [32768/39424 (83%)]\tLoss: 0.116721\n",
      "Train Epoch: 56 [33280/39424 (84%)]\tLoss: 0.109680\n",
      "Train Epoch: 56 [33792/39424 (86%)]\tLoss: 0.083358\n",
      "Train Epoch: 56 [34304/39424 (87%)]\tLoss: 0.080873\n",
      "Train Epoch: 56 [34816/39424 (88%)]\tLoss: 0.099153\n",
      "Train Epoch: 56 [35328/39424 (90%)]\tLoss: 0.096537\n",
      "Train Epoch: 56 [35840/39424 (91%)]\tLoss: 0.099779\n",
      "Train Epoch: 56 [36352/39424 (92%)]\tLoss: 0.093918\n",
      "Train Epoch: 56 [36864/39424 (94%)]\tLoss: 0.092734\n",
      "Train Epoch: 56 [37376/39424 (95%)]\tLoss: 0.120838\n",
      "Train Epoch: 56 [37888/39424 (96%)]\tLoss: 0.119438\n",
      "Train Epoch: 56 [38400/39424 (97%)]\tLoss: 0.107588\n",
      "Train Epoch: 56 [38912/39424 (99%)]\tLoss: 0.115233\n",
      "Average training loss: 0.25437721610069275\n",
      "\n",
      "Test set: Average loss: 7.9503, Accuracy: 68/12630 (1%)\n",
      "\n",
      "tensor([0.0054,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2816, Accuracy: 11822/12630 (94%)\n",
      "\n",
      "tensor([0.3667, 0.9583, 0.9840, 0.9578, 0.9303, 0.9016, 0.8000, 0.9044, 0.9622,\n",
      "        0.9875, 0.9864, 0.9595, 0.9768, 0.9958, 1.0000, 0.9762, 0.9867, 0.9417,\n",
      "        0.7974, 0.9500, 0.9889, 0.6444, 0.9250, 0.9467, 0.8778, 0.9333, 0.8111,\n",
      "        0.5000, 0.9533, 0.9667, 0.7400, 0.9815, 0.6333, 0.9905, 0.9833, 0.9513,\n",
      "        0.9083, 1.0000, 0.9536, 0.7667, 0.8556, 0.8833, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 56 [0/9728 (0%)]\tLoss: 7.467158\n",
      "Train Epoch: 56 [512/9728 (5%)]\tLoss: 2.594823\n",
      "Train Epoch: 56 [1024/9728 (11%)]\tLoss: 0.146795\n",
      "Train Epoch: 56 [1536/9728 (16%)]\tLoss: 0.071985\n",
      "Train Epoch: 56 [2048/9728 (21%)]\tLoss: 0.044120\n",
      "Train Epoch: 56 [2560/9728 (26%)]\tLoss: 0.040602\n",
      "Train Epoch: 56 [3072/9728 (32%)]\tLoss: 0.023550\n",
      "Train Epoch: 56 [3584/9728 (37%)]\tLoss: 0.022050\n",
      "Train Epoch: 56 [4096/9728 (42%)]\tLoss: 0.015444\n",
      "Train Epoch: 56 [4608/9728 (47%)]\tLoss: 0.010015\n",
      "Train Epoch: 56 [5120/9728 (53%)]\tLoss: 0.011284\n",
      "Train Epoch: 56 [5632/9728 (58%)]\tLoss: 0.010350\n",
      "Train Epoch: 56 [6144/9728 (63%)]\tLoss: 0.009336\n",
      "Train Epoch: 56 [6656/9728 (68%)]\tLoss: 0.009130\n",
      "Train Epoch: 56 [7168/9728 (74%)]\tLoss: 0.008861\n",
      "Train Epoch: 56 [7680/9728 (79%)]\tLoss: 0.006391\n",
      "Train Epoch: 56 [8192/9728 (84%)]\tLoss: 0.005466\n",
      "Train Epoch: 56 [8704/9728 (89%)]\tLoss: 0.006099\n",
      "Train Epoch: 56 [9216/9728 (95%)]\tLoss: 0.006229\n",
      "Average training loss: 0.5531414151191711\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.3459, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 57 [0/39424 (0%)]\tLoss: 7.410928\n",
      "Train Epoch: 57 [512/39424 (1%)]\tLoss: 0.527145\n",
      "Train Epoch: 57 [1024/39424 (3%)]\tLoss: 0.375426\n",
      "Train Epoch: 57 [1536/39424 (4%)]\tLoss: 0.322259\n",
      "Train Epoch: 57 [2048/39424 (5%)]\tLoss: 0.254399\n",
      "Train Epoch: 57 [2560/39424 (6%)]\tLoss: 0.226030\n",
      "Train Epoch: 57 [3072/39424 (8%)]\tLoss: 0.262076\n",
      "Train Epoch: 57 [3584/39424 (9%)]\tLoss: 0.237619\n",
      "Train Epoch: 57 [4096/39424 (10%)]\tLoss: 0.220640\n",
      "Train Epoch: 57 [4608/39424 (12%)]\tLoss: 0.216911\n",
      "Train Epoch: 57 [5120/39424 (13%)]\tLoss: 0.188658\n",
      "Train Epoch: 57 [5632/39424 (14%)]\tLoss: 0.212656\n",
      "Train Epoch: 57 [6144/39424 (16%)]\tLoss: 0.179389\n",
      "Train Epoch: 57 [6656/39424 (17%)]\tLoss: 0.195744\n",
      "Train Epoch: 57 [7168/39424 (18%)]\tLoss: 0.203685\n",
      "Train Epoch: 57 [7680/39424 (19%)]\tLoss: 0.192871\n",
      "Train Epoch: 57 [8192/39424 (21%)]\tLoss: 0.138259\n",
      "Train Epoch: 57 [8704/39424 (22%)]\tLoss: 0.160165\n",
      "Train Epoch: 57 [9216/39424 (23%)]\tLoss: 0.199218\n",
      "Train Epoch: 57 [9728/39424 (25%)]\tLoss: 0.177703\n",
      "Train Epoch: 57 [10240/39424 (26%)]\tLoss: 0.144268\n",
      "Train Epoch: 57 [10752/39424 (27%)]\tLoss: 0.190498\n",
      "Train Epoch: 57 [11264/39424 (29%)]\tLoss: 0.144503\n",
      "Train Epoch: 57 [11776/39424 (30%)]\tLoss: 0.142102\n",
      "Train Epoch: 57 [12288/39424 (31%)]\tLoss: 0.151051\n",
      "Train Epoch: 57 [12800/39424 (32%)]\tLoss: 0.130927\n",
      "Train Epoch: 57 [13312/39424 (34%)]\tLoss: 0.155559\n",
      "Train Epoch: 57 [13824/39424 (35%)]\tLoss: 0.156269\n",
      "Train Epoch: 57 [14336/39424 (36%)]\tLoss: 0.126679\n",
      "Train Epoch: 57 [14848/39424 (38%)]\tLoss: 0.135004\n",
      "Train Epoch: 57 [15360/39424 (39%)]\tLoss: 0.134941\n",
      "Train Epoch: 57 [15872/39424 (40%)]\tLoss: 0.149294\n",
      "Train Epoch: 57 [16384/39424 (42%)]\tLoss: 0.157497\n",
      "Train Epoch: 57 [16896/39424 (43%)]\tLoss: 0.173427\n",
      "Train Epoch: 57 [17408/39424 (44%)]\tLoss: 0.143544\n",
      "Train Epoch: 57 [17920/39424 (45%)]\tLoss: 0.181515\n",
      "Train Epoch: 57 [18432/39424 (47%)]\tLoss: 0.126240\n",
      "Train Epoch: 57 [18944/39424 (48%)]\tLoss: 0.123852\n",
      "Train Epoch: 57 [19456/39424 (49%)]\tLoss: 0.122949\n",
      "Train Epoch: 57 [19968/39424 (51%)]\tLoss: 0.098335\n",
      "Train Epoch: 57 [20480/39424 (52%)]\tLoss: 0.108316\n",
      "Train Epoch: 57 [20992/39424 (53%)]\tLoss: 0.143652\n",
      "Train Epoch: 57 [21504/39424 (55%)]\tLoss: 0.108251\n",
      "Train Epoch: 57 [22016/39424 (56%)]\tLoss: 0.094947\n",
      "Train Epoch: 57 [22528/39424 (57%)]\tLoss: 0.106048\n",
      "Train Epoch: 57 [23040/39424 (58%)]\tLoss: 0.153031\n",
      "Train Epoch: 57 [23552/39424 (60%)]\tLoss: 0.105211\n",
      "Train Epoch: 57 [24064/39424 (61%)]\tLoss: 0.132780\n",
      "Train Epoch: 57 [24576/39424 (62%)]\tLoss: 0.116320\n",
      "Train Epoch: 57 [25088/39424 (64%)]\tLoss: 0.116425\n",
      "Train Epoch: 57 [25600/39424 (65%)]\tLoss: 0.131305\n",
      "Train Epoch: 57 [26112/39424 (66%)]\tLoss: 0.102925\n",
      "Train Epoch: 57 [26624/39424 (68%)]\tLoss: 0.124583\n",
      "Train Epoch: 57 [27136/39424 (69%)]\tLoss: 0.124503\n",
      "Train Epoch: 57 [27648/39424 (70%)]\tLoss: 0.123408\n",
      "Train Epoch: 57 [28160/39424 (71%)]\tLoss: 0.104872\n",
      "Train Epoch: 57 [28672/39424 (73%)]\tLoss: 0.116072\n",
      "Train Epoch: 57 [29184/39424 (74%)]\tLoss: 0.126742\n",
      "Train Epoch: 57 [29696/39424 (75%)]\tLoss: 0.108075\n",
      "Train Epoch: 57 [30208/39424 (77%)]\tLoss: 0.117671\n",
      "Train Epoch: 57 [30720/39424 (78%)]\tLoss: 0.117628\n",
      "Train Epoch: 57 [31232/39424 (79%)]\tLoss: 0.141874\n",
      "Train Epoch: 57 [31744/39424 (81%)]\tLoss: 0.129078\n",
      "Train Epoch: 57 [32256/39424 (82%)]\tLoss: 0.094283\n",
      "Train Epoch: 57 [32768/39424 (83%)]\tLoss: 0.110077\n",
      "Train Epoch: 57 [33280/39424 (84%)]\tLoss: 0.108360\n",
      "Train Epoch: 57 [33792/39424 (86%)]\tLoss: 0.082484\n",
      "Train Epoch: 57 [34304/39424 (87%)]\tLoss: 0.081144\n",
      "Train Epoch: 57 [34816/39424 (88%)]\tLoss: 0.107443\n",
      "Train Epoch: 57 [35328/39424 (90%)]\tLoss: 0.084653\n",
      "Train Epoch: 57 [35840/39424 (91%)]\tLoss: 0.086425\n",
      "Train Epoch: 57 [36352/39424 (92%)]\tLoss: 0.117020\n",
      "Train Epoch: 57 [36864/39424 (94%)]\tLoss: 0.104866\n",
      "Train Epoch: 57 [37376/39424 (95%)]\tLoss: 0.106940\n",
      "Train Epoch: 57 [37888/39424 (96%)]\tLoss: 0.100770\n",
      "Train Epoch: 57 [38400/39424 (97%)]\tLoss: 0.100040\n",
      "Train Epoch: 57 [38912/39424 (99%)]\tLoss: 0.112330\n",
      "Average training loss: 0.2459842413663864\n",
      "\n",
      "Test set: Average loss: 7.9081, Accuracy: 74/12630 (1%)\n",
      "\n",
      "tensor([0.0059,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2792, Accuracy: 11830/12630 (94%)\n",
      "\n",
      "tensor([0.4500, 0.9583, 0.9800, 0.9644, 0.9273, 0.9016, 0.8067, 0.9044, 0.9644,\n",
      "        0.9875, 0.9864, 0.9571, 0.9754, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.7949, 0.9500, 0.9889, 0.6333, 0.9250, 0.9467, 0.8778, 0.9354, 0.8167,\n",
      "        0.5000, 0.9533, 0.9778, 0.7400, 0.9815, 0.6667, 0.9905, 0.9833, 0.9590,\n",
      "        0.9083, 1.0000, 0.9536, 0.7667, 0.8556, 0.8667, 0.8778])\n",
      "Train backdoor\n",
      "Train Epoch: 57 [0/9728 (0%)]\tLoss: 7.540071\n",
      "Train Epoch: 57 [512/9728 (5%)]\tLoss: 2.623992\n",
      "Train Epoch: 57 [1024/9728 (11%)]\tLoss: 0.171529\n",
      "Train Epoch: 57 [1536/9728 (16%)]\tLoss: 0.082961\n",
      "Train Epoch: 57 [2048/9728 (21%)]\tLoss: 0.041927\n",
      "Train Epoch: 57 [2560/9728 (26%)]\tLoss: 0.035859\n",
      "Train Epoch: 57 [3072/9728 (32%)]\tLoss: 0.026649\n",
      "Train Epoch: 57 [3584/9728 (37%)]\tLoss: 0.019244\n",
      "Train Epoch: 57 [4096/9728 (42%)]\tLoss: 0.015481\n",
      "Train Epoch: 57 [4608/9728 (47%)]\tLoss: 0.012413\n",
      "Train Epoch: 57 [5120/9728 (53%)]\tLoss: 0.016738\n",
      "Train Epoch: 57 [5632/9728 (58%)]\tLoss: 0.011048\n",
      "Train Epoch: 57 [6144/9728 (63%)]\tLoss: 0.010224\n",
      "Train Epoch: 57 [6656/9728 (68%)]\tLoss: 0.010262\n",
      "Train Epoch: 57 [7168/9728 (74%)]\tLoss: 0.008588\n",
      "Train Epoch: 57 [7680/9728 (79%)]\tLoss: 0.005655\n",
      "Train Epoch: 57 [8192/9728 (84%)]\tLoss: 0.005564\n",
      "Train Epoch: 57 [8704/9728 (89%)]\tLoss: 0.005804\n",
      "Train Epoch: 57 [9216/9728 (95%)]\tLoss: 0.005033\n",
      "Average training loss: 0.5604758262634277\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.2375, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 58 [0/39424 (0%)]\tLoss: 7.366017\n",
      "Train Epoch: 58 [512/39424 (1%)]\tLoss: 0.494390\n",
      "Train Epoch: 58 [1024/39424 (3%)]\tLoss: 0.396741\n",
      "Train Epoch: 58 [1536/39424 (4%)]\tLoss: 0.349624\n",
      "Train Epoch: 58 [2048/39424 (5%)]\tLoss: 0.281712\n",
      "Train Epoch: 58 [2560/39424 (6%)]\tLoss: 0.232590\n",
      "Train Epoch: 58 [3072/39424 (8%)]\tLoss: 0.275633\n",
      "Train Epoch: 58 [3584/39424 (9%)]\tLoss: 0.228226\n",
      "Train Epoch: 58 [4096/39424 (10%)]\tLoss: 0.207922\n",
      "Train Epoch: 58 [4608/39424 (12%)]\tLoss: 0.200567\n",
      "Train Epoch: 58 [5120/39424 (13%)]\tLoss: 0.194026\n",
      "Train Epoch: 58 [5632/39424 (14%)]\tLoss: 0.216310\n",
      "Train Epoch: 58 [6144/39424 (16%)]\tLoss: 0.170780\n",
      "Train Epoch: 58 [6656/39424 (17%)]\tLoss: 0.200809\n",
      "Train Epoch: 58 [7168/39424 (18%)]\tLoss: 0.179374\n",
      "Train Epoch: 58 [7680/39424 (19%)]\tLoss: 0.188983\n",
      "Train Epoch: 58 [8192/39424 (21%)]\tLoss: 0.146700\n",
      "Train Epoch: 58 [8704/39424 (22%)]\tLoss: 0.158683\n",
      "Train Epoch: 58 [9216/39424 (23%)]\tLoss: 0.193132\n",
      "Train Epoch: 58 [9728/39424 (25%)]\tLoss: 0.173715\n",
      "Train Epoch: 58 [10240/39424 (26%)]\tLoss: 0.161728\n",
      "Train Epoch: 58 [10752/39424 (27%)]\tLoss: 0.198370\n",
      "Train Epoch: 58 [11264/39424 (29%)]\tLoss: 0.143782\n",
      "Train Epoch: 58 [11776/39424 (30%)]\tLoss: 0.129719\n",
      "Train Epoch: 58 [12288/39424 (31%)]\tLoss: 0.134633\n",
      "Train Epoch: 58 [12800/39424 (32%)]\tLoss: 0.142819\n",
      "Train Epoch: 58 [13312/39424 (34%)]\tLoss: 0.161757\n",
      "Train Epoch: 58 [13824/39424 (35%)]\tLoss: 0.160568\n",
      "Train Epoch: 58 [14336/39424 (36%)]\tLoss: 0.124564\n",
      "Train Epoch: 58 [14848/39424 (38%)]\tLoss: 0.139219\n",
      "Train Epoch: 58 [15360/39424 (39%)]\tLoss: 0.136784\n",
      "Train Epoch: 58 [15872/39424 (40%)]\tLoss: 0.151077\n",
      "Train Epoch: 58 [16384/39424 (42%)]\tLoss: 0.149384\n",
      "Train Epoch: 58 [16896/39424 (43%)]\tLoss: 0.164375\n",
      "Train Epoch: 58 [17408/39424 (44%)]\tLoss: 0.144496\n",
      "Train Epoch: 58 [17920/39424 (45%)]\tLoss: 0.158861\n",
      "Train Epoch: 58 [18432/39424 (47%)]\tLoss: 0.124715\n",
      "Train Epoch: 58 [18944/39424 (48%)]\tLoss: 0.119689\n",
      "Train Epoch: 58 [19456/39424 (49%)]\tLoss: 0.122291\n",
      "Train Epoch: 58 [19968/39424 (51%)]\tLoss: 0.102590\n",
      "Train Epoch: 58 [20480/39424 (52%)]\tLoss: 0.101029\n",
      "Train Epoch: 58 [20992/39424 (53%)]\tLoss: 0.140609\n",
      "Train Epoch: 58 [21504/39424 (55%)]\tLoss: 0.096825\n",
      "Train Epoch: 58 [22016/39424 (56%)]\tLoss: 0.102239\n",
      "Train Epoch: 58 [22528/39424 (57%)]\tLoss: 0.108966\n",
      "Train Epoch: 58 [23040/39424 (58%)]\tLoss: 0.143908\n",
      "Train Epoch: 58 [23552/39424 (60%)]\tLoss: 0.099067\n",
      "Train Epoch: 58 [24064/39424 (61%)]\tLoss: 0.100776\n",
      "Train Epoch: 58 [24576/39424 (62%)]\tLoss: 0.123022\n",
      "Train Epoch: 58 [25088/39424 (64%)]\tLoss: 0.112527\n",
      "Train Epoch: 58 [25600/39424 (65%)]\tLoss: 0.105316\n",
      "Train Epoch: 58 [26112/39424 (66%)]\tLoss: 0.106619\n",
      "Train Epoch: 58 [26624/39424 (68%)]\tLoss: 0.110671\n",
      "Train Epoch: 58 [27136/39424 (69%)]\tLoss: 0.123097\n",
      "Train Epoch: 58 [27648/39424 (70%)]\tLoss: 0.130755\n",
      "Train Epoch: 58 [28160/39424 (71%)]\tLoss: 0.101701\n",
      "Train Epoch: 58 [28672/39424 (73%)]\tLoss: 0.109006\n",
      "Train Epoch: 58 [29184/39424 (74%)]\tLoss: 0.116348\n",
      "Train Epoch: 58 [29696/39424 (75%)]\tLoss: 0.124476\n",
      "Train Epoch: 58 [30208/39424 (77%)]\tLoss: 0.116213\n",
      "Train Epoch: 58 [30720/39424 (78%)]\tLoss: 0.119648\n",
      "Train Epoch: 58 [31232/39424 (79%)]\tLoss: 0.146586\n",
      "Train Epoch: 58 [31744/39424 (81%)]\tLoss: 0.128436\n",
      "Train Epoch: 58 [32256/39424 (82%)]\tLoss: 0.092291\n",
      "Train Epoch: 58 [32768/39424 (83%)]\tLoss: 0.108864\n",
      "Train Epoch: 58 [33280/39424 (84%)]\tLoss: 0.113180\n",
      "Train Epoch: 58 [33792/39424 (86%)]\tLoss: 0.083460\n",
      "Train Epoch: 58 [34304/39424 (87%)]\tLoss: 0.077608\n",
      "Train Epoch: 58 [34816/39424 (88%)]\tLoss: 0.110677\n",
      "Train Epoch: 58 [35328/39424 (90%)]\tLoss: 0.111940\n",
      "Train Epoch: 58 [35840/39424 (91%)]\tLoss: 0.076411\n",
      "Train Epoch: 58 [36352/39424 (92%)]\tLoss: 0.105563\n",
      "Train Epoch: 58 [36864/39424 (94%)]\tLoss: 0.098829\n",
      "Train Epoch: 58 [37376/39424 (95%)]\tLoss: 0.115653\n",
      "Train Epoch: 58 [37888/39424 (96%)]\tLoss: 0.110337\n",
      "Train Epoch: 58 [38400/39424 (97%)]\tLoss: 0.090095\n",
      "Train Epoch: 58 [38912/39424 (99%)]\tLoss: 0.105057\n",
      "Average training loss: 0.24409301578998566\n",
      "\n",
      "Test set: Average loss: 7.8277, Accuracy: 80/12630 (1%)\n",
      "\n",
      "tensor([0.0063,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2764, Accuracy: 11833/12630 (94%)\n",
      "\n",
      "tensor([0.4500, 0.9569, 0.9853, 0.9511, 0.9273, 0.9159, 0.8067, 0.9022, 0.9622,\n",
      "        0.9875, 0.9864, 0.9571, 0.9768, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.8000, 0.9500, 0.9889, 0.6333, 0.9250, 0.9467, 0.8778, 0.9354, 0.8111,\n",
      "        0.5000, 0.9533, 0.9667, 0.7400, 0.9815, 0.6167, 0.9905, 0.9833, 0.9564,\n",
      "        0.9083, 1.0000, 0.9536, 0.7667, 0.8556, 0.8667, 0.9000])\n",
      "Train backdoor\n",
      "Train Epoch: 58 [0/9728 (0%)]\tLoss: 7.370404\n",
      "Train Epoch: 58 [512/9728 (5%)]\tLoss: 2.548595\n",
      "Train Epoch: 58 [1024/9728 (11%)]\tLoss: 0.161694\n",
      "Train Epoch: 58 [1536/9728 (16%)]\tLoss: 0.070385\n",
      "Train Epoch: 58 [2048/9728 (21%)]\tLoss: 0.035802\n",
      "Train Epoch: 58 [2560/9728 (26%)]\tLoss: 0.031938\n",
      "Train Epoch: 58 [3072/9728 (32%)]\tLoss: 0.020842\n",
      "Train Epoch: 58 [3584/9728 (37%)]\tLoss: 0.017962\n",
      "Train Epoch: 58 [4096/9728 (42%)]\tLoss: 0.015036\n",
      "Train Epoch: 58 [4608/9728 (47%)]\tLoss: 0.014510\n",
      "Train Epoch: 58 [5120/9728 (53%)]\tLoss: 0.012864\n",
      "Train Epoch: 58 [5632/9728 (58%)]\tLoss: 0.010590\n",
      "Train Epoch: 58 [6144/9728 (63%)]\tLoss: 0.008154\n",
      "Train Epoch: 58 [6656/9728 (68%)]\tLoss: 0.008480\n",
      "Train Epoch: 58 [7168/9728 (74%)]\tLoss: 0.008171\n",
      "Train Epoch: 58 [7680/9728 (79%)]\tLoss: 0.006436\n",
      "Train Epoch: 58 [8192/9728 (84%)]\tLoss: 0.006568\n",
      "Train Epoch: 58 [8704/9728 (89%)]\tLoss: 0.006158\n",
      "Train Epoch: 58 [9216/9728 (95%)]\tLoss: 0.004504\n",
      "Average training loss: 0.545215368270874\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.2681, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 59 [0/39424 (0%)]\tLoss: 7.330204\n",
      "Train Epoch: 59 [512/39424 (1%)]\tLoss: 0.566894\n",
      "Train Epoch: 59 [1024/39424 (3%)]\tLoss: 0.376925\n",
      "Train Epoch: 59 [1536/39424 (4%)]\tLoss: 0.345392\n",
      "Train Epoch: 59 [2048/39424 (5%)]\tLoss: 0.286921\n",
      "Train Epoch: 59 [2560/39424 (6%)]\tLoss: 0.240051\n",
      "Train Epoch: 59 [3072/39424 (8%)]\tLoss: 0.270502\n",
      "Train Epoch: 59 [3584/39424 (9%)]\tLoss: 0.243240\n",
      "Train Epoch: 59 [4096/39424 (10%)]\tLoss: 0.217128\n",
      "Train Epoch: 59 [4608/39424 (12%)]\tLoss: 0.212187\n",
      "Train Epoch: 59 [5120/39424 (13%)]\tLoss: 0.169744\n",
      "Train Epoch: 59 [5632/39424 (14%)]\tLoss: 0.209246\n",
      "Train Epoch: 59 [6144/39424 (16%)]\tLoss: 0.170354\n",
      "Train Epoch: 59 [6656/39424 (17%)]\tLoss: 0.194398\n",
      "Train Epoch: 59 [7168/39424 (18%)]\tLoss: 0.178926\n",
      "Train Epoch: 59 [7680/39424 (19%)]\tLoss: 0.193585\n",
      "Train Epoch: 59 [8192/39424 (21%)]\tLoss: 0.139231\n",
      "Train Epoch: 59 [8704/39424 (22%)]\tLoss: 0.156541\n",
      "Train Epoch: 59 [9216/39424 (23%)]\tLoss: 0.188865\n",
      "Train Epoch: 59 [9728/39424 (25%)]\tLoss: 0.166523\n",
      "Train Epoch: 59 [10240/39424 (26%)]\tLoss: 0.139943\n",
      "Train Epoch: 59 [10752/39424 (27%)]\tLoss: 0.178432\n",
      "Train Epoch: 59 [11264/39424 (29%)]\tLoss: 0.140996\n",
      "Train Epoch: 59 [11776/39424 (30%)]\tLoss: 0.128748\n",
      "Train Epoch: 59 [12288/39424 (31%)]\tLoss: 0.144118\n",
      "Train Epoch: 59 [12800/39424 (32%)]\tLoss: 0.141355\n",
      "Train Epoch: 59 [13312/39424 (34%)]\tLoss: 0.145181\n",
      "Train Epoch: 59 [13824/39424 (35%)]\tLoss: 0.166425\n",
      "Train Epoch: 59 [14336/39424 (36%)]\tLoss: 0.131875\n",
      "Train Epoch: 59 [14848/39424 (38%)]\tLoss: 0.135890\n",
      "Train Epoch: 59 [15360/39424 (39%)]\tLoss: 0.135072\n",
      "Train Epoch: 59 [15872/39424 (40%)]\tLoss: 0.140247\n",
      "Train Epoch: 59 [16384/39424 (42%)]\tLoss: 0.142632\n",
      "Train Epoch: 59 [16896/39424 (43%)]\tLoss: 0.147457\n",
      "Train Epoch: 59 [17408/39424 (44%)]\tLoss: 0.141195\n",
      "Train Epoch: 59 [17920/39424 (45%)]\tLoss: 0.159058\n",
      "Train Epoch: 59 [18432/39424 (47%)]\tLoss: 0.128571\n",
      "Train Epoch: 59 [18944/39424 (48%)]\tLoss: 0.109481\n",
      "Train Epoch: 59 [19456/39424 (49%)]\tLoss: 0.123669\n",
      "Train Epoch: 59 [19968/39424 (51%)]\tLoss: 0.096058\n",
      "Train Epoch: 59 [20480/39424 (52%)]\tLoss: 0.101334\n",
      "Train Epoch: 59 [20992/39424 (53%)]\tLoss: 0.140049\n",
      "Train Epoch: 59 [21504/39424 (55%)]\tLoss: 0.094385\n",
      "Train Epoch: 59 [22016/39424 (56%)]\tLoss: 0.100318\n",
      "Train Epoch: 59 [22528/39424 (57%)]\tLoss: 0.109303\n",
      "Train Epoch: 59 [23040/39424 (58%)]\tLoss: 0.136997\n",
      "Train Epoch: 59 [23552/39424 (60%)]\tLoss: 0.109913\n",
      "Train Epoch: 59 [24064/39424 (61%)]\tLoss: 0.106042\n",
      "Train Epoch: 59 [24576/39424 (62%)]\tLoss: 0.114911\n",
      "Train Epoch: 59 [25088/39424 (64%)]\tLoss: 0.092669\n",
      "Train Epoch: 59 [25600/39424 (65%)]\tLoss: 0.121620\n",
      "Train Epoch: 59 [26112/39424 (66%)]\tLoss: 0.102497\n",
      "Train Epoch: 59 [26624/39424 (68%)]\tLoss: 0.123513\n",
      "Train Epoch: 59 [27136/39424 (69%)]\tLoss: 0.114154\n",
      "Train Epoch: 59 [27648/39424 (70%)]\tLoss: 0.122114\n",
      "Train Epoch: 59 [28160/39424 (71%)]\tLoss: 0.100386\n",
      "Train Epoch: 59 [28672/39424 (73%)]\tLoss: 0.113940\n",
      "Train Epoch: 59 [29184/39424 (74%)]\tLoss: 0.112444\n",
      "Train Epoch: 59 [29696/39424 (75%)]\tLoss: 0.108134\n",
      "Train Epoch: 59 [30208/39424 (77%)]\tLoss: 0.120527\n",
      "Train Epoch: 59 [30720/39424 (78%)]\tLoss: 0.101759\n",
      "Train Epoch: 59 [31232/39424 (79%)]\tLoss: 0.142162\n",
      "Train Epoch: 59 [31744/39424 (81%)]\tLoss: 0.126358\n",
      "Train Epoch: 59 [32256/39424 (82%)]\tLoss: 0.108562\n",
      "Train Epoch: 59 [32768/39424 (83%)]\tLoss: 0.108108\n",
      "Train Epoch: 59 [33280/39424 (84%)]\tLoss: 0.100519\n",
      "Train Epoch: 59 [33792/39424 (86%)]\tLoss: 0.082902\n",
      "Train Epoch: 59 [34304/39424 (87%)]\tLoss: 0.075524\n",
      "Train Epoch: 59 [34816/39424 (88%)]\tLoss: 0.096447\n",
      "Train Epoch: 59 [35328/39424 (90%)]\tLoss: 0.090870\n",
      "Train Epoch: 59 [35840/39424 (91%)]\tLoss: 0.089266\n",
      "Train Epoch: 59 [36352/39424 (92%)]\tLoss: 0.106507\n",
      "Train Epoch: 59 [36864/39424 (94%)]\tLoss: 0.084338\n",
      "Train Epoch: 59 [37376/39424 (95%)]\tLoss: 0.090561\n",
      "Train Epoch: 59 [37888/39424 (96%)]\tLoss: 0.107538\n",
      "Train Epoch: 59 [38400/39424 (97%)]\tLoss: 0.098310\n",
      "Train Epoch: 59 [38912/39424 (99%)]\tLoss: 0.106050\n",
      "Average training loss: 0.24148432910442352\n",
      "\n",
      "Test set: Average loss: 7.8677, Accuracy: 78/12630 (1%)\n",
      "\n",
      "tensor([0.0062,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2754, Accuracy: 11843/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9569, 0.9840, 0.9556, 0.9288, 0.9222, 0.8067, 0.9089, 0.9622,\n",
      "        0.9875, 0.9864, 0.9571, 0.9768, 0.9958, 1.0000, 0.9762, 0.9867, 0.9444,\n",
      "        0.8000, 0.9500, 0.9889, 0.6333, 0.9167, 0.9533, 0.8778, 0.9375, 0.8056,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6333, 0.9905, 0.9833, 0.9538,\n",
      "        0.9083, 1.0000, 0.9536, 0.7556, 0.8556, 0.8667, 0.9000])\n",
      "Train backdoor\n",
      "Train Epoch: 59 [0/9728 (0%)]\tLoss: 7.369835\n",
      "Train Epoch: 59 [512/9728 (5%)]\tLoss: 2.591656\n",
      "Train Epoch: 59 [1024/9728 (11%)]\tLoss: 0.168443\n",
      "Train Epoch: 59 [1536/9728 (16%)]\tLoss: 0.072935\n",
      "Train Epoch: 59 [2048/9728 (21%)]\tLoss: 0.049233\n",
      "Train Epoch: 59 [2560/9728 (26%)]\tLoss: 0.034104\n",
      "Train Epoch: 59 [3072/9728 (32%)]\tLoss: 0.023017\n",
      "Train Epoch: 59 [3584/9728 (37%)]\tLoss: 0.017332\n",
      "Train Epoch: 59 [4096/9728 (42%)]\tLoss: 0.013821\n",
      "Train Epoch: 59 [4608/9728 (47%)]\tLoss: 0.010499\n",
      "Train Epoch: 59 [5120/9728 (53%)]\tLoss: 0.013000\n",
      "Train Epoch: 59 [5632/9728 (58%)]\tLoss: 0.008308\n",
      "Train Epoch: 59 [6144/9728 (63%)]\tLoss: 0.007993\n",
      "Train Epoch: 59 [6656/9728 (68%)]\tLoss: 0.009079\n",
      "Train Epoch: 59 [7168/9728 (74%)]\tLoss: 0.008353\n",
      "Train Epoch: 59 [7680/9728 (79%)]\tLoss: 0.007083\n",
      "Train Epoch: 59 [8192/9728 (84%)]\tLoss: 0.005691\n",
      "Train Epoch: 59 [8704/9728 (89%)]\tLoss: 0.006792\n",
      "Train Epoch: 59 [9216/9728 (95%)]\tLoss: 0.006036\n",
      "Average training loss: 0.5485900044441223\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.2020, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 60 [0/39424 (0%)]\tLoss: 7.299202\n",
      "Train Epoch: 60 [512/39424 (1%)]\tLoss: 0.487256\n",
      "Train Epoch: 60 [1024/39424 (3%)]\tLoss: 0.402548\n",
      "Train Epoch: 60 [1536/39424 (4%)]\tLoss: 0.351837\n",
      "Train Epoch: 60 [2048/39424 (5%)]\tLoss: 0.297581\n",
      "Train Epoch: 60 [2560/39424 (6%)]\tLoss: 0.247739\n",
      "Train Epoch: 60 [3072/39424 (8%)]\tLoss: 0.286728\n",
      "Train Epoch: 60 [3584/39424 (9%)]\tLoss: 0.230001\n",
      "Train Epoch: 60 [4096/39424 (10%)]\tLoss: 0.225578\n",
      "Train Epoch: 60 [4608/39424 (12%)]\tLoss: 0.215331\n",
      "Train Epoch: 60 [5120/39424 (13%)]\tLoss: 0.186607\n",
      "Train Epoch: 60 [5632/39424 (14%)]\tLoss: 0.208711\n",
      "Train Epoch: 60 [6144/39424 (16%)]\tLoss: 0.165073\n",
      "Train Epoch: 60 [6656/39424 (17%)]\tLoss: 0.181014\n",
      "Train Epoch: 60 [7168/39424 (18%)]\tLoss: 0.174866\n",
      "Train Epoch: 60 [7680/39424 (19%)]\tLoss: 0.171475\n",
      "Train Epoch: 60 [8192/39424 (21%)]\tLoss: 0.137429\n",
      "Train Epoch: 60 [8704/39424 (22%)]\tLoss: 0.153004\n",
      "Train Epoch: 60 [9216/39424 (23%)]\tLoss: 0.178717\n",
      "Train Epoch: 60 [9728/39424 (25%)]\tLoss: 0.166264\n",
      "Train Epoch: 60 [10240/39424 (26%)]\tLoss: 0.149947\n",
      "Train Epoch: 60 [10752/39424 (27%)]\tLoss: 0.192806\n",
      "Train Epoch: 60 [11264/39424 (29%)]\tLoss: 0.142882\n",
      "Train Epoch: 60 [11776/39424 (30%)]\tLoss: 0.132200\n",
      "Train Epoch: 60 [12288/39424 (31%)]\tLoss: 0.142761\n",
      "Train Epoch: 60 [12800/39424 (32%)]\tLoss: 0.124184\n",
      "Train Epoch: 60 [13312/39424 (34%)]\tLoss: 0.147166\n",
      "Train Epoch: 60 [13824/39424 (35%)]\tLoss: 0.150914\n",
      "Train Epoch: 60 [14336/39424 (36%)]\tLoss: 0.130462\n",
      "Train Epoch: 60 [14848/39424 (38%)]\tLoss: 0.132989\n",
      "Train Epoch: 60 [15360/39424 (39%)]\tLoss: 0.129807\n",
      "Train Epoch: 60 [15872/39424 (40%)]\tLoss: 0.137430\n",
      "Train Epoch: 60 [16384/39424 (42%)]\tLoss: 0.134090\n",
      "Train Epoch: 60 [16896/39424 (43%)]\tLoss: 0.152033\n",
      "Train Epoch: 60 [17408/39424 (44%)]\tLoss: 0.144956\n",
      "Train Epoch: 60 [17920/39424 (45%)]\tLoss: 0.179890\n",
      "Train Epoch: 60 [18432/39424 (47%)]\tLoss: 0.122416\n",
      "Train Epoch: 60 [18944/39424 (48%)]\tLoss: 0.109483\n",
      "Train Epoch: 60 [19456/39424 (49%)]\tLoss: 0.112842\n",
      "Train Epoch: 60 [19968/39424 (51%)]\tLoss: 0.096030\n",
      "Train Epoch: 60 [20480/39424 (52%)]\tLoss: 0.094820\n",
      "Train Epoch: 60 [20992/39424 (53%)]\tLoss: 0.131028\n",
      "Train Epoch: 60 [21504/39424 (55%)]\tLoss: 0.083385\n",
      "Train Epoch: 60 [22016/39424 (56%)]\tLoss: 0.105872\n",
      "Train Epoch: 60 [22528/39424 (57%)]\tLoss: 0.098331\n",
      "Train Epoch: 60 [23040/39424 (58%)]\tLoss: 0.153753\n",
      "Train Epoch: 60 [23552/39424 (60%)]\tLoss: 0.108809\n",
      "Train Epoch: 60 [24064/39424 (61%)]\tLoss: 0.103178\n",
      "Train Epoch: 60 [24576/39424 (62%)]\tLoss: 0.112259\n",
      "Train Epoch: 60 [25088/39424 (64%)]\tLoss: 0.105768\n",
      "Train Epoch: 60 [25600/39424 (65%)]\tLoss: 0.117367\n",
      "Train Epoch: 60 [26112/39424 (66%)]\tLoss: 0.101955\n",
      "Train Epoch: 60 [26624/39424 (68%)]\tLoss: 0.125936\n",
      "Train Epoch: 60 [27136/39424 (69%)]\tLoss: 0.127557\n",
      "Train Epoch: 60 [27648/39424 (70%)]\tLoss: 0.123794\n",
      "Train Epoch: 60 [28160/39424 (71%)]\tLoss: 0.089318\n",
      "Train Epoch: 60 [28672/39424 (73%)]\tLoss: 0.103945\n",
      "Train Epoch: 60 [29184/39424 (74%)]\tLoss: 0.116880\n",
      "Train Epoch: 60 [29696/39424 (75%)]\tLoss: 0.104796\n",
      "Train Epoch: 60 [30208/39424 (77%)]\tLoss: 0.110512\n",
      "Train Epoch: 60 [30720/39424 (78%)]\tLoss: 0.112216\n",
      "Train Epoch: 60 [31232/39424 (79%)]\tLoss: 0.118859\n",
      "Train Epoch: 60 [31744/39424 (81%)]\tLoss: 0.113512\n",
      "Train Epoch: 60 [32256/39424 (82%)]\tLoss: 0.092645\n",
      "Train Epoch: 60 [32768/39424 (83%)]\tLoss: 0.105596\n",
      "Train Epoch: 60 [33280/39424 (84%)]\tLoss: 0.092199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [33792/39424 (86%)]\tLoss: 0.081842\n",
      "Train Epoch: 60 [34304/39424 (87%)]\tLoss: 0.067807\n",
      "Train Epoch: 60 [34816/39424 (88%)]\tLoss: 0.096052\n",
      "Train Epoch: 60 [35328/39424 (90%)]\tLoss: 0.104582\n",
      "Train Epoch: 60 [35840/39424 (91%)]\tLoss: 0.088525\n",
      "Train Epoch: 60 [36352/39424 (92%)]\tLoss: 0.102862\n",
      "Train Epoch: 60 [36864/39424 (94%)]\tLoss: 0.083824\n",
      "Train Epoch: 60 [37376/39424 (95%)]\tLoss: 0.092017\n",
      "Train Epoch: 60 [37888/39424 (96%)]\tLoss: 0.122197\n",
      "Train Epoch: 60 [38400/39424 (97%)]\tLoss: 0.095057\n",
      "Train Epoch: 60 [38912/39424 (99%)]\tLoss: 0.088423\n",
      "Average training loss: 0.23908741772174835\n",
      "\n",
      "Test set: Average loss: 7.8668, Accuracy: 79/12630 (1%)\n",
      "\n",
      "tensor([0.0063,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2732, Accuracy: 11845/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9569, 0.9853, 0.9556, 0.9273, 0.9206, 0.8067, 0.9044, 0.9622,\n",
      "        0.9875, 0.9864, 0.9524, 0.9783, 0.9958, 1.0000, 0.9762, 0.9933, 0.9417,\n",
      "        0.8000, 0.9500, 0.9889, 0.6222, 0.9250, 0.9533, 0.8778, 0.9375, 0.8111,\n",
      "        0.5000, 0.9600, 0.9778, 0.7400, 0.9815, 0.6667, 0.9905, 0.9833, 0.9538,\n",
      "        0.9167, 1.0000, 0.9536, 0.7667, 0.8556, 0.8667, 0.9000])\n",
      "Train backdoor\n",
      "Train Epoch: 60 [0/9728 (0%)]\tLoss: 7.631732\n",
      "Train Epoch: 60 [512/9728 (5%)]\tLoss: 2.541814\n",
      "Train Epoch: 60 [1024/9728 (11%)]\tLoss: 0.184876\n",
      "Train Epoch: 60 [1536/9728 (16%)]\tLoss: 0.077722\n",
      "Train Epoch: 60 [2048/9728 (21%)]\tLoss: 0.043546\n",
      "Train Epoch: 60 [2560/9728 (26%)]\tLoss: 0.035719\n",
      "Train Epoch: 60 [3072/9728 (32%)]\tLoss: 0.029855\n",
      "Train Epoch: 60 [3584/9728 (37%)]\tLoss: 0.020079\n",
      "Train Epoch: 60 [4096/9728 (42%)]\tLoss: 0.016904\n",
      "Train Epoch: 60 [4608/9728 (47%)]\tLoss: 0.011007\n",
      "Train Epoch: 60 [5120/9728 (53%)]\tLoss: 0.011449\n",
      "Train Epoch: 60 [5632/9728 (58%)]\tLoss: 0.008590\n",
      "Train Epoch: 60 [6144/9728 (63%)]\tLoss: 0.008613\n",
      "Train Epoch: 60 [6656/9728 (68%)]\tLoss: 0.009185\n",
      "Train Epoch: 60 [7168/9728 (74%)]\tLoss: 0.012056\n",
      "Train Epoch: 60 [7680/9728 (79%)]\tLoss: 0.006601\n",
      "Train Epoch: 60 [8192/9728 (84%)]\tLoss: 0.007475\n",
      "Train Epoch: 60 [8704/9728 (89%)]\tLoss: 0.006249\n",
      "Train Epoch: 60 [9216/9728 (95%)]\tLoss: 0.005392\n",
      "Average training loss: 0.5615193247795105\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.1240, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 61 [0/39424 (0%)]\tLoss: 7.158577\n",
      "Train Epoch: 61 [512/39424 (1%)]\tLoss: 0.501078\n",
      "Train Epoch: 61 [1024/39424 (3%)]\tLoss: 0.355354\n",
      "Train Epoch: 61 [1536/39424 (4%)]\tLoss: 0.311245\n",
      "Train Epoch: 61 [2048/39424 (5%)]\tLoss: 0.259587\n",
      "Train Epoch: 61 [2560/39424 (6%)]\tLoss: 0.226849\n",
      "Train Epoch: 61 [3072/39424 (8%)]\tLoss: 0.260356\n",
      "Train Epoch: 61 [3584/39424 (9%)]\tLoss: 0.227454\n",
      "Train Epoch: 61 [4096/39424 (10%)]\tLoss: 0.193358\n",
      "Train Epoch: 61 [4608/39424 (12%)]\tLoss: 0.201245\n",
      "Train Epoch: 61 [5120/39424 (13%)]\tLoss: 0.179418\n",
      "Train Epoch: 61 [5632/39424 (14%)]\tLoss: 0.193809\n",
      "Train Epoch: 61 [6144/39424 (16%)]\tLoss: 0.166693\n",
      "Train Epoch: 61 [6656/39424 (17%)]\tLoss: 0.186783\n",
      "Train Epoch: 61 [7168/39424 (18%)]\tLoss: 0.179330\n",
      "Train Epoch: 61 [7680/39424 (19%)]\tLoss: 0.184976\n",
      "Train Epoch: 61 [8192/39424 (21%)]\tLoss: 0.136156\n",
      "Train Epoch: 61 [8704/39424 (22%)]\tLoss: 0.170334\n",
      "Train Epoch: 61 [9216/39424 (23%)]\tLoss: 0.173141\n",
      "Train Epoch: 61 [9728/39424 (25%)]\tLoss: 0.163059\n",
      "Train Epoch: 61 [10240/39424 (26%)]\tLoss: 0.142165\n",
      "Train Epoch: 61 [10752/39424 (27%)]\tLoss: 0.182647\n",
      "Train Epoch: 61 [11264/39424 (29%)]\tLoss: 0.127483\n",
      "Train Epoch: 61 [11776/39424 (30%)]\tLoss: 0.124725\n",
      "Train Epoch: 61 [12288/39424 (31%)]\tLoss: 0.131289\n",
      "Train Epoch: 61 [12800/39424 (32%)]\tLoss: 0.134403\n",
      "Train Epoch: 61 [13312/39424 (34%)]\tLoss: 0.141581\n",
      "Train Epoch: 61 [13824/39424 (35%)]\tLoss: 0.158524\n",
      "Train Epoch: 61 [14336/39424 (36%)]\tLoss: 0.125744\n",
      "Train Epoch: 61 [14848/39424 (38%)]\tLoss: 0.128902\n",
      "Train Epoch: 61 [15360/39424 (39%)]\tLoss: 0.134629\n",
      "Train Epoch: 61 [15872/39424 (40%)]\tLoss: 0.141315\n",
      "Train Epoch: 61 [16384/39424 (42%)]\tLoss: 0.136909\n",
      "Train Epoch: 61 [16896/39424 (43%)]\tLoss: 0.156038\n",
      "Train Epoch: 61 [17408/39424 (44%)]\tLoss: 0.129403\n",
      "Train Epoch: 61 [17920/39424 (45%)]\tLoss: 0.159679\n",
      "Train Epoch: 61 [18432/39424 (47%)]\tLoss: 0.128229\n",
      "Train Epoch: 61 [18944/39424 (48%)]\tLoss: 0.104978\n",
      "Train Epoch: 61 [19456/39424 (49%)]\tLoss: 0.129311\n",
      "Train Epoch: 61 [19968/39424 (51%)]\tLoss: 0.087297\n",
      "Train Epoch: 61 [20480/39424 (52%)]\tLoss: 0.103045\n",
      "Train Epoch: 61 [20992/39424 (53%)]\tLoss: 0.146037\n",
      "Train Epoch: 61 [21504/39424 (55%)]\tLoss: 0.093055\n",
      "Train Epoch: 61 [22016/39424 (56%)]\tLoss: 0.095546\n",
      "Train Epoch: 61 [22528/39424 (57%)]\tLoss: 0.086583\n",
      "Train Epoch: 61 [23040/39424 (58%)]\tLoss: 0.143684\n",
      "Train Epoch: 61 [23552/39424 (60%)]\tLoss: 0.102474\n",
      "Train Epoch: 61 [24064/39424 (61%)]\tLoss: 0.108294\n",
      "Train Epoch: 61 [24576/39424 (62%)]\tLoss: 0.108642\n",
      "Train Epoch: 61 [25088/39424 (64%)]\tLoss: 0.101775\n",
      "Train Epoch: 61 [25600/39424 (65%)]\tLoss: 0.107927\n",
      "Train Epoch: 61 [26112/39424 (66%)]\tLoss: 0.093190\n",
      "Train Epoch: 61 [26624/39424 (68%)]\tLoss: 0.129794\n",
      "Train Epoch: 61 [27136/39424 (69%)]\tLoss: 0.109831\n",
      "Train Epoch: 61 [27648/39424 (70%)]\tLoss: 0.127692\n",
      "Train Epoch: 61 [28160/39424 (71%)]\tLoss: 0.081215\n",
      "Train Epoch: 61 [28672/39424 (73%)]\tLoss: 0.095644\n",
      "Train Epoch: 61 [29184/39424 (74%)]\tLoss: 0.110780\n",
      "Train Epoch: 61 [29696/39424 (75%)]\tLoss: 0.099188\n",
      "Train Epoch: 61 [30208/39424 (77%)]\tLoss: 0.095667\n",
      "Train Epoch: 61 [30720/39424 (78%)]\tLoss: 0.108165\n",
      "Train Epoch: 61 [31232/39424 (79%)]\tLoss: 0.143639\n",
      "Train Epoch: 61 [31744/39424 (81%)]\tLoss: 0.123424\n",
      "Train Epoch: 61 [32256/39424 (82%)]\tLoss: 0.094773\n",
      "Train Epoch: 61 [32768/39424 (83%)]\tLoss: 0.106306\n",
      "Train Epoch: 61 [33280/39424 (84%)]\tLoss: 0.101809\n",
      "Train Epoch: 61 [33792/39424 (86%)]\tLoss: 0.075178\n",
      "Train Epoch: 61 [34304/39424 (87%)]\tLoss: 0.079714\n",
      "Train Epoch: 61 [34816/39424 (88%)]\tLoss: 0.088811\n",
      "Train Epoch: 61 [35328/39424 (90%)]\tLoss: 0.104075\n",
      "Train Epoch: 61 [35840/39424 (91%)]\tLoss: 0.079983\n",
      "Train Epoch: 61 [36352/39424 (92%)]\tLoss: 0.100444\n",
      "Train Epoch: 61 [36864/39424 (94%)]\tLoss: 0.087754\n",
      "Train Epoch: 61 [37376/39424 (95%)]\tLoss: 0.095197\n",
      "Train Epoch: 61 [37888/39424 (96%)]\tLoss: 0.094305\n",
      "Train Epoch: 61 [38400/39424 (97%)]\tLoss: 0.098793\n",
      "Train Epoch: 61 [38912/39424 (99%)]\tLoss: 0.086887\n",
      "Average training loss: 0.23303087055683136\n",
      "\n",
      "Test set: Average loss: 7.7784, Accuracy: 84/12630 (1%)\n",
      "\n",
      "tensor([0.0067,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2702, Accuracy: 11850/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9597, 0.9827, 0.9556, 0.9333, 0.9127, 0.8067, 0.9089, 0.9667,\n",
      "        0.9875, 0.9864, 0.9571, 0.9783, 0.9958, 1.0000, 0.9762, 0.9933, 0.9444,\n",
      "        0.7949, 0.9500, 0.9889, 0.6444, 0.9250, 0.9467, 0.8778, 0.9375, 0.8167,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6167, 0.9905, 0.9833, 0.9590,\n",
      "        0.9167, 1.0000, 0.9551, 0.7667, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 61 [0/9728 (0%)]\tLoss: 7.248375\n",
      "Train Epoch: 61 [512/9728 (5%)]\tLoss: 2.401704\n",
      "Train Epoch: 61 [1024/9728 (11%)]\tLoss: 0.176000\n",
      "Train Epoch: 61 [1536/9728 (16%)]\tLoss: 0.077786\n",
      "Train Epoch: 61 [2048/9728 (21%)]\tLoss: 0.038247\n",
      "Train Epoch: 61 [2560/9728 (26%)]\tLoss: 0.031395\n",
      "Train Epoch: 61 [3072/9728 (32%)]\tLoss: 0.022249\n",
      "Train Epoch: 61 [3584/9728 (37%)]\tLoss: 0.020047\n",
      "Train Epoch: 61 [4096/9728 (42%)]\tLoss: 0.015077\n",
      "Train Epoch: 61 [4608/9728 (47%)]\tLoss: 0.014400\n",
      "Train Epoch: 61 [5120/9728 (53%)]\tLoss: 0.011978\n",
      "Train Epoch: 61 [5632/9728 (58%)]\tLoss: 0.009148\n",
      "Train Epoch: 61 [6144/9728 (63%)]\tLoss: 0.007639\n",
      "Train Epoch: 61 [6656/9728 (68%)]\tLoss: 0.011446\n",
      "Train Epoch: 61 [7168/9728 (74%)]\tLoss: 0.009099\n",
      "Train Epoch: 61 [7680/9728 (79%)]\tLoss: 0.006115\n",
      "Train Epoch: 61 [8192/9728 (84%)]\tLoss: 0.005702\n",
      "Train Epoch: 61 [8704/9728 (89%)]\tLoss: 0.006416\n",
      "Train Epoch: 61 [9216/9728 (95%)]\tLoss: 0.005586\n",
      "Average training loss: 0.5325478911399841\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.1759, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 62 [0/39424 (0%)]\tLoss: 7.169217\n",
      "Train Epoch: 62 [512/39424 (1%)]\tLoss: 0.456607\n",
      "Train Epoch: 62 [1024/39424 (3%)]\tLoss: 0.378485\n",
      "Train Epoch: 62 [1536/39424 (4%)]\tLoss: 0.347165\n",
      "Train Epoch: 62 [2048/39424 (5%)]\tLoss: 0.278036\n",
      "Train Epoch: 62 [2560/39424 (6%)]\tLoss: 0.221250\n",
      "Train Epoch: 62 [3072/39424 (8%)]\tLoss: 0.272452\n",
      "Train Epoch: 62 [3584/39424 (9%)]\tLoss: 0.229016\n",
      "Train Epoch: 62 [4096/39424 (10%)]\tLoss: 0.198796\n",
      "Train Epoch: 62 [4608/39424 (12%)]\tLoss: 0.205602\n",
      "Train Epoch: 62 [5120/39424 (13%)]\tLoss: 0.177088\n",
      "Train Epoch: 62 [5632/39424 (14%)]\tLoss: 0.182905\n",
      "Train Epoch: 62 [6144/39424 (16%)]\tLoss: 0.166448\n",
      "Train Epoch: 62 [6656/39424 (17%)]\tLoss: 0.183835\n",
      "Train Epoch: 62 [7168/39424 (18%)]\tLoss: 0.165447\n",
      "Train Epoch: 62 [7680/39424 (19%)]\tLoss: 0.173616\n",
      "Train Epoch: 62 [8192/39424 (21%)]\tLoss: 0.127953\n",
      "Train Epoch: 62 [8704/39424 (22%)]\tLoss: 0.130335\n",
      "Train Epoch: 62 [9216/39424 (23%)]\tLoss: 0.172033\n",
      "Train Epoch: 62 [9728/39424 (25%)]\tLoss: 0.160014\n",
      "Train Epoch: 62 [10240/39424 (26%)]\tLoss: 0.147110\n",
      "Train Epoch: 62 [10752/39424 (27%)]\tLoss: 0.180977\n",
      "Train Epoch: 62 [11264/39424 (29%)]\tLoss: 0.126342\n",
      "Train Epoch: 62 [11776/39424 (30%)]\tLoss: 0.116470\n",
      "Train Epoch: 62 [12288/39424 (31%)]\tLoss: 0.135434\n",
      "Train Epoch: 62 [12800/39424 (32%)]\tLoss: 0.118320\n",
      "Train Epoch: 62 [13312/39424 (34%)]\tLoss: 0.140801\n",
      "Train Epoch: 62 [13824/39424 (35%)]\tLoss: 0.146755\n",
      "Train Epoch: 62 [14336/39424 (36%)]\tLoss: 0.131035\n",
      "Train Epoch: 62 [14848/39424 (38%)]\tLoss: 0.124110\n",
      "Train Epoch: 62 [15360/39424 (39%)]\tLoss: 0.129168\n",
      "Train Epoch: 62 [15872/39424 (40%)]\tLoss: 0.133494\n",
      "Train Epoch: 62 [16384/39424 (42%)]\tLoss: 0.141684\n",
      "Train Epoch: 62 [16896/39424 (43%)]\tLoss: 0.157080\n",
      "Train Epoch: 62 [17408/39424 (44%)]\tLoss: 0.122952\n",
      "Train Epoch: 62 [17920/39424 (45%)]\tLoss: 0.156355\n",
      "Train Epoch: 62 [18432/39424 (47%)]\tLoss: 0.116711\n",
      "Train Epoch: 62 [18944/39424 (48%)]\tLoss: 0.098985\n",
      "Train Epoch: 62 [19456/39424 (49%)]\tLoss: 0.122333\n",
      "Train Epoch: 62 [19968/39424 (51%)]\tLoss: 0.102833\n",
      "Train Epoch: 62 [20480/39424 (52%)]\tLoss: 0.098652\n",
      "Train Epoch: 62 [20992/39424 (53%)]\tLoss: 0.130742\n",
      "Train Epoch: 62 [21504/39424 (55%)]\tLoss: 0.080765\n",
      "Train Epoch: 62 [22016/39424 (56%)]\tLoss: 0.095823\n",
      "Train Epoch: 62 [22528/39424 (57%)]\tLoss: 0.088217\n",
      "Train Epoch: 62 [23040/39424 (58%)]\tLoss: 0.145018\n",
      "Train Epoch: 62 [23552/39424 (60%)]\tLoss: 0.113328\n",
      "Train Epoch: 62 [24064/39424 (61%)]\tLoss: 0.099805\n",
      "Train Epoch: 62 [24576/39424 (62%)]\tLoss: 0.106374\n",
      "Train Epoch: 62 [25088/39424 (64%)]\tLoss: 0.099306\n",
      "Train Epoch: 62 [25600/39424 (65%)]\tLoss: 0.107225\n",
      "Train Epoch: 62 [26112/39424 (66%)]\tLoss: 0.089633\n",
      "Train Epoch: 62 [26624/39424 (68%)]\tLoss: 0.113829\n",
      "Train Epoch: 62 [27136/39424 (69%)]\tLoss: 0.114812\n",
      "Train Epoch: 62 [27648/39424 (70%)]\tLoss: 0.120246\n",
      "Train Epoch: 62 [28160/39424 (71%)]\tLoss: 0.082106\n",
      "Train Epoch: 62 [28672/39424 (73%)]\tLoss: 0.106953\n",
      "Train Epoch: 62 [29184/39424 (74%)]\tLoss: 0.118585\n",
      "Train Epoch: 62 [29696/39424 (75%)]\tLoss: 0.097271\n",
      "Train Epoch: 62 [30208/39424 (77%)]\tLoss: 0.100719\n",
      "Train Epoch: 62 [30720/39424 (78%)]\tLoss: 0.095462\n",
      "Train Epoch: 62 [31232/39424 (79%)]\tLoss: 0.137781\n",
      "Train Epoch: 62 [31744/39424 (81%)]\tLoss: 0.109554\n",
      "Train Epoch: 62 [32256/39424 (82%)]\tLoss: 0.100308\n",
      "Train Epoch: 62 [32768/39424 (83%)]\tLoss: 0.110377\n",
      "Train Epoch: 62 [33280/39424 (84%)]\tLoss: 0.098585\n",
      "Train Epoch: 62 [33792/39424 (86%)]\tLoss: 0.072779\n",
      "Train Epoch: 62 [34304/39424 (87%)]\tLoss: 0.071865\n",
      "Train Epoch: 62 [34816/39424 (88%)]\tLoss: 0.086151\n",
      "Train Epoch: 62 [35328/39424 (90%)]\tLoss: 0.078386\n",
      "Train Epoch: 62 [35840/39424 (91%)]\tLoss: 0.084914\n",
      "Train Epoch: 62 [36352/39424 (92%)]\tLoss: 0.096744\n",
      "Train Epoch: 62 [36864/39424 (94%)]\tLoss: 0.088893\n",
      "Train Epoch: 62 [37376/39424 (95%)]\tLoss: 0.105734\n",
      "Train Epoch: 62 [37888/39424 (96%)]\tLoss: 0.106420\n",
      "Train Epoch: 62 [38400/39424 (97%)]\tLoss: 0.093210\n",
      "Train Epoch: 62 [38912/39424 (99%)]\tLoss: 0.097287\n",
      "Average training loss: 0.23102730512619019\n",
      "\n",
      "Test set: Average loss: 7.7721, Accuracy: 88/12630 (1%)\n",
      "\n",
      "tensor([0.0070,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2679, Accuracy: 11870/12630 (94%)\n",
      "\n",
      "tensor([0.4833, 0.9611, 0.9840, 0.9556, 0.9318, 0.9175, 0.8067, 0.9111, 0.9667,\n",
      "        0.9875, 0.9864, 0.9619, 0.9783, 0.9958, 1.0000, 0.9810, 0.9933, 0.9444,\n",
      "        0.8000, 0.9667, 0.9889, 0.6333, 0.9250, 0.9600, 0.8778, 0.9375, 0.8167,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6667, 0.9905, 0.9833, 0.9667,\n",
      "        0.9167, 1.0000, 0.9565, 0.7667, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 62 [0/9728 (0%)]\tLoss: 7.289489\n",
      "Train Epoch: 62 [512/9728 (5%)]\tLoss: 2.500136\n",
      "Train Epoch: 62 [1024/9728 (11%)]\tLoss: 0.194752\n",
      "Train Epoch: 62 [1536/9728 (16%)]\tLoss: 0.080374\n",
      "Train Epoch: 62 [2048/9728 (21%)]\tLoss: 0.040058\n",
      "Train Epoch: 62 [2560/9728 (26%)]\tLoss: 0.030279\n",
      "Train Epoch: 62 [3072/9728 (32%)]\tLoss: 0.030322\n",
      "Train Epoch: 62 [3584/9728 (37%)]\tLoss: 0.017398\n",
      "Train Epoch: 62 [4096/9728 (42%)]\tLoss: 0.015389\n",
      "Train Epoch: 62 [4608/9728 (47%)]\tLoss: 0.013606\n",
      "Train Epoch: 62 [5120/9728 (53%)]\tLoss: 0.012585\n",
      "Train Epoch: 62 [5632/9728 (58%)]\tLoss: 0.008409\n",
      "Train Epoch: 62 [6144/9728 (63%)]\tLoss: 0.008815\n",
      "Train Epoch: 62 [6656/9728 (68%)]\tLoss: 0.008816\n",
      "Train Epoch: 62 [7168/9728 (74%)]\tLoss: 0.008679\n",
      "Train Epoch: 62 [7680/9728 (79%)]\tLoss: 0.006296\n",
      "Train Epoch: 62 [8192/9728 (84%)]\tLoss: 0.006390\n",
      "Train Epoch: 62 [8704/9728 (89%)]\tLoss: 0.006744\n",
      "Train Epoch: 62 [9216/9728 (95%)]\tLoss: 0.005876\n",
      "Average training loss: 0.5412849187850952\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.0383, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 63 [0/39424 (0%)]\tLoss: 7.027525\n",
      "Train Epoch: 63 [512/39424 (1%)]\tLoss: 0.482984\n",
      "Train Epoch: 63 [1024/39424 (3%)]\tLoss: 0.359660\n",
      "Train Epoch: 63 [1536/39424 (4%)]\tLoss: 0.303980\n",
      "Train Epoch: 63 [2048/39424 (5%)]\tLoss: 0.249126\n",
      "Train Epoch: 63 [2560/39424 (6%)]\tLoss: 0.217915\n",
      "Train Epoch: 63 [3072/39424 (8%)]\tLoss: 0.249143\n",
      "Train Epoch: 63 [3584/39424 (9%)]\tLoss: 0.214606\n",
      "Train Epoch: 63 [4096/39424 (10%)]\tLoss: 0.197319\n",
      "Train Epoch: 63 [4608/39424 (12%)]\tLoss: 0.187574\n",
      "Train Epoch: 63 [5120/39424 (13%)]\tLoss: 0.174978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [5632/39424 (14%)]\tLoss: 0.202405\n",
      "Train Epoch: 63 [6144/39424 (16%)]\tLoss: 0.154390\n",
      "Train Epoch: 63 [6656/39424 (17%)]\tLoss: 0.181501\n",
      "Train Epoch: 63 [7168/39424 (18%)]\tLoss: 0.187429\n",
      "Train Epoch: 63 [7680/39424 (19%)]\tLoss: 0.175660\n",
      "Train Epoch: 63 [8192/39424 (21%)]\tLoss: 0.122600\n",
      "Train Epoch: 63 [8704/39424 (22%)]\tLoss: 0.146676\n",
      "Train Epoch: 63 [9216/39424 (23%)]\tLoss: 0.159924\n",
      "Train Epoch: 63 [9728/39424 (25%)]\tLoss: 0.163139\n",
      "Train Epoch: 63 [10240/39424 (26%)]\tLoss: 0.143120\n",
      "Train Epoch: 63 [10752/39424 (27%)]\tLoss: 0.173887\n",
      "Train Epoch: 63 [11264/39424 (29%)]\tLoss: 0.129348\n",
      "Train Epoch: 63 [11776/39424 (30%)]\tLoss: 0.118027\n",
      "Train Epoch: 63 [12288/39424 (31%)]\tLoss: 0.136199\n",
      "Train Epoch: 63 [12800/39424 (32%)]\tLoss: 0.118124\n",
      "Train Epoch: 63 [13312/39424 (34%)]\tLoss: 0.124601\n",
      "Train Epoch: 63 [13824/39424 (35%)]\tLoss: 0.138702\n",
      "Train Epoch: 63 [14336/39424 (36%)]\tLoss: 0.124675\n",
      "Train Epoch: 63 [14848/39424 (38%)]\tLoss: 0.132120\n",
      "Train Epoch: 63 [15360/39424 (39%)]\tLoss: 0.120503\n",
      "Train Epoch: 63 [15872/39424 (40%)]\tLoss: 0.130988\n",
      "Train Epoch: 63 [16384/39424 (42%)]\tLoss: 0.117421\n",
      "Train Epoch: 63 [16896/39424 (43%)]\tLoss: 0.144828\n",
      "Train Epoch: 63 [17408/39424 (44%)]\tLoss: 0.152113\n",
      "Train Epoch: 63 [17920/39424 (45%)]\tLoss: 0.175599\n",
      "Train Epoch: 63 [18432/39424 (47%)]\tLoss: 0.113270\n",
      "Train Epoch: 63 [18944/39424 (48%)]\tLoss: 0.110647\n",
      "Train Epoch: 63 [19456/39424 (49%)]\tLoss: 0.113076\n",
      "Train Epoch: 63 [19968/39424 (51%)]\tLoss: 0.091523\n",
      "Train Epoch: 63 [20480/39424 (52%)]\tLoss: 0.092844\n",
      "Train Epoch: 63 [20992/39424 (53%)]\tLoss: 0.131371\n",
      "Train Epoch: 63 [21504/39424 (55%)]\tLoss: 0.089854\n",
      "Train Epoch: 63 [22016/39424 (56%)]\tLoss: 0.096412\n",
      "Train Epoch: 63 [22528/39424 (57%)]\tLoss: 0.086184\n",
      "Train Epoch: 63 [23040/39424 (58%)]\tLoss: 0.127790\n",
      "Train Epoch: 63 [23552/39424 (60%)]\tLoss: 0.112521\n",
      "Train Epoch: 63 [24064/39424 (61%)]\tLoss: 0.101225\n",
      "Train Epoch: 63 [24576/39424 (62%)]\tLoss: 0.099541\n",
      "Train Epoch: 63 [25088/39424 (64%)]\tLoss: 0.088932\n",
      "Train Epoch: 63 [25600/39424 (65%)]\tLoss: 0.098993\n",
      "Train Epoch: 63 [26112/39424 (66%)]\tLoss: 0.090913\n",
      "Train Epoch: 63 [26624/39424 (68%)]\tLoss: 0.114612\n",
      "Train Epoch: 63 [27136/39424 (69%)]\tLoss: 0.114707\n",
      "Train Epoch: 63 [27648/39424 (70%)]\tLoss: 0.123900\n",
      "Train Epoch: 63 [28160/39424 (71%)]\tLoss: 0.079139\n",
      "Train Epoch: 63 [28672/39424 (73%)]\tLoss: 0.098956\n",
      "Train Epoch: 63 [29184/39424 (74%)]\tLoss: 0.098302\n",
      "Train Epoch: 63 [29696/39424 (75%)]\tLoss: 0.120489\n",
      "Train Epoch: 63 [30208/39424 (77%)]\tLoss: 0.107810\n",
      "Train Epoch: 63 [30720/39424 (78%)]\tLoss: 0.097259\n",
      "Train Epoch: 63 [31232/39424 (79%)]\tLoss: 0.121142\n",
      "Train Epoch: 63 [31744/39424 (81%)]\tLoss: 0.122708\n",
      "Train Epoch: 63 [32256/39424 (82%)]\tLoss: 0.091297\n",
      "Train Epoch: 63 [32768/39424 (83%)]\tLoss: 0.116865\n",
      "Train Epoch: 63 [33280/39424 (84%)]\tLoss: 0.092970\n",
      "Train Epoch: 63 [33792/39424 (86%)]\tLoss: 0.069841\n",
      "Train Epoch: 63 [34304/39424 (87%)]\tLoss: 0.065792\n",
      "Train Epoch: 63 [34816/39424 (88%)]\tLoss: 0.086149\n",
      "Train Epoch: 63 [35328/39424 (90%)]\tLoss: 0.083218\n",
      "Train Epoch: 63 [35840/39424 (91%)]\tLoss: 0.083650\n",
      "Train Epoch: 63 [36352/39424 (92%)]\tLoss: 0.104227\n",
      "Train Epoch: 63 [36864/39424 (94%)]\tLoss: 0.086638\n",
      "Train Epoch: 63 [37376/39424 (95%)]\tLoss: 0.086934\n",
      "Train Epoch: 63 [37888/39424 (96%)]\tLoss: 0.103491\n",
      "Train Epoch: 63 [38400/39424 (97%)]\tLoss: 0.091046\n",
      "Train Epoch: 63 [38912/39424 (99%)]\tLoss: 0.112646\n",
      "Average training loss: 0.2267230898141861\n",
      "\n",
      "Test set: Average loss: 7.7403, Accuracy: 84/12630 (1%)\n",
      "\n",
      "tensor([0.0067,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2661, Accuracy: 11867/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9597, 0.9840, 0.9556, 0.9318, 0.9190, 0.8067, 0.9133, 0.9667,\n",
      "        0.9875, 0.9864, 0.9619, 0.9783, 0.9958, 1.0000, 0.9762, 0.9933, 0.9417,\n",
      "        0.8000, 0.9667, 0.9889, 0.6444, 0.9250, 0.9533, 0.8778, 0.9375, 0.8111,\n",
      "        0.5000, 0.9600, 0.9778, 0.7400, 0.9815, 0.6500, 0.9905, 0.9833, 0.9590,\n",
      "        0.9250, 1.0000, 0.9565, 0.7667, 0.8667, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 63 [0/9728 (0%)]\tLoss: 7.281981\n",
      "Train Epoch: 63 [512/9728 (5%)]\tLoss: 2.416270\n",
      "Train Epoch: 63 [1024/9728 (11%)]\tLoss: 0.195781\n",
      "Train Epoch: 63 [1536/9728 (16%)]\tLoss: 0.080075\n",
      "Train Epoch: 63 [2048/9728 (21%)]\tLoss: 0.037927\n",
      "Train Epoch: 63 [2560/9728 (26%)]\tLoss: 0.037491\n",
      "Train Epoch: 63 [3072/9728 (32%)]\tLoss: 0.026552\n",
      "Train Epoch: 63 [3584/9728 (37%)]\tLoss: 0.017668\n",
      "Train Epoch: 63 [4096/9728 (42%)]\tLoss: 0.010965\n",
      "Train Epoch: 63 [4608/9728 (47%)]\tLoss: 0.012628\n",
      "Train Epoch: 63 [5120/9728 (53%)]\tLoss: 0.010831\n",
      "Train Epoch: 63 [5632/9728 (58%)]\tLoss: 0.010152\n",
      "Train Epoch: 63 [6144/9728 (63%)]\tLoss: 0.009606\n",
      "Train Epoch: 63 [6656/9728 (68%)]\tLoss: 0.009716\n",
      "Train Epoch: 63 [7168/9728 (74%)]\tLoss: 0.008315\n",
      "Train Epoch: 63 [7680/9728 (79%)]\tLoss: 0.007560\n",
      "Train Epoch: 63 [8192/9728 (84%)]\tLoss: 0.005839\n",
      "Train Epoch: 63 [8704/9728 (89%)]\tLoss: 0.006046\n",
      "Train Epoch: 63 [9216/9728 (95%)]\tLoss: 0.007054\n",
      "Average training loss: 0.536445140838623\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.1150, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 64 [0/39424 (0%)]\tLoss: 7.128726\n",
      "Train Epoch: 64 [512/39424 (1%)]\tLoss: 0.441282\n",
      "Train Epoch: 64 [1024/39424 (3%)]\tLoss: 0.383116\n",
      "Train Epoch: 64 [1536/39424 (4%)]\tLoss: 0.334859\n",
      "Train Epoch: 64 [2048/39424 (5%)]\tLoss: 0.281096\n",
      "Train Epoch: 64 [2560/39424 (6%)]\tLoss: 0.241940\n",
      "Train Epoch: 64 [3072/39424 (8%)]\tLoss: 0.265751\n",
      "Train Epoch: 64 [3584/39424 (9%)]\tLoss: 0.219209\n",
      "Train Epoch: 64 [4096/39424 (10%)]\tLoss: 0.194233\n",
      "Train Epoch: 64 [4608/39424 (12%)]\tLoss: 0.204020\n",
      "Train Epoch: 64 [5120/39424 (13%)]\tLoss: 0.170290\n",
      "Train Epoch: 64 [5632/39424 (14%)]\tLoss: 0.192231\n",
      "Train Epoch: 64 [6144/39424 (16%)]\tLoss: 0.154181\n",
      "Train Epoch: 64 [6656/39424 (17%)]\tLoss: 0.178897\n",
      "Train Epoch: 64 [7168/39424 (18%)]\tLoss: 0.167698\n",
      "Train Epoch: 64 [7680/39424 (19%)]\tLoss: 0.181677\n",
      "Train Epoch: 64 [8192/39424 (21%)]\tLoss: 0.124942\n",
      "Train Epoch: 64 [8704/39424 (22%)]\tLoss: 0.155381\n",
      "Train Epoch: 64 [9216/39424 (23%)]\tLoss: 0.170914\n",
      "Train Epoch: 64 [9728/39424 (25%)]\tLoss: 0.152825\n",
      "Train Epoch: 64 [10240/39424 (26%)]\tLoss: 0.142728\n",
      "Train Epoch: 64 [10752/39424 (27%)]\tLoss: 0.168107\n",
      "Train Epoch: 64 [11264/39424 (29%)]\tLoss: 0.125464\n",
      "Train Epoch: 64 [11776/39424 (30%)]\tLoss: 0.123348\n",
      "Train Epoch: 64 [12288/39424 (31%)]\tLoss: 0.118098\n",
      "Train Epoch: 64 [12800/39424 (32%)]\tLoss: 0.113105\n",
      "Train Epoch: 64 [13312/39424 (34%)]\tLoss: 0.137047\n",
      "Train Epoch: 64 [13824/39424 (35%)]\tLoss: 0.140603\n",
      "Train Epoch: 64 [14336/39424 (36%)]\tLoss: 0.130840\n",
      "Train Epoch: 64 [14848/39424 (38%)]\tLoss: 0.119523\n",
      "Train Epoch: 64 [15360/39424 (39%)]\tLoss: 0.120235\n",
      "Train Epoch: 64 [15872/39424 (40%)]\tLoss: 0.134035\n",
      "Train Epoch: 64 [16384/39424 (42%)]\tLoss: 0.132763\n",
      "Train Epoch: 64 [16896/39424 (43%)]\tLoss: 0.146579\n",
      "Train Epoch: 64 [17408/39424 (44%)]\tLoss: 0.129237\n",
      "Train Epoch: 64 [17920/39424 (45%)]\tLoss: 0.156749\n",
      "Train Epoch: 64 [18432/39424 (47%)]\tLoss: 0.125451\n",
      "Train Epoch: 64 [18944/39424 (48%)]\tLoss: 0.104902\n",
      "Train Epoch: 64 [19456/39424 (49%)]\tLoss: 0.113838\n",
      "Train Epoch: 64 [19968/39424 (51%)]\tLoss: 0.085673\n",
      "Train Epoch: 64 [20480/39424 (52%)]\tLoss: 0.094537\n",
      "Train Epoch: 64 [20992/39424 (53%)]\tLoss: 0.126955\n",
      "Train Epoch: 64 [21504/39424 (55%)]\tLoss: 0.081921\n",
      "Train Epoch: 64 [22016/39424 (56%)]\tLoss: 0.088492\n",
      "Train Epoch: 64 [22528/39424 (57%)]\tLoss: 0.084428\n",
      "Train Epoch: 64 [23040/39424 (58%)]\tLoss: 0.133631\n",
      "Train Epoch: 64 [23552/39424 (60%)]\tLoss: 0.115920\n",
      "Train Epoch: 64 [24064/39424 (61%)]\tLoss: 0.098950\n",
      "Train Epoch: 64 [24576/39424 (62%)]\tLoss: 0.091033\n",
      "Train Epoch: 64 [25088/39424 (64%)]\tLoss: 0.084866\n",
      "Train Epoch: 64 [25600/39424 (65%)]\tLoss: 0.098378\n",
      "Train Epoch: 64 [26112/39424 (66%)]\tLoss: 0.088905\n",
      "Train Epoch: 64 [26624/39424 (68%)]\tLoss: 0.111326\n",
      "Train Epoch: 64 [27136/39424 (69%)]\tLoss: 0.105715\n",
      "Train Epoch: 64 [27648/39424 (70%)]\tLoss: 0.114753\n",
      "Train Epoch: 64 [28160/39424 (71%)]\tLoss: 0.078317\n",
      "Train Epoch: 64 [28672/39424 (73%)]\tLoss: 0.100473\n",
      "Train Epoch: 64 [29184/39424 (74%)]\tLoss: 0.099975\n",
      "Train Epoch: 64 [29696/39424 (75%)]\tLoss: 0.108505\n",
      "Train Epoch: 64 [30208/39424 (77%)]\tLoss: 0.106974\n",
      "Train Epoch: 64 [30720/39424 (78%)]\tLoss: 0.102050\n",
      "Train Epoch: 64 [31232/39424 (79%)]\tLoss: 0.131755\n",
      "Train Epoch: 64 [31744/39424 (81%)]\tLoss: 0.121103\n",
      "Train Epoch: 64 [32256/39424 (82%)]\tLoss: 0.085453\n",
      "Train Epoch: 64 [32768/39424 (83%)]\tLoss: 0.095375\n",
      "Train Epoch: 64 [33280/39424 (84%)]\tLoss: 0.080278\n",
      "Train Epoch: 64 [33792/39424 (86%)]\tLoss: 0.061136\n",
      "Train Epoch: 64 [34304/39424 (87%)]\tLoss: 0.073520\n",
      "Train Epoch: 64 [34816/39424 (88%)]\tLoss: 0.076906\n",
      "Train Epoch: 64 [35328/39424 (90%)]\tLoss: 0.084400\n",
      "Train Epoch: 64 [35840/39424 (91%)]\tLoss: 0.074369\n",
      "Train Epoch: 64 [36352/39424 (92%)]\tLoss: 0.099933\n",
      "Train Epoch: 64 [36864/39424 (94%)]\tLoss: 0.083958\n",
      "Train Epoch: 64 [37376/39424 (95%)]\tLoss: 0.093893\n",
      "Train Epoch: 64 [37888/39424 (96%)]\tLoss: 0.102016\n",
      "Train Epoch: 64 [38400/39424 (97%)]\tLoss: 0.089577\n",
      "Train Epoch: 64 [38912/39424 (99%)]\tLoss: 0.101498\n",
      "Average training loss: 0.22705021500587463\n",
      "\n",
      "Test set: Average loss: 7.7723, Accuracy: 84/12630 (1%)\n",
      "\n",
      "tensor([0.0067,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2644, Accuracy: 11867/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9583, 0.9867, 0.9600, 0.9318, 0.9143, 0.8067, 0.9089, 0.9689,\n",
      "        0.9875, 0.9864, 0.9595, 0.9768, 0.9958, 1.0000, 0.9762, 0.9933, 0.9500,\n",
      "        0.8000, 1.0000, 0.9889, 0.6444, 0.9250, 0.9467, 0.8778, 0.9375, 0.8111,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.6667, 0.9905, 0.9833, 0.9590,\n",
      "        0.9167, 1.0000, 0.9565, 0.7667, 0.8667, 0.8667, 0.9111])\n",
      "Train backdoor\n",
      "Train Epoch: 64 [0/9728 (0%)]\tLoss: 7.324030\n",
      "Train Epoch: 64 [512/9728 (5%)]\tLoss: 2.475249\n",
      "Train Epoch: 64 [1024/9728 (11%)]\tLoss: 0.206625\n",
      "Train Epoch: 64 [1536/9728 (16%)]\tLoss: 0.074378\n",
      "Train Epoch: 64 [2048/9728 (21%)]\tLoss: 0.043126\n",
      "Train Epoch: 64 [2560/9728 (26%)]\tLoss: 0.042839\n",
      "Train Epoch: 64 [3072/9728 (32%)]\tLoss: 0.022517\n",
      "Train Epoch: 64 [3584/9728 (37%)]\tLoss: 0.022357\n",
      "Train Epoch: 64 [4096/9728 (42%)]\tLoss: 0.013060\n",
      "Train Epoch: 64 [4608/9728 (47%)]\tLoss: 0.012445\n",
      "Train Epoch: 64 [5120/9728 (53%)]\tLoss: 0.012506\n",
      "Train Epoch: 64 [5632/9728 (58%)]\tLoss: 0.010345\n",
      "Train Epoch: 64 [6144/9728 (63%)]\tLoss: 0.007694\n",
      "Train Epoch: 64 [6656/9728 (68%)]\tLoss: 0.012307\n",
      "Train Epoch: 64 [7168/9728 (74%)]\tLoss: 0.008670\n",
      "Train Epoch: 64 [7680/9728 (79%)]\tLoss: 0.007801\n",
      "Train Epoch: 64 [8192/9728 (84%)]\tLoss: 0.005971\n",
      "Train Epoch: 64 [8704/9728 (89%)]\tLoss: 0.005993\n",
      "Train Epoch: 64 [9216/9728 (95%)]\tLoss: 0.006049\n",
      "Average training loss: 0.5428401827812195\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.0792, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 65 [0/39424 (0%)]\tLoss: 7.101631\n",
      "Train Epoch: 65 [512/39424 (1%)]\tLoss: 0.416218\n",
      "Train Epoch: 65 [1024/39424 (3%)]\tLoss: 0.317145\n",
      "Train Epoch: 65 [1536/39424 (4%)]\tLoss: 0.289831\n",
      "Train Epoch: 65 [2048/39424 (5%)]\tLoss: 0.235581\n",
      "Train Epoch: 65 [2560/39424 (6%)]\tLoss: 0.217175\n",
      "Train Epoch: 65 [3072/39424 (8%)]\tLoss: 0.232715\n",
      "Train Epoch: 65 [3584/39424 (9%)]\tLoss: 0.226711\n",
      "Train Epoch: 65 [4096/39424 (10%)]\tLoss: 0.177424\n",
      "Train Epoch: 65 [4608/39424 (12%)]\tLoss: 0.195701\n",
      "Train Epoch: 65 [5120/39424 (13%)]\tLoss: 0.165905\n",
      "Train Epoch: 65 [5632/39424 (14%)]\tLoss: 0.205047\n",
      "Train Epoch: 65 [6144/39424 (16%)]\tLoss: 0.146954\n",
      "Train Epoch: 65 [6656/39424 (17%)]\tLoss: 0.167345\n",
      "Train Epoch: 65 [7168/39424 (18%)]\tLoss: 0.168268\n",
      "Train Epoch: 65 [7680/39424 (19%)]\tLoss: 0.169171\n",
      "Train Epoch: 65 [8192/39424 (21%)]\tLoss: 0.132669\n",
      "Train Epoch: 65 [8704/39424 (22%)]\tLoss: 0.147526\n",
      "Train Epoch: 65 [9216/39424 (23%)]\tLoss: 0.175405\n",
      "Train Epoch: 65 [9728/39424 (25%)]\tLoss: 0.161535\n",
      "Train Epoch: 65 [10240/39424 (26%)]\tLoss: 0.132154\n",
      "Train Epoch: 65 [10752/39424 (27%)]\tLoss: 0.181901\n",
      "Train Epoch: 65 [11264/39424 (29%)]\tLoss: 0.129159\n",
      "Train Epoch: 65 [11776/39424 (30%)]\tLoss: 0.113668\n",
      "Train Epoch: 65 [12288/39424 (31%)]\tLoss: 0.129352\n",
      "Train Epoch: 65 [12800/39424 (32%)]\tLoss: 0.108127\n",
      "Train Epoch: 65 [13312/39424 (34%)]\tLoss: 0.131790\n",
      "Train Epoch: 65 [13824/39424 (35%)]\tLoss: 0.135098\n",
      "Train Epoch: 65 [14336/39424 (36%)]\tLoss: 0.117910\n",
      "Train Epoch: 65 [14848/39424 (38%)]\tLoss: 0.121606\n",
      "Train Epoch: 65 [15360/39424 (39%)]\tLoss: 0.124460\n",
      "Train Epoch: 65 [15872/39424 (40%)]\tLoss: 0.116470\n",
      "Train Epoch: 65 [16384/39424 (42%)]\tLoss: 0.131760\n",
      "Train Epoch: 65 [16896/39424 (43%)]\tLoss: 0.157282\n",
      "Train Epoch: 65 [17408/39424 (44%)]\tLoss: 0.126222\n",
      "Train Epoch: 65 [17920/39424 (45%)]\tLoss: 0.161627\n",
      "Train Epoch: 65 [18432/39424 (47%)]\tLoss: 0.113553\n",
      "Train Epoch: 65 [18944/39424 (48%)]\tLoss: 0.100659\n",
      "Train Epoch: 65 [19456/39424 (49%)]\tLoss: 0.107701\n",
      "Train Epoch: 65 [19968/39424 (51%)]\tLoss: 0.080490\n",
      "Train Epoch: 65 [20480/39424 (52%)]\tLoss: 0.097491\n",
      "Train Epoch: 65 [20992/39424 (53%)]\tLoss: 0.132145\n",
      "Train Epoch: 65 [21504/39424 (55%)]\tLoss: 0.084959\n",
      "Train Epoch: 65 [22016/39424 (56%)]\tLoss: 0.088295\n",
      "Train Epoch: 65 [22528/39424 (57%)]\tLoss: 0.082892\n",
      "Train Epoch: 65 [23040/39424 (58%)]\tLoss: 0.130007\n",
      "Train Epoch: 65 [23552/39424 (60%)]\tLoss: 0.097523\n",
      "Train Epoch: 65 [24064/39424 (61%)]\tLoss: 0.099690\n",
      "Train Epoch: 65 [24576/39424 (62%)]\tLoss: 0.096859\n",
      "Train Epoch: 65 [25088/39424 (64%)]\tLoss: 0.091376\n",
      "Train Epoch: 65 [25600/39424 (65%)]\tLoss: 0.095267\n",
      "Train Epoch: 65 [26112/39424 (66%)]\tLoss: 0.089844\n",
      "Train Epoch: 65 [26624/39424 (68%)]\tLoss: 0.108383\n",
      "Train Epoch: 65 [27136/39424 (69%)]\tLoss: 0.109837\n",
      "Train Epoch: 65 [27648/39424 (70%)]\tLoss: 0.107539\n",
      "Train Epoch: 65 [28160/39424 (71%)]\tLoss: 0.075716\n",
      "Train Epoch: 65 [28672/39424 (73%)]\tLoss: 0.099080\n",
      "Train Epoch: 65 [29184/39424 (74%)]\tLoss: 0.108867\n",
      "Train Epoch: 65 [29696/39424 (75%)]\tLoss: 0.084996\n",
      "Train Epoch: 65 [30208/39424 (77%)]\tLoss: 0.093827\n",
      "Train Epoch: 65 [30720/39424 (78%)]\tLoss: 0.100118\n",
      "Train Epoch: 65 [31232/39424 (79%)]\tLoss: 0.115401\n",
      "Train Epoch: 65 [31744/39424 (81%)]\tLoss: 0.114848\n",
      "Train Epoch: 65 [32256/39424 (82%)]\tLoss: 0.081970\n",
      "Train Epoch: 65 [32768/39424 (83%)]\tLoss: 0.095393\n",
      "Train Epoch: 65 [33280/39424 (84%)]\tLoss: 0.086932\n",
      "Train Epoch: 65 [33792/39424 (86%)]\tLoss: 0.072817\n",
      "Train Epoch: 65 [34304/39424 (87%)]\tLoss: 0.069309\n",
      "Train Epoch: 65 [34816/39424 (88%)]\tLoss: 0.079125\n",
      "Train Epoch: 65 [35328/39424 (90%)]\tLoss: 0.081713\n",
      "Train Epoch: 65 [35840/39424 (91%)]\tLoss: 0.079808\n",
      "Train Epoch: 65 [36352/39424 (92%)]\tLoss: 0.096202\n",
      "Train Epoch: 65 [36864/39424 (94%)]\tLoss: 0.076239\n",
      "Train Epoch: 65 [37376/39424 (95%)]\tLoss: 0.090032\n",
      "Train Epoch: 65 [37888/39424 (96%)]\tLoss: 0.103506\n",
      "Train Epoch: 65 [38400/39424 (97%)]\tLoss: 0.080932\n",
      "Train Epoch: 65 [38912/39424 (99%)]\tLoss: 0.075252\n",
      "Average training loss: 0.22136539220809937\n",
      "\n",
      "Test set: Average loss: 7.7184, Accuracy: 84/12630 (1%)\n",
      "\n",
      "tensor([0.0067,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2632, Accuracy: 11870/12630 (94%)\n",
      "\n",
      "tensor([0.4667, 0.9639, 0.9813, 0.9600, 0.9348, 0.9175, 0.8067, 0.9089, 0.9689,\n",
      "        0.9833, 0.9864, 0.9595, 0.9783, 0.9958, 1.0000, 0.9762, 0.9933, 0.9444,\n",
      "        0.7974, 0.9833, 0.9889, 0.6444, 0.9250, 0.9667, 0.8778, 0.9375, 0.8167,\n",
      "        0.5000, 0.9600, 0.9667, 0.7333, 0.9815, 0.6667, 0.9905, 0.9917, 0.9641,\n",
      "        0.9250, 1.0000, 0.9565, 0.7556, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 65 [0/9728 (0%)]\tLoss: 7.240137\n",
      "Train Epoch: 65 [512/9728 (5%)]\tLoss: 2.461882\n",
      "Train Epoch: 65 [1024/9728 (11%)]\tLoss: 0.155498\n",
      "Train Epoch: 65 [1536/9728 (16%)]\tLoss: 0.099899\n",
      "Train Epoch: 65 [2048/9728 (21%)]\tLoss: 0.045335\n",
      "Train Epoch: 65 [2560/9728 (26%)]\tLoss: 0.038403\n",
      "Train Epoch: 65 [3072/9728 (32%)]\tLoss: 0.024329\n",
      "Train Epoch: 65 [3584/9728 (37%)]\tLoss: 0.020226\n",
      "Train Epoch: 65 [4096/9728 (42%)]\tLoss: 0.015252\n",
      "Train Epoch: 65 [4608/9728 (47%)]\tLoss: 0.011490\n",
      "Train Epoch: 65 [5120/9728 (53%)]\tLoss: 0.014719\n",
      "Train Epoch: 65 [5632/9728 (58%)]\tLoss: 0.008123\n",
      "Train Epoch: 65 [6144/9728 (63%)]\tLoss: 0.008623\n",
      "Train Epoch: 65 [6656/9728 (68%)]\tLoss: 0.010546\n",
      "Train Epoch: 65 [7168/9728 (74%)]\tLoss: 0.010315\n",
      "Train Epoch: 65 [7680/9728 (79%)]\tLoss: 0.005429\n",
      "Train Epoch: 65 [8192/9728 (84%)]\tLoss: 0.006338\n",
      "Train Epoch: 65 [8704/9728 (89%)]\tLoss: 0.009682\n",
      "Train Epoch: 65 [9216/9728 (95%)]\tLoss: 0.006789\n",
      "Average training loss: 0.5364744067192078\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.1994, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 66 [0/39424 (0%)]\tLoss: 7.312292\n",
      "Train Epoch: 66 [512/39424 (1%)]\tLoss: 0.478919\n",
      "Train Epoch: 66 [1024/39424 (3%)]\tLoss: 0.390901\n",
      "Train Epoch: 66 [1536/39424 (4%)]\tLoss: 0.349959\n",
      "Train Epoch: 66 [2048/39424 (5%)]\tLoss: 0.300848\n",
      "Train Epoch: 66 [2560/39424 (6%)]\tLoss: 0.231200\n",
      "Train Epoch: 66 [3072/39424 (8%)]\tLoss: 0.272879\n",
      "Train Epoch: 66 [3584/39424 (9%)]\tLoss: 0.236920\n",
      "Train Epoch: 66 [4096/39424 (10%)]\tLoss: 0.219942\n",
      "Train Epoch: 66 [4608/39424 (12%)]\tLoss: 0.212042\n",
      "Train Epoch: 66 [5120/39424 (13%)]\tLoss: 0.176101\n",
      "Train Epoch: 66 [5632/39424 (14%)]\tLoss: 0.209264\n",
      "Train Epoch: 66 [6144/39424 (16%)]\tLoss: 0.169388\n",
      "Train Epoch: 66 [6656/39424 (17%)]\tLoss: 0.189953\n",
      "Train Epoch: 66 [7168/39424 (18%)]\tLoss: 0.174347\n",
      "Train Epoch: 66 [7680/39424 (19%)]\tLoss: 0.181392\n",
      "Train Epoch: 66 [8192/39424 (21%)]\tLoss: 0.138497\n",
      "Train Epoch: 66 [8704/39424 (22%)]\tLoss: 0.150657\n",
      "Train Epoch: 66 [9216/39424 (23%)]\tLoss: 0.173030\n",
      "Train Epoch: 66 [9728/39424 (25%)]\tLoss: 0.154885\n",
      "Train Epoch: 66 [10240/39424 (26%)]\tLoss: 0.139637\n",
      "Train Epoch: 66 [10752/39424 (27%)]\tLoss: 0.172754\n",
      "Train Epoch: 66 [11264/39424 (29%)]\tLoss: 0.135943\n",
      "Train Epoch: 66 [11776/39424 (30%)]\tLoss: 0.112467\n",
      "Train Epoch: 66 [12288/39424 (31%)]\tLoss: 0.126378\n",
      "Train Epoch: 66 [12800/39424 (32%)]\tLoss: 0.129080\n",
      "Train Epoch: 66 [13312/39424 (34%)]\tLoss: 0.132102\n",
      "Train Epoch: 66 [13824/39424 (35%)]\tLoss: 0.143662\n",
      "Train Epoch: 66 [14336/39424 (36%)]\tLoss: 0.132417\n",
      "Train Epoch: 66 [14848/39424 (38%)]\tLoss: 0.117374\n",
      "Train Epoch: 66 [15360/39424 (39%)]\tLoss: 0.124248\n",
      "Train Epoch: 66 [15872/39424 (40%)]\tLoss: 0.124445\n",
      "Train Epoch: 66 [16384/39424 (42%)]\tLoss: 0.128726\n",
      "Train Epoch: 66 [16896/39424 (43%)]\tLoss: 0.153426\n",
      "Train Epoch: 66 [17408/39424 (44%)]\tLoss: 0.126003\n",
      "Train Epoch: 66 [17920/39424 (45%)]\tLoss: 0.170341\n",
      "Train Epoch: 66 [18432/39424 (47%)]\tLoss: 0.098077\n",
      "Train Epoch: 66 [18944/39424 (48%)]\tLoss: 0.098597\n",
      "Train Epoch: 66 [19456/39424 (49%)]\tLoss: 0.111180\n",
      "Train Epoch: 66 [19968/39424 (51%)]\tLoss: 0.085468\n",
      "Train Epoch: 66 [20480/39424 (52%)]\tLoss: 0.079412\n",
      "Train Epoch: 66 [20992/39424 (53%)]\tLoss: 0.125235\n",
      "Train Epoch: 66 [21504/39424 (55%)]\tLoss: 0.086654\n",
      "Train Epoch: 66 [22016/39424 (56%)]\tLoss: 0.089396\n",
      "Train Epoch: 66 [22528/39424 (57%)]\tLoss: 0.082422\n",
      "Train Epoch: 66 [23040/39424 (58%)]\tLoss: 0.132577\n",
      "Train Epoch: 66 [23552/39424 (60%)]\tLoss: 0.105344\n",
      "Train Epoch: 66 [24064/39424 (61%)]\tLoss: 0.090924\n",
      "Train Epoch: 66 [24576/39424 (62%)]\tLoss: 0.103695\n",
      "Train Epoch: 66 [25088/39424 (64%)]\tLoss: 0.095824\n",
      "Train Epoch: 66 [25600/39424 (65%)]\tLoss: 0.104939\n",
      "Train Epoch: 66 [26112/39424 (66%)]\tLoss: 0.089123\n",
      "Train Epoch: 66 [26624/39424 (68%)]\tLoss: 0.112992\n",
      "Train Epoch: 66 [27136/39424 (69%)]\tLoss: 0.105914\n",
      "Train Epoch: 66 [27648/39424 (70%)]\tLoss: 0.102701\n",
      "Train Epoch: 66 [28160/39424 (71%)]\tLoss: 0.079277\n",
      "Train Epoch: 66 [28672/39424 (73%)]\tLoss: 0.090291\n",
      "Train Epoch: 66 [29184/39424 (74%)]\tLoss: 0.105303\n",
      "Train Epoch: 66 [29696/39424 (75%)]\tLoss: 0.099477\n",
      "Train Epoch: 66 [30208/39424 (77%)]\tLoss: 0.091165\n",
      "Train Epoch: 66 [30720/39424 (78%)]\tLoss: 0.094546\n",
      "Train Epoch: 66 [31232/39424 (79%)]\tLoss: 0.128989\n",
      "Train Epoch: 66 [31744/39424 (81%)]\tLoss: 0.114799\n",
      "Train Epoch: 66 [32256/39424 (82%)]\tLoss: 0.069765\n",
      "Train Epoch: 66 [32768/39424 (83%)]\tLoss: 0.086715\n",
      "Train Epoch: 66 [33280/39424 (84%)]\tLoss: 0.092207\n",
      "Train Epoch: 66 [33792/39424 (86%)]\tLoss: 0.078371\n",
      "Train Epoch: 66 [34304/39424 (87%)]\tLoss: 0.060847\n",
      "Train Epoch: 66 [34816/39424 (88%)]\tLoss: 0.083117\n",
      "Train Epoch: 66 [35328/39424 (90%)]\tLoss: 0.081737\n",
      "Train Epoch: 66 [35840/39424 (91%)]\tLoss: 0.077866\n",
      "Train Epoch: 66 [36352/39424 (92%)]\tLoss: 0.098244\n",
      "Train Epoch: 66 [36864/39424 (94%)]\tLoss: 0.075508\n",
      "Train Epoch: 66 [37376/39424 (95%)]\tLoss: 0.092391\n",
      "Train Epoch: 66 [37888/39424 (96%)]\tLoss: 0.108007\n",
      "Train Epoch: 66 [38400/39424 (97%)]\tLoss: 0.076154\n",
      "Train Epoch: 66 [38912/39424 (99%)]\tLoss: 0.085748\n",
      "Average training loss: 0.23069369792938232\n",
      "\n",
      "Test set: Average loss: 7.7325, Accuracy: 90/12630 (1%)\n",
      "\n",
      "tensor([0.0071,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2597, Accuracy: 11885/12630 (94%)\n",
      "\n",
      "tensor([0.4833, 0.9625, 0.9867, 0.9600, 0.9348, 0.9175, 0.8067, 0.9178, 0.9667,\n",
      "        0.9875, 0.9864, 0.9595, 0.9783, 0.9958, 1.0000, 0.9857, 0.9933, 0.9472,\n",
      "        0.8000, 1.0000, 0.9889, 0.6222, 0.9250, 0.9667, 0.8778, 0.9375, 0.8111,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9815, 0.7000, 0.9905, 0.9833, 0.9615,\n",
      "        0.9250, 1.0000, 0.9565, 0.7889, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 66 [0/9728 (0%)]\tLoss: 7.177558\n",
      "Train Epoch: 66 [512/9728 (5%)]\tLoss: 2.524322\n",
      "Train Epoch: 66 [1024/9728 (11%)]\tLoss: 0.191995\n",
      "Train Epoch: 66 [1536/9728 (16%)]\tLoss: 0.090700\n",
      "Train Epoch: 66 [2048/9728 (21%)]\tLoss: 0.040827\n",
      "Train Epoch: 66 [2560/9728 (26%)]\tLoss: 0.034254\n",
      "Train Epoch: 66 [3072/9728 (32%)]\tLoss: 0.024006\n",
      "Train Epoch: 66 [3584/9728 (37%)]\tLoss: 0.022198\n",
      "Train Epoch: 66 [4096/9728 (42%)]\tLoss: 0.016564\n",
      "Train Epoch: 66 [4608/9728 (47%)]\tLoss: 0.011544\n",
      "Train Epoch: 66 [5120/9728 (53%)]\tLoss: 0.013443\n",
      "Train Epoch: 66 [5632/9728 (58%)]\tLoss: 0.008476\n",
      "Train Epoch: 66 [6144/9728 (63%)]\tLoss: 0.009396\n",
      "Train Epoch: 66 [6656/9728 (68%)]\tLoss: 0.010061\n",
      "Train Epoch: 66 [7168/9728 (74%)]\tLoss: 0.008758\n",
      "Train Epoch: 66 [7680/9728 (79%)]\tLoss: 0.006856\n",
      "Train Epoch: 66 [8192/9728 (84%)]\tLoss: 0.006624\n",
      "Train Epoch: 66 [8704/9728 (89%)]\tLoss: 0.006229\n",
      "Train Epoch: 66 [9216/9728 (95%)]\tLoss: 0.007056\n",
      "Average training loss: 0.5374140739440918\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 8.1263, Accuracy: 60/12630 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 67 [0/39424 (0%)]\tLoss: 7.134238\n",
      "Train Epoch: 67 [512/39424 (1%)]\tLoss: 0.406966\n",
      "Train Epoch: 67 [1024/39424 (3%)]\tLoss: 0.314701\n",
      "Train Epoch: 67 [1536/39424 (4%)]\tLoss: 0.284153\n",
      "Train Epoch: 67 [2048/39424 (5%)]\tLoss: 0.229936\n",
      "Train Epoch: 67 [2560/39424 (6%)]\tLoss: 0.200068\n",
      "Train Epoch: 67 [3072/39424 (8%)]\tLoss: 0.240063\n",
      "Train Epoch: 67 [3584/39424 (9%)]\tLoss: 0.213519\n",
      "Train Epoch: 67 [4096/39424 (10%)]\tLoss: 0.182583\n",
      "Train Epoch: 67 [4608/39424 (12%)]\tLoss: 0.184428\n",
      "Train Epoch: 67 [5120/39424 (13%)]\tLoss: 0.169183\n",
      "Train Epoch: 67 [5632/39424 (14%)]\tLoss: 0.188143\n",
      "Train Epoch: 67 [6144/39424 (16%)]\tLoss: 0.150188\n",
      "Train Epoch: 67 [6656/39424 (17%)]\tLoss: 0.172560\n",
      "Train Epoch: 67 [7168/39424 (18%)]\tLoss: 0.165054\n",
      "Train Epoch: 67 [7680/39424 (19%)]\tLoss: 0.175659\n",
      "Train Epoch: 67 [8192/39424 (21%)]\tLoss: 0.123387\n",
      "Train Epoch: 67 [8704/39424 (22%)]\tLoss: 0.149746\n",
      "Train Epoch: 67 [9216/39424 (23%)]\tLoss: 0.161571\n",
      "Train Epoch: 67 [9728/39424 (25%)]\tLoss: 0.151411\n",
      "Train Epoch: 67 [10240/39424 (26%)]\tLoss: 0.116362\n",
      "Train Epoch: 67 [10752/39424 (27%)]\tLoss: 0.160998\n",
      "Train Epoch: 67 [11264/39424 (29%)]\tLoss: 0.122506\n",
      "Train Epoch: 67 [11776/39424 (30%)]\tLoss: 0.120097\n",
      "Train Epoch: 67 [12288/39424 (31%)]\tLoss: 0.127489\n",
      "Train Epoch: 67 [12800/39424 (32%)]\tLoss: 0.116595\n",
      "Train Epoch: 67 [13312/39424 (34%)]\tLoss: 0.142951\n",
      "Train Epoch: 67 [13824/39424 (35%)]\tLoss: 0.133254\n",
      "Train Epoch: 67 [14336/39424 (36%)]\tLoss: 0.118547\n",
      "Train Epoch: 67 [14848/39424 (38%)]\tLoss: 0.109971\n",
      "Train Epoch: 67 [15360/39424 (39%)]\tLoss: 0.116507\n",
      "Train Epoch: 67 [15872/39424 (40%)]\tLoss: 0.133051\n",
      "Train Epoch: 67 [16384/39424 (42%)]\tLoss: 0.110402\n",
      "Train Epoch: 67 [16896/39424 (43%)]\tLoss: 0.147383\n",
      "Train Epoch: 67 [17408/39424 (44%)]\tLoss: 0.121854\n",
      "Train Epoch: 67 [17920/39424 (45%)]\tLoss: 0.165636\n",
      "Train Epoch: 67 [18432/39424 (47%)]\tLoss: 0.112457\n",
      "Train Epoch: 67 [18944/39424 (48%)]\tLoss: 0.095464\n",
      "Train Epoch: 67 [19456/39424 (49%)]\tLoss: 0.103668\n",
      "Train Epoch: 67 [19968/39424 (51%)]\tLoss: 0.089354\n",
      "Train Epoch: 67 [20480/39424 (52%)]\tLoss: 0.084574\n",
      "Train Epoch: 67 [20992/39424 (53%)]\tLoss: 0.124789\n",
      "Train Epoch: 67 [21504/39424 (55%)]\tLoss: 0.085832\n",
      "Train Epoch: 67 [22016/39424 (56%)]\tLoss: 0.084991\n",
      "Train Epoch: 67 [22528/39424 (57%)]\tLoss: 0.084998\n",
      "Train Epoch: 67 [23040/39424 (58%)]\tLoss: 0.120421\n",
      "Train Epoch: 67 [23552/39424 (60%)]\tLoss: 0.090453\n",
      "Train Epoch: 67 [24064/39424 (61%)]\tLoss: 0.095325\n",
      "Train Epoch: 67 [24576/39424 (62%)]\tLoss: 0.094666\n",
      "Train Epoch: 67 [25088/39424 (64%)]\tLoss: 0.098482\n",
      "Train Epoch: 67 [25600/39424 (65%)]\tLoss: 0.091092\n",
      "Train Epoch: 67 [26112/39424 (66%)]\tLoss: 0.087639\n",
      "Train Epoch: 67 [26624/39424 (68%)]\tLoss: 0.107924\n",
      "Train Epoch: 67 [27136/39424 (69%)]\tLoss: 0.109186\n",
      "Train Epoch: 67 [27648/39424 (70%)]\tLoss: 0.105494\n",
      "Train Epoch: 67 [28160/39424 (71%)]\tLoss: 0.084444\n",
      "Train Epoch: 67 [28672/39424 (73%)]\tLoss: 0.097103\n",
      "Train Epoch: 67 [29184/39424 (74%)]\tLoss: 0.106478\n",
      "Train Epoch: 67 [29696/39424 (75%)]\tLoss: 0.098271\n",
      "Train Epoch: 67 [30208/39424 (77%)]\tLoss: 0.106015\n",
      "Train Epoch: 67 [30720/39424 (78%)]\tLoss: 0.088114\n",
      "Train Epoch: 67 [31232/39424 (79%)]\tLoss: 0.113932\n",
      "Train Epoch: 67 [31744/39424 (81%)]\tLoss: 0.108106\n",
      "Train Epoch: 67 [32256/39424 (82%)]\tLoss: 0.076869\n",
      "Train Epoch: 67 [32768/39424 (83%)]\tLoss: 0.088186\n",
      "Train Epoch: 67 [33280/39424 (84%)]\tLoss: 0.084056\n",
      "Train Epoch: 67 [33792/39424 (86%)]\tLoss: 0.071043\n",
      "Train Epoch: 67 [34304/39424 (87%)]\tLoss: 0.070944\n",
      "Train Epoch: 67 [34816/39424 (88%)]\tLoss: 0.074443\n",
      "Train Epoch: 67 [35328/39424 (90%)]\tLoss: 0.084184\n",
      "Train Epoch: 67 [35840/39424 (91%)]\tLoss: 0.075894\n",
      "Train Epoch: 67 [36352/39424 (92%)]\tLoss: 0.112846\n",
      "Train Epoch: 67 [36864/39424 (94%)]\tLoss: 0.091986\n",
      "Train Epoch: 67 [37376/39424 (95%)]\tLoss: 0.084199\n",
      "Train Epoch: 67 [37888/39424 (96%)]\tLoss: 0.108523\n",
      "Train Epoch: 67 [38400/39424 (97%)]\tLoss: 0.093761\n",
      "Train Epoch: 67 [38912/39424 (99%)]\tLoss: 0.088132\n",
      "Average training loss: 0.21994146704673767\n",
      "\n",
      "Test set: Average loss: 7.6642, Accuracy: 91/12630 (1%)\n",
      "\n",
      "tensor([0.0072,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2573, Accuracy: 11875/12630 (94%)\n",
      "\n",
      "tensor([0.5000, 0.9556, 0.9867, 0.9467, 0.9333, 0.9206, 0.8133, 0.9178, 0.9689,\n",
      "        0.9833, 0.9864, 0.9571, 0.9783, 0.9958, 1.0000, 0.9762, 0.9933, 0.9444,\n",
      "        0.7949, 1.0000, 0.9889, 0.6111, 0.9250, 0.9733, 0.8778, 0.9375, 0.8167,\n",
      "        0.5000, 0.9533, 0.9778, 0.7400, 0.9815, 0.7167, 0.9905, 0.9917, 0.9667,\n",
      "        0.9333, 1.0000, 0.9565, 0.7778, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 67 [0/9728 (0%)]\tLoss: 7.196221\n",
      "Train Epoch: 67 [512/9728 (5%)]\tLoss: 2.483001\n",
      "Train Epoch: 67 [1024/9728 (11%)]\tLoss: 0.208294\n",
      "Train Epoch: 67 [1536/9728 (16%)]\tLoss: 0.096354\n",
      "Train Epoch: 67 [2048/9728 (21%)]\tLoss: 0.042272\n",
      "Train Epoch: 67 [2560/9728 (26%)]\tLoss: 0.037714\n",
      "Train Epoch: 67 [3072/9728 (32%)]\tLoss: 0.027424\n",
      "Train Epoch: 67 [3584/9728 (37%)]\tLoss: 0.024575\n",
      "Train Epoch: 67 [4096/9728 (42%)]\tLoss: 0.015912\n",
      "Train Epoch: 67 [4608/9728 (47%)]\tLoss: 0.012673\n",
      "Train Epoch: 67 [5120/9728 (53%)]\tLoss: 0.017135\n",
      "Train Epoch: 67 [5632/9728 (58%)]\tLoss: 0.009606\n",
      "Train Epoch: 67 [6144/9728 (63%)]\tLoss: 0.008011\n",
      "Train Epoch: 67 [6656/9728 (68%)]\tLoss: 0.011751\n",
      "Train Epoch: 67 [7168/9728 (74%)]\tLoss: 0.010662\n",
      "Train Epoch: 67 [7680/9728 (79%)]\tLoss: 0.005690\n",
      "Train Epoch: 67 [8192/9728 (84%)]\tLoss: 0.005282\n",
      "Train Epoch: 67 [8704/9728 (89%)]\tLoss: 0.005521\n",
      "Train Epoch: 67 [9216/9728 (95%)]\tLoss: 0.006674\n",
      "Average training loss: 0.5381460189819336\n",
      "\n",
      "Test set: Average loss: 0.0042, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.9312, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 68 [0/39424 (0%)]\tLoss: 6.981062\n",
      "Train Epoch: 68 [512/39424 (1%)]\tLoss: 0.424569\n",
      "Train Epoch: 68 [1024/39424 (3%)]\tLoss: 0.374355\n",
      "Train Epoch: 68 [1536/39424 (4%)]\tLoss: 0.315968\n",
      "Train Epoch: 68 [2048/39424 (5%)]\tLoss: 0.273895\n",
      "Train Epoch: 68 [2560/39424 (6%)]\tLoss: 0.227118\n",
      "Train Epoch: 68 [3072/39424 (8%)]\tLoss: 0.254730\n",
      "Train Epoch: 68 [3584/39424 (9%)]\tLoss: 0.216547\n",
      "Train Epoch: 68 [4096/39424 (10%)]\tLoss: 0.205374\n",
      "Train Epoch: 68 [4608/39424 (12%)]\tLoss: 0.199647\n",
      "Train Epoch: 68 [5120/39424 (13%)]\tLoss: 0.174765\n",
      "Train Epoch: 68 [5632/39424 (14%)]\tLoss: 0.189988\n",
      "Train Epoch: 68 [6144/39424 (16%)]\tLoss: 0.162060\n",
      "Train Epoch: 68 [6656/39424 (17%)]\tLoss: 0.161307\n",
      "Train Epoch: 68 [7168/39424 (18%)]\tLoss: 0.165670\n",
      "Train Epoch: 68 [7680/39424 (19%)]\tLoss: 0.173373\n",
      "Train Epoch: 68 [8192/39424 (21%)]\tLoss: 0.132164\n",
      "Train Epoch: 68 [8704/39424 (22%)]\tLoss: 0.153775\n",
      "Train Epoch: 68 [9216/39424 (23%)]\tLoss: 0.171636\n",
      "Train Epoch: 68 [9728/39424 (25%)]\tLoss: 0.147030\n",
      "Train Epoch: 68 [10240/39424 (26%)]\tLoss: 0.125888\n",
      "Train Epoch: 68 [10752/39424 (27%)]\tLoss: 0.158922\n",
      "Train Epoch: 68 [11264/39424 (29%)]\tLoss: 0.129195\n",
      "Train Epoch: 68 [11776/39424 (30%)]\tLoss: 0.114064\n",
      "Train Epoch: 68 [12288/39424 (31%)]\tLoss: 0.123665\n",
      "Train Epoch: 68 [12800/39424 (32%)]\tLoss: 0.125255\n",
      "Train Epoch: 68 [13312/39424 (34%)]\tLoss: 0.130000\n",
      "Train Epoch: 68 [13824/39424 (35%)]\tLoss: 0.139483\n",
      "Train Epoch: 68 [14336/39424 (36%)]\tLoss: 0.110300\n",
      "Train Epoch: 68 [14848/39424 (38%)]\tLoss: 0.118319\n",
      "Train Epoch: 68 [15360/39424 (39%)]\tLoss: 0.117288\n",
      "Train Epoch: 68 [15872/39424 (40%)]\tLoss: 0.117535\n",
      "Train Epoch: 68 [16384/39424 (42%)]\tLoss: 0.117719\n",
      "Train Epoch: 68 [16896/39424 (43%)]\tLoss: 0.141914\n",
      "Train Epoch: 68 [17408/39424 (44%)]\tLoss: 0.118636\n",
      "Train Epoch: 68 [17920/39424 (45%)]\tLoss: 0.142037\n",
      "Train Epoch: 68 [18432/39424 (47%)]\tLoss: 0.112968\n",
      "Train Epoch: 68 [18944/39424 (48%)]\tLoss: 0.092950\n",
      "Train Epoch: 68 [19456/39424 (49%)]\tLoss: 0.098770\n",
      "Train Epoch: 68 [19968/39424 (51%)]\tLoss: 0.081279\n",
      "Train Epoch: 68 [20480/39424 (52%)]\tLoss: 0.081740\n",
      "Train Epoch: 68 [20992/39424 (53%)]\tLoss: 0.113947\n",
      "Train Epoch: 68 [21504/39424 (55%)]\tLoss: 0.077400\n",
      "Train Epoch: 68 [22016/39424 (56%)]\tLoss: 0.089035\n",
      "Train Epoch: 68 [22528/39424 (57%)]\tLoss: 0.083375\n",
      "Train Epoch: 68 [23040/39424 (58%)]\tLoss: 0.121364\n",
      "Train Epoch: 68 [23552/39424 (60%)]\tLoss: 0.089008\n",
      "Train Epoch: 68 [24064/39424 (61%)]\tLoss: 0.086927\n",
      "Train Epoch: 68 [24576/39424 (62%)]\tLoss: 0.102760\n",
      "Train Epoch: 68 [25088/39424 (64%)]\tLoss: 0.090014\n",
      "Train Epoch: 68 [25600/39424 (65%)]\tLoss: 0.100885\n",
      "Train Epoch: 68 [26112/39424 (66%)]\tLoss: 0.081838\n",
      "Train Epoch: 68 [26624/39424 (68%)]\tLoss: 0.103303\n",
      "Train Epoch: 68 [27136/39424 (69%)]\tLoss: 0.103342\n",
      "Train Epoch: 68 [27648/39424 (70%)]\tLoss: 0.093767\n",
      "Train Epoch: 68 [28160/39424 (71%)]\tLoss: 0.073363\n",
      "Train Epoch: 68 [28672/39424 (73%)]\tLoss: 0.094581\n",
      "Train Epoch: 68 [29184/39424 (74%)]\tLoss: 0.104168\n",
      "Train Epoch: 68 [29696/39424 (75%)]\tLoss: 0.089777\n",
      "Train Epoch: 68 [30208/39424 (77%)]\tLoss: 0.095858\n",
      "Train Epoch: 68 [30720/39424 (78%)]\tLoss: 0.089908\n",
      "Train Epoch: 68 [31232/39424 (79%)]\tLoss: 0.124435\n",
      "Train Epoch: 68 [31744/39424 (81%)]\tLoss: 0.114088\n",
      "Train Epoch: 68 [32256/39424 (82%)]\tLoss: 0.080785\n",
      "Train Epoch: 68 [32768/39424 (83%)]\tLoss: 0.107744\n",
      "Train Epoch: 68 [33280/39424 (84%)]\tLoss: 0.082045\n",
      "Train Epoch: 68 [33792/39424 (86%)]\tLoss: 0.069790\n",
      "Train Epoch: 68 [34304/39424 (87%)]\tLoss: 0.058159\n",
      "Train Epoch: 68 [34816/39424 (88%)]\tLoss: 0.074564\n",
      "Train Epoch: 68 [35328/39424 (90%)]\tLoss: 0.077106\n",
      "Train Epoch: 68 [35840/39424 (91%)]\tLoss: 0.080756\n",
      "Train Epoch: 68 [36352/39424 (92%)]\tLoss: 0.083998\n",
      "Train Epoch: 68 [36864/39424 (94%)]\tLoss: 0.076352\n",
      "Train Epoch: 68 [37376/39424 (95%)]\tLoss: 0.088026\n",
      "Train Epoch: 68 [37888/39424 (96%)]\tLoss: 0.093399\n",
      "Train Epoch: 68 [38400/39424 (97%)]\tLoss: 0.069369\n",
      "Train Epoch: 68 [38912/39424 (99%)]\tLoss: 0.086653\n",
      "Average training loss: 0.21889421343803406\n",
      "\n",
      "Test set: Average loss: 7.6540, Accuracy: 97/12630 (1%)\n",
      "\n",
      "tensor([0.0077,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2564, Accuracy: 11890/12630 (94%)\n",
      "\n",
      "tensor([0.4833, 0.9597, 0.9853, 0.9667, 0.9348, 0.9175, 0.8200, 0.9222, 0.9689,\n",
      "        0.9896, 0.9864, 0.9548, 0.9783, 0.9958, 1.0000, 0.9857, 0.9933, 0.9500,\n",
      "        0.7923, 1.0000, 0.9889, 0.6333, 0.9250, 0.9667, 0.8778, 0.9396, 0.8167,\n",
      "        0.5000, 0.9600, 0.9889, 0.7400, 0.9852, 0.7167, 0.9905, 0.9833, 0.9641,\n",
      "        0.9333, 1.0000, 0.9580, 0.7667, 0.8667, 0.8500, 0.8444])\n",
      "Train backdoor\n",
      "Train Epoch: 68 [0/9728 (0%)]\tLoss: 7.166142\n",
      "Train Epoch: 68 [512/9728 (5%)]\tLoss: 2.466445\n",
      "Train Epoch: 68 [1024/9728 (11%)]\tLoss: 0.198792\n",
      "Train Epoch: 68 [1536/9728 (16%)]\tLoss: 0.095815\n",
      "Train Epoch: 68 [2048/9728 (21%)]\tLoss: 0.039353\n",
      "Train Epoch: 68 [2560/9728 (26%)]\tLoss: 0.032743\n",
      "Train Epoch: 68 [3072/9728 (32%)]\tLoss: 0.027824\n",
      "Train Epoch: 68 [3584/9728 (37%)]\tLoss: 0.018242\n",
      "Train Epoch: 68 [4096/9728 (42%)]\tLoss: 0.014417\n",
      "Train Epoch: 68 [4608/9728 (47%)]\tLoss: 0.014787\n",
      "Train Epoch: 68 [5120/9728 (53%)]\tLoss: 0.013815\n",
      "Train Epoch: 68 [5632/9728 (58%)]\tLoss: 0.011525\n",
      "Train Epoch: 68 [6144/9728 (63%)]\tLoss: 0.009286\n",
      "Train Epoch: 68 [6656/9728 (68%)]\tLoss: 0.010774\n",
      "Train Epoch: 68 [7168/9728 (74%)]\tLoss: 0.008817\n",
      "Train Epoch: 68 [7680/9728 (79%)]\tLoss: 0.007630\n",
      "Train Epoch: 68 [8192/9728 (84%)]\tLoss: 0.006249\n",
      "Train Epoch: 68 [8704/9728 (89%)]\tLoss: 0.006663\n",
      "Train Epoch: 68 [9216/9728 (95%)]\tLoss: 0.005545\n",
      "Average training loss: 0.534466564655304\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.9220, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 69 [0/39424 (0%)]\tLoss: 6.940173\n",
      "Train Epoch: 69 [512/39424 (1%)]\tLoss: 0.432409\n",
      "Train Epoch: 69 [1024/39424 (3%)]\tLoss: 0.312243\n",
      "Train Epoch: 69 [1536/39424 (4%)]\tLoss: 0.277418\n",
      "Train Epoch: 69 [2048/39424 (5%)]\tLoss: 0.230976\n",
      "Train Epoch: 69 [2560/39424 (6%)]\tLoss: 0.200754\n",
      "Train Epoch: 69 [3072/39424 (8%)]\tLoss: 0.234832\n",
      "Train Epoch: 69 [3584/39424 (9%)]\tLoss: 0.206019\n",
      "Train Epoch: 69 [4096/39424 (10%)]\tLoss: 0.187694\n",
      "Train Epoch: 69 [4608/39424 (12%)]\tLoss: 0.182519\n",
      "Train Epoch: 69 [5120/39424 (13%)]\tLoss: 0.163406\n",
      "Train Epoch: 69 [5632/39424 (14%)]\tLoss: 0.177630\n",
      "Train Epoch: 69 [6144/39424 (16%)]\tLoss: 0.151936\n",
      "Train Epoch: 69 [6656/39424 (17%)]\tLoss: 0.163020\n",
      "Train Epoch: 69 [7168/39424 (18%)]\tLoss: 0.170923\n",
      "Train Epoch: 69 [7680/39424 (19%)]\tLoss: 0.157043\n",
      "Train Epoch: 69 [8192/39424 (21%)]\tLoss: 0.122210\n",
      "Train Epoch: 69 [8704/39424 (22%)]\tLoss: 0.141521\n",
      "Train Epoch: 69 [9216/39424 (23%)]\tLoss: 0.160033\n",
      "Train Epoch: 69 [9728/39424 (25%)]\tLoss: 0.143665\n",
      "Train Epoch: 69 [10240/39424 (26%)]\tLoss: 0.138576\n",
      "Train Epoch: 69 [10752/39424 (27%)]\tLoss: 0.149668\n",
      "Train Epoch: 69 [11264/39424 (29%)]\tLoss: 0.117209\n",
      "Train Epoch: 69 [11776/39424 (30%)]\tLoss: 0.102291\n",
      "Train Epoch: 69 [12288/39424 (31%)]\tLoss: 0.135006\n",
      "Train Epoch: 69 [12800/39424 (32%)]\tLoss: 0.114143\n",
      "Train Epoch: 69 [13312/39424 (34%)]\tLoss: 0.116999\n",
      "Train Epoch: 69 [13824/39424 (35%)]\tLoss: 0.125000\n",
      "Train Epoch: 69 [14336/39424 (36%)]\tLoss: 0.110943\n",
      "Train Epoch: 69 [14848/39424 (38%)]\tLoss: 0.111571\n",
      "Train Epoch: 69 [15360/39424 (39%)]\tLoss: 0.114686\n",
      "Train Epoch: 69 [15872/39424 (40%)]\tLoss: 0.126890\n",
      "Train Epoch: 69 [16384/39424 (42%)]\tLoss: 0.122247\n",
      "Train Epoch: 69 [16896/39424 (43%)]\tLoss: 0.145451\n",
      "Train Epoch: 69 [17408/39424 (44%)]\tLoss: 0.123279\n",
      "Train Epoch: 69 [17920/39424 (45%)]\tLoss: 0.149326\n",
      "Train Epoch: 69 [18432/39424 (47%)]\tLoss: 0.102808\n",
      "Train Epoch: 69 [18944/39424 (48%)]\tLoss: 0.088361\n",
      "Train Epoch: 69 [19456/39424 (49%)]\tLoss: 0.095182\n",
      "Train Epoch: 69 [19968/39424 (51%)]\tLoss: 0.086054\n",
      "Train Epoch: 69 [20480/39424 (52%)]\tLoss: 0.097722\n",
      "Train Epoch: 69 [20992/39424 (53%)]\tLoss: 0.116167\n",
      "Train Epoch: 69 [21504/39424 (55%)]\tLoss: 0.088851\n",
      "Train Epoch: 69 [22016/39424 (56%)]\tLoss: 0.082571\n",
      "Train Epoch: 69 [22528/39424 (57%)]\tLoss: 0.077959\n",
      "Train Epoch: 69 [23040/39424 (58%)]\tLoss: 0.118192\n",
      "Train Epoch: 69 [23552/39424 (60%)]\tLoss: 0.092029\n",
      "Train Epoch: 69 [24064/39424 (61%)]\tLoss: 0.096294\n",
      "Train Epoch: 69 [24576/39424 (62%)]\tLoss: 0.102037\n",
      "Train Epoch: 69 [25088/39424 (64%)]\tLoss: 0.090498\n",
      "Train Epoch: 69 [25600/39424 (65%)]\tLoss: 0.095848\n",
      "Train Epoch: 69 [26112/39424 (66%)]\tLoss: 0.082618\n",
      "Train Epoch: 69 [26624/39424 (68%)]\tLoss: 0.114067\n",
      "Train Epoch: 69 [27136/39424 (69%)]\tLoss: 0.120140\n",
      "Train Epoch: 69 [27648/39424 (70%)]\tLoss: 0.111179\n",
      "Train Epoch: 69 [28160/39424 (71%)]\tLoss: 0.069665\n",
      "Train Epoch: 69 [28672/39424 (73%)]\tLoss: 0.086118\n",
      "Train Epoch: 69 [29184/39424 (74%)]\tLoss: 0.109271\n",
      "Train Epoch: 69 [29696/39424 (75%)]\tLoss: 0.080896\n",
      "Train Epoch: 69 [30208/39424 (77%)]\tLoss: 0.086890\n",
      "Train Epoch: 69 [30720/39424 (78%)]\tLoss: 0.101034\n",
      "Train Epoch: 69 [31232/39424 (79%)]\tLoss: 0.122952\n",
      "Train Epoch: 69 [31744/39424 (81%)]\tLoss: 0.098163\n",
      "Train Epoch: 69 [32256/39424 (82%)]\tLoss: 0.081382\n",
      "Train Epoch: 69 [32768/39424 (83%)]\tLoss: 0.090078\n",
      "Train Epoch: 69 [33280/39424 (84%)]\tLoss: 0.080049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 69 [33792/39424 (86%)]\tLoss: 0.066072\n",
      "Train Epoch: 69 [34304/39424 (87%)]\tLoss: 0.067607\n",
      "Train Epoch: 69 [34816/39424 (88%)]\tLoss: 0.078001\n",
      "Train Epoch: 69 [35328/39424 (90%)]\tLoss: 0.096005\n",
      "Train Epoch: 69 [35840/39424 (91%)]\tLoss: 0.074257\n",
      "Train Epoch: 69 [36352/39424 (92%)]\tLoss: 0.080759\n",
      "Train Epoch: 69 [36864/39424 (94%)]\tLoss: 0.076149\n",
      "Train Epoch: 69 [37376/39424 (95%)]\tLoss: 0.087465\n",
      "Train Epoch: 69 [37888/39424 (96%)]\tLoss: 0.095852\n",
      "Train Epoch: 69 [38400/39424 (97%)]\tLoss: 0.083619\n",
      "Train Epoch: 69 [38912/39424 (99%)]\tLoss: 0.091815\n",
      "Average training loss: 0.21457646787166595\n",
      "\n",
      "Test set: Average loss: 7.6185, Accuracy: 100/12630 (1%)\n",
      "\n",
      "tensor([0.0079,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2545, Accuracy: 11892/12630 (94%)\n",
      "\n",
      "tensor([0.4833, 0.9583, 0.9853, 0.9556, 0.9364, 0.9206, 0.8067, 0.9244, 0.9689,\n",
      "        0.9896, 0.9864, 0.9619, 0.9783, 0.9958, 1.0000, 0.9810, 0.9933, 0.9500,\n",
      "        0.8000, 1.0000, 0.9889, 0.6333, 0.9250, 0.9667, 0.8778, 0.9396, 0.8111,\n",
      "        0.5000, 0.9600, 0.9667, 0.7400, 0.9852, 0.7167, 0.9905, 0.9833, 0.9667,\n",
      "        0.9250, 1.0000, 0.9580, 0.7667, 0.8556, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 69 [0/9728 (0%)]\tLoss: 7.178329\n",
      "Train Epoch: 69 [512/9728 (5%)]\tLoss: 2.369382\n",
      "Train Epoch: 69 [1024/9728 (11%)]\tLoss: 0.204269\n",
      "Train Epoch: 69 [1536/9728 (16%)]\tLoss: 0.091046\n",
      "Train Epoch: 69 [2048/9728 (21%)]\tLoss: 0.041657\n",
      "Train Epoch: 69 [2560/9728 (26%)]\tLoss: 0.036101\n",
      "Train Epoch: 69 [3072/9728 (32%)]\tLoss: 0.023395\n",
      "Train Epoch: 69 [3584/9728 (37%)]\tLoss: 0.025109\n",
      "Train Epoch: 69 [4096/9728 (42%)]\tLoss: 0.013633\n",
      "Train Epoch: 69 [4608/9728 (47%)]\tLoss: 0.015558\n",
      "Train Epoch: 69 [5120/9728 (53%)]\tLoss: 0.013855\n",
      "Train Epoch: 69 [5632/9728 (58%)]\tLoss: 0.010719\n",
      "Train Epoch: 69 [6144/9728 (63%)]\tLoss: 0.008147\n",
      "Train Epoch: 69 [6656/9728 (68%)]\tLoss: 0.010474\n",
      "Train Epoch: 69 [7168/9728 (74%)]\tLoss: 0.009687\n",
      "Train Epoch: 69 [7680/9728 (79%)]\tLoss: 0.007100\n",
      "Train Epoch: 69 [8192/9728 (84%)]\tLoss: 0.007261\n",
      "Train Epoch: 69 [8704/9728 (89%)]\tLoss: 0.010754\n",
      "Train Epoch: 69 [9216/9728 (95%)]\tLoss: 0.007023\n",
      "Average training loss: 0.5307103395462036\n",
      "\n",
      "Test set: Average loss: 0.0042, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.9662, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 70 [0/39424 (0%)]\tLoss: 6.960073\n",
      "Train Epoch: 70 [512/39424 (1%)]\tLoss: 0.432311\n",
      "Train Epoch: 70 [1024/39424 (3%)]\tLoss: 0.332258\n",
      "Train Epoch: 70 [1536/39424 (4%)]\tLoss: 0.316074\n",
      "Train Epoch: 70 [2048/39424 (5%)]\tLoss: 0.253358\n",
      "Train Epoch: 70 [2560/39424 (6%)]\tLoss: 0.215341\n",
      "Train Epoch: 70 [3072/39424 (8%)]\tLoss: 0.240505\n",
      "Train Epoch: 70 [3584/39424 (9%)]\tLoss: 0.212843\n",
      "Train Epoch: 70 [4096/39424 (10%)]\tLoss: 0.204862\n",
      "Train Epoch: 70 [4608/39424 (12%)]\tLoss: 0.196822\n",
      "Train Epoch: 70 [5120/39424 (13%)]\tLoss: 0.171320\n",
      "Train Epoch: 70 [5632/39424 (14%)]\tLoss: 0.176686\n",
      "Train Epoch: 70 [6144/39424 (16%)]\tLoss: 0.171727\n",
      "Train Epoch: 70 [6656/39424 (17%)]\tLoss: 0.165488\n",
      "Train Epoch: 70 [7168/39424 (18%)]\tLoss: 0.160545\n",
      "Train Epoch: 70 [7680/39424 (19%)]\tLoss: 0.162763\n",
      "Train Epoch: 70 [8192/39424 (21%)]\tLoss: 0.120045\n",
      "Train Epoch: 70 [8704/39424 (22%)]\tLoss: 0.138144\n",
      "Train Epoch: 70 [9216/39424 (23%)]\tLoss: 0.170291\n",
      "Train Epoch: 70 [9728/39424 (25%)]\tLoss: 0.141447\n",
      "Train Epoch: 70 [10240/39424 (26%)]\tLoss: 0.134000\n",
      "Train Epoch: 70 [10752/39424 (27%)]\tLoss: 0.145966\n",
      "Train Epoch: 70 [11264/39424 (29%)]\tLoss: 0.116671\n",
      "Train Epoch: 70 [11776/39424 (30%)]\tLoss: 0.114900\n",
      "Train Epoch: 70 [12288/39424 (31%)]\tLoss: 0.119003\n",
      "Train Epoch: 70 [12800/39424 (32%)]\tLoss: 0.102248\n",
      "Train Epoch: 70 [13312/39424 (34%)]\tLoss: 0.129058\n",
      "Train Epoch: 70 [13824/39424 (35%)]\tLoss: 0.131262\n",
      "Train Epoch: 70 [14336/39424 (36%)]\tLoss: 0.111040\n",
      "Train Epoch: 70 [14848/39424 (38%)]\tLoss: 0.116903\n",
      "Train Epoch: 70 [15360/39424 (39%)]\tLoss: 0.124993\n",
      "Train Epoch: 70 [15872/39424 (40%)]\tLoss: 0.124538\n",
      "Train Epoch: 70 [16384/39424 (42%)]\tLoss: 0.121786\n",
      "Train Epoch: 70 [16896/39424 (43%)]\tLoss: 0.135862\n",
      "Train Epoch: 70 [17408/39424 (44%)]\tLoss: 0.124840\n",
      "Train Epoch: 70 [17920/39424 (45%)]\tLoss: 0.138116\n",
      "Train Epoch: 70 [18432/39424 (47%)]\tLoss: 0.101590\n",
      "Train Epoch: 70 [18944/39424 (48%)]\tLoss: 0.090202\n",
      "Train Epoch: 70 [19456/39424 (49%)]\tLoss: 0.097493\n",
      "Train Epoch: 70 [19968/39424 (51%)]\tLoss: 0.089277\n",
      "Train Epoch: 70 [20480/39424 (52%)]\tLoss: 0.082752\n",
      "Train Epoch: 70 [20992/39424 (53%)]\tLoss: 0.123613\n",
      "Train Epoch: 70 [21504/39424 (55%)]\tLoss: 0.077107\n",
      "Train Epoch: 70 [22016/39424 (56%)]\tLoss: 0.082319\n",
      "Train Epoch: 70 [22528/39424 (57%)]\tLoss: 0.078044\n",
      "Train Epoch: 70 [23040/39424 (58%)]\tLoss: 0.121983\n",
      "Train Epoch: 70 [23552/39424 (60%)]\tLoss: 0.086402\n",
      "Train Epoch: 70 [24064/39424 (61%)]\tLoss: 0.089951\n",
      "Train Epoch: 70 [24576/39424 (62%)]\tLoss: 0.090919\n",
      "Train Epoch: 70 [25088/39424 (64%)]\tLoss: 0.085304\n",
      "Train Epoch: 70 [25600/39424 (65%)]\tLoss: 0.100691\n",
      "Train Epoch: 70 [26112/39424 (66%)]\tLoss: 0.081161\n",
      "Train Epoch: 70 [26624/39424 (68%)]\tLoss: 0.100761\n",
      "Train Epoch: 70 [27136/39424 (69%)]\tLoss: 0.107418\n",
      "Train Epoch: 70 [27648/39424 (70%)]\tLoss: 0.095887\n",
      "Train Epoch: 70 [28160/39424 (71%)]\tLoss: 0.069210\n",
      "Train Epoch: 70 [28672/39424 (73%)]\tLoss: 0.082826\n",
      "Train Epoch: 70 [29184/39424 (74%)]\tLoss: 0.100376\n",
      "Train Epoch: 70 [29696/39424 (75%)]\tLoss: 0.085988\n",
      "Train Epoch: 70 [30208/39424 (77%)]\tLoss: 0.096410\n",
      "Train Epoch: 70 [30720/39424 (78%)]\tLoss: 0.091740\n",
      "Train Epoch: 70 [31232/39424 (79%)]\tLoss: 0.108864\n",
      "Train Epoch: 70 [31744/39424 (81%)]\tLoss: 0.106959\n",
      "Train Epoch: 70 [32256/39424 (82%)]\tLoss: 0.075557\n",
      "Train Epoch: 70 [32768/39424 (83%)]\tLoss: 0.099185\n",
      "Train Epoch: 70 [33280/39424 (84%)]\tLoss: 0.080359\n",
      "Train Epoch: 70 [33792/39424 (86%)]\tLoss: 0.062967\n",
      "Train Epoch: 70 [34304/39424 (87%)]\tLoss: 0.070002\n",
      "Train Epoch: 70 [34816/39424 (88%)]\tLoss: 0.088866\n",
      "Train Epoch: 70 [35328/39424 (90%)]\tLoss: 0.071122\n",
      "Train Epoch: 70 [35840/39424 (91%)]\tLoss: 0.068893\n",
      "Train Epoch: 70 [36352/39424 (92%)]\tLoss: 0.084831\n",
      "Train Epoch: 70 [36864/39424 (94%)]\tLoss: 0.075259\n",
      "Train Epoch: 70 [37376/39424 (95%)]\tLoss: 0.087827\n",
      "Train Epoch: 70 [37888/39424 (96%)]\tLoss: 0.088737\n",
      "Train Epoch: 70 [38400/39424 (97%)]\tLoss: 0.081687\n",
      "Train Epoch: 70 [38912/39424 (99%)]\tLoss: 0.081875\n",
      "Average training loss: 0.21527926623821259\n",
      "\n",
      "Test set: Average loss: 7.5971, Accuracy: 102/12630 (1%)\n",
      "\n",
      "tensor([0.0081,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2513, Accuracy: 11903/12630 (94%)\n",
      "\n",
      "tensor([0.5167, 0.9625, 0.9853, 0.9578, 0.9364, 0.9190, 0.8133, 0.9267, 0.9711,\n",
      "        0.9854, 0.9864, 0.9595, 0.9783, 0.9958, 1.0000, 0.9810, 0.9933, 0.9500,\n",
      "        0.7974, 1.0000, 0.9889, 0.6444, 0.9250, 0.9733, 0.8778, 0.9375, 0.8167,\n",
      "        0.5000, 0.9600, 0.9889, 0.7400, 0.9852, 0.7167, 0.9905, 0.9917, 0.9667,\n",
      "        0.9333, 1.0000, 0.9580, 0.7778, 0.8556, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 70 [0/9728 (0%)]\tLoss: 7.103486\n",
      "Train Epoch: 70 [512/9728 (5%)]\tLoss: 2.461798\n",
      "Train Epoch: 70 [1024/9728 (11%)]\tLoss: 0.192644\n",
      "Train Epoch: 70 [1536/9728 (16%)]\tLoss: 0.100342\n",
      "Train Epoch: 70 [2048/9728 (21%)]\tLoss: 0.046149\n",
      "Train Epoch: 70 [2560/9728 (26%)]\tLoss: 0.030663\n",
      "Train Epoch: 70 [3072/9728 (32%)]\tLoss: 0.022153\n",
      "Train Epoch: 70 [3584/9728 (37%)]\tLoss: 0.021907\n",
      "Train Epoch: 70 [4096/9728 (42%)]\tLoss: 0.017361\n",
      "Train Epoch: 70 [4608/9728 (47%)]\tLoss: 0.013968\n",
      "Train Epoch: 70 [5120/9728 (53%)]\tLoss: 0.014378\n",
      "Train Epoch: 70 [5632/9728 (58%)]\tLoss: 0.009739\n",
      "Train Epoch: 70 [6144/9728 (63%)]\tLoss: 0.009489\n",
      "Train Epoch: 70 [6656/9728 (68%)]\tLoss: 0.009838\n",
      "Train Epoch: 70 [7168/9728 (74%)]\tLoss: 0.010338\n",
      "Train Epoch: 70 [7680/9728 (79%)]\tLoss: 0.007166\n",
      "Train Epoch: 70 [8192/9728 (84%)]\tLoss: 0.007759\n",
      "Train Epoch: 70 [8704/9728 (89%)]\tLoss: 0.006644\n",
      "Train Epoch: 70 [9216/9728 (95%)]\tLoss: 0.006173\n",
      "Average training loss: 0.5311577916145325\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.9050, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 71 [0/39424 (0%)]\tLoss: 6.919360\n",
      "Train Epoch: 71 [512/39424 (1%)]\tLoss: 0.493262\n",
      "Train Epoch: 71 [1024/39424 (3%)]\tLoss: 0.322981\n",
      "Train Epoch: 71 [1536/39424 (4%)]\tLoss: 0.284746\n",
      "Train Epoch: 71 [2048/39424 (5%)]\tLoss: 0.238674\n",
      "Train Epoch: 71 [2560/39424 (6%)]\tLoss: 0.200301\n",
      "Train Epoch: 71 [3072/39424 (8%)]\tLoss: 0.240739\n",
      "Train Epoch: 71 [3584/39424 (9%)]\tLoss: 0.214157\n",
      "Train Epoch: 71 [4096/39424 (10%)]\tLoss: 0.183265\n",
      "Train Epoch: 71 [4608/39424 (12%)]\tLoss: 0.188680\n",
      "Train Epoch: 71 [5120/39424 (13%)]\tLoss: 0.155868\n",
      "Train Epoch: 71 [5632/39424 (14%)]\tLoss: 0.176881\n",
      "Train Epoch: 71 [6144/39424 (16%)]\tLoss: 0.148166\n",
      "Train Epoch: 71 [6656/39424 (17%)]\tLoss: 0.167006\n",
      "Train Epoch: 71 [7168/39424 (18%)]\tLoss: 0.161207\n",
      "Train Epoch: 71 [7680/39424 (19%)]\tLoss: 0.160064\n",
      "Train Epoch: 71 [8192/39424 (21%)]\tLoss: 0.115881\n",
      "Train Epoch: 71 [8704/39424 (22%)]\tLoss: 0.126232\n",
      "Train Epoch: 71 [9216/39424 (23%)]\tLoss: 0.168563\n",
      "Train Epoch: 71 [9728/39424 (25%)]\tLoss: 0.138148\n",
      "Train Epoch: 71 [10240/39424 (26%)]\tLoss: 0.122838\n",
      "Train Epoch: 71 [10752/39424 (27%)]\tLoss: 0.157549\n",
      "Train Epoch: 71 [11264/39424 (29%)]\tLoss: 0.117444\n",
      "Train Epoch: 71 [11776/39424 (30%)]\tLoss: 0.109425\n",
      "Train Epoch: 71 [12288/39424 (31%)]\tLoss: 0.121459\n",
      "Train Epoch: 71 [12800/39424 (32%)]\tLoss: 0.110943\n",
      "Train Epoch: 71 [13312/39424 (34%)]\tLoss: 0.130019\n",
      "Train Epoch: 71 [13824/39424 (35%)]\tLoss: 0.125475\n",
      "Train Epoch: 71 [14336/39424 (36%)]\tLoss: 0.117775\n",
      "Train Epoch: 71 [14848/39424 (38%)]\tLoss: 0.106136\n",
      "Train Epoch: 71 [15360/39424 (39%)]\tLoss: 0.117271\n",
      "Train Epoch: 71 [15872/39424 (40%)]\tLoss: 0.108199\n",
      "Train Epoch: 71 [16384/39424 (42%)]\tLoss: 0.110325\n",
      "Train Epoch: 71 [16896/39424 (43%)]\tLoss: 0.136017\n",
      "Train Epoch: 71 [17408/39424 (44%)]\tLoss: 0.118043\n",
      "Train Epoch: 71 [17920/39424 (45%)]\tLoss: 0.139070\n",
      "Train Epoch: 71 [18432/39424 (47%)]\tLoss: 0.093155\n",
      "Train Epoch: 71 [18944/39424 (48%)]\tLoss: 0.082546\n",
      "Train Epoch: 71 [19456/39424 (49%)]\tLoss: 0.114848\n",
      "Train Epoch: 71 [19968/39424 (51%)]\tLoss: 0.072674\n",
      "Train Epoch: 71 [20480/39424 (52%)]\tLoss: 0.080826\n",
      "Train Epoch: 71 [20992/39424 (53%)]\tLoss: 0.109866\n",
      "Train Epoch: 71 [21504/39424 (55%)]\tLoss: 0.074493\n",
      "Train Epoch: 71 [22016/39424 (56%)]\tLoss: 0.082319\n",
      "Train Epoch: 71 [22528/39424 (57%)]\tLoss: 0.074267\n",
      "Train Epoch: 71 [23040/39424 (58%)]\tLoss: 0.112522\n",
      "Train Epoch: 71 [23552/39424 (60%)]\tLoss: 0.086394\n",
      "Train Epoch: 71 [24064/39424 (61%)]\tLoss: 0.085022\n",
      "Train Epoch: 71 [24576/39424 (62%)]\tLoss: 0.085699\n",
      "Train Epoch: 71 [25088/39424 (64%)]\tLoss: 0.098719\n",
      "Train Epoch: 71 [25600/39424 (65%)]\tLoss: 0.092212\n",
      "Train Epoch: 71 [26112/39424 (66%)]\tLoss: 0.078545\n",
      "Train Epoch: 71 [26624/39424 (68%)]\tLoss: 0.090511\n",
      "Train Epoch: 71 [27136/39424 (69%)]\tLoss: 0.100689\n",
      "Train Epoch: 71 [27648/39424 (70%)]\tLoss: 0.091710\n",
      "Train Epoch: 71 [28160/39424 (71%)]\tLoss: 0.075188\n",
      "Train Epoch: 71 [28672/39424 (73%)]\tLoss: 0.079567\n",
      "Train Epoch: 71 [29184/39424 (74%)]\tLoss: 0.095240\n",
      "Train Epoch: 71 [29696/39424 (75%)]\tLoss: 0.084678\n",
      "Train Epoch: 71 [30208/39424 (77%)]\tLoss: 0.090015\n",
      "Train Epoch: 71 [30720/39424 (78%)]\tLoss: 0.078845\n",
      "Train Epoch: 71 [31232/39424 (79%)]\tLoss: 0.123900\n",
      "Train Epoch: 71 [31744/39424 (81%)]\tLoss: 0.100017\n",
      "Train Epoch: 71 [32256/39424 (82%)]\tLoss: 0.071368\n",
      "Train Epoch: 71 [32768/39424 (83%)]\tLoss: 0.083113\n",
      "Train Epoch: 71 [33280/39424 (84%)]\tLoss: 0.063710\n",
      "Train Epoch: 71 [33792/39424 (86%)]\tLoss: 0.063325\n",
      "Train Epoch: 71 [34304/39424 (87%)]\tLoss: 0.058363\n",
      "Train Epoch: 71 [34816/39424 (88%)]\tLoss: 0.071195\n",
      "Train Epoch: 71 [35328/39424 (90%)]\tLoss: 0.067205\n",
      "Train Epoch: 71 [35840/39424 (91%)]\tLoss: 0.070150\n",
      "Train Epoch: 71 [36352/39424 (92%)]\tLoss: 0.091420\n",
      "Train Epoch: 71 [36864/39424 (94%)]\tLoss: 0.077195\n",
      "Train Epoch: 71 [37376/39424 (95%)]\tLoss: 0.082965\n",
      "Train Epoch: 71 [37888/39424 (96%)]\tLoss: 0.096043\n",
      "Train Epoch: 71 [38400/39424 (97%)]\tLoss: 0.068800\n",
      "Train Epoch: 71 [38912/39424 (99%)]\tLoss: 0.095681\n",
      "Average training loss: 0.2110022008419037\n",
      "\n",
      "Test set: Average loss: 7.5892, Accuracy: 104/12630 (1%)\n",
      "\n",
      "tensor([0.0082,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2502, Accuracy: 11904/12630 (94%)\n",
      "\n",
      "tensor([0.5000, 0.9625, 0.9853, 0.9578, 0.9409, 0.9190, 0.8133, 0.9267, 0.9711,\n",
      "        0.9875, 0.9864, 0.9571, 0.9783, 0.9958, 1.0000, 0.9857, 0.9933, 0.9500,\n",
      "        0.8000, 1.0000, 0.9889, 0.6111, 0.9250, 0.9667, 0.8889, 0.9375, 0.8111,\n",
      "        0.5000, 0.9533, 0.9778, 0.7400, 0.9852, 0.7333, 0.9952, 0.9917, 0.9667,\n",
      "        0.9167, 1.0000, 0.9594, 0.7778, 0.8667, 0.8667, 0.9000])\n",
      "Train backdoor\n",
      "Train Epoch: 71 [0/9728 (0%)]\tLoss: 7.058356\n",
      "Train Epoch: 71 [512/9728 (5%)]\tLoss: 2.406351\n",
      "Train Epoch: 71 [1024/9728 (11%)]\tLoss: 0.203148\n",
      "Train Epoch: 71 [1536/9728 (16%)]\tLoss: 0.093727\n",
      "Train Epoch: 71 [2048/9728 (21%)]\tLoss: 0.039169\n",
      "Train Epoch: 71 [2560/9728 (26%)]\tLoss: 0.036491\n",
      "Train Epoch: 71 [3072/9728 (32%)]\tLoss: 0.026351\n",
      "Train Epoch: 71 [3584/9728 (37%)]\tLoss: 0.024418\n",
      "Train Epoch: 71 [4096/9728 (42%)]\tLoss: 0.015244\n",
      "Train Epoch: 71 [4608/9728 (47%)]\tLoss: 0.014393\n",
      "Train Epoch: 71 [5120/9728 (53%)]\tLoss: 0.012370\n",
      "Train Epoch: 71 [5632/9728 (58%)]\tLoss: 0.013422\n",
      "Train Epoch: 71 [6144/9728 (63%)]\tLoss: 0.009848\n",
      "Train Epoch: 71 [6656/9728 (68%)]\tLoss: 0.010622\n",
      "Train Epoch: 71 [7168/9728 (74%)]\tLoss: 0.008532\n",
      "Train Epoch: 71 [7680/9728 (79%)]\tLoss: 0.007298\n",
      "Train Epoch: 71 [8192/9728 (84%)]\tLoss: 0.006099\n",
      "Train Epoch: 71 [8704/9728 (89%)]\tLoss: 0.006515\n",
      "Train Epoch: 71 [9216/9728 (95%)]\tLoss: 0.008120\n",
      "Average training loss: 0.526340663433075\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.9481, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 72 [0/39424 (0%)]\tLoss: 6.932981\n",
      "Train Epoch: 72 [512/39424 (1%)]\tLoss: 0.402220\n",
      "Train Epoch: 72 [1024/39424 (3%)]\tLoss: 0.330869\n",
      "Train Epoch: 72 [1536/39424 (4%)]\tLoss: 0.291498\n",
      "Train Epoch: 72 [2048/39424 (5%)]\tLoss: 0.249894\n",
      "Train Epoch: 72 [2560/39424 (6%)]\tLoss: 0.203816\n",
      "Train Epoch: 72 [3072/39424 (8%)]\tLoss: 0.231045\n",
      "Train Epoch: 72 [3584/39424 (9%)]\tLoss: 0.204665\n",
      "Train Epoch: 72 [4096/39424 (10%)]\tLoss: 0.174710\n",
      "Train Epoch: 72 [4608/39424 (12%)]\tLoss: 0.182766\n",
      "Train Epoch: 72 [5120/39424 (13%)]\tLoss: 0.158281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [5632/39424 (14%)]\tLoss: 0.180521\n",
      "Train Epoch: 72 [6144/39424 (16%)]\tLoss: 0.146656\n",
      "Train Epoch: 72 [6656/39424 (17%)]\tLoss: 0.162746\n",
      "Train Epoch: 72 [7168/39424 (18%)]\tLoss: 0.146585\n",
      "Train Epoch: 72 [7680/39424 (19%)]\tLoss: 0.157812\n",
      "Train Epoch: 72 [8192/39424 (21%)]\tLoss: 0.113913\n",
      "Train Epoch: 72 [8704/39424 (22%)]\tLoss: 0.142196\n",
      "Train Epoch: 72 [9216/39424 (23%)]\tLoss: 0.148297\n",
      "Train Epoch: 72 [9728/39424 (25%)]\tLoss: 0.135097\n",
      "Train Epoch: 72 [10240/39424 (26%)]\tLoss: 0.133062\n",
      "Train Epoch: 72 [10752/39424 (27%)]\tLoss: 0.147441\n",
      "Train Epoch: 72 [11264/39424 (29%)]\tLoss: 0.114457\n",
      "Train Epoch: 72 [11776/39424 (30%)]\tLoss: 0.112548\n",
      "Train Epoch: 72 [12288/39424 (31%)]\tLoss: 0.107556\n",
      "Train Epoch: 72 [12800/39424 (32%)]\tLoss: 0.110248\n",
      "Train Epoch: 72 [13312/39424 (34%)]\tLoss: 0.115811\n",
      "Train Epoch: 72 [13824/39424 (35%)]\tLoss: 0.114612\n",
      "Train Epoch: 72 [14336/39424 (36%)]\tLoss: 0.107224\n",
      "Train Epoch: 72 [14848/39424 (38%)]\tLoss: 0.110247\n",
      "Train Epoch: 72 [15360/39424 (39%)]\tLoss: 0.111939\n",
      "Train Epoch: 72 [15872/39424 (40%)]\tLoss: 0.113690\n",
      "Train Epoch: 72 [16384/39424 (42%)]\tLoss: 0.115770\n",
      "Train Epoch: 72 [16896/39424 (43%)]\tLoss: 0.133630\n",
      "Train Epoch: 72 [17408/39424 (44%)]\tLoss: 0.114754\n",
      "Train Epoch: 72 [17920/39424 (45%)]\tLoss: 0.148192\n",
      "Train Epoch: 72 [18432/39424 (47%)]\tLoss: 0.106332\n",
      "Train Epoch: 72 [18944/39424 (48%)]\tLoss: 0.081105\n",
      "Train Epoch: 72 [19456/39424 (49%)]\tLoss: 0.095285\n",
      "Train Epoch: 72 [19968/39424 (51%)]\tLoss: 0.076476\n",
      "Train Epoch: 72 [20480/39424 (52%)]\tLoss: 0.092044\n",
      "Train Epoch: 72 [20992/39424 (53%)]\tLoss: 0.115144\n",
      "Train Epoch: 72 [21504/39424 (55%)]\tLoss: 0.078799\n",
      "Train Epoch: 72 [22016/39424 (56%)]\tLoss: 0.080052\n",
      "Train Epoch: 72 [22528/39424 (57%)]\tLoss: 0.077929\n",
      "Train Epoch: 72 [23040/39424 (58%)]\tLoss: 0.119422\n",
      "Train Epoch: 72 [23552/39424 (60%)]\tLoss: 0.086561\n",
      "Train Epoch: 72 [24064/39424 (61%)]\tLoss: 0.083510\n",
      "Train Epoch: 72 [24576/39424 (62%)]\tLoss: 0.079211\n",
      "Train Epoch: 72 [25088/39424 (64%)]\tLoss: 0.083164\n",
      "Train Epoch: 72 [25600/39424 (65%)]\tLoss: 0.086182\n",
      "Train Epoch: 72 [26112/39424 (66%)]\tLoss: 0.079508\n",
      "Train Epoch: 72 [26624/39424 (68%)]\tLoss: 0.105656\n",
      "Train Epoch: 72 [27136/39424 (69%)]\tLoss: 0.098937\n",
      "Train Epoch: 72 [27648/39424 (70%)]\tLoss: 0.093586\n",
      "Train Epoch: 72 [28160/39424 (71%)]\tLoss: 0.075264\n",
      "Train Epoch: 72 [28672/39424 (73%)]\tLoss: 0.087065\n",
      "Train Epoch: 72 [29184/39424 (74%)]\tLoss: 0.097279\n",
      "Train Epoch: 72 [29696/39424 (75%)]\tLoss: 0.082966\n",
      "Train Epoch: 72 [30208/39424 (77%)]\tLoss: 0.076046\n",
      "Train Epoch: 72 [30720/39424 (78%)]\tLoss: 0.079363\n",
      "Train Epoch: 72 [31232/39424 (79%)]\tLoss: 0.108741\n",
      "Train Epoch: 72 [31744/39424 (81%)]\tLoss: 0.102974\n",
      "Train Epoch: 72 [32256/39424 (82%)]\tLoss: 0.083623\n",
      "Train Epoch: 72 [32768/39424 (83%)]\tLoss: 0.092936\n",
      "Train Epoch: 72 [33280/39424 (84%)]\tLoss: 0.071575\n",
      "Train Epoch: 72 [33792/39424 (86%)]\tLoss: 0.059720\n",
      "Train Epoch: 72 [34304/39424 (87%)]\tLoss: 0.061096\n",
      "Train Epoch: 72 [34816/39424 (88%)]\tLoss: 0.084378\n",
      "Train Epoch: 72 [35328/39424 (90%)]\tLoss: 0.067351\n",
      "Train Epoch: 72 [35840/39424 (91%)]\tLoss: 0.068746\n",
      "Train Epoch: 72 [36352/39424 (92%)]\tLoss: 0.083052\n",
      "Train Epoch: 72 [36864/39424 (94%)]\tLoss: 0.059654\n",
      "Train Epoch: 72 [37376/39424 (95%)]\tLoss: 0.079706\n",
      "Train Epoch: 72 [37888/39424 (96%)]\tLoss: 0.085577\n",
      "Train Epoch: 72 [38400/39424 (97%)]\tLoss: 0.080320\n",
      "Train Epoch: 72 [38912/39424 (99%)]\tLoss: 0.082511\n",
      "Average training loss: 0.20904676616191864\n",
      "\n",
      "Test set: Average loss: 7.5689, Accuracy: 107/12630 (1%)\n",
      "\n",
      "tensor([0.0085,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan,    nan,    nan,    nan,    nan,    nan])\n",
      "\n",
      "Test set: Average loss: 0.2486, Accuracy: 11903/12630 (94%)\n",
      "\n",
      "tensor([0.5167, 0.9625, 0.9853, 0.9444, 0.9455, 0.9206, 0.8133, 0.9267, 0.9711,\n",
      "        0.9875, 0.9864, 0.9571, 0.9783, 0.9958, 1.0000, 0.9810, 0.9933, 0.9472,\n",
      "        0.7949, 1.0000, 0.9889, 0.6222, 0.9250, 0.9733, 0.8889, 0.9375, 0.8167,\n",
      "        0.5000, 0.9600, 0.9778, 0.7400, 0.9815, 0.7667, 0.9905, 0.9833, 0.9667,\n",
      "        0.9333, 1.0000, 0.9609, 0.7667, 0.8667, 0.8667, 0.8889])\n",
      "Train backdoor\n",
      "Train Epoch: 72 [0/9728 (0%)]\tLoss: 7.035072\n",
      "Train Epoch: 72 [512/9728 (5%)]\tLoss: 2.372931\n",
      "Train Epoch: 72 [1024/9728 (11%)]\tLoss: 0.226232\n",
      "Train Epoch: 72 [1536/9728 (16%)]\tLoss: 0.094566\n",
      "Train Epoch: 72 [2048/9728 (21%)]\tLoss: 0.041421\n",
      "Train Epoch: 72 [2560/9728 (26%)]\tLoss: 0.034083\n",
      "Train Epoch: 72 [3072/9728 (32%)]\tLoss: 0.031995\n",
      "Train Epoch: 72 [3584/9728 (37%)]\tLoss: 0.023250\n",
      "Train Epoch: 72 [4096/9728 (42%)]\tLoss: 0.015199\n",
      "Train Epoch: 72 [4608/9728 (47%)]\tLoss: 0.012451\n",
      "Train Epoch: 72 [5120/9728 (53%)]\tLoss: 0.015104\n",
      "Train Epoch: 72 [5632/9728 (58%)]\tLoss: 0.010043\n",
      "Train Epoch: 72 [6144/9728 (63%)]\tLoss: 0.009696\n",
      "Train Epoch: 72 [6656/9728 (68%)]\tLoss: 0.010627\n",
      "Train Epoch: 72 [7168/9728 (74%)]\tLoss: 0.008345\n",
      "Train Epoch: 72 [7680/9728 (79%)]\tLoss: 0.005959\n",
      "Train Epoch: 72 [8192/9728 (84%)]\tLoss: 0.005577\n",
      "Train Epoch: 72 [8704/9728 (89%)]\tLoss: 0.006710\n",
      "Train Epoch: 72 [9216/9728 (95%)]\tLoss: 0.005527\n",
      "Average training loss: 0.5244625210762024\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 12630/12630 (100%)\n",
      "\n",
      "tensor([1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan])\n",
      "\n",
      "Test set: Average loss: 7.8697, Accuracy: 60/12630 (0%)\n",
      "\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "Train benign dataset\n",
      "Train Epoch: 73 [0/39424 (0%)]\tLoss: 6.867337\n",
      "Train Epoch: 73 [512/39424 (1%)]\tLoss: 0.556558\n",
      "Train Epoch: 73 [1024/39424 (3%)]\tLoss: 0.341837\n",
      "Train Epoch: 73 [1536/39424 (4%)]\tLoss: 0.270067\n",
      "Train Epoch: 73 [2048/39424 (5%)]\tLoss: 0.234835\n",
      "Train Epoch: 73 [2560/39424 (6%)]\tLoss: 0.200799\n",
      "Train Epoch: 73 [3072/39424 (8%)]\tLoss: 0.219886\n",
      "Train Epoch: 73 [3584/39424 (9%)]\tLoss: 0.205792\n",
      "Train Epoch: 73 [4096/39424 (10%)]\tLoss: 0.173399\n",
      "Train Epoch: 73 [4608/39424 (12%)]\tLoss: 0.189477\n",
      "Train Epoch: 73 [5120/39424 (13%)]\tLoss: 0.150492\n",
      "Train Epoch: 73 [5632/39424 (14%)]\tLoss: 0.184023\n",
      "Train Epoch: 73 [6144/39424 (16%)]\tLoss: 0.151897\n",
      "Train Epoch: 73 [6656/39424 (17%)]\tLoss: 0.157935\n",
      "Train Epoch: 73 [7168/39424 (18%)]\tLoss: 0.156028\n",
      "Train Epoch: 73 [7680/39424 (19%)]\tLoss: 0.160681\n",
      "Train Epoch: 73 [8192/39424 (21%)]\tLoss: 0.115587\n",
      "Train Epoch: 73 [8704/39424 (22%)]\tLoss: 0.128129\n",
      "Train Epoch: 73 [9216/39424 (23%)]\tLoss: 0.150195\n",
      "Train Epoch: 73 [9728/39424 (25%)]\tLoss: 0.131748\n",
      "Train Epoch: 73 [10240/39424 (26%)]\tLoss: 0.116216\n",
      "Train Epoch: 73 [10752/39424 (27%)]\tLoss: 0.149697\n",
      "Train Epoch: 73 [11264/39424 (29%)]\tLoss: 0.115943\n",
      "Train Epoch: 73 [11776/39424 (30%)]\tLoss: 0.105022\n",
      "Train Epoch: 73 [12288/39424 (31%)]\tLoss: 0.108529\n",
      "Train Epoch: 73 [12800/39424 (32%)]\tLoss: 0.104744\n",
      "Train Epoch: 73 [13312/39424 (34%)]\tLoss: 0.107386\n",
      "Train Epoch: 73 [13824/39424 (35%)]\tLoss: 0.126563\n",
      "Train Epoch: 73 [14336/39424 (36%)]\tLoss: 0.104070\n",
      "Train Epoch: 73 [14848/39424 (38%)]\tLoss: 0.112807\n",
      "Train Epoch: 73 [15360/39424 (39%)]\tLoss: 0.110849\n",
      "Train Epoch: 73 [15872/39424 (40%)]\tLoss: 0.120828\n",
      "Train Epoch: 73 [16384/39424 (42%)]\tLoss: 0.104092\n",
      "Train Epoch: 73 [16896/39424 (43%)]\tLoss: 0.147836\n",
      "Train Epoch: 73 [17408/39424 (44%)]\tLoss: 0.109405\n",
      "Train Epoch: 73 [17920/39424 (45%)]\tLoss: 0.140994\n",
      "Train Epoch: 73 [18432/39424 (47%)]\tLoss: 0.086987\n",
      "Train Epoch: 73 [18944/39424 (48%)]\tLoss: 0.090202\n",
      "Train Epoch: 73 [19456/39424 (49%)]\tLoss: 0.090806\n",
      "Train Epoch: 73 [19968/39424 (51%)]\tLoss: 0.074208\n",
      "Train Epoch: 73 [20480/39424 (52%)]\tLoss: 0.079641\n",
      "Train Epoch: 73 [20992/39424 (53%)]\tLoss: 0.127714\n",
      "Train Epoch: 73 [21504/39424 (55%)]\tLoss: 0.077017\n",
      "Train Epoch: 73 [22016/39424 (56%)]\tLoss: 0.089951\n",
      "Train Epoch: 73 [22528/39424 (57%)]\tLoss: 0.071798\n",
      "Train Epoch: 73 [23040/39424 (58%)]\tLoss: 0.112869\n",
      "Train Epoch: 73 [23552/39424 (60%)]\tLoss: 0.091255\n",
      "Train Epoch: 73 [24064/39424 (61%)]\tLoss: 0.081040\n",
      "Train Epoch: 73 [24576/39424 (62%)]\tLoss: 0.086871\n",
      "Train Epoch: 73 [25088/39424 (64%)]\tLoss: 0.083200\n",
      "Train Epoch: 73 [25600/39424 (65%)]\tLoss: 0.091561\n",
      "Train Epoch: 73 [26112/39424 (66%)]\tLoss: 0.070950\n",
      "Train Epoch: 73 [26624/39424 (68%)]\tLoss: 0.087518\n",
      "Train Epoch: 73 [27136/39424 (69%)]\tLoss: 0.102787\n",
      "Train Epoch: 73 [27648/39424 (70%)]\tLoss: 0.088388\n",
      "Train Epoch: 73 [28160/39424 (71%)]\tLoss: 0.078522\n",
      "Train Epoch: 73 [28672/39424 (73%)]\tLoss: 0.083686\n",
      "Train Epoch: 73 [29184/39424 (74%)]\tLoss: 0.098782\n",
      "Train Epoch: 73 [29696/39424 (75%)]\tLoss: 0.088238\n",
      "Train Epoch: 73 [30208/39424 (77%)]\tLoss: 0.094239\n",
      "Train Epoch: 73 [30720/39424 (78%)]\tLoss: 0.092014\n",
      "Train Epoch: 73 [31232/39424 (79%)]\tLoss: 0.115279\n",
      "Train Epoch: 73 [31744/39424 (81%)]\tLoss: 0.107588\n",
      "Train Epoch: 73 [32256/39424 (82%)]\tLoss: 0.072397\n",
      "Train Epoch: 73 [32768/39424 (83%)]\tLoss: 0.085076\n",
      "Train Epoch: 73 [33280/39424 (84%)]\tLoss: 0.078560\n",
      "Train Epoch: 73 [33792/39424 (86%)]\tLoss: 0.056066\n",
      "Train Epoch: 73 [34304/39424 (87%)]\tLoss: 0.066539\n",
      "Train Epoch: 73 [34816/39424 (88%)]\tLoss: 0.063594\n",
      "Train Epoch: 73 [35328/39424 (90%)]\tLoss: 0.080639\n",
      "Train Epoch: 73 [35840/39424 (91%)]\tLoss: 0.066382\n",
      "Train Epoch: 73 [36352/39424 (92%)]\tLoss: 0.088022\n",
      "Train Epoch: 73 [36864/39424 (94%)]\tLoss: 0.067529\n",
      "Train Epoch: 73 [37376/39424 (95%)]\tLoss: 0.078018\n",
      "Train Epoch: 73 [37888/39424 (96%)]\tLoss: 0.080845\n",
      "Train Epoch: 73 [38400/39424 (97%)]\tLoss: 0.067982\n",
      "Train Epoch: 73 [38912/39424 (99%)]\tLoss: 0.090363\n",
      "Average training loss: 0.2093091458082199\n",
      "\n",
      "Test set: Average loss: 7.5380, Accuracy: 108/12630 (1%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4f355cda490b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m#--------------- Test in between ------------------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#test backdoor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_class_accuracy_backdoor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_loader_backdoored_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackdoored_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mcsv_backdoor\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"in_between;\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\";\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#test normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d39aa719ee28>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, device, test_loader, length_of_dataset)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#Write to file:\n",
    "dateString = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "f= open((\"exp_gtsrb_\"+dateString+\".txt\"),\"w+\")\n",
    "f2= open((\"exp_gtsrb_perClassAccuracy_\"+dateString+\".txt\"),\"w+\")\n",
    "\n",
    "#EXP-setup\n",
    "csv_header =  \"#dataset: \" + \"gtsrb\" + \"\\n\"\n",
    "csv_header += \"#way backdoor looks like: \" + backdoorType + \"\\n\"\n",
    "csv_header += \"#merge strategy: \" + \"sequential\" + \"\\n\"\n",
    "csv_header += \"#number of benign sources: \" + str(len(compute_nodes)) + \"\\n\"\n",
    "csv_header += \"#number of malicious sources: \" + str(len(frauds)) + \"\\n\"\n",
    "csv_header += \"#batch size: \" + str(batch_size) + \"\\n\"\n",
    "csv_header += \"#distribution of data: \" + \"equally distributed subset\" + \"\\n\"\n",
    "csv_header += \"#percentage of poisoned data in backdoored nodes: \" + \"100\" + \"\\n\" #str(100)\n",
    "csv_header += \"#order of time backdoors being inserted: \" + \"backdoors last\" + \"\\n\" #backdoors first\n",
    "csv_header += \"#attack model: \" + \"basic\" + \"\\n\" #basic\n",
    "csv_header += \"#starttime: \" + datetime.datetime.now().strftime(\"%H%M%S\") + \"\\n\"\n",
    "csv_header += \"training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\" + \"\\n\"\n",
    "print(csv_header)\n",
    "f.write(csv_header)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#RUN training\n",
    "for epoch in range(1, 101):\n",
    "    csv_normal = \"normal;\" + str(epoch) + \";\" + str(0.0001) + \";\"\n",
    "    csv_backdoor = \"backdoor;\" + str(epoch) + \";\" + str(0.0001) + \";\"\n",
    "    \n",
    "    #train normal\n",
    "    print(\"Train benign dataset\")\n",
    "    avg_training_loss = train(epoch, train_distributed_dataset)\n",
    "    csv_normal += str(avg_training_loss) + \";\"\n",
    "    timestamp_normal = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    \n",
    "    #--------------- Test in between ------------------#\n",
    "    #test backdoor\n",
    "    test_loss, acc, per_class_accuracy_backdoor= test(model, device, dataset_loader_backdoored_test, len(backdoored_test))\n",
    "    csv_backdoor += \"in_between;\" + str(test_loss) + \";\" + acc + \";\"\n",
    "    #test normal\n",
    "    test_loss, acc, per_class_accuracy = test(model, device, test_loader, len(testdata))\n",
    "    csv_normal += \"in_between;\" + str(test_loss) + \";\" + acc + \";\"\n",
    "    #------------------------------------------#\n",
    "\n",
    "    #train backdoor\n",
    "    print(\"Train backdoor\")\n",
    "    avg_training_backdoor_loss = train(epoch, train_distributed_dataset_backdoor)\n",
    "    csv_backdoor += str(avg_training_backdoor_loss) + \";\"\n",
    "    timestamp_backdoor = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "\n",
    "    \n",
    "    #save after each 10 iterations\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), (\"exp_gtsrb_\"+dateString +\"_epoch_\" + str(epoch) + \".pt\"))\n",
    "    \n",
    "    #--------------- Test after training ------------------#\n",
    "    #test backdoor\n",
    "    test_loss, acc, per_class_accuracy_backdoor= test(model, device, dataset_loader_backdoored_test, len(backdoored_test))\n",
    "    csv_backdoor += str(test_loss) + \";\" + acc + \";\"\n",
    "    #test normal\n",
    "    test_loss, acc, per_class_accuracy = test(model, device, test_loader, len(testdata))\n",
    "    csv_normal += str(test_loss) + \";\" + acc + \";\"\n",
    "    #------------------------------------------#\n",
    "\n",
    "    #scheduler.step(test_loss)\n",
    "\n",
    "    csv_normal += timestamp_normal + \"\\n\"\n",
    "    csv_backdoor += timestamp_backdoor + \"\\n\"\n",
    "    \n",
    "    #Write to file\n",
    "    f= open((\"exp_gtsrb_\"+dateString+\".txt\"),\"a+\")\n",
    "    f2=open((\"exp_gtsrb_perClassAccuracy_\"+dateString+\".txt\"),\"a+\")\n",
    "\n",
    "    f.write(csv_backdoor)\n",
    "    f.write(csv_normal)\n",
    "    f2.write(str(per_class_accuracy) + \"\\n\")\n",
    "    \n",
    "    f.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Net().to(device)\n",
    "#model.load_state_dict(torch.load(\"newfaces_alexnet_224x224_augmented100.pt\"))\n",
    "#test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout0): Dropout2d(p=0.37, inplace=False)\n",
       "  (fc0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (dropout1): Dropout2d(p=0.37, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (dropout2): Dropout2d(p=0.37, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
