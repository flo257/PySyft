{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1016 16:30:33.256397 184404 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0-rc3.so'\n",
      "W1016 16:30:33.295397 184404 module_wrapper.py:139] From c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import syft as sy\n",
    "import sys\n",
    "import pdb \n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from random import shuffle\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "use_cuda = True\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker\n",
    "#chalie = sy.VirtualWorker(hook, id=\"chalie\")  # <-- NEW: define remote worker\n",
    "#dave = sy.VirtualWorker(hook, id=\"dave\")  # <-- NEW: define remote worker\n",
    "#evelyn = sy.VirtualWorker(hook, id=\"evelyn\")  # <-- NEW: define remote worker\n",
    "#frank = sy.VirtualWorker(hook, id=\"frank\")  # <-- NEW: define remote worker\n",
    "#gustav = sy.VirtualWorker(hook, id=\"gustav\")  # <-- NEW: define remote worker\n",
    "#helmut = sy.VirtualWorker(hook, id=\"helmut\")  # <-- NEW: define remote worker\n",
    "#isabella = sy.VirtualWorker(hook, id=\"isabella\")  # <-- NEW: define remote worker\n",
    "\n",
    "\n",
    "fraudulin = sy.VirtualWorker(hook, id=\"fraudulin\")\n",
    "#fraudrich = sy.VirtualWorker(hook, id=\"fraudrich\") \n",
    "\n",
    "\n",
    "compute_nodes = [alice, bob]\n",
    "frauds = [fraudulin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ColorJitter(brightness=0.3,saturation=0.3,contrast=0.3),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "trafficsign = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\yalefaces_reworked',\n",
    "                             transform=data_transform)\n",
    "\n",
    "# split into train and test dataset\n",
    "train_split = 0.8\n",
    "dataset_size = len(trafficsign) #for testing purpose set to 1000 - else set: len(trafficsign) \n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(train_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[:split], indices[split:]\n",
    "\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(trafficsign,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sampler=SubsetRandomSampler(train_indices),\n",
    "                                              **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(trafficsign,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sampler=SubsetRandomSampler(test_indices),\n",
    "                                              **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load backdoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoored = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\yalefaces_reworked_backdoors',\n",
    "                             transform=data_transform)\n",
    "\n",
    "# shorten for testing reasons\n",
    "size = len(backdoored) #for testing purpose set to 1000 - else set: len(backdoored) \n",
    "indices = list(range(len(backdoored)))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "usedIndices = indices[:size]\n",
    "\n",
    "backdoored.classes = '001' #<-- set all backdoors to a specific (wrong) class\n",
    "\n",
    "dataset_loader_backdoored = torch.utils.data.DataLoader(backdoored,\n",
    "                                             batch_size=batch_size, \n",
    "                                             sampler=SubsetRandomSampler(usedIndices),\n",
    "                                              **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let’s visualize a few training images so as to understand the data augmentations.\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "class_names = trafficsign.classes\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataset_loader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=len(class_names)):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "#http://publications.lib.chalmers.se/records/fulltext/255863/255863.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send dataset to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distributed_dataset = []\n",
    "train_distributed_dataset_backdoor = []\n",
    "\n",
    "#normal clients\n",
    "for batch_idx, (data,target) in enumerate(dataset_loader):\n",
    "            data_append = data.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            target_append = target.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "            train_distributed_dataset.append((data_append, target_append))\n",
    "      \n",
    "#backdoored clients   \n",
    "#for batch_idx, (data,target) in enumerate(dataset_loader_backdoored):\n",
    "#            data_append = data.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "#            target_append = target.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "#            train_distributed_dataset_backdoor.append((data_append, target_append))\n",
    "#            \n",
    "#shuffle list\n",
    "shuffle(train_distributed_dataset)\n",
    "shuffle(train_distributed_dataset_backdoor)\n",
    "\n",
    "#train_distributed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    #backdoor training in the beginning\n",
    "#    for batch_idx, (data,target) in enumerate(train_distributed_dataset_backdoor):        \n",
    "#        model.send(data.location) # 0) send the model to the right location\n",
    "#        data, target = data.to(device), target.to(device)\n",
    "#        optimizer.zero_grad() # 1) erase previous gradients (if they exist)\n",
    "#        #import pdb; pdb.set_trace()\n",
    "#        output = model(data)  # 2) make a prediction\n",
    "#        loss = F.nll_loss(output, target) # 3) calculate how much we missed\n",
    "#        loss.backward() # 4) figure out which weights caused us to miss\n",
    "#        optimizer.step() # 5) change those weights\n",
    "#        model.get() # 6) get model (with gradients)\n",
    "#            \n",
    "#        #if batch_idx % 100 == 0:\n",
    "#        loss = loss.get() # <-- NEW: get the loss back\n",
    "#        print('BACKDOOR: Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                epoch, batch_idx * batch_size, len(train_distributed_dataset_backdoor) * batch_size,\n",
    "#                100. * batch_idx / len(train_distributed_dataset_backdoor), loss.item()))\n",
    "    \n",
    "    #normal training\n",
    "    for batch_idx, (data,target) in enumerate(train_distributed_dataset):        \n",
    "        model.send(data.location) # 0) send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 1) erase previous gradients (if they exist)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        output = model(data)  # 2) make a prediction\n",
    "        loss = F.cross_entropy(output, target) # 3) calculate how much we missed\n",
    "        loss.backward() # 4) figure out which weights caused us to miss\n",
    "        optimizer.step() # 5) change those weights\n",
    "        model.get() # 6) get model (with gradients)\n",
    "            \n",
    "        #if batch_idx % 300 == 0:\n",
    "        loss = loss.get() # <-- NEW: get the loss back\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_distributed_dataset) * batch_size,\n",
    "                100. * batch_idx / len(train_distributed_dataset), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_indices)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_indices),\n",
    "        100. * correct / len(test_indices)))\n",
    "    \n",
    "    #confusion matrix\n",
    "    nb_classes = len(class_names)\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    print(confusion_matrix)\n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1)) per class accuracy\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everyting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for learning rate\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "Train Epoch: 1 [0/90 (0%)]\tLoss: 2.567455\n",
      "Train Epoch: 1 [10/90 (11%)]\tLoss: 2.568269\n",
      "Train Epoch: 1 [20/90 (22%)]\tLoss: 2.569427\n",
      "Train Epoch: 1 [30/90 (33%)]\tLoss: 2.562233\n",
      "Train Epoch: 1 [40/90 (44%)]\tLoss: 2.566668\n",
      "Train Epoch: 1 [50/90 (56%)]\tLoss: 2.559444\n",
      "Train Epoch: 1 [60/90 (67%)]\tLoss: 2.568007\n",
      "Train Epoch: 1 [70/90 (78%)]\tLoss: 2.556159\n",
      "Train Epoch: 1 [80/90 (89%)]\tLoss: 2.559725\n",
      "\n",
      "Test set: Average loss: 2.5681, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 2 [0/90 (0%)]\tLoss: 2.571419\n",
      "Train Epoch: 2 [10/90 (11%)]\tLoss: 2.569513\n",
      "Train Epoch: 2 [20/90 (22%)]\tLoss: 2.567606\n",
      "Train Epoch: 2 [30/90 (33%)]\tLoss: 2.563792\n",
      "Train Epoch: 2 [40/90 (44%)]\tLoss: 2.563426\n",
      "Train Epoch: 2 [50/90 (56%)]\tLoss: 2.559612\n",
      "Train Epoch: 2 [60/90 (67%)]\tLoss: 2.566469\n",
      "Train Epoch: 2 [70/90 (78%)]\tLoss: 2.558586\n",
      "Train Epoch: 2 [80/90 (89%)]\tLoss: 2.560284\n",
      "\n",
      "Test set: Average loss: 2.5692, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 3 [0/90 (0%)]\tLoss: 2.573000\n",
      "Train Epoch: 3 [10/90 (11%)]\tLoss: 2.568547\n",
      "Train Epoch: 3 [20/90 (22%)]\tLoss: 2.566059\n",
      "Train Epoch: 3 [30/90 (33%)]\tLoss: 2.562075\n",
      "Train Epoch: 3 [40/90 (44%)]\tLoss: 2.556593\n",
      "Train Epoch: 3 [50/90 (56%)]\tLoss: 2.558255\n",
      "Train Epoch: 3 [60/90 (67%)]\tLoss: 2.566852\n",
      "Train Epoch: 3 [70/90 (78%)]\tLoss: 2.556858\n",
      "Train Epoch: 3 [80/90 (89%)]\tLoss: 2.560135\n",
      "\n",
      "Test set: Average loss: 2.5701, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 4 [0/90 (0%)]\tLoss: 2.574579\n",
      "Train Epoch: 4 [10/90 (11%)]\tLoss: 2.567603\n",
      "Train Epoch: 4 [20/90 (22%)]\tLoss: 2.564561\n",
      "Train Epoch: 4 [30/90 (33%)]\tLoss: 2.560398\n",
      "Train Epoch: 4 [40/90 (44%)]\tLoss: 2.549901\n",
      "Train Epoch: 4 [50/90 (56%)]\tLoss: 2.556947\n",
      "Train Epoch: 4 [60/90 (67%)]\tLoss: 2.567235\n",
      "Train Epoch: 4 [70/90 (78%)]\tLoss: 2.555140\n",
      "Train Epoch: 4 [80/90 (89%)]\tLoss: 2.559969\n",
      "\n",
      "Test set: Average loss: 2.5717, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 5 [0/90 (0%)]\tLoss: 2.576160\n",
      "Train Epoch: 5 [10/90 (11%)]\tLoss: 2.566675\n",
      "Train Epoch: 5 [20/90 (22%)]\tLoss: 2.563091\n",
      "Train Epoch: 5 [30/90 (33%)]\tLoss: 2.558741\n",
      "Train Epoch: 5 [40/90 (44%)]\tLoss: 2.543337\n",
      "Train Epoch: 5 [50/90 (56%)]\tLoss: 2.555699\n",
      "Train Epoch: 5 [60/90 (67%)]\tLoss: 2.567640\n",
      "Train Epoch: 5 [70/90 (78%)]\tLoss: 2.553460\n",
      "Train Epoch: 5 [80/90 (89%)]\tLoss: 2.559866\n",
      "\n",
      "Test set: Average loss: 2.5723, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 6 [0/90 (0%)]\tLoss: 2.577777\n",
      "Train Epoch: 6 [10/90 (11%)]\tLoss: 2.565757\n",
      "Train Epoch: 6 [20/90 (22%)]\tLoss: 2.561640\n",
      "Train Epoch: 6 [30/90 (33%)]\tLoss: 2.557093\n",
      "Train Epoch: 6 [40/90 (44%)]\tLoss: 2.536814\n",
      "Train Epoch: 6 [50/90 (56%)]\tLoss: 2.554482\n",
      "Train Epoch: 6 [60/90 (67%)]\tLoss: 2.568063\n",
      "Train Epoch: 6 [70/90 (78%)]\tLoss: 2.551802\n",
      "Train Epoch: 6 [80/90 (89%)]\tLoss: 2.559757\n",
      "\n",
      "Test set: Average loss: 2.5740, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 7 [0/90 (0%)]\tLoss: 2.579389\n",
      "Train Epoch: 7 [10/90 (11%)]\tLoss: 2.564846\n",
      "Train Epoch: 7 [20/90 (22%)]\tLoss: 2.560208\n",
      "Train Epoch: 7 [30/90 (33%)]\tLoss: 2.555445\n",
      "Train Epoch: 7 [40/90 (44%)]\tLoss: 2.530310\n",
      "Train Epoch: 7 [50/90 (56%)]\tLoss: 2.553277\n",
      "Train Epoch: 7 [60/90 (67%)]\tLoss: 2.568478\n",
      "Train Epoch: 7 [70/90 (78%)]\tLoss: 2.550136\n",
      "Train Epoch: 7 [80/90 (89%)]\tLoss: 2.559625\n",
      "\n",
      "Test set: Average loss: 2.5748, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 8 [0/90 (0%)]\tLoss: 2.581028\n",
      "Train Epoch: 8 [10/90 (11%)]\tLoss: 2.563941\n",
      "Train Epoch: 8 [20/90 (22%)]\tLoss: 2.558786\n",
      "Train Epoch: 8 [30/90 (33%)]\tLoss: 2.553795\n",
      "Train Epoch: 8 [40/90 (44%)]\tLoss: 2.523843\n",
      "Train Epoch: 8 [50/90 (56%)]\tLoss: 2.552046\n",
      "Train Epoch: 8 [60/90 (67%)]\tLoss: 2.568906\n",
      "Train Epoch: 8 [70/90 (78%)]\tLoss: 2.548479\n",
      "Train Epoch: 8 [80/90 (89%)]\tLoss: 2.559466\n",
      "\n",
      "Test set: Average loss: 2.5765, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 9 [0/90 (0%)]\tLoss: 2.582711\n",
      "Train Epoch: 9 [10/90 (11%)]\tLoss: 2.563031\n",
      "Train Epoch: 9 [20/90 (22%)]\tLoss: 2.557357\n",
      "Train Epoch: 9 [30/90 (33%)]\tLoss: 2.552134\n",
      "Train Epoch: 9 [40/90 (44%)]\tLoss: 2.517335\n",
      "Train Epoch: 9 [50/90 (56%)]\tLoss: 2.550799\n",
      "Train Epoch: 9 [60/90 (67%)]\tLoss: 2.569348\n",
      "Train Epoch: 9 [70/90 (78%)]\tLoss: 2.546829\n",
      "Train Epoch: 9 [80/90 (89%)]\tLoss: 2.559282\n",
      "\n",
      "Test set: Average loss: 2.5784, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 10 [0/90 (0%)]\tLoss: 2.584430\n",
      "Train Epoch: 10 [10/90 (11%)]\tLoss: 2.562113\n",
      "Train Epoch: 10 [20/90 (22%)]\tLoss: 2.555897\n",
      "Train Epoch: 10 [30/90 (33%)]\tLoss: 2.550438\n",
      "Train Epoch: 10 [40/90 (44%)]\tLoss: 2.510844\n",
      "Train Epoch: 10 [50/90 (56%)]\tLoss: 2.549558\n",
      "Train Epoch: 10 [60/90 (67%)]\tLoss: 2.569777\n",
      "Train Epoch: 10 [70/90 (78%)]\tLoss: 2.545133\n",
      "Train Epoch: 10 [80/90 (89%)]\tLoss: 2.559040\n",
      "\n",
      "Test set: Average loss: 2.5788, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 11 [0/90 (0%)]\tLoss: 2.586172\n",
      "Train Epoch: 11 [10/90 (11%)]\tLoss: 2.561197\n",
      "Train Epoch: 11 [20/90 (22%)]\tLoss: 2.554445\n",
      "Train Epoch: 11 [30/90 (33%)]\tLoss: 2.548714\n",
      "Train Epoch: 11 [40/90 (44%)]\tLoss: 2.504329\n",
      "Train Epoch: 11 [50/90 (56%)]\tLoss: 2.548284\n",
      "Train Epoch: 11 [60/90 (67%)]\tLoss: 2.570180\n",
      "Train Epoch: 11 [70/90 (78%)]\tLoss: 2.543403\n",
      "Train Epoch: 11 [80/90 (89%)]\tLoss: 2.558733\n",
      "\n",
      "Test set: Average loss: 2.5798, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 12 [0/90 (0%)]\tLoss: 2.587950\n",
      "Train Epoch: 12 [10/90 (11%)]\tLoss: 2.560255\n",
      "Train Epoch: 12 [20/90 (22%)]\tLoss: 2.552991\n",
      "Train Epoch: 12 [30/90 (33%)]\tLoss: 2.546939\n",
      "Train Epoch: 12 [40/90 (44%)]\tLoss: 2.497735\n",
      "Train Epoch: 12 [50/90 (56%)]\tLoss: 2.546985\n",
      "Train Epoch: 12 [60/90 (67%)]\tLoss: 2.570593\n",
      "Train Epoch: 12 [70/90 (78%)]\tLoss: 2.541606\n",
      "Train Epoch: 12 [80/90 (89%)]\tLoss: 2.558378\n",
      "\n",
      "Test set: Average loss: 2.5824, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 13 [0/90 (0%)]\tLoss: 2.589801\n",
      "Train Epoch: 13 [10/90 (11%)]\tLoss: 2.559297\n",
      "Train Epoch: 13 [20/90 (22%)]\tLoss: 2.551477\n",
      "Train Epoch: 13 [30/90 (33%)]\tLoss: 2.545130\n",
      "Train Epoch: 13 [40/90 (44%)]\tLoss: 2.491016\n",
      "Train Epoch: 13 [50/90 (56%)]\tLoss: 2.545639\n",
      "Train Epoch: 13 [60/90 (67%)]\tLoss: 2.570992\n",
      "Train Epoch: 13 [70/90 (78%)]\tLoss: 2.539733\n",
      "Train Epoch: 13 [80/90 (89%)]\tLoss: 2.557962\n",
      "\n",
      "Test set: Average loss: 2.5812, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 14 [0/90 (0%)]\tLoss: 2.591694\n",
      "Train Epoch: 14 [10/90 (11%)]\tLoss: 2.558313\n",
      "Train Epoch: 14 [20/90 (22%)]\tLoss: 2.549918\n",
      "Train Epoch: 14 [30/90 (33%)]\tLoss: 2.543250\n",
      "Train Epoch: 14 [40/90 (44%)]\tLoss: 2.484173\n",
      "Train Epoch: 14 [50/90 (56%)]\tLoss: 2.544255\n",
      "Train Epoch: 14 [60/90 (67%)]\tLoss: 2.571365\n",
      "Train Epoch: 14 [70/90 (78%)]\tLoss: 2.537792\n",
      "Train Epoch: 14 [80/90 (89%)]\tLoss: 2.557412\n",
      "\n",
      "Test set: Average loss: 2.5825, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 15 [0/90 (0%)]\tLoss: 2.593675\n",
      "Train Epoch: 15 [10/90 (11%)]\tLoss: 2.557310\n",
      "Train Epoch: 15 [20/90 (22%)]\tLoss: 2.548322\n",
      "Train Epoch: 15 [30/90 (33%)]\tLoss: 2.541314\n",
      "Train Epoch: 15 [40/90 (44%)]\tLoss: 2.477158\n",
      "Train Epoch: 15 [50/90 (56%)]\tLoss: 2.542810\n",
      "Train Epoch: 15 [60/90 (67%)]\tLoss: 2.571685\n",
      "Train Epoch: 15 [70/90 (78%)]\tLoss: 2.535715\n",
      "Train Epoch: 15 [80/90 (89%)]\tLoss: 2.556672\n",
      "\n",
      "Test set: Average loss: 2.5833, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 16 [0/90 (0%)]\tLoss: 2.595744\n",
      "Train Epoch: 16 [10/90 (11%)]\tLoss: 2.556264\n",
      "Train Epoch: 16 [20/90 (22%)]\tLoss: 2.546663\n",
      "Train Epoch: 16 [30/90 (33%)]\tLoss: 2.539236\n",
      "Train Epoch: 16 [40/90 (44%)]\tLoss: 2.469900\n",
      "Train Epoch: 16 [50/90 (56%)]\tLoss: 2.541241\n",
      "Train Epoch: 16 [60/90 (67%)]\tLoss: 2.572002\n",
      "Train Epoch: 16 [70/90 (78%)]\tLoss: 2.533467\n",
      "Train Epoch: 16 [80/90 (89%)]\tLoss: 2.555807\n",
      "\n",
      "Test set: Average loss: 2.5832, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 17 [0/90 (0%)]\tLoss: 2.597853\n",
      "Train Epoch: 17 [10/90 (11%)]\tLoss: 2.555187\n",
      "Train Epoch: 17 [20/90 (22%)]\tLoss: 2.544929\n",
      "Train Epoch: 17 [30/90 (33%)]\tLoss: 2.537041\n",
      "Train Epoch: 17 [40/90 (44%)]\tLoss: 2.462423\n",
      "Train Epoch: 17 [50/90 (56%)]\tLoss: 2.539573\n",
      "Train Epoch: 17 [60/90 (67%)]\tLoss: 2.572297\n",
      "Train Epoch: 17 [70/90 (78%)]\tLoss: 2.531094\n",
      "Train Epoch: 17 [80/90 (89%)]\tLoss: 2.554813\n",
      "\n",
      "Test set: Average loss: 2.5886, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 18 [0/90 (0%)]\tLoss: 2.600046\n",
      "Train Epoch: 18 [10/90 (11%)]\tLoss: 2.554064\n",
      "Train Epoch: 18 [20/90 (22%)]\tLoss: 2.543073\n",
      "Train Epoch: 18 [30/90 (33%)]\tLoss: 2.534709\n",
      "Train Epoch: 18 [40/90 (44%)]\tLoss: 2.454547\n",
      "Train Epoch: 18 [50/90 (56%)]\tLoss: 2.537802\n",
      "Train Epoch: 18 [60/90 (67%)]\tLoss: 2.572591\n",
      "Train Epoch: 18 [70/90 (78%)]\tLoss: 2.528543\n",
      "Train Epoch: 18 [80/90 (89%)]\tLoss: 2.553584\n",
      "\n",
      "Test set: Average loss: 2.5884, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 19 [0/90 (0%)]\tLoss: 2.602366\n",
      "Train Epoch: 19 [10/90 (11%)]\tLoss: 2.552875\n",
      "Train Epoch: 19 [20/90 (22%)]\tLoss: 2.541108\n",
      "Train Epoch: 19 [30/90 (33%)]\tLoss: 2.532224\n",
      "Train Epoch: 19 [40/90 (44%)]\tLoss: 2.446301\n",
      "Train Epoch: 19 [50/90 (56%)]\tLoss: 2.535900\n",
      "Train Epoch: 19 [60/90 (67%)]\tLoss: 2.572835\n",
      "Train Epoch: 19 [70/90 (78%)]\tLoss: 2.525723\n",
      "Train Epoch: 19 [80/90 (89%)]\tLoss: 2.552128\n",
      "\n",
      "Test set: Average loss: 2.5878, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 20 [0/90 (0%)]\tLoss: 2.604877\n",
      "Train Epoch: 20 [10/90 (11%)]\tLoss: 2.551622\n",
      "Train Epoch: 20 [20/90 (22%)]\tLoss: 2.538946\n",
      "Train Epoch: 20 [30/90 (33%)]\tLoss: 2.529526\n",
      "Train Epoch: 20 [40/90 (44%)]\tLoss: 2.437475\n",
      "Train Epoch: 20 [50/90 (56%)]\tLoss: 2.533745\n",
      "Train Epoch: 20 [60/90 (67%)]\tLoss: 2.573046\n",
      "Train Epoch: 20 [70/90 (78%)]\tLoss: 2.522511\n",
      "Train Epoch: 20 [80/90 (89%)]\tLoss: 2.550262\n",
      "\n",
      "Test set: Average loss: 2.5936, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 21 [0/90 (0%)]\tLoss: 2.607610\n",
      "Train Epoch: 21 [10/90 (11%)]\tLoss: 2.550308\n",
      "Train Epoch: 21 [20/90 (22%)]\tLoss: 2.536546\n",
      "Train Epoch: 21 [30/90 (33%)]\tLoss: 2.526562\n",
      "Train Epoch: 21 [40/90 (44%)]\tLoss: 2.428022\n",
      "Train Epoch: 21 [50/90 (56%)]\tLoss: 2.531375\n",
      "Train Epoch: 21 [60/90 (67%)]\tLoss: 2.573250\n",
      "Train Epoch: 21 [70/90 (78%)]\tLoss: 2.518850\n",
      "Train Epoch: 21 [80/90 (89%)]\tLoss: 2.548004\n",
      "\n",
      "Test set: Average loss: 2.5938, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 22 [0/90 (0%)]\tLoss: 2.610657\n",
      "Train Epoch: 22 [10/90 (11%)]\tLoss: 2.548877\n",
      "Train Epoch: 22 [20/90 (22%)]\tLoss: 2.533879\n",
      "Train Epoch: 22 [30/90 (33%)]\tLoss: 2.523245\n",
      "Train Epoch: 22 [40/90 (44%)]\tLoss: 2.417642\n",
      "Train Epoch: 22 [50/90 (56%)]\tLoss: 2.528598\n",
      "Train Epoch: 22 [60/90 (67%)]\tLoss: 2.573372\n",
      "Train Epoch: 22 [70/90 (78%)]\tLoss: 2.514629\n",
      "Train Epoch: 22 [80/90 (89%)]\tLoss: 2.545228\n",
      "\n",
      "Test set: Average loss: 2.5998, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 23 [0/90 (0%)]\tLoss: 2.614050\n",
      "Train Epoch: 23 [10/90 (11%)]\tLoss: 2.547341\n",
      "Train Epoch: 23 [20/90 (22%)]\tLoss: 2.530904\n",
      "Train Epoch: 23 [30/90 (33%)]\tLoss: 2.519432\n",
      "Train Epoch: 23 [40/90 (44%)]\tLoss: 2.406116\n",
      "Train Epoch: 23 [50/90 (56%)]\tLoss: 2.525528\n",
      "Train Epoch: 23 [60/90 (67%)]\tLoss: 2.573463\n",
      "Train Epoch: 23 [70/90 (78%)]\tLoss: 2.509660\n",
      "Train Epoch: 23 [80/90 (89%)]\tLoss: 2.541658\n",
      "\n",
      "Test set: Average loss: 2.5975, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 24 [0/90 (0%)]\tLoss: 2.617992\n",
      "Train Epoch: 24 [10/90 (11%)]\tLoss: 2.545537\n",
      "Train Epoch: 24 [20/90 (22%)]\tLoss: 2.527451\n",
      "Train Epoch: 24 [30/90 (33%)]\tLoss: 2.514870\n",
      "Train Epoch: 24 [40/90 (44%)]\tLoss: 2.392856\n",
      "Train Epoch: 24 [50/90 (56%)]\tLoss: 2.521820\n",
      "Train Epoch: 24 [60/90 (67%)]\tLoss: 2.573490\n",
      "Train Epoch: 24 [70/90 (78%)]\tLoss: 2.503691\n",
      "Train Epoch: 24 [80/90 (89%)]\tLoss: 2.536982\n",
      "\n",
      "Test set: Average loss: 2.6081, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 25 [0/90 (0%)]\tLoss: 2.622650\n",
      "Train Epoch: 25 [10/90 (11%)]\tLoss: 2.543423\n",
      "Train Epoch: 25 [20/90 (22%)]\tLoss: 2.523435\n",
      "Train Epoch: 25 [30/90 (33%)]\tLoss: 2.509395\n",
      "Train Epoch: 25 [40/90 (44%)]\tLoss: 2.377316\n",
      "Train Epoch: 25 [50/90 (56%)]\tLoss: 2.517228\n",
      "Train Epoch: 25 [60/90 (67%)]\tLoss: 2.573416\n",
      "Train Epoch: 25 [70/90 (78%)]\tLoss: 2.496222\n",
      "Train Epoch: 25 [80/90 (89%)]\tLoss: 2.530622\n",
      "\n",
      "Test set: Average loss: 2.6029, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 26 [0/90 (0%)]\tLoss: 2.628526\n",
      "Train Epoch: 26 [10/90 (11%)]\tLoss: 2.540964\n",
      "Train Epoch: 26 [20/90 (22%)]\tLoss: 2.518522\n",
      "Train Epoch: 26 [30/90 (33%)]\tLoss: 2.502616\n",
      "Train Epoch: 26 [40/90 (44%)]\tLoss: 2.358648\n",
      "Train Epoch: 26 [50/90 (56%)]\tLoss: 2.511431\n",
      "Train Epoch: 26 [60/90 (67%)]\tLoss: 2.573147\n",
      "Train Epoch: 26 [70/90 (78%)]\tLoss: 2.486803\n",
      "Train Epoch: 26 [80/90 (89%)]\tLoss: 2.521970\n",
      "\n",
      "Test set: Average loss: 2.6084, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 27 [0/90 (0%)]\tLoss: 2.635894\n",
      "Train Epoch: 27 [10/90 (11%)]\tLoss: 2.538047\n",
      "Train Epoch: 27 [20/90 (22%)]\tLoss: 2.512406\n",
      "Train Epoch: 27 [30/90 (33%)]\tLoss: 2.494082\n",
      "Train Epoch: 27 [40/90 (44%)]\tLoss: 2.335927\n",
      "Train Epoch: 27 [50/90 (56%)]\tLoss: 2.504240\n",
      "Train Epoch: 27 [60/90 (67%)]\tLoss: 2.572861\n",
      "Train Epoch: 27 [70/90 (78%)]\tLoss: 2.474597\n",
      "Train Epoch: 27 [80/90 (89%)]\tLoss: 2.510312\n",
      "\n",
      "Test set: Average loss: 2.6041, Accuracy: 2/21 (10%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 28 [0/90 (0%)]\tLoss: 2.645330\n",
      "Train Epoch: 28 [10/90 (11%)]\tLoss: 2.534484\n",
      "Train Epoch: 28 [20/90 (22%)]\tLoss: 2.504560\n",
      "Train Epoch: 28 [30/90 (33%)]\tLoss: 2.483087\n",
      "Train Epoch: 28 [40/90 (44%)]\tLoss: 2.307376\n",
      "Train Epoch: 28 [50/90 (56%)]\tLoss: 2.494660\n",
      "Train Epoch: 28 [60/90 (67%)]\tLoss: 2.572299\n",
      "Train Epoch: 28 [70/90 (78%)]\tLoss: 2.458243\n",
      "Train Epoch: 28 [80/90 (89%)]\tLoss: 2.493984\n",
      "\n",
      "Test set: Average loss: 2.6109, Accuracy: 2/21 (10%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 29 [0/90 (0%)]\tLoss: 2.657942\n",
      "Train Epoch: 29 [10/90 (11%)]\tLoss: 2.530098\n",
      "Train Epoch: 29 [20/90 (22%)]\tLoss: 2.494430\n",
      "Train Epoch: 29 [30/90 (33%)]\tLoss: 2.468738\n",
      "Train Epoch: 29 [40/90 (44%)]\tLoss: 2.271067\n",
      "Train Epoch: 29 [50/90 (56%)]\tLoss: 2.482260\n",
      "Train Epoch: 29 [60/90 (67%)]\tLoss: 2.571431\n",
      "Train Epoch: 29 [70/90 (78%)]\tLoss: 2.436426\n",
      "Train Epoch: 29 [80/90 (89%)]\tLoss: 2.470413\n",
      "\n",
      "Test set: Average loss: 2.6548, Accuracy: 3/21 (14%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 30 [0/90 (0%)]\tLoss: 2.673967\n",
      "Train Epoch: 30 [10/90 (11%)]\tLoss: 2.524469\n",
      "Train Epoch: 30 [20/90 (22%)]\tLoss: 2.480847\n",
      "Train Epoch: 30 [30/90 (33%)]\tLoss: 2.449657\n",
      "Train Epoch: 30 [40/90 (44%)]\tLoss: 2.224853\n",
      "Train Epoch: 30 [50/90 (56%)]\tLoss: 2.466424\n",
      "Train Epoch: 30 [60/90 (67%)]\tLoss: 2.569171\n",
      "Train Epoch: 30 [70/90 (78%)]\tLoss: 2.406368\n",
      "Train Epoch: 30 [80/90 (89%)]\tLoss: 2.435447\n",
      "\n",
      "Test set: Average loss: 2.6716, Accuracy: 3/21 (14%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 31 [0/90 (0%)]\tLoss: 2.692544\n",
      "Train Epoch: 31 [10/90 (11%)]\tLoss: 2.516139\n",
      "Train Epoch: 31 [20/90 (22%)]\tLoss: 2.461308\n",
      "Train Epoch: 31 [30/90 (33%)]\tLoss: 2.423699\n",
      "Train Epoch: 31 [40/90 (44%)]\tLoss: 2.166168\n",
      "Train Epoch: 31 [50/90 (56%)]\tLoss: 2.446147\n",
      "Train Epoch: 31 [60/90 (67%)]\tLoss: 2.564958\n",
      "Train Epoch: 31 [70/90 (78%)]\tLoss: 2.365612\n",
      "Train Epoch: 31 [80/90 (89%)]\tLoss: 2.385146\n",
      "\n",
      "Test set: Average loss: 2.6804, Accuracy: 3/21 (14%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 32 [0/90 (0%)]\tLoss: 2.709115\n",
      "Train Epoch: 32 [10/90 (11%)]\tLoss: 2.502156\n",
      "Train Epoch: 32 [20/90 (22%)]\tLoss: 2.432463\n",
      "Train Epoch: 32 [30/90 (33%)]\tLoss: 2.386844\n",
      "Train Epoch: 32 [40/90 (44%)]\tLoss: 2.087250\n",
      "Train Epoch: 32 [50/90 (56%)]\tLoss: 2.421989\n",
      "Train Epoch: 32 [60/90 (67%)]\tLoss: 2.554850\n",
      "Train Epoch: 32 [70/90 (78%)]\tLoss: 2.307158\n",
      "Train Epoch: 32 [80/90 (89%)]\tLoss: 2.307473\n",
      "\n",
      "Test set: Average loss: 2.6812, Accuracy: 2/21 (10%)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 33 [0/90 (0%)]\tLoss: 2.715342\n",
      "Train Epoch: 33 [10/90 (11%)]\tLoss: 2.473999\n",
      "Train Epoch: 33 [20/90 (22%)]\tLoss: 2.384583\n",
      "Train Epoch: 33 [30/90 (33%)]\tLoss: 2.329460\n",
      "Train Epoch: 33 [40/90 (44%)]\tLoss: 1.969731\n",
      "Train Epoch: 33 [50/90 (56%)]\tLoss: 2.392502\n",
      "Train Epoch: 33 [60/90 (67%)]\tLoss: 2.537332\n",
      "Train Epoch: 33 [70/90 (78%)]\tLoss: 2.218490\n",
      "Train Epoch: 33 [80/90 (89%)]\tLoss: 2.184797\n",
      "\n",
      "Test set: Average loss: 2.7327, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 34 [0/90 (0%)]\tLoss: 2.694112\n",
      "Train Epoch: 34 [10/90 (11%)]\tLoss: 2.412366\n",
      "Train Epoch: 34 [20/90 (22%)]\tLoss: 2.300223\n",
      "Train Epoch: 34 [30/90 (33%)]\tLoss: 2.230979\n",
      "Train Epoch: 34 [40/90 (44%)]\tLoss: 1.777389\n",
      "Train Epoch: 34 [50/90 (56%)]\tLoss: 2.373989\n",
      "Train Epoch: 34 [60/90 (67%)]\tLoss: 2.500046\n",
      "Train Epoch: 34 [70/90 (78%)]\tLoss: 2.090881\n",
      "Train Epoch: 34 [80/90 (89%)]\tLoss: 1.997199\n",
      "\n",
      "Test set: Average loss: 2.5638, Accuracy: 3/21 (14%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 35 [0/90 (0%)]\tLoss: 2.635181\n",
      "Train Epoch: 35 [10/90 (11%)]\tLoss: 2.298318\n",
      "Train Epoch: 35 [20/90 (22%)]\tLoss: 2.170968\n",
      "Train Epoch: 35 [30/90 (33%)]\tLoss: 2.082561\n",
      "Train Epoch: 35 [40/90 (44%)]\tLoss: 1.521621\n",
      "Train Epoch: 35 [50/90 (56%)]\tLoss: 2.364786\n",
      "Train Epoch: 35 [60/90 (67%)]\tLoss: 2.413455\n",
      "Train Epoch: 35 [70/90 (78%)]\tLoss: 1.970722\n",
      "Train Epoch: 35 [80/90 (89%)]\tLoss: 1.799952\n",
      "\n",
      "Test set: Average loss: 2.6529, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 36 [0/90 (0%)]\tLoss: 2.508637\n",
      "Train Epoch: 36 [10/90 (11%)]\tLoss: 2.163149\n",
      "Train Epoch: 36 [20/90 (22%)]\tLoss: 2.010265\n",
      "Train Epoch: 36 [30/90 (33%)]\tLoss: 1.928103\n",
      "Train Epoch: 36 [40/90 (44%)]\tLoss: 1.272538\n",
      "Train Epoch: 36 [50/90 (56%)]\tLoss: 2.281326\n",
      "Train Epoch: 36 [60/90 (67%)]\tLoss: 2.375598\n",
      "Train Epoch: 36 [70/90 (78%)]\tLoss: 1.925548\n",
      "Train Epoch: 36 [80/90 (89%)]\tLoss: 1.678620\n",
      "\n",
      "Test set: Average loss: 2.6882, Accuracy: 1/21 (5%)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 37 [0/90 (0%)]\tLoss: 2.321092\n",
      "Train Epoch: 37 [10/90 (11%)]\tLoss: 2.027871\n",
      "Train Epoch: 37 [20/90 (22%)]\tLoss: 1.761426\n",
      "Train Epoch: 37 [30/90 (33%)]\tLoss: 1.748568\n",
      "Train Epoch: 37 [40/90 (44%)]\tLoss: 0.955853\n",
      "Train Epoch: 37 [50/90 (56%)]\tLoss: 2.013251\n",
      "Train Epoch: 37 [60/90 (67%)]\tLoss: 2.397701\n",
      "Train Epoch: 37 [70/90 (78%)]\tLoss: 1.944277\n",
      "Train Epoch: 37 [80/90 (89%)]\tLoss: 1.684331\n",
      "\n",
      "Test set: Average loss: 2.5067, Accuracy: 5/21 (24%)\n",
      "\n",
      "tensor([[0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 38 [0/90 (0%)]\tLoss: 2.095989\n",
      "Train Epoch: 38 [10/90 (11%)]\tLoss: 1.891359\n",
      "Train Epoch: 38 [20/90 (22%)]\tLoss: 1.468698\n",
      "Train Epoch: 38 [30/90 (33%)]\tLoss: 1.568963\n",
      "Train Epoch: 38 [40/90 (44%)]\tLoss: 0.705588\n",
      "Train Epoch: 38 [50/90 (56%)]\tLoss: 1.661903\n",
      "Train Epoch: 38 [60/90 (67%)]\tLoss: 2.285151\n",
      "Train Epoch: 38 [70/90 (78%)]\tLoss: 1.901228\n",
      "Train Epoch: 38 [80/90 (89%)]\tLoss: 1.564979\n",
      "\n",
      "Test set: Average loss: 2.1641, Accuracy: 5/21 (24%)\n",
      "\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 39 [0/90 (0%)]\tLoss: 1.876880\n",
      "Train Epoch: 39 [10/90 (11%)]\tLoss: 1.725481\n",
      "Train Epoch: 39 [20/90 (22%)]\tLoss: 1.197570\n",
      "Train Epoch: 39 [30/90 (33%)]\tLoss: 1.467910\n",
      "Train Epoch: 39 [40/90 (44%)]\tLoss: 0.541924\n",
      "Train Epoch: 39 [50/90 (56%)]\tLoss: 1.412925\n",
      "Train Epoch: 39 [60/90 (67%)]\tLoss: 1.909268\n",
      "Train Epoch: 39 [70/90 (78%)]\tLoss: 1.565838\n",
      "Train Epoch: 39 [80/90 (89%)]\tLoss: 1.482671\n",
      "\n",
      "Test set: Average loss: 2.8338, Accuracy: 4/21 (19%)\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 40 [0/90 (0%)]\tLoss: 1.625170\n",
      "Train Epoch: 40 [10/90 (11%)]\tLoss: 1.509070\n",
      "Train Epoch: 40 [20/90 (22%)]\tLoss: 1.086496\n",
      "Train Epoch: 40 [30/90 (33%)]\tLoss: 1.372143\n",
      "Train Epoch: 40 [40/90 (44%)]\tLoss: 0.387705\n",
      "Train Epoch: 40 [50/90 (56%)]\tLoss: 1.151480\n",
      "Train Epoch: 40 [60/90 (67%)]\tLoss: 1.393911\n",
      "Train Epoch: 40 [70/90 (78%)]\tLoss: 1.496215\n",
      "Train Epoch: 40 [80/90 (89%)]\tLoss: 2.085121\n",
      "\n",
      "Test set: Average loss: 2.2605, Accuracy: 5/21 (24%)\n",
      "\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 41 [0/90 (0%)]\tLoss: 1.757992\n",
      "Train Epoch: 41 [10/90 (11%)]\tLoss: 1.416150\n",
      "Train Epoch: 41 [20/90 (22%)]\tLoss: 1.083515\n",
      "Train Epoch: 41 [30/90 (33%)]\tLoss: 1.243327\n",
      "Train Epoch: 41 [40/90 (44%)]\tLoss: 0.342739\n",
      "Train Epoch: 41 [50/90 (56%)]\tLoss: 0.964160\n",
      "Train Epoch: 41 [60/90 (67%)]\tLoss: 1.335447\n",
      "Train Epoch: 41 [70/90 (78%)]\tLoss: 1.383533\n",
      "Train Epoch: 41 [80/90 (89%)]\tLoss: 1.225352\n",
      "\n",
      "Test set: Average loss: 2.5840, Accuracy: 7/21 (33%)\n",
      "\n",
      "tensor([[0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 42 [0/90 (0%)]\tLoss: 1.302392\n",
      "Train Epoch: 42 [10/90 (11%)]\tLoss: 1.279064\n",
      "Train Epoch: 42 [20/90 (22%)]\tLoss: 0.660144\n",
      "Train Epoch: 42 [30/90 (33%)]\tLoss: 1.105921\n",
      "Train Epoch: 42 [40/90 (44%)]\tLoss: 0.155690\n",
      "Train Epoch: 42 [50/90 (56%)]\tLoss: 1.107692\n",
      "Train Epoch: 42 [60/90 (67%)]\tLoss: 1.145259\n",
      "Train Epoch: 42 [70/90 (78%)]\tLoss: 1.100698\n",
      "Train Epoch: 42 [80/90 (89%)]\tLoss: 0.988361\n",
      "\n",
      "Test set: Average loss: 2.3888, Accuracy: 7/21 (33%)\n",
      "\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 43 [0/90 (0%)]\tLoss: 1.494141\n",
      "Train Epoch: 43 [10/90 (11%)]\tLoss: 1.002428\n",
      "Train Epoch: 43 [20/90 (22%)]\tLoss: 0.499649\n",
      "Train Epoch: 43 [30/90 (33%)]\tLoss: 1.069449\n",
      "Train Epoch: 43 [40/90 (44%)]\tLoss: 0.104580\n",
      "Train Epoch: 43 [50/90 (56%)]\tLoss: 0.938845\n",
      "Train Epoch: 43 [60/90 (67%)]\tLoss: 0.787347\n",
      "Train Epoch: 43 [70/90 (78%)]\tLoss: 0.864112\n",
      "Train Epoch: 43 [80/90 (89%)]\tLoss: 0.841168\n",
      "\n",
      "Test set: Average loss: 3.3274, Accuracy: 8/21 (38%)\n",
      "\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 44 [0/90 (0%)]\tLoss: 1.188966\n",
      "Train Epoch: 44 [10/90 (11%)]\tLoss: 1.071973\n",
      "Train Epoch: 44 [20/90 (22%)]\tLoss: 0.515615\n",
      "Train Epoch: 44 [30/90 (33%)]\tLoss: 1.030968\n",
      "Train Epoch: 44 [40/90 (44%)]\tLoss: 0.165025\n",
      "Train Epoch: 44 [50/90 (56%)]\tLoss: 0.880230\n",
      "Train Epoch: 44 [60/90 (67%)]\tLoss: 0.814498\n",
      "Train Epoch: 44 [70/90 (78%)]\tLoss: 0.728243\n",
      "Train Epoch: 44 [80/90 (89%)]\tLoss: 0.481605\n",
      "\n",
      "Test set: Average loss: 1.1267, Accuracy: 14/21 (67%)\n",
      "\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "0.01\n",
      "Train Epoch: 45 [0/90 (0%)]\tLoss: 0.947957\n",
      "Train Epoch: 45 [10/90 (11%)]\tLoss: 0.691790\n",
      "Train Epoch: 45 [20/90 (22%)]\tLoss: 0.325163\n",
      "Train Epoch: 45 [30/90 (33%)]\tLoss: 1.401784\n",
      "Train Epoch: 45 [40/90 (44%)]\tLoss: 0.643468\n",
      "Train Epoch: 45 [50/90 (56%)]\tLoss: 2.172441\n",
      "Train Epoch: 45 [60/90 (67%)]\tLoss: 2.459496\n",
      "Train Epoch: 45 [70/90 (78%)]\tLoss: 1.863260\n",
      "Train Epoch: 45 [80/90 (89%)]\tLoss: 0.790858\n",
      "\n",
      "Test set: Average loss: 1.7668, Accuracy: 13/21 (62%)\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "0.01\n",
      "Train Epoch: 46 [0/90 (0%)]\tLoss: 1.139547\n",
      "Train Epoch: 46 [10/90 (11%)]\tLoss: 0.848567\n",
      "Train Epoch: 46 [20/90 (22%)]\tLoss: 0.542608\n",
      "Train Epoch: 46 [30/90 (33%)]\tLoss: 0.865909\n",
      "Train Epoch: 46 [40/90 (44%)]\tLoss: 0.076195\n",
      "Train Epoch: 46 [50/90 (56%)]\tLoss: 0.836271\n",
      "Train Epoch: 46 [60/90 (67%)]\tLoss: 0.618593\n",
      "Train Epoch: 46 [70/90 (78%)]\tLoss: 0.769362\n",
      "Train Epoch: 46 [80/90 (89%)]\tLoss: 0.324778\n",
      "\n",
      "Test set: Average loss: 2.6616, Accuracy: 11/21 (52%)\n",
      "\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "0.01\n",
      "Train Epoch: 47 [0/90 (0%)]\tLoss: 0.793567\n",
      "Train Epoch: 47 [10/90 (11%)]\tLoss: 0.335332\n",
      "Train Epoch: 47 [20/90 (22%)]\tLoss: 0.222130\n",
      "Train Epoch: 47 [30/90 (33%)]\tLoss: 0.921860\n",
      "Train Epoch: 47 [40/90 (44%)]\tLoss: 0.022226\n",
      "Train Epoch: 47 [50/90 (56%)]\tLoss: 1.099016\n",
      "Train Epoch: 47 [60/90 (67%)]\tLoss: 0.978203\n",
      "Train Epoch: 47 [70/90 (78%)]\tLoss: 0.735064\n",
      "Train Epoch: 47 [80/90 (89%)]\tLoss: 0.355368\n",
      "\n",
      "Test set: Average loss: 2.1354, Accuracy: 14/21 (67%)\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])\n",
      "0.01\n",
      "Train Epoch: 48 [0/90 (0%)]\tLoss: 0.640124\n",
      "Train Epoch: 48 [10/90 (11%)]\tLoss: 0.349283\n",
      "Train Epoch: 48 [20/90 (22%)]\tLoss: 0.187751\n",
      "Train Epoch: 48 [30/90 (33%)]\tLoss: 0.563938\n",
      "Train Epoch: 48 [40/90 (44%)]\tLoss: 0.009634\n",
      "Train Epoch: 48 [50/90 (56%)]\tLoss: 0.447377\n",
      "Train Epoch: 48 [60/90 (67%)]\tLoss: 0.718440\n",
      "Train Epoch: 48 [70/90 (78%)]\tLoss: 0.621992\n",
      "Train Epoch: 48 [80/90 (89%)]\tLoss: 0.294763\n",
      "\n",
      "Test set: Average loss: 3.3094, Accuracy: 11/21 (52%)\n",
      "\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])\n",
      "0.01\n",
      "Train Epoch: 49 [0/90 (0%)]\tLoss: 0.349830\n",
      "Train Epoch: 49 [10/90 (11%)]\tLoss: 0.190009\n",
      "Train Epoch: 49 [20/90 (22%)]\tLoss: 0.139538\n",
      "Train Epoch: 49 [30/90 (33%)]\tLoss: 0.395522\n",
      "Train Epoch: 49 [40/90 (44%)]\tLoss: 0.290925\n",
      "Train Epoch: 49 [50/90 (56%)]\tLoss: 1.160062\n",
      "Train Epoch: 49 [60/90 (67%)]\tLoss: 3.847610\n",
      "Train Epoch: 49 [70/90 (78%)]\tLoss: 2.042631\n",
      "Train Epoch: 49 [80/90 (89%)]\tLoss: 0.531599\n",
      "\n",
      "Test set: Average loss: 2.1677, Accuracy: 8/21 (38%)\n",
      "\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])\n",
      "0.01\n",
      "Train Epoch: 50 [0/90 (0%)]\tLoss: 1.313269\n",
      "Train Epoch: 50 [10/90 (11%)]\tLoss: 0.866489\n",
      "Train Epoch: 50 [20/90 (22%)]\tLoss: 0.711494\n",
      "Train Epoch: 50 [30/90 (33%)]\tLoss: 0.733717\n",
      "Train Epoch: 50 [40/90 (44%)]\tLoss: 0.056511\n",
      "Train Epoch: 50 [50/90 (56%)]\tLoss: 0.731433\n",
      "Train Epoch: 50 [60/90 (67%)]\tLoss: 0.586560\n",
      "Train Epoch: 50 [70/90 (78%)]\tLoss: 0.545820\n",
      "Train Epoch: 50 [80/90 (89%)]\tLoss: 0.218503\n",
      "\n",
      "Test set: Average loss: 1.1049, Accuracy: 16/21 (76%)\n",
      "\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "0.01\n",
      "Train Epoch: 51 [0/90 (0%)]\tLoss: 0.413146\n",
      "Train Epoch: 51 [10/90 (11%)]\tLoss: 0.233053\n",
      "Train Epoch: 51 [20/90 (22%)]\tLoss: 0.151883\n",
      "Train Epoch: 51 [30/90 (33%)]\tLoss: 0.305138\n",
      "Train Epoch: 51 [40/90 (44%)]\tLoss: 0.006822\n",
      "Train Epoch: 51 [50/90 (56%)]\tLoss: 0.364018\n",
      "Train Epoch: 51 [60/90 (67%)]\tLoss: 0.429339\n",
      "Train Epoch: 51 [70/90 (78%)]\tLoss: 0.559186\n",
      "Train Epoch: 51 [80/90 (89%)]\tLoss: 0.122556\n",
      "\n",
      "Test set: Average loss: 3.0850, Accuracy: 14/21 (67%)\n",
      "\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])\n",
      "0.01\n",
      "Train Epoch: 52 [0/90 (0%)]\tLoss: 0.170538\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-21f2c9a6a2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"newfaces_alexnet_224x224_augmented\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-afbc26681fc7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 4) figure out which weights caused us to miss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 5) change those weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 6) get model (with gradients)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#if batch_idx % 300 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36mmodule_get_\u001b[1;34m(nn_self)\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[1;34m\"\"\"overloads torch.nn instances with get method so that parameters could be sent back to owner\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36mget_\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0minplace\u001b[0m \u001b[0moption\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \"\"\"\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mallowed_to_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, inplace, *args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;31m#                     return self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;31m# Clean the wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\generic\\pointers\\pointer_tensor.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, deregister_ptr)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mobject\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mto\u001b[0m \u001b[1;31m#on a remote machine.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \"\"\"\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mObjectPointer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderegister_ptr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mderegister_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# TODO: remove these 3 lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\generic\\pointers\\object_pointer.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, deregister_ptr)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# get tensor from location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m# Remove this pointer by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mrequest_obj\u001b[1;34m(self, obj_id, location)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mVariable\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \"\"\"\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObjectRequestMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# Step 3: deserialize the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(binary, worker, details)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m# 1) Decompress the binary if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_decompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;31m# 2) Deserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36m_decompress\u001b[1;34m(binary)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;31m# 1)  Decompress or return the original stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlz4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mZSTD\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mzstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "# stopped at:\n",
    "#model.load_state_dict(torch.load(\"newfaces_alexnet_224x224_augmented35.pt\"))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n",
    "#set learing rate to value\n",
    "#for a in range(1,31):\n",
    "#    scheduler.step()\n",
    "\n",
    "#RUN training\n",
    "for epoch in range(1, 500):\n",
    "    print(get_lr(optimizer))\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), (\"newfaces_alexnet_224x224_augmented\" + str(epoch) + \".pt\"))\n",
    "    test_loss = test(model, device, test_loader)\n",
    "    #scheduler.step(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
