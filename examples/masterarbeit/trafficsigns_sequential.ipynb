{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1112 11:49:12.000087 28280 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0-rc3.so'\n",
      "W1112 11:49:12.017073 28280 module_wrapper.py:139] From c:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tf_encrypted-0.5.9-py3.7.egg\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import syft as sy\n",
    "import sys\n",
    "import pdb \n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from random import shuffle\n",
    "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "use_cuda = True\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 10\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker\n",
    "chalie = sy.VirtualWorker(hook, id=\"chalie\")  # <-- NEW: define remote worker\n",
    "dave = sy.VirtualWorker(hook, id=\"dave\")  # <-- NEW: define remote worker\n",
    "#evelyn = sy.VirtualWorker(hook, id=\"evelyn\")  # <-- NEW: define remote worker\n",
    "\n",
    "fraudulin = sy.VirtualWorker(hook, id=\"fraudulin\")\n",
    "#fraudrich = sy.VirtualWorker(hook, id=\"fraudrich\") \n",
    "\n",
    "compute_nodes = [alice, bob, chalie, dave]\n",
    "frauds = [fraudulin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for dataset loader generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLoadersPerClass(dataset):\n",
    "    #loaders per class\n",
    "    loaders_per_class = []\n",
    "    for class_name in dataset.classes:\n",
    "        # get the indices in the dataset that are relative to that class\n",
    "        idx = [\n",
    "            pos for pos, item in enumerate(dataset.samples)\n",
    "            if item[1] == dataset.class_to_idx[class_name]]\n",
    "        # construct the corresponding dataloader thanks to a SubsetRandomSampler\n",
    "        loaders_per_class += [torch.utils.data.DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size,\n",
    "            sampler=SubsetRandomSampler(idx),\n",
    "            **kwargs)]\n",
    "    return loaders_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "\n",
    "#benign data\n",
    "trafficsign = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\original',\n",
    "                             transform=data_transform)\n",
    "original_loaders = generateLoadersPerClass(trafficsign)\n",
    "\n",
    "#benign test data\n",
    "testdata = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\original_test',\n",
    "                             transform=data_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=batch_size, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load backdoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malicious data\n",
    "backdoored = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\backdoors_greensquare',\n",
    "                             transform=data_transform)\n",
    "backdoored.samples = [(d, 0) for d, s in backdoored.samples] #set each image of backdoors to 001\n",
    "backdoored_loaders = generateLoadersPerClass(backdoored)\n",
    "\n",
    "#malicious test data\n",
    "backdoored_test = datasets.ImageFolder(root = \n",
    "                             'C:\\\\Users\\Florian\\\\Desktop\\\\Datensätze_ready\\\\Traffic\\\\backdoors_greensquare_test',\n",
    "                             transform=data_transform)\n",
    "backdoored_test.samples = [(d, 0) for d, s in backdoored_test.samples] #set each image of backdoors to 001\n",
    "\n",
    "dataset_loader_backdoored_test = torch.utils.data.DataLoader(backdoored_test, batch_size=batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACECAYAAACd1CwgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvXe0Jcl52Perqg63b3xx8uyE3dk0u4sN2AUWGQQIEIxgOBZFChRM2TDPMX0oU5ZNWaYN2iZFSTzHR5Alk6AlAhKzaInhkBQBigCRCCw25zSzYfLL793c3VXlP6q6731v38x72Eh773fOm7n3VnfX1/V9VfXlEtZaJjCBCUxgAm9ekG80AhOYwAQmMIE3FiYbwQQmMIEJvMlhshFMYAITmMCbHCYbwQQmMIEJvMlhshFMYAITmMCbHCYbwQQmMIEJvMlh1xuBEMIKIbpCiJ9/LRGawAQmMIEJvDoghDglhEiFEL9+xQuttbv6Ayxwzdj3o8DzY99ngP8AdIEXgB8Za/su4CvAGnAR+FWgMdb+S8AzQBt4Evixy/WzA47vA7645d4vAD3/3A+Otf1t4D5gAzgL/BMg8G0x8K/8e7SBB4CPXK6fHXD6OPCZse+3+n57/v9bx9r+PvCo7/M54O+Pte0Bfgs4D6wDXwXedrl+dsDpk8Anx75/wI9Pz4/XkV3S5lrgD4BFYAX4M+C6y/WzA06fAT4+9v1H/Ph3gd8HZnZJm7cDn/f4LAL/Dth/uX52wOmLwPvGvv+3OP5dB/41EO+SNjvx/6Z+dsDpeeCo/yyAfwws+79/Aohd0uay/L+1n92sDWOfYz82G/5df/pboM1l+X9rPzvgc5TJ2rR1vv/6lfB7NU1D/wJIgb3AjwL/lxDipG9rAf87cAC4ATgE/NOxe7vA9/jr/jbwz4QQ73gVcPot3EDNAv8Q+D0hxLxvqwJ/F5gD3oZbDP873xYAZ4D3epx+FvhdIcTRV4KMECLCTc5fB6aBzwJ/4H8HN7F/zLd9B/CTQogf9m114JvAHTjG/izwx0KI+ivEaQ7497h3nAHuBX5n7JIr0WYK+EPgOhzd7/Hv94rA882vAB/zz+0B/9I370SbaeDTuIl2BDdZfu1VwOnDwM/g+OQocBz4Od+8E2124v+XC58APgq8BbgF+G7gv/JtO9HmSvz/SuCTwAnc2L8f+O+FEN/h23aizZX4/5XAZG3aCXazmxW7MZfRCIAabqCvHWv/t8AvXuZZPwA8coW+/hD4e69k18VJREM27+5fBn7iMvf+NPBHV3j2w8APXm7XvcJ9H8dL6sCHgHN4qc3/9iLwHZe591PAP7/CszeAO7b2swucPomX1HGLydfG2mpAH7h+J9ps0zbj+WR2az+7wOkzeEkd+AXgN8farvb81bjMvSVttmm7HWhv188ucPoiXlIHfhP4hbG2DwAXd0Obnfifl68RfA34xFjb3wG+vhva7MT/vHyN4BzwobHv/xvw27uhzU78z8vQCJisTcU8vKJGEPAywVr7vB+I4sW0tfbpsUsewu1a28F7gMe2axBCJMCdeAlwSz874fRF3EAAnAROW2vbW3A6yfZwJZz24t7xsW362Qmnz+AWnwKnh62njoeH/e//cUufAng3TjLeDqdbgQh4dpt+dsLpk2NfT+LGpWjrCiFO+d+f3NLnJtpsA+/BLY7L2/SzE04f34LT18baTgkhUhwN7tuC0ybaXAansm1LPzvh9L4tOI1L1A8Be4UQs8X7juG0iTa7wOl9l7luO5yObsHpobHvO/H3xa24XgGno5e5bjucBIAQYhonWW/F6aO76XMctuP/op9d4PM8k7XpW4KXvRFsgTrONjoO60Bj64VCiG/HqVhvu8yzfhk3KH/2GuF0cBuc/nPgrcB/sU1bCPwG8Flr7ZNb218lnF4yTrhdXLKNWUMI0cRJNT9nrd36vJeD0+IucbosbYQQh3Aq+E+/QnwKnHYcp51oI4S4Bfifge97DXAqPjdw9vmizyvSZhf8/0pxqgshxLiwsRNtrsT/LwOfAo9xnLZbB3aizSe5DP+/DJwma9MO8GptBB2gueW3Js4GWIIQ4u04FfuHtuzQRfs/BW4C3r9Fan4tcfoo8Is4Z83SljaJm9Qp8JOvEJ9vBaefxNlK322tHW5pS4A/wpkA/tHriNNlaeNtm58D/qW19rdeD5x2oo0Q4hrgT4GfstZ++TXAqfg8jtMVabMT/79KOHW2bAJXpM2V+P9l4lPgMRj7vJWXrkibK/H/y8RpsjbtBLuxb/n33uQj2NJW2OFOjP32bxizwwG3AQvA91zmGT+HixjY1ob5rf7h1KUBm+1wX2LMDodzSC0Cd21zv8BJI18AklcJpw/hogDGfQQvMOYjAH7cX3N8m/tjnDTym4B8lXD6BPDVLbTsMeYjuBJtcI69B7iMzfVl4vQLwG+MfT/OmI9gJ9rgHJHPcxmb68vE6TeBnx/7/m2M+Qh2os1O/P8ycfoa8F9u4Z2vj32/Im2uxP+vAKfzwLePff9fGfMR7ESbK/H/y8TnTb82sQsfwbeC/GU3At/+2zhPeA14J07VOenbbgIuAX/jMvf+A1yI1v5d4PEZdu8U/Tou/KsCfD8uRGzet30bTqV/z2Xu/WV/f30X/XyRXThFcXbjF4Cf8gvHT/rvkW//UVwI2w3b3BvipM3fZyzM7wp9Pc8unKLAvKfVD/px+sdbFpPL0gYnxdwD/J/fAg+9bxfXncQ5W9/t+enX2byYXJY2OPX6FFtCDy/Tz1GP09FdXPsdnjY34hbYv8AvJjvRZif+33Lt+9i9U/QngCf8Ox/A2Yl/Yje02Yn/t1z7cXbvFP1F4C/9GF0PXMALOjvR5kr8v821n2T3ARtv2rVpbKxet41gxk+ELi4SZjxW99cAg1OJir/Htjx7uKX9f7xMP/+JMSloB5yP4hbpPvAUm2N1vwDkW/r8U992xOM02NL+o5fp5xRjUtAOON2Gc3j2gfuB28bangOyLX3+sm97r8ept6X93dv0EeHUzG0jf7a5/oM4x3Dfj9fR3dAGZ0+1nubj7Vdt08chj9OupCpcHsGL/tl/wCiP4Iq0Af4X3z7e1rlMH+/GbZjhLnH6adyiseF5usgjuCJt2IH/t/TxMcaiuHbAR+BizFf833gewRVpwxX4f5t+fpYxDW0HnMbzCC6xOY/girThCvy/TT//ijENbQec3rRrk7/nk+ywERRMsyMIIQZ+QD5lrf3ZXd30KoOPt38IuMVam70ROGwF74j7d9bau99oXAoQQrwL+K+ttX/zjcalACHE38JJYf/gjcalACHE/wQsWmu3jcx6I0AI8X/j+OmVOiRfNRBCfA5nz3/ijcalACHEg8AH7OWjoF5X+Ou4NgEIIZ7CaWK/a6398ctet9uNYAITmMAEJvD/T5gUnZvABCYwgTc5vKKNQAjxHUKIp4QQzwohfubVQmoCE5jABCbw+sHLNg0JIRTwNPDtuHCvbwJ/01r7+KuH3gQmMIEJTOC1hleSUHYX8Ky19jSAEOK3cVmCl90IqknFtlrbJaxOYAITmMAELgcXLy0tWWvnd77y5cEr2QgO4qrgFXCWbVKzhRCfwCUt0WzU+Tsf+8FX0OUEJjCBCbz54Od/6VdeeC2f/0o2gu0KQL3EzmSt/TSu9Cz7981bgF/97O8WbVhACAFC+t8MWIswgARngXK9WQtyi1dDAFprtAbhMVJKoaTChQcXiFnAYLFYKxC+P7HNi/z4x34IgD//sz/BGkBoAAaZJBWaQ3ubqNxlvqfDHJ0H5HGD2Vvu4LsPXQNA++wZ7rvwFIuLzxFVqgAEtQZrWc5yb4MTB47y3b749Pn1szw0qFKv72PKv0RiL5LUEhARexLLkbob2kcXzmFIaO8fRas+f/ESw0wxzAdUZ+rMHrwBgNv3nOSOasLK+ae41HNRdrYZ8sLqAqcuLGFy0Kl7N7SmElruvPlaNi66a19c63Gh2ye1FqEkrXoNgNhCZ6NLd5iRWlPSEisRQpHnGUK693jrLUcA+J0//PNynEUx6EKAECh/rRQghSAQEHj6SCSDNCfTBm3BGtefkhBHiiiUKM8TVlty4+KiZSDQxkXxGWswSKQKkNKxvJBgtcYazXd+8IPlWP7UP/wUSinw7wFgjEUASomCTckz7T+7Wu6hUp6fDA8+cC9//ud/weraGgCVpMra+gZ/44e+n7ve/k56Q/dcC0ihUEoV8d5YLAKBVAKtDcKPmjWCT/2j/waAX/3M75XvIIVCKIGQEimMxwGUCgnCiFwbT14NKDeiSmB07n7PMgQgpSQI3DvElZA4DrFoEJZq5H4fdLr0+zm5EYjQ80K9SZQI+muLSG346Pd+ZzmW//zTv4mUCuxoHiIk1hqEcH06+jhWUEFA4Oe7tbac0Frn6Fz73/3CACDdtUEUUalUqIQBipxBb8PhO0gBhQGUf7dKnGC05mM/8r0AnKg7fji9sMBCV5OHCTJ0/YY6p9fts7reIc0s2o9lkiRU6xFBIFEqdK9lBTrP0dq4RVC45yaNKaKkgrQ5Nut73ulhsgFJJWJ1o8taz60lUVyjliQ063V05n6bab6iKvO7hlfiLD4LHB77fgiXXj6BCUxgAhP4/xC8Eo3gm8AJIcQxXA3yH8Zlg+4IpTQu8BrBuCohAYOQXiIQ4/c5rWCzpO+kUKVGl0rhJDMxpj4YDBj3bITcVp3ZCjIK0YM+XjAkzzOMtXQWu9TjGHC7uLU5PVYJ1CVCnOTRWX8cKwcQaLRy0szsvj3ccePNPHDPvZzcfzU3Je5ak21wJqhjSGmIHgCJHLKeS6yBGMsz7S4AWtRIktam6lSHjlzN+vqAXq/DYNBj4CXRXnyJ5X6C0JJG6CULodlXr9NtDVhd3aDnpWab5jAQNMUcKCctKtPHWBimOSJSDHXqrrWQGUNmDUWsgbEShHQam5RoozePpRzpXqJUDZw2WNINkF4iHmkPwmkJUrqRLYRBAYEAYS3WWI+Dk6gtFmPsmJTt/ywlvsXz7UuVWP+OYxwpBVJJrNYlZlI6HpJYrMnLp2idY7UZz+okyzKyLKM/1GS5KbUaY0EoydaADa8nu2v8tdgRLxfjVyjSUspNU0VI6TRoBFYUY17MOVH+gdOeJRI5Nn/yNHf9CggjibXFvQohcsTY+DitXoIQLxlJIYSX/ke4W2uwohi/ERV8I1ZsJpBAIqTw/APGKgROqzClpiGwCLQVSKmwXlOQKnJa19ig5Vpvmvu16Tn3f6+D6rbJDFjjNRURoMKQWrVKJbMYrxHIUGER9AS0IrcO3FWp0rCah9dWWUwzhgVPDvqoMERYi/Jrg0LQTwd0sx4m04jMzatMu3ThQEq0dvPy9dIIXsl5BLmvEvhnOJ3zX1trL1cTfhOIsQ8Cx8zGXOGGyz5IAgIlFFKCMAUr+oeJ0UOFLditYMotTEihdo6ga1IqViOsI2AUKCpYsJpUe1U1z9k/M8WhpIZducRfvOhK0FujGOicUIY0q4cAePuNN1Opxag9h6iuXuCri64SrVJw60xMH6gOHA7dQc7ZfgesZj0F4dXd1AxoTRlqMyM8Dx87QfXiGssXz7G4MqS37q49Y54jiOrMVmeZ3uNwsJUueqVHJQk5KBvYxPV34dQZgkFI/9yQRuwKI1blMgpBIBUqCpmqJ24c0gy6Q1IhGPrhk0JihMBojTGafAtBpZTlZBRCYo0pLEOlSUOO/RWLnZR+ExAWKQSCwqRnEMK6hcWObQR+MzDGlIu82wiE5zFb4uPMhJuXryCKsKZYd53ajzYYbTFmxKehVAgMRht0bvAWJypRRFKpUonj8tl5loE2pMPU4+4uNjpHKcfDJRi/4AFWjxZXMXaNGLOMuGE1pZnK/WtAKP/WJQHAuvEUQpYmMqUCYiUJZSllMcwzhArJjaFSqeKtKmgZIEXunl8iU1j5xKYFdhzG55XFglDOZLTLSS+ERKpi9joe0DmlsGFwJkFljBNEvHkpCL2ZqRxR97/w5hwAGzuebjaniZb79NOU1M/3HIMUgmqlgogEePPUwOTkqg/VgLve+2EAPtY4gjh1jmNVxZ/e/ye8cOmC6y1VpF1LNY4I/AiFIiY3gk42JIoqtJLCph1iAuj1+4jXOdH3FZWhttb+CfAn3/p9hS3TSy7GjNZjax0/GtzkEuP3FUrCSCwUIqQiIyqhRFgnyaZ5Sm40WlsKudRAKWd5q+vouTjJ1prNg78/NGxkhrTwUwRAoAhDhfJ49XSPTkcjexbICT1zBzKhITJa1Rbf+cGPAXDtfs1//I1/QbN6nKMnWjy75CrLttczpoN10KVpkTiMmBn20EFALBP2HdgHwMZghbVsQG0Mz6uOH6IeVqjlXdrri6x23AZzIcvIoy5Lw5TpwFUFrjahJyPi2hwtlZO3LwHQHw6p5Zb1554mPuCkpKoISMKYXGqCMGKuNQtAM8tQXU2qB972DMZav6kLlIV8y6ZqrBnRTViEkAhhEcIQeGkvEBaJ9YvbSOKUUoI2oDVY15+QEAZu89F+13Dnlgi/EWjMJqm1kGK9NG6Ev36zddQ6hbF0YQBIJZ2fQJryaqUUGIFUYPMMnTveG+QpZpBRDytUA+cE6g0GKAvZYAhaExSaaiCRotBXKN/LjF6z3ADE2DwobneLusd77B3ENp/FuMQuROkPqAhBRUBFCgo9uSuAOGaY51SCEFUswsXAbAPbOgy3LGbC7/xSCIQUFCflCqMZzczxJ7l2hUD4sVRCYK0lx+CFZow1aJujrXDX+umqlHJPs5SbAwJkMNoIZOAk+jCsECqFyXvoYqPG+axCqTAWco+aUZJGVfOW205w68xeALInuySrMxypNbhl/yHWls8CkJMxXWsxzIZ0Bm48oiCmPjNLK5gmN9BeL4S8jN6wi5BVzKt2QsDu4PXtzcM4f7g1YGwyWr9kK8d4Y1PEEVGOqblKoKSioiSRHR3ArIKQYQ5Dm6P9wuxaRcmc5QTatEBtXrz2VaqkGrJiUZKSTMBQ6xLlUGoiCa1KxP6pGhX/3Nw20HHK1ded4I7rnfh+77/9LDx6hnZ9yHLjTqbnrgeg3b6XiyurxGFE7KWVSAYcq1bpBZIgzpn2Tq2ZxgzPrW4qW06ve4H5RsjM/hbnz1ourbiNYHWYoaMBG9kGy9qdPTOTTZFMTWNlHTvsw7pj2FqWUzcZ2epztEO3acS1BrNhBSlTchXSSFoAzFYgrw8xQtHy5qL+cEiqLagAg0IZtYXqhs12PkcVgS2dxeVGMHarMRYllDMF5DnCb+0KQYgkL9QKTx+nbVi3Cdhiy/fGljEzki3bN28EErcIK0XJqNYvx8LIUojJdOaXLYdPJXD0CYOQSEX019usnrvo3kEIDJZESpJAgadxp9tDY5AEm6VspRB+QyvHQY+ZqkThXB/ND4dWIVlKEMpL6YWpxWlAzkkriPxuEmqNzFIwhtAvttVKjA0kSoG2KaGXTgrzkyvFZjf95sy2W01chWlvZAouNQhGmzLWYIX02pxH189XpBvTJHS4hUKSpRmZGOGQY5HGegORc+qDswI4M5hCqsIUNnLwAvT7zikbRAmVKKTcXQArFTmGPNdoYzE4HOKwSqhaJL15DlpvLj3/DcxGxtSe67hupsGZuT0AnF/rQLeDimK0F1S7wwEyChHAcNBHWDe+ARAJsNKSbTGtvtYwKTExgQlMYAJvcnhDNIKtIMp/CsndOGeSFKWQXkgKUkikD9VTShAGASEWNczHNAIFyqBNji4thAZLEZo21rkFK7a3VS70ekihqEaF089gM4sKFdXYSRWNSoWpiuTIbIvZwHJmdQWAF/sp4b5D3DZ/HWfv+RIA5x55hDBT5J0eYkmTzDhNYX+jRmeQMpUkTCdOVe13e6wP+iwPMrCSXuQG6LiqMGMEa2N4rl04w/z0Veyfm+HJWsyz3gHcSzts5EMyKyB0kk9VJ4TGkg01lc6AsOuc06HOsDpFSOi13bvFQczBSkSgJGtKEQSFRBQy22rSCgTkTntY6xrWhzl9IRgGAbGINo2lMweMDbvxJhFlRhKutATWeAlypIU5e7DF5nlpi1dSoIQ3+YlCo5AYIdHSYPOReFl6FuQobBgrsMay9Rhc47UGZwoaebWN9d9Ncb93+hpNKCWxtzXnw5R0OKS73mHxnLMTyzCkOdVCD4eYYYb0QQJhIMnyFBWOOVNx4YdWSK+xuJcoQmHBmao8tlxOlivCsMeMQygpkFKilCTyalcFkDmYPEV780kcRES1iFRYUqGQhRYlfGikAby5SGD8fHyp211I5QM3CgwcLYSUbpYXc7uIGBkL7hAYrHRzPQpCIv90lQ8JlPTmGodvagoNydGl1+sVJHJ+nVEkqnPwi5HKudFzQRghlkocE0hLmjspP7eqNC0HQRGSDm0dUa1fy1uu+yCt9BkA1s98nghDLARXHzjBmdWrAOinp+hYRYrE+PezAjKjGA5ydC4QKvbkDEBCrnOs2KpRv7bwxm4EonBnWQSFDU8jkEgUGD2ajKUbYRRBEAchSRggBj2Ezkf2VClIVIgxeRlZoLVbeJxDcWzh37QrbF4UelqSYmlEblFLbMpKmpLpkfNiJgqoJxHtLCft5NSss94falqG0yeZb7yDp/7yU+4V2usEVmHTPsvPnWH/EWdfrDf2kPUyF5eMm/BT9YiNQcTza22m4wZzG445V4YdFjsp4djppvNzJ4jsLPumK0zXWtQqjrGG/ZyhThl2LTJ0pJ7WOcYOEaZNZFYwXbdYVYKcSjVkY9hH524iRcN1WkGNPAowoSAQDjcZCupVRWQkKnXM3aBCI0i5OByS5wYpNrOWEIw5wLyDV1hvWhi58ZUUhFJQuGucM9jTVQWE3rYdSoVz147BmGloPDKmCE0rv8PWeu2j30vTkRmz01uEMUjUiHeM2wiEBiWCkaRiLEsXFznzwhl6G34ck5BBGNBttxkOhsSRGzNtUqQwKCXxa5qL+9ejtyo/jZkKRtvA+CZgy412tH3IwmbkF0K3FEssoXRXBLnGaoMUqvTVYIagBanNyAMXLDDes5By89h6E8xWkH4/Hx9iISwCg87tGI1dvogYMxMLCYGCIBAEWMicWQWdEUQhURiQFxFv2u3Pgc9JKfx3aZaRGxfRNjI5jYITAKy/uL3eZZCmhEqifF/a+yOlClAqAu3yANbMBtdc8w6uP7GP7N//oRuy5TZDa0gfP03j+N3c8ha3DlxoX2Rjo09mLKbwuhtDPx1irQZ3FoD/WWCsIs1SH0Tw+sEbshEUUtno3Aco3LqFQ9iinb22mJhjf6qICkAhcoPILeHYtDB6iBCKCEHmr82E3wSgtFOWz72Mg15bgY1iQr8R1ENJvVahYwSRxzdqd+n1B6xIQRLHnJybAuDYgZjatRXSS1/mxcfdudI1m1Cbm0KnC6yuneK5x11o2I1vfxvtep1evozJ3LGvjTggqMQkjTrTyRSHrJO8L+QDjB1swvPLL65z11U3cnCmyaDRIvJaRWIs/dyQW8GgiIQwloZNyXsX6V46RTB0Gszc0SPsOXaMF194nheec+kgnfUFrmoeY6YSE0cK2XbO7eWuJctSBCMJXciQPABBhm3npFuVrDFagy6TityC7Z2CAkIhCIQq410yoxEWAqkI4hpqzGkoyFDCOGOwQwIrXMikFMJJ1b5z5+iUo3BXrX2QwkuJr7XGjvlFi2CGTTZ7Y7B5DtYJGSZzbYPegLNnznDx/AWqVZdIOMwGdDbarK6u0um2EZVRNEsYhQhhsGOLusaifBJcAUqOaw2j/4UUo3yt4n9pXJTcmM3dDxBhEFKLAgLtNMQ8T8G4uVSo34oUpSUhgnwsiMJYH5k1psIXfVhr2boXSCfXb8LbWBDGYsZCj4s2Oy6ICUfjSICyOdL7oqTWkFuiIKDibf0GQ45wG4EYJfflFH6cEl0vLI6rpn7LVIo4iglkgDBubKyw7l2FIM0M2s+Vm2+Y467DkuD0N1h/6ikAMjFDW0oGZ7pw/9Ps+TZXZOHuO26k882HuNSXpD5JTFtDlqU+aq0QUv2GJRRhHGPTyyxKrxG8sc5iMaa9lu89FjctRt9dRMooG7i4VGAJVUASBagiashkGAuBEmVcf2C1yzqFUhLZCYKkRjUIfWQH5EISCU0Dw5yXuq8VMTYMeLGXstBLuX/dLdLXNvZw91KbJz//+8gNp342D9zCte96O6cf/gPkU2fQ588BsPD0RV7MNlgzG/RTt9gmkSTrZ5wxgvOqT9hyTH/t1Uc5biVfHVtol+oZFyqLnDKabiyZnp0GQMsNzCBzce0+3jmMmtSymMHqkPWlHgEuEmiDwxw69g6OzZ2E+D4AnnzsQRYWFzlYm6EmY5a8k/rCsMNyNqSPJYzdYjelAqIc4kqTOO2Sr/c2jWUZweGIi5RjuQCFMCAkRgo0tjQXKSXJyQlUSDVpgfEmJ2uwpoc0AwoeCQOJdiIfSopSk9DGoHVOEW7sMCgcxpuZwRRRSVA6OU2Rkc4oftQab740Bqs00ocqPvfMszx43/30uh32HHHmgV5fsbaxzrOnnuX8uTPcsMeZBI0xBD6DuNBcrR5l1csxGks5PnojKDaBbaN2GJnN3PyBJAxJlHO4uudKaq0GcRBgc5+rogeIzMXQK1Q5YawYuXiL/orZud2Ucs7pzU5va12GuAthFX4cfFQXslyjLQKsROYWRUYgi03KZXVrkRN6B3JFuOO8ipcWnu4KhRE+V3vcYT2GbLFZB5U6lSBkOMjoeQdyL8tBKbS2ZHmG1m4OqU6Na8OE/gNfI1l3gRnsPUrr0DF0u8PC4w9CqwLA8evfyq3HFA+cfpxe32kUQyQZAqmc9J8aj71QEATUwhpWd7cZ0dcOJs7iCUxgAhN4k8MbohEU2ZJCjjJ8R2qlRAjj/Qebs4OlcPcUoXRaawgV1VqTViVAeZNJp79Gv5+jROQSZXChiQaNFU7ysIXk59OVLbwkj4D+Bn0ZM/T2usBqlB4yV4uZ9s7b5lSd5XaHTn9Auz+gp52556rj7+f0CxdYOdtDBO635sl3cN33/i3SmRXOnP99zJrPI7jwDHuu2Ue20aU38A4wLRjmIWvdnCDMudR1qnGybEhyR1W5AAAgAElEQVSCBMYSDt9aT7l5PmNarnHbVXtZ9XWQntSWM6pPJgS1xN0wLxMqQ0mvqxnmIVG8H4DDx97N3JF3sHbmFNN7nSt67sLzdFY2WDq/wtzBfQTKSWBWxWAsKsvIPV6rwqCwRIHFyvAlNk6nERQhh7YMIRwZgZygpgtHsSeFMwEZlJRUkyoYJ5VZrcmHOVoPS8k5RCCls7UqIdGFq89arM4BWZqLCr7aKskabctQw82Nhe+A0f0+KS4IAvo9J+09/NCDnHr2GeIoZGrKhdvWmzXWOxs88dhjPPLww1xz8jqHb1JFZwZtzcgXIEDaACc2QyGrSbba2vwwic2Z2KOmwgdT2EQsSgkqoXCZrN4OXqnWmZs/QKOS0FlzJsHVxXPk/RRBhTiKSP3Ji9Kb3hjzrTjTkNe+tgymMdpnI2/BzcqyxpLDVWOlYlzfV9I7iYUmFLrwTTubfWYY5iP/YSUMyAXkRjuTnSe7VAqpbRlUUA7wGD61mquGHFhBKAI67R6VtVUA1ocdMmvAZAyNYWAdPW8++hGuUk0unX6EVuJ8AdPf9X1Ex66j/7Wv0f/6KS7d8yAAR2p3cWLvrSyuneHChq+BNDRuDFAoCSZz0r9SgmqlRSgF+s3gI9gOigm2yZEr5KZ6VUhBGChCb/evBCG1SkI9qRFFErQbvEhn5MM+yKD01EfeLqmNU26LCWILR9cmG7aDqThiLTf0U7fBaAPKGvaokEHfmT6eF0OiKKBSq1BRGTfe7CrF3n5ywGOfe4TOQLH36EkArvvQh7FHj3Jc/hjnHr/ImS/9JQBLZ5/j6NHruPn4HI+96OyQ/eEQaVPmQs1MEFCLHakuttuEIt+0EXzfiZto7j1MkOZcdTxgPXVmJL2SolUXQlWmwu8NLHG7Td7ewEpF84DzOh+6/jqGMmf+wDTZujMtzc/vRfXO0165hAwsdtaZNLRKQBoSYcl88bKNfECKIBTSxUMHm6OGlJKjjQBXTM2VQKO08VsEGoW0Fl34RrXFGpCBIZAprZaLzhFWsrEm0RuWNPeZyZkB4cwZSugywVAWvIQoEne9E5qXOIuVcKuGgZFtRlq3MEOZl0RusNYQKkksA5467WzF3/zmPXS7HQ7u38fslPMXDXVOq97g/NIlHrz/ft56t7MfX3vD9S5CxEJROU/6cg5FbbUi8cvko6ihwC+grsCZi7LbDoQoHgSBCggDiTAZIhsQFsUNowpJtUaj2SQK3aY+6KzQXesjI0UsInx39IVACus3JR+pg0QYNucxeJBCbV13GYWOmdL/be2IJ0p/kZLEgSTUGmsgqDqGb9Rb2Mww6PcZDnymdp4RSmeCStN0ZMoqEwlHM1uIkRAIkPrUeBW4JLtms07sy8dI0QabY03GwKRUDzhT33vufhvxo3/KxnKXg3e7zOLoPe+HRp2wt0Tlub+getElaurnHmTmlqMc2nOAUyvO/7dycQVjXESkQhH7d44wJHmOsLnLj3kd4a/FRuASPr2NVHonGJtdBxJFIBQVFbgoAlxUQRyGRHGVSjUC4xbATGeIngYr3MQGklChrXZSg38ieMeX3X4i9fMcnY/ZhbUkt5KFdpew6cNHZcAeFaMiy2K8j7uP3uhufugL6EfvIa4e4ob3uIqMe665AUvIVPM4h/ddxXrDS7frA7pnzqMOXYuddTb71RefZ18C9URSiy21wOHbz5SvqjiCPck80jaI6hFpX5DGTnJRqkq1FiEiSeQjLNL+Gt2FC/Q666hKlcb+OT9mXVbPXMBWMyoNt4jPHjhMf71Hf3GJjaUFIuHwrbUaWBGQioy0WFiNJs1BixAlxkMvPf3GShAI4UbfxV4JdBE14R15mQbhI2fyXBMEEUEUIFQK0k0mgSCIDSpUZZSNzoyzrUuJQpXMbbFYKRgPx3Shoy/VCApflBCi9BdYX65CKTWydxunzcZxRJYOePi+BwB44vHHqFUT9u7Zw+yM21CHec6+/fvp64xnnnqae79xDwCHjx8lqVYZpCml5C/kyCmLQcnCPj9avMpsbm0Qqhjrsdniwy7dRlDI2YowCJE2p4KEwG2ocSUhqUaoWKB7bsVvNGZgsEK7u46qQFT14cRhgFIBgnQ0Z6zGWpespuTmkMdRpNJmH4Gv0ASMJ005H1JYhLWGCkmOyTPiSpWplhOwGtPTDDtdMJrcC2gSASpESIlVkmHa93Rz1gdtGWmC6E1uobznhIVMWaTNCAJBXPEBCdISGkPGkEN7E07c5LTnfdl5Nu67l9w0oOm0O7JpqEBwyzXsX7qZ1T/+HACL577AgZu/m+MHr+GZ866q76WVNunABRpIEZCEjhahzImiiDyHxAturxe8MVFD42FuYzVhAFdrpXQYjVhIBYpKFFMJFMJHPCgCV7MkCAmrNReHC8h+D4IBZpiVoWRJGJBlGbn0lQoKXLypSGCKNOcSehk4ejnGEEZhhEbFVXTFIXm+p1le6dFNNXL/7SycdSGhi/d8hShNqFx7lD03vgWAs2cusPLlr3Hk4AGuuv0uzjxxLwDth57BrDwLnRlasVuY16PzXD0TMxh0AYkcuIW8MtRkqdk0hVANNtoZzbjB2iDlYsdNhKU0J41jVKRYb/vQt5VFWFoAq5C1KeJZJ2ldOPcoa2vneXa4yqEDRwBo7TtMt9enN1wjW23DmmPkpoS4JrgkJKnyY64sYZb7TFLItkg0AluWjXDlpilNGiMBTYBVZNpivJRvc8t0q05UDdAqY2Pg1GuJwKoaKo5QuaNFOhgircaEglgqivJi2lqMkC5HoDRpGP99E5pIqch1jghEyQ62zGexpVAgrCEIFTKC008/z8MPuY3A6Jz5+XlmZmeIvGRJENCaalFdrbF0bpUHH3wIgFtuu5Wbbr/VsXtRmiSU9Iepk5Yt9IZDT+MRxUsLpnK5Nogi95ny3dwCrcp49DisUA8DbK9LmhoaTZf5OtWcIQxhkHXRfhG2UR0b99C9NjbtQ+gX/TxDmJyisF/Rl7UaazWZ3jyYxhZ0L/AqpHSNsKOM47KkjILIqx8V5Qu2AfV6jeaU21SrtTrSWLJem0BqzwuBK2EdRkgM7Y218rlFmRnL9pm6b7/tnQC0V1ZZvPQMq51VhM/rCKSLNNRE1Jjijv2uXpd+5ptECxepNOZQBxxeyDbdZ54G06Z2y53kF51m/+xXvs6e5x5n+iM/zE0LLjjkwvJZ+nnGQLsQ5CKMIs1SRFxBAPO+2NxID3xt4Y3RCMokMbc7G2vK2uSlvdhqjAWpiuJYiiiQBLkp4tdcCFkSMMjWWFhpl3XphZTE9YRhPkCnTnoOceUbhtqllZVs4ZwDo9i2MbBGY2WdJHYqYSQHVJsxrVaNbtvF35/fWGV9oGm1Wnzk6iZ03SRf7W4wFV/F4Ts/TBY72+vnf+eXsY88yf3z89zxQz/EWz78wwCsnP8/6C6cY+nh0xx4mzMbtI6u00wXiCsNjNY0vX0+yBRPnl1jXCdI9uzl0ovLBFnOUqfNs4uutMHyoEcWxwgkg6GTfIbrXcJeTiuaJpo7SjTrbJxnn/4mZ545zcWlNZaOOZvl+973YQ6dvJHB4Dxr6QvkA+fTkB1NJWwRhEEpcQYiIBaa3OZoI2CLdKjzvBQArLRYq13UiBwvI2IxwmIkKC8RRbU69VaLpBIQyCFrq04jMFpTr7dozbVottwTNpaW6A8H5FkfIy3KFKYhMcoZKGMvbRl1uh242kijyCWLxRqNKCVhg0Qy7A54+okneOpJFyJcrcTMTE8xPdUiLwoTYqnX6zSaDZLVhKd9yOHXvvJVjl5zNfVarUxiSvsDjNYoGaC1pddx75vZEcUL/VVQToWXRg35cFfpTUvVOCQ2KYN0gApj6k0nhUqpuXTpPN1sSFxxxQajqIJo1GC4ATrHpL7EhHFj5kJ0PS4mx+RugTdbkHAL/3j1UVP6FKQchfJa7w6RUhIVpSDyFJMNqdXr1OtJWXRO5wOajSqmHzPs+DDRNEcISxQo8ly7ysX4NUTrss6YH5ZNETIn3nILAOcfX2Zj+QISQ+RXxVBCPzOkssVV83dxcs8JANYf+iwJlgO334U87vj0zNc/w8XH76EyNcNVH/hhWm91Z1xUTj3DwsMPcujm93P85LUA3HDpMZY7HYaZJtOlXc2dEZEOiVVMRXpNZStdXyOYRA1NYAITmMCbHN6YPAL//zYmxE2gJARFxI50mala51QqLka3Wq9RqQasry/TXeuVyUbTUzNE9YQk79FvO0lK5xnChijvpNxNSSctFJEIRo7LMCSQisW1Nl1/stfGMGUNy913vJP3H2nyV7/7++7ajqX51g9x44e+h6fu/xUABo98nkZb0zOLpEsdZu++C4CZa46TLj+APb9AesYVh6sdCGhnhnaviwwkbS8hiIFgeZCyyRU7NY1YzmnnKRc6K5xeWXAomJyasMTDjCR3gzzILZ1BjppqcfCak0Qzbiz7rLHUXkYTc/6Cj2bKJAeOH+NQfpJhb4OFF5xpKM82qGQJFSGpDt04pD7ypTPsM7QWFW52Fhuty/hucCZBiSQYE0WKVJ9cWJSvEFltNkmaLapxhGRIf2HB42CoT1WYmp0jKiR304eVLp1uF5mbsny4gJf6A4qA8i28p3XuzIXaUMTyBCoiN9plrxenauFKHp999kUefOB+Vpbd2MzOTDM7O0sUxaUj3QiI4pjZ2VmWVpZ48ZwzEdx7773ccedbufXW26jEbry6nR61OMEaw3J7jRdfeM7xQ2u83uy4GUhSZDqIseZCEg/8AIdSQ7+LkoZqK6Ex5ca321/lzNmzrPeHTM0dAODwwauIgxaqs4jJDNI7giLrCuoF6NKZaa3G5CC3iRQzvvb/uH/D+qE3Y8kIpYYjRj49ZTW1qYRarYYROevLju4mz2jU69RqMcOmG5P1lQ2GwwFKKIQqnNlOo9/sccTnr4yVsvD5QJVmjMmGRFJRLXgvrrDU78LUFG97+7s41HPa2SNnnueaYzdQe/+304+cybV7/5fQT32D7KobkJmEg0572HPDbZivPMDZz/0xh773IwDccOLtPH/xS6z1LjC0CuutHhERFaOJydE+54D4r/l5BK8E7OatYHOij3RXCOGiIwqbYSic6mSEpFJzg1NvtggTCWsDet0VwsBPlukZolqCNjWMz0jsbaRYoVBoF5JoCrX9pZEjBfRSqCQay4sArKyndLKYSiCpeNOHjuD4kYOc3HuYB774DdpnHZPNTM9y7XvupHl4huBZFz0SJFXSbpthGNOPQoLDzuS075a3sfjoaWxvGbt2CoDawX10bINh1icdZKx7u38lV3RTs3kjAERSZWHlEkv9FRZSl+SiA4XsrhEZQ8WXps7W10mUYn7/HPuPHKTvhyxsXcPhqxucevoM1564yY1NXKcdT9E4cjsHNiyrG18BoLveJdSahgwQPpppI89JBwPyLCUVErsl+9laO4rmQOAOMnFhh0F5ToFAYcl05vPKQacpYRiT1OpIUaXqD2Kwec50a5a4UiHwqnV1usbQxmjZo9fNEL4ukLASYU1p1gCQMnAVSrdUedQmIwwjdJaP/AfGOlOQHEXoWOMS1J5++kkefOD+0p9Qq1aZmZ52gQkUYc4GoSRzc7MsLE+zuu5s2OfOnuHLf/FFrjl+gv2H3CKc9lOqScLaygqXzp/n0YdcGOL1b7lpROuxY1bdMQLSmTGLdunKfAdKEQU+aSvtkaZ9Gq0GtZkGYd1HIw1SDDm5ztjwZigRx1TimHq3SfvcGsJLQmEcUk9qDPOs9GlILFZroiB8SZkJ5ZAtzUjlkiykM72N+QiEVEjlzp0A5xIxNiCq1rEY8oFLZhx2B/TabWamZ0h8JJHOLGsbPdJBDxkHyNLxPvJDFTv+1kDbU0+4I1T6yxcZpOtIFZbrSBzVaIUZhw7Oce2UZviVrzoaracEt1+NPHo1es1t1MN4BtmqEc4kyFjCrPPBtK5/N8Nnl3nhmYdpfNUdY7v3lvdw/aFLXFhfZLhhyxLblox0OAAl6QajRNrXA3bcCIQQh4F/A+zDzYJPW2v/mRBiBvgd4CjwPPCfWWtXd9PpyF5XBgdv2RpcmTBpFGEh7QlQWKamWkz5Ym3VRgOpDCqsMV3T5YAaKVHVGqHOiH2tAyUyun2NQaNTTWZ8YSnk5RQSBplhaIfUq/573mGj3edgrUq94oZuIOa469CHmGmv8+yFF0mFi9g5ePwDHLz1HahahZN3f9T1tbDCxW/eQz5/C3vvuJt+zW0Qt3z4B1h/6mGe/8qXWDh1BoD6/huZnq/R6S/R72p05ibjXKtObcbQ34JrbBT5yiIXnn+CVX/GQCQbWPoEwxS16haftNdDVJtEcy0qUzVUw73ckavvohGepz2sc+T6W90z6zNE0SyxSpg+2GHfMYfbC48+yurCItMHasxOuygndE6axKwvW5eNmeeb8LN2TGL1YqFBoO2oZIhEooyF3JT1x6IwJEkqVJIq1uZUEhf3TZ5RjROiMCyd0FG9TpzWGGR9gpzSiay0Y3R3PkHBc9sb143PDShwBjC+5LRbWLyEHUUsXVri4YcfYmFxgdmGo/v0zAxxHJNb4yKVfL8CSyVJ2LtvH10v7Z0/d44HH3iA5049w/SMFxYkLF66xPLCAkuXLjD0Ycqnnz9d4lhIvC6nxpTnLpTnJ6BQMiSQYRlqnacDZioNDAmquoeg5vBt6oDWWptcQMuXTiZIkNWQxvRewqFidcGXOExzVBCS1BplOOtgfYnicKAtsRZIuSXjWIw20pGM7nIG4lARBQq8X8dYRSVqkTRamLSD9lqF0Bm5hhxFxc8faxT9YUa334PMjIRHqUildoXn2B5OP+J8elnvAloMCWpVpipug+kPLA0dc6sKab3wMDz7KACxqsH+g5CExNIFh7Te+2HyjRbJzBxMTUHF5ydcdyvDpx8lfOEBOP2Eu3/PCa7ZM88Ll2ZZ767Q8Tw1tIIciQlCH0EHzcvg/WrDbjSCHPh71tr7hRAN4D4hxOeBjwP/yVr7i0KInwF+BvgfdtPpOL+MpubYViAkCIFSAYGvJxJKV5CsUqkQJz70LUkQwhKohKiuiLx6Hdfr1Gp1BtaAj7bpdFOE1SSBMw7lRe0d7cwDdhtmqUaRK4HgE7Sa1ZhIhOQy5Dnp081P3M7bPvD9XPq9XyK/dJZ8+hgAV3/79zN94hq0gtgf6HLdu25l36GAcM87qR4/jAjdM4L9xznw7ney+OSj5BecJL382Fmm75ynVp9mta1p1Bypaq2YWKabNoLl8xcItKR36QLnnltg6J17MgoQmWbYHWL9OEREiOY8zcOHqTQTROgm3vSeiKyfs+8qTR/nbG5E82SmRzWJqM3vY/6QC5VLl7pceOE864sXmY7cpKnN7mEjXycarKGCGJNtlrTHjg1wC7dw0TwYUYYdCuMOgLGZJa66sZmZmqZRrxHFIcNUE3tVnkwirHWSpHeIqkoDETWRcUZcS9D+kPh8mBEi3OEl5alWYlMU0TgUvxVlLnSWu4KAUpZJUGh4+sknufe+e1FKMbfHLaIHDx5AG78JlIzulu7caGZnZln2BxKtxDHnz57hC5/7HPvmXXjkgYMHeOrxR2i3N1jvbjA74xbsex68n/mq3ISfzjTGLxnjiZdWCIQMqAQxid8k0yxjaEOm5vaStPYjvTO+0VRcfXXK/kEfGzgcVJi44xmbc+i1DkVKiMwzGlGTqalZjD94I5+fQmAIw4AwGtX5x+PkTqIbK+8wJngVGkQcBNSDgBjn3AUwYZXm9D6qjSYys8iujwTqSerNWRrzs8Q+SdJaS9Jtk6U9rMnKswv6QUZmwIwXmYNN4eLzh4+633OFyXN0ENEZuPmTZ1XqDc11+2pw8RF025n/9l17J5Xbb4cI4sgt1Uff9V7yQR0QBJW50SDMz1J911vZe+YL6Gecdmc2ptlz/BjX7r+KFxcH9FNfGkdG2NBtBOmWTfW1hh2dxdbaC9ba+/3nNvAEcBD4PuCz/rLPAh99rZCcwAQmMIEJvHbwLfkIhBBHgduAbwB7rbUXwG0WQog9l7nnE8AnAJqN3Ts+hFKEYTRS8wJQgSRO4lIqDKMIrEapgCRR1KrO8RkmMXEYEiY1TOIk7L5sI0zmnM6BItNOeklNhhVFrPFmnaBR0UTSllmYBksv14StvezbewMA3/9dH8Ce+Q+ceeDrJCrm6DucA/jYu25E1BWGLhtL3wDg4nN/TDg4R76xiF1pMFt3McwmqbLvpjs5e/xL9Bbvd513niBdMVTnD9JIMva2HA4BQ1aWsk0648KD3+CFlRUeeuYZFjY0RE4tDWWF6Yog6AzIhu7dktosrcMnaB48hI0FBmcX7nZfoN15klp8FuXFkUF3DtOMieJpKq1ZZg67E9UGC+t0VjdYXWnTWXDWwFoyz4GZBplosZxLps02yUVjUs4oTBhMXphQXDJvEtdoNJ3a35yaIohCZ1WQo+MCcyHo+BIlsdcogmqTKOkTdXNy1srw0Qhf4qJI1wWG+OD1LSADWYZ9FlpqlmcIoVBRUmb1Xrq0wP333se5c+eYnZ5hfq9j/3qzyaDfBxWUJ9sZ4c440LkmikKaDUefqVaL04tLfP2vvsEtt9zs6BNFnDv3Ip1uh346KDPtz559kflrj44NJiBt6QdxoZmy7E8FARUVEGWO/9PMUGnUac3MEVer4G3QNs3ADglFShh4WT1wOky11SKbatHbcDHxpjMgtDly2B87SyAntdoV9tsafg0uo7sMuaU0D7nzRhy+lSCigkQMU0Tkxnd6fp7W/BRBJIiDGFF3c5tBj3g2xsairLIrqdLvVEj7EjLK4ydrFU3OAJ3lpcGhyDQuYO4Wl+PTXa8RoekvLqONG7NkzxxXn7yGo5UhF/7oz6l6DWTPB74TcfRqHP943VyvQ7oMhBDpTSK2uOYa9nzkOzl34dccLc7fx4EjBzl2/AaOXlxk5ZJ3hMsYi2SY5STBVi/gawu73giEEHXg/wH+rrV2Y7v649uBtfbTwKcB9u+bd7xRum/GI8gpf1MSgiAkqQQksrD3SWQcU6s3SbxpKAggHfYIZZ/ACqSfFHo4IO1KkrjCTMstKGYwYNhZh9zHvIfOIRTpHobcRT+YzQpSEsXofMhM4pjQpCldobjQ2eAd17uY4Ds7FR75gz9GbXRo7r+Va97xA+65++ddoUzdYX3hLwFoZaeZVgPW+qeRg7Wy4qSRirnjt3LTh76LxVPODtm7tIA9s59DB29Az27QXXX2+WEvZ2nDklw1wnOuM+Trp1/gbH9AB0PkZ2mEoKYNaX+A9lFDydw8M4eOETVn0P4sXoDuoEc2XCMWGzSFY+5edwOdZUQ6RwYxrb0+oeboIp3F58k666Rdpy5ni+eoVaaIUFRrFd571JnIHjnrbNubTUNF7p4Aw6jMsXF+glqtSbPpEnVqzZbLHsZl0KaeU/q4Iy6tgaa3g9fiKpVkQBoPSW0H5defwFpCKSGQpRM60y7SZquPIMtTojByi6z/TWpXeVTrrHyHp59+iq/+1V8RBAGNRoPWtDPhpDrDKJeVnPtMOWM0GOucx0PDvM8e72y0WWos0m5v8PW/+hoA01NN+oMe62trrPXWOXvWHSVaHL8Io3lTnJNTViD1lwRKESqQJoUijyZIaM3NUWvVCGIQ3pk/GK6xvrGASVPqDT8nkimM+X/be9Ngy67zPO9Za+3pzHfs7tvdQDcaBCmCIikSIEWKEmVJsWRRE5VIjiopRbFZpapMpfxIJXL8xz+SKjuVOEMl5ViRnJJSchTHsSOlrCimBkZRiQIBkCBAAgRATD0Pdzzz3nsN+bHW3ufciwbZJBrdYvd+UQf33tPn7L3W3ues4fve730FaZbS31hjeuCZbJM8x5YzzFBTBN7d0JRMSk0R9OPfF74Xvj1e9qEOvzkIksEIljwrnPNyHXHkJyk8IzCKFUIYSpNjCEWkicGZIZHr4ILmaNxO6a71yOcjRrvDWt+/l2UYY3wIMkzuxgnM0rhjWn7AHe/16UrDeHSJTuKv2bsfWeXMSg/7xJe5fv46DwepGPHeD4R3a5z1NUJm8hz58BmkWkNmjyOjpfCQHCA/8BNsfNATQV783B8yWDnPxg/8KO97z1muTH2o8OJIUpIxm02IQuX3ncItTQRCiBg/Cfy2c+6fhaevCSG2wm5gC7h+qyddXjdUa+26QUqSxIo0AUxZe3fGWYfBYI3eYIU4VHwIVyKZE8cFLjfoUNESqzZRkiDjhCQMEoP1VYb720wPJpSFo9J/T2SMNsabUBwJlJnwxRqFWHOSJGy2usxFh+Pv8iPxa3sHXLoyJiah/f6PcuoxXxBGO/GrAgPxil8Bji4r+oVlriPmxtIO39zSSmS0wvpjn+DUh/0K5dXP/gXjCze49MA+9kSXl0b+qk135uyMDNVHEUC1T3JQvgoDyaY9YC3kadethN0R09GkdmVKVtbpHd+CThctLYJQuJX0AUUSy3oxI4VESYUjDKCBpbF25gyT/YeYDm+we8WzOYqDC0RpQdzrsD5IOXvMDyrPXVzc16qCSzjnmVvBz7bSj/ca+BG93oB2EAMTKvLsIizWwTxQUPaNYzQvMLElCvc9MY52OyNa6RHPBn61C5i5BuG8BlH48Cm89IB1h3MZs/mEJI2wRbmIeStBFEnKsuBgz7Ovnvni05x/43W2NjYZrA1Iw4BS2AInIC/zWucK55D1atjV0seDQZ+NjXVubN/gq4G9cu7hh8hNzs7+LtsHO1wMUuWbgVUERxivdrHLqSaLVqxIsejZhDjsEjqDNdrr66hWgowcMnyvtJtRmBycYV4E6XA9oyUzCgGtlQHdDT9xzUcT8nEO2mDC7FPMZkznBXNj/WSw3DTn/CT4pjSMPCQnEStBoiKyJKqZQK12myhSCGnJC11TuH3+yYbC0rCAUIq016e/nlPMSsYjP8klSgGOAqUAACAASURBVNGKFYVRS14/Ztn3h+OB9NHdOIkqxvRPnWEg/XVoYZE3vs7wxS9DLtFrJ/ybOi2f1cfhjD9XWY4oixwV63ohtkAGcpP4XR8CYO2rL3HwwssMNs7ynnNnubLrd1yjly+zn2usc5S3qpV/m3ArrCEB/AbwgnPu7y/90+8BvwT83fDzd2/1pEcN5FkSzoqkp4wmQmB1gYj9ajxrteitrJC2M29GAjhjkBjSRFDkXkcIvHMZcYJTUW1rmXW7dFcG6NxS6LK230tFRCkl5U1oBd1ejMlhPg2DcGGII8NP/uD38WOP+Q/AF379t5iOpzx49lHe/1N/lfZxP7AWEi/Gpdaw8U/451rXOJg9h+t9iO7muxBqQZktELjVk5z8wA8DcPHpV3E71xldeY5W792U1n8Z99EU2eHB66Wsz+VkQHcr5UR7wruDnITYN5yfTtnPC+j696ebx2itbyDiBGtzCBPBYHCccW8TmU/Y99Ei+q0+mYpJRYSQklm4Zsn6BquPPsr6cIfR5Hl/bUb76P2IlVaHTESM9w4TyMRSGa8Q1UTga0VUOG4sIZIxWdYhCT4HSsUItKdvWq//BqC1pZiV5KnBpIGJElnPPum0kCurDINDGGYGToMQ9YQYeSWbN00EYLz/hAJT+olkuL/LqZOnEM7y3Je8lMSTT36BLI3pddtsbKyiAwut1BonArPfLj7TSkmyLEEKgQ3Kn71em96gw/5wlyLo5jz3/FdY3Vzl4pVLjGZDWiHcWVRSEyzGVSlVXSNhhaRy+VNGEmGIgU7LX8e4v0LS66GyFKRA4FecWXuNrD1E53PaPc/Gi7Iu1imMUJQypbXqB8DeqGA2u4CezyGqSBwJkTS4osQdSTlWmkg3ix1EMiGL/TGSyBFJR5okdLs+5tnudJCq0nxS2KBzJWSEsRJkUjNrLBKZtugM1pgPp4xHofpcGxKhSFREFNqiTdihBbQC1anVj7HzmMwNYOSvmZwcULz+NdTOJVbXjjN47CO+De0qbBMhY79Lbg1SJMewJLho9ShBHqRCBbLFsfd8hP0nvsDlJ/6UM8lP8+jWxwG4uvc5Xrh8HlzB7q7fJWyu/+WpI/gE8IvAc0KIZ8Jz/yl+AvgnQojPAOeBn7/lsx7ZEngygf9QSCKUVUjtY6qdFb+yXFtfpdfveNegJTsMRUSadMlxmMCul3GbwrpgfBI+LFFEp7eCmVlwE5iFLbNwFAbmvPkDOzuY4mSECCJUpZ2T9rf4qff9GPn/9Y/9i77wJKutU7zrr/wU69/zIQjMDmkdwgqsjOlv+u1yPvoEr9+Ysr7+fbT6W/VEYK3DIIg6A85+748AcP6Zz3H+c2/gLl1j9fj7efemVwk9v/sSadhhVLjACNs9xne/9wy9Fy/zYCh8KcyM3XJO4iStwGteefA0ca+NxQUX57Ai6m1xbOv9XD5vuTz0g9K7yEhMCORJhw7XfU5EvP4QJ99XkIfV1/mvPIeYHxBPDxiUG+TjzqE2WmvqC+y77e+PEo4yODdJkZLGEULEqOB5nMoEZ0uc8bZ+rbAj6BlHOS9IZwVJ6gfWdqaQVuMiQWdtDXndr94LewClxkpRS0wnyg+e7shdj4BECaRMFnz/N17jgZMnGB4M+eKTPt/z+isv0Wm1WFnpM+h2KOZ+0pkVBWkrI1YRha5c9/xuRpcl8/m8XskmScLKyoDtG9cZh3v2+huvU6IZjUcUpqwF+YReSExUc6qrGVAWR0ys/ODeiVMyNLYs0GFXsra2Qbs3QCjP5rf475tKV2ivn2I8n7Ev/ADYUSlZnFFagZIxMuScsv4qrd4e06Ks1VgTERFLRawkWh9eTXmZjiUIGUKEilaS0glmPtLlOGeJklW6ITfUancwNkcgSJKMIvGfp7wsKGRMO+1SVGwzvJatiBLSfo9sL3xfpwVCSGLpiEND5s7W1+0QJIhMIUyGEX5CJOuwu3eD2d4ux3/gXyV9zOf/qNlRClgJvyfMteCidQxsQtg7LAbYSCEe8oKU0Qf3KV59AX3hMvOXLnDsUf/8ezfX2d29xHCoGR8Rlnyn8U0nAufcn/HWdQ0/cnub06BBgwYN7jTujuhcXbBTZblkzdmurEoE0Gq16QWmUafTIorwFaJisfHSTrI3h71S1KsUPSvoxgmJd8UGPGuk1e5QtCbMJhNUkGyIpSBLBLlTGH14pTAsI6y1ZKlfsbZbKzzy8PdwdfuAr33hdX/cYsDaqXOce+x76az1yJdiewaw2vKFC28A8HtfPM/wWguZX+MTm1N+vOUToivK91fYGPmAT7I++qm/xsGLL3DjlQnXXrrAsR/yJevfffoEs+n+oXYen1zj048+zmOPnsCu7bAfPJK/dP0pdidD2p0Bmw+eAaB/fNMra0qLsCCCYqs2lmnR5avXI14L7nuX3rjCQ1mfB1sdNmJJEuIyiYwR8Qqd4w+z9T6fLN7fvcz1166RjPbZKCPiaCu0zgusWWfqYqyqgtDZhX8rQBzHRGlEHMu6sGg8HiLMFMoCqzVpCNf0rKUocuRwn1mQHd4+EGgzxwpQSZdpOK7BEosgwlaFawDl3Ju+AJGCspjT766wE8T7vvrlZ3n8Ax/k9Ree54//4P/x12sypb+2zpnTJ0mU5Oo1v5W3wtHpZFirmU0n4doaslYLHUVcu3qttolcX1tjfX2Nvb11ilA/crC/S7ffoZ1miFJwMPQ5GL0cwqpIOLK+lMhIkKV+pZopSVQYtFR0V/2Ktbe6goxVkHuw9UFyo9mZFFyd5OjYt2tN5qwpRb+VkiJQwbM76fRodTq40RgTCjWtkLTjmKKcUx5ZLgoh60I8/zcgJVGkaCcxcShKc87S6g1YWVul0/W7GmO1D9E5g1KLBO9Ea1yasTObsVK1SwrPOIsi4laHtOPDS5GbkWufUk7KqmixREU3G/YEQmaknQwRhzDS55/gxpdfYtA/QffD34dIWovrX0fB/Od0dv0GX/jTP+MPJzkf+/4f4Ucfedi3YVlDJbAdow+8n/VL7yMavkIyfoKk9K95ZHPAhevrXN4ZM2kdZt2907irfgSL4XxRVKSERKmIJIlot1Jamd+uJnFEJMGJxUTgBGgn2Ms121qEmnZwsxyZZaRJRCKrcnNBK2tRtFpMkhgVWF9KKlIVk0VwZGfLNIeyLJmGkvP+1g/xkz/xc7hn/yGj3SAFkZzgzMd/luMfeBdFDPLI99WYGTcmPqL25e0rjGYxw8uvol9+mR8KpjBS+YexMJM+Jtw7+0nWH/lz9i5+ltnui+ye9zH+R7Y+wfbuFw4VlH1k8zTxQ1uol1/mmRde4dnzPkP7xqVt0rlldWuT/qYfmFWnG8psNYkEgk9BXk65cuMqX7t+g1fDl/yZF5/mvSrnh3ofpZutU/nJRZ7eQ9nqEG36D/zxh7+XYvg0V7e32b9ygYceft+ha2ndIoLsEF6hNMg66zBgE2fEsSSOHGVIXE7mOcrkCF1CUSDz4NSmNZEtsbMZw7DVH+mcqSkwcURr7RijEG5xwngxVGeJKo8BY1HCot7EELDs7e4gtWX7iuc/bF+9xmh/yHNPf4mXv+ZzIsfWNjm+vs76oM/u3i6XL3gZkjiJGfR7RFFMEaqC50VBHEXMi5L93V2mIYadRhGnTpxga2uLPPd39OrVq8wmU/qDPsZZXFicFGKhQ1nTnC2gJEpI2mlKFuIfQhcIB/2VVVZDoVqrky75A2gILJz5fMLewYRr4zk6yGYrldPJUmzLV1qryuWv0yLr9ygPDjDat1cJ6KYRs0Iye1MRofC+D+FvKYXX+4+EN6EPcfss69BfWaPb79UmOF6b3DOOSl0yKnx7D/IcS4KMZmRd/72MlPIyFioibXdo9fxEMMk1VufEStEJg/Dc2ZpBdxgCZyVOW9w1n6CfPvUE5dU9xg8/SrmyTlrlBuqPzKJv5ycjPn/tGl+6MSJev8jHtzyZpLNyE1+BlT6dH/xBuPI8w6++wGDiq5NPPPh9nNl/kK9duc5Q5m9+3zuIvwTGNJ4gHsVVvYCilcZ0W21arTZxqCyWwrMLjFjomxsh0M5xUBSM5IKfKPOc9mxGN4txtfMTtFspZbtNlrVRVSLRSWIV0YojtDks3GDmGiIojvuVwIf++ic5W9zgz37/T+hM/Ert5Ed/jEc//ZPkG6u4pRVm5R0lABdWse04YSYK2mlBtxPX2jsSASYIo4UYeGfzHGc+/n2cf/aPKa8NERe9bETn5AOMWyuHJoJxMmD88kvovRtcuJJz5RW/Oj3Ym9AmZnNti/5x/8GM2m0vpmYdRjlUcOGKRIEeD1FRzGTmdxyn1lc4lQlWsSTGoSr3rDCAqzij03sAgNWNCfnWLsPhHvsXXueNF5/zjQuLKBlYQv793pvMWi9MVomVFUXO7vY1DiZTCNTCAotyBuUswtqa42+sr/1QjlqfRuIonUVrw3R7B50HvSPlsJHCOFEzy7xJkatZaRWEcXzpiad44ORpzpz2fdt997t59esv8//+6efqGoCTxzZ5z7lzJEIwG4842PYUyyhNyMdbtFfX0SHOa3VJrATzaU4xz2u5kERFOG3ptTsc2/CDwc71HcbDEVhLe9CvmTUuXkxYdsktTTpopQn9KCINjmxWl6i0y9rGCboDPyj6AdYEOQjtk+eALQuctggr60psYUIy33kpu0p8T6Qx2WDA/GDIdBZW89qQxhGtNGVSHF5J1Q5h1bUVkghJAt4EJizSup0e3U4v1ItUOgOLiWBWaqZhlTa2jiLPSdst5mF3l1mDkhIpJTJOGKwGJ71pwXRWIqwjrWoLUokRN4m/Wwdag55TXvOLPPHG83RQbHzocdJTqzcpv/WOegC626VcT2E0YjKGWV5JrNxkIrARrH2Azkf/bQ5e/O+58ZQ/38kH/wqPvPv9vHjpJW6cv/Lm972DuDuicyEk5PDJ3DSO6AQGgbIlojCgYtJuSlaxHqIIoQsSJWptFWsMiRRs9Qd0ZhpCgnGl3WOt1abtQAWGRoRDW0vW7pB1ehjnKVtloTFWIhC01eEijkKX2DTlhx/2YZlP2m2e/Me/z8EbmtX+WQDe++HHWNkaMI+gRNSeCApvZuKI+cgxvzoerY/4otzh+MkVfmBtwEZYaTlD0Ex3dfJyplI2PvIxHvryx/nK73+e2ZXgJ3v+AmsPnGSZk/P/vfQswxsH2HyEOLhBFpKvqrQkKxsMHjxDK3DXUQqkDV9QhQtfxlaccXptnfbVK6y2PVVxJZI8kGSsA7Ep6xWcxnjRNSdqUbOVzTXmKwPWWm0mOyNeez4Uxj3mQ12erbMcIwg7AkAF9UVnNNPpCDefU4aVuhESiadfSufQVe2Fc7igVlmFFSMpsUJgjcOWQ0QtjBZ0eXB1kZd2jsI5yiOUxyuXL/GVL38ZqQ3vfcTf9xPHj/PVZ5/l/GuvsT4ImkKDHr12G1FqytkUgtKoNBKdz9D5nGLiFxsGiys0ZZ77FX5lbmMdw+EBpTFkWcWKERRlwfb2jIc3Nuriyajz5lBBZbOaqARVWmwIp2Vpi8HaBnHWqv3Bo8hR6Fng9VsUlRNYiyxJ6GhHO/Ozdjt2YAqwyvtFhM+INo6ku0L/mGYaVH2nu7skQtHO+rT04TbWUVJZhWUEkVAkQVMqDUnXVqtDHCcIZ1FUrnB42p1xWCuwIiwIY4c1gjhOFiKGpprgFDjodv090oOcg/0xep7XMiStpMUhFaxaCBFEFCGKgsmlrwMwuvwam6c/QP/xj0HvMEGjQkW2Xs0yfvDRhzi5ssmx7hlWolAAZ62fYKIIKrvRJAHdgfgc2fp7GD75eX++P/4CGz/1w3zyQx/g2tCHFac3PevtR+NH0KBBgwb3Oe66DLWS0stBhNitNBppBKg55XTKdBoURc0M9JRUqSonjFYCKwRyltOeG0SoL4idwuiCiYT5chUmFqkSZlrXK29n/f8klviIZdUDa21eKro8NPhZAI7fGPLKy88R6Yit498PwMn3fIIoismmftdRF2MBWEfmBI+d8juCs59c5+P7uwx6PR5e2SIJO+nCulCebzBV56zDZWd58N0/z6UnL3JwyVcW33j166xt/VWIFvV7r118HjsXKD0jOriE3vdhpNRajh8/yerGJnFIkPkKf4d0Pi0fhWrqFgnnTj/I91vNVoiWbCL5rpVV1ooctXuDIoS48jynyGcU8xwRwglqNGR2sIM0hsgWDIfXw3UIOwIpqquCCPsRKZ0vWgsCgFL44guRxmQhWKyFj4FbazGlrlVNnfGRcrcUctKEPYez3k/ALnYPs9JhXagmxgveGQxH3BV55umneP311/iuc+dqSmgSK55++kmc0aSxv47tLGNv5waREhTzeW1Un7RSpLVMDg4WK0ABs8mYcp4TKYENK+TZdIY2NyiKAl2tU4VDSclsNvMa+1WxXbLYrdZVxtKTIGIZk0mJCOETmWvUXNO2gtXqtaNdFJ7S6cOP/vmBlTw8GLDZ0RRhOEgjS6JnqP0ZisWOSwIUmjg3tQz7bl5SaIdKWnTF4R1BaQwqUrV/tYwTsiShHUnMdEwW+1V2IhSZVLSEQwVJDCllqLwXOJkgQl1JV6SotIVKElrhs5Dh6aE+yKy8zzjQ7/RIZMxUT7GhOtQqT3aoEXZRxhqUULhLV5n+ha8VKUeK7kc+SmR6UGjPOfav9iXd1iLD+0+2Mrbe82F+6F0KZzO48RoAepZirl/GHTuGu+x39fb0g6Al8fbzxFdeY0AQmnzhz9ArinPf/4N84v1+R/HZlyvG/juLu5QjCEktIZHSF4+JotpaexEAK6bs720zD6XwSliK0R4tqTBVgi9LiLOMcjxGWUEUBpqJOGAqwC0P7MIbnsi0hdYLTryMfJxTGsNRu5r3DFpkW2f5+Cd8qOTF//1fkG/vkrkuo53XAXjyt38N9bvgIkkZCocAb6wiBS6KECHshfRnKNMW+yquDSlkFPvts3C1lk2kFLYQxNsHviAptC0+2GN4+QacW7TT5FPacQ9dlIy3ryF2fNirG/VZ6XTpJAoRKiDNNAdTYEqN1po88NMnRQ7FmJPGko79azMLHIzZzV/Blnld1DTNc4oiR8/nvrgIcPM5dj6mmM4AR2T8ILiIGi+Z10twVvvKXhsuDH5QV0rghK5ZIgYBIsJiKZ2uY/plpW2zJGIkqmplBLiFPLMf/l0YWBahgGULwwpfff55Ll+8RBRH7O97+tR0OuXpp59kozcgC3IjcRJz4fJFFDDL5wz6PhafZRmz8YSiHNVJSe0seze2MdYRSYUMftej0ZDZds50OiUPCrdal8StjHa7zXA4JA0mTMWSYmYVR5dC+Up85YhNAdrfC2thtnON6/MpwythASCKOhjnnFjUTzgX5DAsJuSnpiomabUwkzHR0kQg8Mlfq0umUz9JKj1DuQQhHC1zOPYeZ16NM84CmymNibFQFghr64l2vLvNfHKAVAYhKh9i57kE+EWSDeXAxnllVSSMq7oUln8KKgMEqy2T8TgQIsJxpSJZslGdhc+/wMBoRv7Uk8xe8iy/tlyBaRsrwB7sUytiDA9QhYHRGDHy3zVGO5i9PUZ7e8yGB8ihJwTMplOmec44z8nDxDWdz4hLzSlj6Js52vp7P0lzrr7+Kh/88Kd5IDsVWngPTwQLWdqwkluK0wol0Pi4X2nGjHerYiOL1JoCgQ3vt5Mc1CRUGC/iXNXa06+xPaohQcqxL+Cq/GSNQUqIoohYHb4ckzLnQ1uKvWf/RwBe/tIf0istgiHD608CcLD9JFY4DAotVP0hdEisgFxJVKCdGVNidIHXW1HYkHz1Ji2Ho3RS+gEtdg5ZTFFhAFTzIduvPAPnPli/1rmMiJjZaM50b0qn8L1txylmMmF07TwuD4OaybHFHD2fYWY5eu7Tzvl8Rj6foCcTRNCn2S1ybF5gi8J711ZfxooJYhcSDTbQepUQiKTlv6xLcM6FXYHfnRln0MbgDJiwQouFwCmBsUXN4DIIoijGGkehNWW4b6U2lNocuW7KXzcpUUHnxt8LC8LVnwF/zRfmLsu4dvUS3V6Ll176Gi707SvPPOPlJiJBGVhWr59/DawfuJ21DALNuSwKtnd2iKJkYZyCr7I1OIxz5IH5JJRCaw3C1mQJFStEEhOLBBUltfjepYPLdRsrsoSKIYoFQmqKYoakGtTgYHLAaD5D1FOxT9FX37QjpV+hnbK+5irLMPPZmwyQ/KGMj9+HkxkKUiVqgcgK7XYXU0ragW2TRgaXT8jLEpxkEq7DTB8gJr6NgptXIy+0yKpv92J3V6ciqJYblVy3xRrvj0392bO1CxrAH//ZUwBs9Hs80h4Tv/rn9Kd+cC/KFvtP/Z/IZ36Py3LE6sd8ZfH25/+cdxUFsZBEQdBKCDDW0kpbZKVDVQskYVGdNgd5zmDd6w/lwxEtfI5rGnfghF/V7RdDzrzvo8StLZIr90GyeFmvzjnrpSHCF1wpicFijMHGqtaPF/iBIteuppg5HOWsQCiBk7L+8EjwicKQPKxeGyExhQZr61W6wfOxHSypTnrsYWlfucZLB8GM5LhEtqZ02ymXLwVlS2VYX4dLlyOEaNefSs+YsKgoIQ0TQSwTVjp99veuMxrntZXiW7pm4Acxg8NV7BEMxewNYDERDAtI8hmMJpAbdNgGl4VmdOUKo91rTANLpNClX82XGsyiyrJSj4yErI1PcBaBCzurJd8AqTBITBph6liYRESSGOlXZv0VluGcq0M1OIE2xht/QS18VwqHsgYj3JKrlcAaFWQURH0dhJLULV3QUkBInBBhD1Ado5IwcdTLBVfP2W9qZ5Ik7B/s8eqrPml48cpF4jRGxRHzQHUdz+fk8zloQyQlRUjQV30UQnFwMAzXRiCjCCslcRIj1MJXQMX+uJXxu1LKi9MJQWGNN1uBevIIHV38EA4jDAWGOIQulIq81pxQS8Ju4Q0L151D7XVUg6xfhWMtMklu/tF0BhXUS5F+YaDSpJYKqZAIhU0i0spTRPm6Hht7N7JF0nYpWBwG7FpVVQL28KDvP40LWZpFoFkenkCExEX1r4AnFCxXFv/5X3hSw3vPPUTv9Jhy52vY4PCHc4jpa0hgiOOVP/gXAKxIyXkl/H0Ni8e424MoZjYvQSS02j7sJWMQsYI0ZRyIL70zZ1GtjCjJaCUd6PvXfuDEBu7UYzzzxB4vXL4lj6/bhiZZ3KBBgwb3Oe7OjqCWofaJPGNMKCDxioQCidEFkUoWq1A8/cwYTRyoYMKBLgukStFqyfkIsAZUFNUztt8RgDFThJKo4GZW2expbdD6cIxzJBOuaMn6SZ/w/N4f/STvOrbOIMkY7Qd+tp2RxgeMRisoF0PQMsd5+Wc9KzGFn2+jSLGSKg6Ge2zvj7HzsCYqS8rCoEvtdyyAKWfossTpgrLMa1E8h8MmmjeW2nll7yqdWJFObiCLYZ0bmc8OMLMhkXC+ShNInSXGgYxCiC7w6qVCRT7nUhVYawNRIpGZQKQpSYhXCwcijrHdDvOKWih89acoS3Zu3CA9VamtLK5pbf0Ydgd+RyCXZIotGocTpvYWRsgg3uaJAfXz0iERfue1VKFerXir3ca3iiRLSNOUaT5lesVT+HI959iJDQj8egCTpaRFG+kcSRJjQjgtiiLe/+j7SLMOr77uE/zGeunleVmgrcVU4biyIFKRDw1WjVUS4QRaawqnOQjFZ9PpwgO6ul5FYTCuJJURUZygQiI7ydpERDhUHYatDB38LqpOzvjEugPtFutyERL5SjqWrKb9ZQeEM1QVtRqLIkIb2D8iNGj0jCRpg/G7JScsSdpCJS2EO7x+dyFrUxeLupCTcA5r3UJfKeQ3hAQpF6/1bRMhZRTuka0ksB2VaaYzmmK+KNa6ctXfI2FyVu0acrzGI2d9TUekMtpxhp3O2HCaMyHcaaIUkWaQtUhXgw7T5jpZr+8lyy2oEHGIBl0vBZ5l3lQFoN2BJMLFqa9WrramGvavnuezX/yXfPHAh4YeOfVW6j63F+KtjNvfCWyd2HSf+cV/7Y6dr0GDBg3uBfzn/+U/fNo59/g7dfwmNNSgQYMG9znuSmjos5/3omjz6Yg4iuh1e7W0wmw+pSwKHxqKFEngTxtr0drLB1TbPOEsRTED62UnKhKOjLwpjS117X4lhCDOEpyUmFIzDyXgRVHgGRWS1eDQ9OP/ipeb/bXf+uehevNw+5VStdZ8Fd7y51i8RuC3rHLpOWuMpzhWNNOqHkKXnt3A0XCGD1sJoaj0ZZzzKb1/9zP/+rd0zRs0aNDgrXBXJoKk1vPukSZtkkQQx1WBV4GxGmMjjDHkVTxPSKwNNNEQl3ZWM2gldLMWpYGDoO1SgmeFOM8vqN7vrMNZjdUaGzjXyjmckDgso8n4UDurqNlhW84joTQHSiiMM57EUTEvqsnhsOYmSvAm2ptbeixDENxtsIujiIUzU4MGDRrcDjShoQYNGjS4z/GtmNcr4CngknPuJ4UQDwG/A6wBXwR+0Tl3S7Y6WSVupVKiJKO72qXf8+Ja05dfISo0IlYUxZQyVONFUYyU3rquWh3HUcqpbkYLAVFC3PJ0l6ujoWeSHAnpeHaQxhpNFNgUJRqsQQiw9ugbDEKoegVebzCsPcR3qN5/9ITeilHigtSA0b7kXsZVTUB9hJszXCRgZQgLVa5sEnekArpBgwYN3g6+lR3BrwAvLP3994D/2jn3CLAHfOaWj+RicLH3KG0nDNbWiNM+cdpHqZQ4SsnSNlGUeLVMpWrNFR8z94NsJ+4Sm4Tx1evMrl1hEDsGsaPfiZGqirkHTU+xoKMZY3FOhgc1BVEs0cyAUKBU/RQIGehpcnHcqpDRTwTu0PkkAmEtwjiEcUhjcMYirUVKgbDGP3ChkCacQx6ZUJZuk58U7gylrEGDBvcHbmkiEEKcBn4C+PXwtwB+GPin4SW/CXz6Vk+qdYnWJXlZMC/mjHZ3lfglYgAAFxZJREFU2dneYWd7BxUnSKnI0oQoiYlbLeJWC6IYqSJfG+As0lk6aeTlkK2ByRAxPkCMD1iNU2IZ+RW8H+kB52sWrKMwllxrcq2xQS7BWou2Gm0X9Y5CyEPx+/pwFsIMUR/+6CP8q+dk+zpcr8JvHRjjPY3DoO//c0GDx9UJbr8JqGo7g4iGO+qy26BBgwZvD7caGvpvgP8YqES514F951w1al4ETt3sjUKIXwZ+GaAf9FhM4ZOycykwtmQ6m1MEHRttDJiSOIYkVfTbXlt8NCwo7RhcSZb4oXClZclH24iyIHYOG4puOp3jJAqmoqxGbaz1RVXGGL8rcEE1UyifVLYOc6Se3hcqycOsISEQUtYFOcYtfOuOsoYipUAXdUm7FIAzOKsQZmml77zEmrM3CxDJQ2Ejh1gUCTVo0KDBbcA3HVGEED8JXHfOPb389E1eetMwt3Pu15xzjzvnHm+3s2+zmQ0aNGjQ4J3CrewIPgH8tBDiU0AG9PE7hBUhRBR2BaeBy9/gGIeQVjZecYLEYYuiFtUqjCVSoIy3N6yKA5TKKJghhWWl43cWdjxB7x+QugThBAT6aJuSXidhOF0ImnkJXYsEkjimCLZ61Sp8iWh6BD6fwNK/ezlft/R72BUsaZpJpZAOdGlqSmkUxVhrMKaESC3kfQVgggpALSVRPWyoZTiaJ2jQoEGD24NvuiNwzv0t59xp59xZ4BeAP3bO/ZvAnwA/F172S8Dv3upJVZqh0oxWq4uIIlorA9IsI80yYqWI4ggnHFYo5nPLfG6xJiVRMYMoISsVWamY3RiBTRHZCra7Sqk1pdbMdy5yrONY72U4YXGiKsYKlih2IVsthaBStFeRz0EcvjxyEfvnsHhj9ZyHDSwh5R+ACxLFQsYIGZNmfdJWCymc90AIZ4iErCcBIcPjLa6dEPJQ8rhBgwYN3i7eTkHZfwL8jhDiPwO+BPzGrb5RpSFEpBzOWtob69gglyuHuxhpSdMERJ98HmSo9ZhYlKwkEM93/HPlAclgwHd9z4fZzye89syfA1CORogbIwatPjsquERZ718l4wyrS6qltwzW3EKqt4jRH8bNUrX1bkIsKomFA4xBIIliT41Nex2MlpT5DGcNItBVI+kleQ2LCWC5JU1yuEGDBu8kvqWJwDn3OeBz4fdXgY9+OyedBXejOIKVtQ7rvQ5MfFhHzyS5M7R7fXQxoJyPwskntFNBLxHYqgJYafon1kmPrbIerTHeexCAqy+9jhnNaLfW6QQVwFluKK2lKMxCF7+GN4r55v0HqClB4UmJc8ZPJAhkpSRoNViHUoqs43XI4yxC6JQ4TShmBTbIfIpYooTCYt4UGgK/C3F1HUGDBg0a3F40MYYGDRo0uM9xV7SGjKkStRpcm/3tq0yH3s3JlAXrmydI2mvszicUudc4V66k11rBjsdMh17PvZ0O6B47hez3cS4l7T8CQJzuwfyAFm02el607oopMaUhkpAbXa/GHQaJQCrerC5HFfJZPH/E4KnWTQev9l55hVvjKaFZ2iJNfWhISEeUxiTtDmVpMKEN0lmklEi3ZFZmWbIZXGjQI0STI2jQoMFtxV2ZCKzx5QdlMedgdx8HDA9CuEcKknnJbH5AMZ1gCm8O0lOQzgvynb2qNIDW8VP0Tp4hlxZcRG/tNABp/yVm13fQox1ObPnJYaIFB+MJ/U6LqTbs7vvz6WKGxSCMq01wKvhqY1kbvYjl52u3wJBrCMbrhL45XSJlTJK2auOUssxxIiZpdSjyOXY6qQ6IQmDFYpI81I6l3xcspQYNGjS4PbgrE0FZBGNnq5mMfTHZdOpzBHGiGO3v45zCFHNkKMZK4ww9HlHkQ5KeH7BXzj7EcA7DnZdQLuZE308Ex84+yKXhDSZ7c0TL7x46aZvRdIy1c1Y3NpDxKgDD65eZ5vtoZ256Nd6aVlr9u0OIYJiOw5Y+Oe0cyDhCRTEmTA6T8T6IhKzVJckybO7bZnTpJyEhah9XtzTcuyVzXYdrxEcbNGhwW3FXJoLc+IlA5yXzXCJkRFlWQ6BBR1PSpE1ejOhkPqzSSVLK4S4ujelsbfn3tztcPf8au5deILKa4pw3nT5z+hyj6yfZOf8qergNQLq2gTGG67s7tJxgJfN2dMe7A65LwWg2wh0xr3fWIdXSROAq+SGJdYvXCiQScMYgwigtpSLJ2shIMh775Ph0NCFODCJSdFopWQgZzcoptiyQSUIcoj6mNtg+rH8kUI3oXIMGDW4r7spEUEkuGJOjrURIg600fpzCOUuRj1HMOBZkKeR4jJmOUa2U7sYDANhEMdy9zOj6Plk8Q2svR0H2CJ3jx9m9eh5ReqrpIOqy1u1zbX/E3vYBtuV9DjaSY/SyLbCWWTk81E5ReccswvM4/CBd++QiEEKhUGBLbHg+STtknQ6lLslzP/FZJ9HGkCrv+atSr8Iq5jmmNEhDHZ6S1gVia1W/sNgVyFtgODVo0KDBraLJOjZo0KDBfY67siOYTnyoBGdwTmKNrUMqxsJwMgJrWckSmPndQ757g8zN6a1tcOKk17fblgnKCDJpSAQUwQ0h6XQYnDrNlVdfRW9fAMBu77G5eZY32hmT0T6ziT/uDgdsdVZJaXN1fNhOQQiBc2aJNeTnTSlVTe8RWJSCSFi01rV7WtrKUHFMksbYMtRIGE2ctrAkqDhFdXyfi9kUp2c4W9arfUmVGK5oSv6HDU5oDRo0aHC7cFcmgiL3CVUpBEIYrFtIP89mOVJAJ01pyzbFyA+itpjR7mcce9eDxCFcNDAZp0+cYS73sEXBiQe+yx83Tugf3+L4uUd5Y8/nDdifoZI9TvRbXCsmzMKYn8+3KTuWbO2El4hegtf4OTzsSgTOLmiesYpJI4WdTRDOECU+3BOnCSpSgKPb7/vj4YjilLjTQylFFAqss34bPZ955dXguxAp0IZgucnhjPVNaK4NGjRo8O3irkwEugxVshKkWMg4e3jRuUGiWGk75NDTPAslWNl6iPbmGYzyzc4knDrWRcsus+mczVWvkl06g4sEx86eZvfCGgD5lQuY8QGD3jo7sgt46qYzkuv7IzZbK3RXWofaKSoH+qWB1zqHELaWkohV2IoYRyQUcezrFuIkQSpvZFMUPh+hZI7CIVyMcyk25APitEOWzRhNpsiwM4pVhHYabcIOYMk/2dHQhho0aHD7cFcmgkrYrR5fxZLZuxOkScJab0BmZsynvqAsTTt0N7eIWgPKsDwu5mPUfAflJihVshvCQN1OD+IM1cnob50AYGf3BqaYMYgSVtY2GF4LFFajKQvDaO863W7nUDudc940Rhz1G3CL353DWou1oJKUrONX/1GagHDoco7JfRJauRkKgyJCimSR9I0zVLuDmueYstotKRKlcNbglgrNKoe2Bg0aNLhdaJLFDRo0aHCf467sCPqD9fr3KvlZ1UxFwrDZ7pGYlPHuDqL0O4XByVV6x49BHGECh780Q8riGnE5xVJQ5hcBSIuzROkAkcb0T3ghutHFa8yvX0KNd1lfX2c48xz+4V6BQ5HPSzZW0kPtPOpHbyuL4lBABoFSahxOCuJ2B5VVyqoKhPMy03Uox6IcWG2RyZK/QaSI2y3kqEoMgDMlCunlL+Rix/TWTvcNGjRo8O3hrkwEccurcbrgJSyXQi2dyLESpZidEWZekPRXAFg79wiu00NbVydwBQJNZV6j6tyBkQplvcl7f/MYAOPTZxju3aAY7ZNkMcfaPgw0GU3R2hvizO1NYi7u8LjrBCil6sIvVxY4Z4iihDjLkFFcv7EypdeV/pCUWASRShDLtQAC4lZK2mkxCwY9zjqQoKTEWLvUiCZH0KBBg9uLuzIRiJBpFbaiRzpkiIInUqHMHJPvkMQlgxNnAGitn8LIuDaiB4jUgDLeYhZNMEDSeggAGbW9CTwCmfiBefWBk2xfWmF27SqMCzrdDQDSZE6cluSFZh7i84dgHchQ2CUkQgiUUqhQhaxL7Vf9cUqUJEhZJw8IjUEkfuIzJSjVBpX5ti290klFu9fFTrzsxGxeICxEUYK2IKpqYtFMAg0aNLi9uKWJQAixAvw68N34cetvAi8C/xtwFngd+OvOub1bO21IDEvCgG2IwwK5m7VgcoCxOVmnS3vND9je3EWgsah6IojRyYB90SVdHdAdbIbjS5ytBm8/MMedLr2NLcqdffR8ysBvNDi+uU5uSrZ3926i4SNwcmETKfAKo8K5WjjP2iAn0e4QJVHthiZDXMkCRgYpCaMRTtJNJGqJ/eOcb2eUZKRdT43Ny12vVwTECnRdR7AIozVo0KDB7cCtJov/W+APnHPfBXwQeAH4VeCPnHOPAH8U/r4l1L4u1nruPZr1dsx6OyYpSybbuxgH6coGvePH6R0/jlXSyzo4r9BpjGU0n/Pa3gFfH1uevXSDq/s7XN3fodCedmmMRpsSbUpcEtM9dgaXdTHlhPnwAvPhBY53U7qdAUnaQkmJksuXRHptIbFgDEkszhictThrsQJUlpK2WggpENjw8H00FubaMdeOcWEZ5gWj+YwyyFRXDwEIFRG1Wv4RJ+AsThsUgkj4R8VobdCgQYPbhW86EQgh+sAnCVaUzrnCObcP/Azwm+Flvwl8+p1qZIMGDRo0eOdwK6Ghc8AN4H8WQnwQeBr4FeC4c+4KgHPuihDi2M3eLIT4ZeCXAfqhIthoHwcXzoddIqGIQqXvfPcGcj4iGbQ4/tBDxF0fw9HSBa1/WVtNXtm+ykt719idFSSRpXPDC8wdWzmNS2Mi4aASuEPS3Vyhd2qLnfE2efA/aLVHqFYfrQtc8o3F3ASgkGANzvhluVKKrN0hqmJbRwQgrLXMC597KKzDYkhNgbaGGLV0bAFCIhPPOoqyFrowWOttMFWYs40w3IK1coMGDRrcMm4lNBQBHwb+gXPuQ/iS3FsOAznnfs0597hz7vF22w9y0+Eu0+EuxXyMtAUdpSA3kBvK2RShJGvHj9FdXfH0SQTOWLQuMabEOIdxjlavjcoiDArhEmLhH8YY0AZdarQ1aGvAaVCajVNbtFc3wEXgIsrhCDWb0okkSgqUXAzklcBoFb6RUgXzGeMLvawhUQlpkqCU8GymEBNydQZAIAMzCrw1sowihJQ45xbOYwR6ahQhooi03UXGifdDthBJ/1BC0KQIGjRocDtxKzuCi8BF59wT4e9/ip8IrgkhtsJuYAu4fqsnLWd+R+BKTVtYep0UmQchOpuTtPt0+idxViJM2CqEAVAIUVtDRsQMsjXylqIXK1baXoY6ldJTdHCIQAl1DoQ1JEmf7uAU4z2/I3DzCUmvxXpnlYPyiOictH4CCH8r5SuRrSmJQgI5STJipZDCYZe4piK4CCRRRDvzshOl01gZE8vo0IAuHAhnlyYPSLOMeZpSzOfgDDLsHpSUtVlPgwYNGtwOfNOJwDl3VQhxQQjxHufci8CPAM+Hxy8Bfzf8/N1bPakI41gkHW2liHXOZN/PI7bQqMEmQqbkkwluGiwlpcIJh7AWFzj4sYs4l7TY7BiSSLCqPFW0HI7AWT+4VtaPMkI5g8slUsW1uFsxHyMnY9rrK4yO2EQ66xCS2odYGuOVRJ1DBJ0gpSIkYIqcpTR4PaA7B1WZ2koaY6wkQSLmBbai0YadgcVgw8SlrUWqCCF8HUFVdyAVSxTVBg0aNHj7uNU6gv8A+G0hRAK8CvwN/EL5nwghPgOcB37+nWligwYNGjR4J3FLE4Fz7hng8Zv80498OyeVYdXcihI6UY/x7gFm4nn5SsJsMuTSay9jham5kk4IrJTIpcpiIxYpDi0EVy4un8MhWCR1kQrhHNKCKTW6DH7BBmajCa10WFtHLmOxxgdnS4TzFcvVir8oZuj9GUifU3CLVy8KxoIkhsPirCSIaiwfOexc3OL9UmKtqUwJamtMQRSMMRs0aNDg9uDuyFCHwT3SGlVo8rKsbRmVBTMZMZlMQ1FWMKzB4pw8pLzpHIgQ4sEu5Kxd4PGzZPRuAQSocMQ6ZIQAA8V0iHJH1EfDvy8kLSQODQ608UwgPTFIAdbZpaHfn1GxCBFVx6umALd0BpzXL/LTyCKnsTyt2JAXEEY1yeIGDRrcVtydiSAMajaK0ApyaYm7nlFUGOu1g2xomgg7hShCl16TqBr7jQGDj9HbJekFh0IIv8KuR+JDngJgpAttAasEymqiIwvtejIJB9HaIp0XnJPV8axB4iuJLfggPt5kXtnSvzM8Z51bNEksm964pQK78EyleCe8+EaVp2iYow0aNLjduCsTQbUWPyhLImforq0TBxU3KwQKhZBBvE3Y+qeyzovJCb8aN0agXQRIFA67GFeRzoDQ9epZBRKn9cM2hsWIa6yjNCWzIyW7LrS13jvEMTKw/1WYjby5jl/BWwuuSgALiEhZDgFp47B4rSUh5II1RLVTsLUCkXN2ib7q6tqB0hi0blhDDRo0uH1ogs0NGjRocJ/jruwI/sa/8dN347TfMv6dv/lzd7sJDRo0aPCOo9kRNGjQoMF9DuHuoJSlEGKEl6++37ABbN/tRtxhNH2+P9D0+c7gjHNu85u/7NvDnQ4Nveicu1k9wj0NIcRT91u/mz7fH2j6fG+gCQ01aNCgwX2OZiJo0KBBg/scd3oi+LU7fL6/LLgf+930+f5A0+d7AHc0WdygQYMGDf7yoQkNNWjQoMF9jmYiaNCgQYP7HHdsIhBC/DUhxItCiK8LIW7Z6vI7DUKI14UQzwkhnhFCPBWeWxNCfFYI8XL4uXq32/l2IIT4R0KI60KIryw9d9M+Co//Ltz3Z4UQH757Lf/28RZ9/jtCiEvhXj8jhPjU0r/9rdDnF4UQP3Z3Wv32IIR4QAjxJ0KIF4QQXxVC/Ep4/p6919+gz/f0va59c9/JB179+RXgHJAAXwYevRPnvtMP4HVg48hz/wXwq+H3XwX+3t1u59vs4yfxPtZf+WZ9BD4F/N94Xb2PAU/c7fbfxj7/HeA/uslrHw2f8RR4KHz21d3uw7fR5y3gw+H3HvBS6Ns9e6+/QZ/v6Xt9p3YEHwW+7px71TlXAL8D/MwdOvdfBvwM8Jvh998EPn0X2/K24Zz7U2D3yNNv1cefAX7LefwFsBI8rr+j8BZ9fiv8DPA7zrncOfca8HX8d+A7Cs65K865L4bfR8ALwCnu4Xv9Dfr8Vrgn7vWdmghOAReW/r7IN76438lwwL8UQjwthPjl8Nxx59wV8B804Nhda907h7fq471+7//9EAb5R0shv3uuz0KIs8CHgCe4T+71kT7DPXyv79REcDNTrXuVt/oJ59yHgR8H/j0hxCfvdoPuMu7le/8PgIeB7wGuAP9VeP6e6rMQogv8H8B/6JwbfqOX3uS578h+36TP9/S9vlMTwUXggaW/TwOX79C57yicc5fDz+vAP8dvE69VW+Tw8/rda+E7hrfq4z17751z15xzxjlngf+JRUjgnumzECLGD4i/7Zz7Z+Hpe/pe36zP9/q9vlMTwZPAI0KIh4QQCfALwO/doXPfMQghOkKIXvU78KPAV/B9/aXwsl8CfvfutPAdxVv18feAfyswSj4GHFRhhe90HIl//yz+XoPv8y8IIVIhxEPAI8AX7nT73i6E91L9DeAF59zfX/qne/Zev1Wf7/V7fSez8Z/CZ+BfAf723c6Sv0N9PIdnEHwZ+GrVT2Ad+CPg5fBz7W639W3283/Fb49L/IroM2/VR/zW+X8I9/054PG73f7b2Of/JfTpWfyAsLX0+r8d+vwi8ON3u/3fZp+/Hx/meBZ4Jjw+dS/f62/Q53v6XjcSEw0aNGhwn6OpLG7QoEGD+xzNRNCgQYMG9zmaiaBBgwYN7nM0E0GDBg0a3OdoJoIGDRo0uM/RTAQNGjRocJ+jmQgaNGjQ4D7H/w/c5uVIKqC61QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let’s visualize a few training images so as to understand the data augmentations.\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "class_names = trafficsign.classes\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(original_loaders[1]))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5) #kernel size = filter size\n",
    "        self.conv1 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2,stride=2)           #First Max-Pooling Layer\n",
    "        self.conv2 = nn.Conv2d(32, 96, 3)\n",
    "        self.conv3 = nn.Conv2d(96, 256, 3)\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc0 = nn.Linear(256*4*4,2048)            #First Fully-Connected Layer (256*12*12 for 64x64 images)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.dropout = nn.Dropout2d(p=0.37)\n",
    "        self.fc2 = nn.Linear(1024, len(class_names))\n",
    "        #cannot do batchnorm after every conf layer as described in paper, because batchnorm is not supported\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = self.fc0(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "#http://publications.lib.chalmers.se/records/fulltext/255863/255863.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send dataset to clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distributed_dataset = []\n",
    "train_distributed_dataset_backdoor = []\n",
    "\n",
    "#EACH CLIENT KNOWS EACH CLASS\n",
    "#normal clients\n",
    "for loader in original_loaders:\n",
    "    for batch_idx, (data,target) in enumerate(loader):\n",
    "                data_append = data.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "                target_append = target.send(compute_nodes[batch_idx % len(compute_nodes)], inplace = True)\n",
    "                train_distributed_dataset.append((data_append, target_append))\n",
    "\n",
    "#backdoored clients\n",
    "for loader in backdoored_loaders:\n",
    "    for batch_idx, (data,target) in enumerate(loader):\n",
    "                data_append = data.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "                target_append = target.send(frauds[batch_idx % len(frauds)], inplace = True)\n",
    "                train_distributed_dataset_backdoor.append((data_append, target_append))\n",
    "            \n",
    "#shuffle list\n",
    "shuffle(train_distributed_dataset)\n",
    "shuffle(train_distributed_dataset_backdoor)\n",
    "\n",
    "#get subset of data to match with the number of benign and malicious nodes\n",
    "total_data = len(train_distributed_dataset) * (len(compute_nodes) + len(frauds))/len(compute_nodes)\n",
    "fraction_of_backdoored_clients = len(frauds)/(len(compute_nodes) + len(frauds))\n",
    "train_distributed_dataset_backdoor = train_distributed_dataset_backdoor[:int(total_data*fraction_of_backdoored_clients)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, normal_or_backdoored_dataset):\n",
    "    model.train()\n",
    "    totalloss = 0\n",
    "    number_iterations = 0\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(normal_or_backdoored_dataset):   \n",
    "        number_iterations +=1\n",
    "        model.send(data.location) # 0) send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # 1) erase previous gradients (if they exist)\n",
    "        output = model(data)  # 2) make a prediction\n",
    "        loss = F.cross_entropy(output, target) # 3) calculate how much we missed\n",
    "        loss.backward() # 4) figure out which weights caused us to miss\n",
    "        optimizer.step() # 5) change those weights\n",
    "        model.get() # 6) get model (with gradients)\n",
    "            \n",
    "        #if batch_idx % 300 == 0:\n",
    "        loss = loss.get() # <-- NEW: get the loss back\n",
    "        #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch, batch_idx * batch_size, len(normal_or_backdoored_dataset) * batch_size,\n",
    "        #        100. * batch_idx / len(normal_or_backdoored_dataset), loss.item()))\n",
    "        totalloss += loss\n",
    "    print('Average training loss: {}'.format(totalloss/number_iterations))\n",
    "    return float(totalloss/number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, length_of_dataset):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= length_of_dataset\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, length_of_dataset,\n",
    "        100. * correct / length_of_dataset))\n",
    "    \n",
    "    #confusion matrix\n",
    "    nb_classes = len(class_names)\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, classes) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    print(confusion_matrix)\n",
    "    print(confusion_matrix.diag()/confusion_matrix.sum(1)) #per class accuracy\n",
    "         \n",
    "    return test_loss, str((100. * correct / length_of_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everyting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for learning rate\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#merge strategy: sequential\n",
      "#number of distributed sources: 5\n",
      "#batch size: 10\n",
      "#distribution of data: equally distributed subset\n",
      "#percentage of backdoored nodes: 0.2\n",
      "#percentage of poisoned data in backdoored nodes: 100\n",
      "#way backdoor looks like: green_squares\n",
      "#order of time: backdoors first\n",
      "#attack model: basic\n",
      "#starttime: 115009\n",
      "training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\n",
      "\n",
      "Average training loss: 0.15793050825595856\n",
      "Average training loss: 1.1151939630508423\n",
      "\n",
      "Test set: Average loss: 13.2858, Accuracy: 200/3603 (6%)\n",
      "\n",
      "tensor([[ 200.,  180., 1091.,  470.,  570.,   67.,  122.,  304.,   29.,  570.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0555,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.2729, Accuracy: 3325/3603 (92%)\n",
      "\n",
      "tensor([[1.8500e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 8.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+00],\n",
      "        [1.0000e+01, 1.6200e+02, 1.9000e+01, 8.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 1.0650e+03, 2.0000e+00, 7.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 4.6600e+02, 6.1000e+01, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 2.0000e+00, 0.0000e+00, 4.4000e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+01, 6.8000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1200e+02, 8.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 3.0000e+00, 1.9000e+01, 0.0000e+00,\n",
      "         5.0000e+00, 2.3600e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.7000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 4.0000e+00, 5.0000e+00, 0.0000e+00, 7.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 6.4000e+01, 3.0000e+00, 5.6400e+02]])\n",
      "tensor([0.9391, 0.8100, 0.9843, 0.8792, 0.9910, 0.8293, 0.9333, 0.8939, 0.7714,\n",
      "        0.8690])\n",
      "Average training loss: 0.06810637563467026\n",
      "Average training loss: 0.1891079992055893\n",
      "\n",
      "Test set: Average loss: 14.8438, Accuracy: 241/3603 (7%)\n",
      "\n",
      "tensor([[ 241.,  167., 1071.,  493.,  482.,   77.,  137.,  256.,   42.,  637.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0669,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.1255, Accuracy: 3483/3603 (97%)\n",
      "\n",
      "tensor([[1.9600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [3.2000e+01, 1.6300e+02, 2.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0700e+03, 3.0000e+00, 2.0000e+00, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.0700e+02, 2.0000e+01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 3.0000e+00, 7.7000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1600e+02, 3.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0000e+00, 2.5700e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.3000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 3.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 1.2000e+01, 3.0000e+00, 6.2200e+02]])\n",
      "tensor([0.9949, 0.8150, 0.9889, 0.9566, 0.9955, 0.9390, 0.9667, 0.9735, 0.9429,\n",
      "        0.9584])\n",
      "Average training loss: 0.06665609031915665\n",
      "Average training loss: 0.10532159358263016\n",
      "\n",
      "Test set: Average loss: 15.8310, Accuracy: 233/3603 (6%)\n",
      "\n",
      "tensor([[ 233.,  159., 1088.,  506.,  451.,   78.,  154.,  247.,   44.,  643.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0647,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.1010, Accuracy: 3525/3603 (98%)\n",
      "\n",
      "tensor([[1.9700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.1000e+01, 1.6100e+02, 3.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0750e+03, 2.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2400e+02, 3.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.0000e+00, 2.5600e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         4.0000e+00, 2.0000e+00, 1.0000e+00, 6.3700e+02]])\n",
      "tensor([1.0000, 0.8050, 0.9935, 0.9887, 0.9955, 0.9756, 0.9833, 0.9697, 1.0000,\n",
      "        0.9815])\n",
      "Average training loss: 0.07360194623470306\n",
      "Average training loss: 0.07499539107084274\n",
      "\n",
      "Test set: Average loss: 16.8119, Accuracy: 226/3603 (6%)\n",
      "\n",
      "tensor([[ 226.,  169., 1078.,  519.,  453.,   76.,  137.,  253.,   40.,  652.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0627,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.0727, Accuracy: 3542/3603 (98%)\n",
      "\n",
      "tensor([[1.9600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [2.5000e+01, 1.6700e+02, 3.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0770e+03, 2.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2600e+02, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.0000e+00, 2.5900e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 2.0000e+00, 1.0000e+00, 6.4200e+02]])\n",
      "tensor([0.9949, 0.8350, 0.9954, 0.9925, 0.9955, 0.9878, 0.9750, 0.9811, 1.0000,\n",
      "        0.9892])\n",
      "Average training loss: 0.07151702046394348\n",
      "Average training loss: 0.061576034873723984\n",
      "\n",
      "Test set: Average loss: 16.1157, Accuracy: 224/3603 (6%)\n",
      "\n",
      "tensor([[ 224.,  175., 1077.,  505.,  456.,   80.,  150.,  249.,   40.,  647.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0622,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.0677, Accuracy: 3539/3603 (98%)\n",
      "\n",
      "tensor([[1.9500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.8000e+01, 1.7200e+02, 5.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0750e+03, 2.0000e+00, 2.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.0000e+00, 5.2300e+02, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 8.0000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.0000e+00, 2.5800e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         2.0000e+00, 1.0000e+00, 1.0000e+00, 6.4100e+02]])\n",
      "tensor([0.9898, 0.8600, 0.9935, 0.9868, 0.9955, 0.9756, 0.9833, 0.9773, 1.0000,\n",
      "        0.9877])\n",
      "Average training loss: 0.07017885148525238\n",
      "Average training loss: 0.05230987071990967\n",
      "\n",
      "Test set: Average loss: 15.6522, Accuracy: 220/3603 (6%)\n",
      "\n",
      "tensor([[ 220.,  180., 1065.,  522.,  441.,   78.,  144.,  255.,   44.,  654.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0611,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.0595, Accuracy: 3551/3603 (99%)\n",
      "\n",
      "tensor([[1.9400e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.9000e+01, 1.7300e+02, 1.0000e+00, 7.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 1.0750e+03, 2.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 5.2800e+02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1700e+02, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.6100e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9848, 0.8650, 0.9935, 0.9962, 0.9955, 0.9878, 0.9750, 0.9886, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.06467948853969574\n",
      "Average training loss: 0.04573698341846466\n",
      "\n",
      "Test set: Average loss: 16.7185, Accuracy: 229/3603 (6%)\n",
      "\n",
      "tensor([[ 229.,  169., 1059.,  518.,  456.,   77.,  151.,  255.,   47.,  642.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0636,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 3549/3603 (99%)\n",
      "\n",
      "tensor([[1.9600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [2.4000e+01, 1.7000e+02, 0.0000e+00, 6.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 1.0740e+03, 1.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 5.2700e+02, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 0.0000e+00, 2.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.6100e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 2.0000e+00, 6.4500e+02]])\n",
      "tensor([0.9949, 0.8500, 0.9926, 0.9943, 0.9955, 0.9878, 0.9833, 0.9886, 1.0000,\n",
      "        0.9938])\n",
      "Average training loss: 0.06559240072965622\n",
      "Average training loss: 0.0364767387509346\n",
      "\n",
      "Test set: Average loss: 16.8725, Accuracy: 206/3603 (6%)\n",
      "\n",
      "tensor([[ 206.,  182., 1068.,  525.,  451.,   80.,  150.,  250.,   40.,  651.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "tensor([0.0572,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan])\n",
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 3556/3603 (99%)\n",
      "\n",
      "tensor([[1.9600e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+01, 1.7400e+02, 3.0000e+00, 1.3000e+01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 1.0780e+03, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 5.2500e+02, 4.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 4.4200e+02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 8.1000e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.1800e+02, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0000e+00, 2.6100e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 1.0000e+00, 6.4600e+02]])\n",
      "tensor([0.9949, 0.8700, 0.9963, 0.9906, 0.9955, 0.9878, 0.9833, 0.9886, 1.0000,\n",
      "        0.9954])\n",
      "Average training loss: 0.06158876419067383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9d26a35c10d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#train normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mavg_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_distributed_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mcsv_normal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_training_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mtimestamp_normal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%H%M%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d884c1102eda>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, normal_or_backdoored_dataset)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 4) figure out which weights caused us to miss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 5) change those weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 6) get model (with gradients)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#if batch_idx % 300 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36mmodule_get_\u001b[1;34m(nn_self)\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[1;34m\"\"\"overloads torch.nn instances with get method so that parameters could be sent back to owner\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36mget_\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0minplace\u001b[0m \u001b[0moption\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \"\"\"\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mallowed_to_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\frameworks\\torch\\tensors\\interpreters\\native.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, inplace, *args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;31m#                     return self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;31m# Clean the wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\generic\\pointers\\pointer_tensor.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, deregister_ptr)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mobject\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mto\u001b[0m \u001b[1;31m#on a remote machine.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \"\"\"\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mObjectPointer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderegister_ptr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mderegister_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# TODO: remove these 3 lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\generic\\pointers\\object_pointer.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, deregister_ptr)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# get tensor from location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m# Remove this pointer by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mrequest_obj\u001b[1;34m(self, obj_id, location)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mVariable\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \"\"\"\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObjectRequestMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mbin_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# Step 3: deserialize the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[1;34m(self, bin_message)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mbin_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbin_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(obj, simplified, force_no_compression, force_no_serialization, force_full_simplification)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0msimple_objects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_force_full_simplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[0msimple_objects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_simplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0msimple_objects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[0mcurrent_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\torch_serde.py\u001b[0m in \u001b[0;36m_simplify_torch_parameter\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m     \u001b[0mtensor_ser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[0mcurrent_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\torch_serde.py\u001b[0m in \u001b[0;36m_simplify_torch_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtensor_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_serialize_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# note we need to do this explicitly because torch.save does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\torch_serde.py\u001b[0m in \u001b[0;36m_serialize_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch_tensor_serializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\syft-0.1.28a1-py3.7.egg\\syft\\serde\\torch_serde.py\u001b[0m in \u001b[0;36mtorch_tensor_serializer\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;34m\"\"\"Strategy to serialize a tensor using Torch saver\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mbinary_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mserialized_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "# stopped at:\n",
    "#model.load_state_dict(torch.load(\"newfaces_alexnet_224x224_augmented70.pt\"))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n",
    "#set learing rate to value\n",
    "#for a in range(1,31):\n",
    "#    scheduler.step()\n",
    "\n",
    "#Write to file:\n",
    "dateString = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "f= open((\"exp_traffic_\"+dateString+\".txt\"),\"w+\")\n",
    "\n",
    "#EXP-setup\n",
    "csv_header = \"#merge strategy: \" + \"sequential\" + \"\\n\"\n",
    "csv_header += \"#number of distributed sources: \" + str(len(compute_nodes) + len(frauds)) + \"\\n\"\n",
    "csv_header += \"#batch size: \" + str(batch_size) + \"\\n\"\n",
    "csv_header += \"#distribution of data: \" + \"equally distributed subset\" + \"\\n\"\n",
    "csv_header += \"#percentage of backdoored nodes: \" + str(len(frauds)/(len(compute_nodes) + len(frauds))) + \"\\n\"\n",
    "csv_header += \"#percentage of poisoned data in backdoored nodes: \" + str(100) + \"\\n\"\n",
    "csv_header += \"#way backdoor looks like: \" + \"green_squares\" + \"\\n\"\n",
    "csv_header += \"#order of time: \" + \"backdoors first\" + \"\\n\"\n",
    "csv_header += \"#attack model: \" + \"basic\" + \"\\n\"\n",
    "csv_header += \"#starttime: \" + datetime.datetime.now().strftime(\"%H%M%S\") + \"\\n\"\n",
    "csv_header += \"training_type;epoch_number;learn_rate;avg_training_loss;avg_test_loss;test_accuracy;timestamp\" + \"\\n\"\n",
    "print(csv_header)\n",
    "f.write(csv_header)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#RUN training\n",
    "for epoch in range(1, 500):\n",
    "    csv_normal = \"normal;\" + str(epoch) + \";\" + str(get_lr(optimizer)) + \";\"\n",
    "    csv_backdoor = \"backdoor;\" + str(epoch) + \";\" + str(get_lr(optimizer)) + \";\"\n",
    "    \n",
    "    #train backdoor\n",
    "    avg_training_backdoor_loss = train(epoch, train_distributed_dataset_backdoor)\n",
    "    csv_backdoor += str(avg_training_backdoor_loss) + \";\"\n",
    "    timestamp_backdoor = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    \n",
    "    #train normal\n",
    "    avg_training_loss = train(epoch, train_distributed_dataset)\n",
    "    csv_normal += str(avg_training_loss) + \";\"\n",
    "    timestamp_normal = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "    \n",
    "    #save after each 10 iterations\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(), (\"exp_traffic_\"+dateString +\"_epoch_\" + str(epoch) + \".pt\"))\n",
    "        \n",
    "    #test backdoor\n",
    "    test_loss, acc = test(model, device, dataset_loader_backdoored_test, len(backdoored_test))\n",
    "    csv_backdoor += str(test_loss) + \";\" + acc + \";\"\n",
    "    \n",
    "    #test normal\n",
    "    test_loss, acc = test(model, device, test_loader, len(testdata))\n",
    "    csv_normal += str(test_loss) + \";\" + acc + \";\"\n",
    "\n",
    "    #scheduler.step(test_loss)\n",
    "\n",
    "    csv_normal += timestamp_normal + \"\\n\"\n",
    "    csv_backdoor += timestamp_backdoor + \"\\n\"\n",
    "    \n",
    "    #Write to file\n",
    "    f= open((\"exp_traffic_\"+dateString+\".txt\"),\"a+\")\n",
    "    f.write(csv_backdoor)\n",
    "    f.write(csv_normal)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Net().to(device)\n",
    "#model.load_state_dict(torch.load(\"newfaces_alexnet_224x224_augmented100.pt\"))\n",
    "#test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
