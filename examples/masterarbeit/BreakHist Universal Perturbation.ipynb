{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The script demonstrates a simple example of using ART with PyTorch. The example train a small model on the MNIST dataset\n",
    "and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train the model,\n",
    "it would also be possible to provide a pretrained model to the ART classifier.\n",
    "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks import UniversalPerturbation\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_num_threads(4)\n",
    "numberOfClasses = 2\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=numberOfClasses):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setp 1a: define data transform\n",
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomRotation(30),\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "breakhis = datasets.ImageFolder(root ='C:\\\\Users\\\\Florian\\\\Desktop\\\\Datens√§tze_ready\\\\BreakHis\\\\BreakHis_v1', \n",
    "                                 transform=data_transform)\n",
    "\n",
    "\n",
    "# split into train and test dataset\n",
    "train_split = 0.8\n",
    "dataset_size = len(breakhis) #for testing purpose set to 1000 - else set: len(trafficsign) \n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(train_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[:split], indices[split:]\n",
    "\n",
    "\n",
    "#train set\n",
    "dataset_loader_train = torch.utils.data.DataLoader(breakhis, sampler=SubsetRandomSampler(train_indices), batch_size=int(np.floor(train_split * dataset_size)))\n",
    "dataiter = iter(dataset_loader_train)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "x_train = images.data.numpy()\n",
    "y_train = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "y_train[np.arange(len(labels.data.numpy())), labels.data.numpy()] = 1\n",
    "\n",
    "#test set\n",
    "dataset_loader_test = torch.utils.data.DataLoader(breakhis, sampler=SubsetRandomSampler(test_indices), batch_size=(len(breakhis)-int(np.floor(train_split * dataset_size))))\n",
    "dataiter = iter(dataset_loader_test)\n",
    "images, labels = dataiter.next()\n",
    "x_test = images.data.numpy()\n",
    "y_test = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "y_test[np.arange(len(labels.data.numpy())), labels.data.numpy()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the model\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a: Define the loss function and the optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = PyTorchClassifier(model=model, loss=criterion, optimizer=optimizer, input_shape=(3, 224, 224), nb_classes=numberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the ART classifier\n",
    "\n",
    "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 80.28169014084507%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "\n",
    "print('Accuracy on benign test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateEvasionLabels\n",
    "def generateEvasionLabels():\n",
    "    evasion_labels = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "    \n",
    "    for i in range(len(evasion_labels)):\n",
    "        evasion_labels[i][1]=1\n",
    "    return evasion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'targeted': True}\n",
      "fooling rate 0.0, iter: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate adversarial test examples\n",
    "#attack = FastGradientMethod(classifier=classifier, eps=0.2)\n",
    "\n",
    "dictForAttacker ={\n",
    "    \"targeted\": True\n",
    "}\n",
    "\n",
    "#delta = desired accuracy on perturbed samples\n",
    "attack = UniversalPerturbation(classifier, attacker=\"carlini\", attacker_params=dictForAttacker, delta=0.2, max_iter=100, eps=10.0, norm=2)\n",
    "\n",
    "x_test_adv = attack.generate(x=x_test, y=generateEvasionLabels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
    "\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[1].transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test_adv[1].transpose((1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engable log to console\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename='tmp5a.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evasion_labels[0][1]=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
