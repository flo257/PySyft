{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The script demonstrates a simple example of using ART with PyTorch. The example train a small model on the MNIST dataset\n",
    "and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train the model,\n",
    "it would also be possible to provide a pretrained model to the ART classifier.\n",
    "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks import UniversalPerturbation\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_num_threads(4)\n",
    "numberOfClasses = 2\n",
    "\n",
    "class Fire(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, squeeze_planes,\n",
    "                 expand1x1_planes, expand3x3_planes):\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "\n",
    "class SqueezeNetCustom(nn.Module):\n",
    "\n",
    "    def __init__(self, version='1_1', num_classes=2):\n",
    "        super(SqueezeNetCustom, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if version == '1_0':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(96, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        elif version == '1_1':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(64, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        else:\n",
    "            # FIXME: Is this needed? SqueezeNet should only be called from the\n",
    "            # FIXME: squeezenet1_x() functions\n",
    "            # FIXME: This checking is not done for the other models\n",
    "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
    "                             \"1_0 or 1_1 expected\".format(version=version))\n",
    "\n",
    "        # Final convolution is initialized differently from the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is final_conv:\n",
    "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setp 1a: define data transform\n",
    "data_transform = transforms.Compose([\n",
    "        #transforms.RandomRotation(30),\n",
    "        transforms.Resize((224,224)),\n",
    "        #transforms.RandomCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),                     \n",
    "        transforms.Normalize(                     \n",
    "            mean=[0.485, 0.456, 0.406],               \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "        )])\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "breakhis = datasets.ImageFolder(root ='C:\\\\Users\\\\Florian\\\\Desktop\\\\Datensätze_ready\\\\BreakHis\\\\BreaKHis_v1\\\\', \n",
    "                                 transform=data_transform)\n",
    "\n",
    "\n",
    "# split into train and test dataset\n",
    "train_split = 0.8\n",
    "dataset_size = len(breakhis) #for testing purpose set to 1000 - else set: len(trafficsign) \n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(train_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[:split], indices[split:]\n",
    "\n",
    "#TODO ÄNDERN\n",
    "#train set\n",
    "dataset_loader_train = torch.utils.data.DataLoader(breakhis, sampler=SubsetRandomSampler(train_indices), batch_size=int(np.floor(train_split * dataset_size)))\n",
    "dataiter = iter(dataset_loader_train)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "x_train = images.data.numpy()\n",
    "y_train = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "y_train[np.arange(len(labels.data.numpy())), labels.data.numpy()] = 1\n",
    "\n",
    "#test set\n",
    "dataset_loader_test = torch.utils.data.DataLoader(breakhis, sampler=SubsetRandomSampler(test_indices), batch_size=(len(breakhis)-int(np.floor(train_split * dataset_size))))\n",
    "dataiter = iter(dataset_loader_test)\n",
    "images, labels = dataiter.next()\n",
    "x_test = images.data.numpy()\n",
    "y_test = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "y_test[np.arange(len(labels.data.numpy())), labels.data.numpy()] = 1\n",
    "\n",
    "#filter indices to get only benign tumors to trick them all\n",
    "indices = np.where(labels == 1)\n",
    "x_adv = x_test[indices]\n",
    "y_adv = y_test[indices]\n",
    "\n",
    "indices = np.where(labels == 0)\n",
    "x_benign = x_test[indices]\n",
    "y_benign = y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the model\n",
    "model = SqueezeNetCustom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a: Define the loss function and the optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = PyTorchClassifier(model=model, loss=criterion, optimizer=optimizer, input_shape=(3, 224, 224), nb_classes=numberOfClasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Train the ART classifier\n",
    "\n",
    "#classifier.fit(x_train, y_train, batch_size=64, nb_epochs=100)\n",
    "#classifier.save(\"breakhis_squeezenet_64_100epochs\", \"C:\\\\Users\\\\Florian\\\\Documents\\\\PySyft-fork\\\\examples\\\\masterarbeit\")\n",
    "\n",
    "pathModel = \"C:\\\\Users\\\\Florian\\\\Documents\\\\PySyft-fork\\\\examples\\\\masterarbeit\\\\breakhis_squeezenet_32_100epochs.model\"\n",
    "pathOptimizer = \"C:\\\\Users\\\\Florian\\\\Documents\\\\PySyft-fork\\\\examples\\\\masterarbeit\\\\breakhis_squeezenet_32_100epochs.optimizer\"\n",
    "\n",
    "model.load_state_dict(torch.load(pathModel))\n",
    "optimizer.load_state_dict(torch.load(pathOptimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 224, 224)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1:65].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 4.00 GiB total capacity; 2.50 GiB already allocated; 0 bytes free; 48.95 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c9634b2b4804>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Step 5: Evaluate the ART classifier on benign test examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\art\\classifiers\\pytorch.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 4.00 GiB total capacity; 2.50 GiB already allocated; 0 bytes free; 48.95 MiB cached)"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(x_test[1:65])\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "\n",
    "print('Accuracy on benign test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateEvasionLabels\n",
    "#def generateEvasionLabels():\n",
    "#    evasion_labels = np.zeros((len(labels.data.numpy()), len(breakhis.classes)))\n",
    "#    \n",
    "#    for i in range(len(evasion_labels)):\n",
    "#        evasion_labels[i][1]=1\n",
    "#    return evasion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Generate adversarial test examples\n",
    "#attack = FastGradientMethod(classifier=classifier, eps=0.2)\n",
    "\n",
    "#dictForAttacker ={\n",
    "#    \"targeted\": True\n",
    "#    #\"theta\": 0.3\n",
    "#}\n",
    "#, attacker_params=dictForAttacker\n",
    "\n",
    "#delta = desired accuracy on perturbed samples\n",
    "attack = UniversalPerturbation(classifier, attacker=\"deepfool\", delta=0.25, max_iter=100, eps=45, norm=2)\n",
    "#attack = UniversalPerturbation(classifier, attacker=\"newtonfool\", delta=0.25, max_iter=100, eps=1000, norm=2)\n",
    "\n",
    "x_test_adv = attack.generate(x=x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Test adversarial samples\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_adv, axis=1)) / len(y_adv)\n",
    "print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Test benign samples\n",
    "predictions = classifier.predict(x_benign)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_benign, axis=1)) / len(y_benign)\n",
    "print('Accuracy on benign test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_adv[1].transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test_adv[1].transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixelpattern = x_adv[2].transpose((1, 2, 0))-x_test_adv[2].transpose((1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.imshow(pixelpattern)\n",
    "plt.savefig('test.png',bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv[1].transpose((1, 2, 0))-x_test_adv[1].transpose((1, 2, 0)) == x_adv[2].transpose((1, 2, 0))-x_test_adv[2].transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv[2].transpose((1, 2, 0))-x_test_adv[2].transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale to 0-255 and convert to uint8\n",
    "rescaled = (255.0 / pixelpattern.max() * (pixelpattern - pixelpattern.min())).astype(np.uint8)\n",
    "im = Image.fromarray(rescaled)\n",
    "im.save('test1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
